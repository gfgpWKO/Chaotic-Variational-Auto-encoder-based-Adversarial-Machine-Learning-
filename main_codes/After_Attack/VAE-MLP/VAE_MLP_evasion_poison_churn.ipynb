{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2jDnKenRZ97Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coea/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kfy-M5brZ97S"
   },
   "outputs": [],
   "source": [
    "# # data = pd.read_csv(\"D:/Udler downloads/train.csv\")\n",
    "data = pd.read_csv(\"../../../datasets/Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7nnkha-OZ97T",
    "outputId": "850b9ddb-5edb-49c2-88dd-e373380ff525"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB5KTaxPZ97T",
    "outputId": "4a0c859b-3d11-447d-c847-2880f1062e39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          10000\n",
       "CustomerId         10000\n",
       "Surname             2932\n",
       "CreditScore          460\n",
       "Geography              3\n",
       "Gender                 2\n",
       "Age                   70\n",
       "Tenure                11\n",
       "Balance             6382\n",
       "NumOfProducts          4\n",
       "HasCrCard              2\n",
       "IsActiveMember         2\n",
       "EstimatedSalary     9999\n",
       "Exited                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfI0iU4IZ97T",
    "outputId": "4ad4472c-c075-4672-acda-7049475d2c57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dApTDn4HZ97U"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../../datasets/Churn_Modelling.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FzHCy5z-Z97U"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7-xjb_JrZ97U"
   },
   "outputs": [],
   "source": [
    "def load_and_standardize_data(path):\n",
    "    # read in from csv\n",
    "    df = pd.read_csv(path, sep=',')\n",
    "    # replace nan with -99\n",
    "    # df = df.fillna(-99)\n",
    "    y = df['Exited']\n",
    "    df.drop(['RowNumber', 'CustomerId', 'Surname','Geography',\n",
    "       'Gender','Exited'],axis=1,inplace=True)\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(df,y,stratify = y,test_size = 0.3,random_state = 4)\n",
    "    # df = df.values.reshape(-1, df.shape[1]).astype('float32')\n",
    "    # randomly split\n",
    "\n",
    "    # standardize values\n",
    "#     scaler = preprocessing.StandardScaler()\n",
    "    scaler=preprocessing.MinMaxScaler()\n",
    "    xtrain = scaler.fit_transform(xtrain)\n",
    "    xtest= scaler.transform(xtest)\n",
    "    return xtrain,xtest,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WYLJY0GHZ97V"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class DataBuilder(Dataset):\n",
    "    def __init__(self, path, train=True):\n",
    "        self.X_train, self.X_test, self.standardizer = load_and_standardize_data(DATA_PATH)\n",
    "        if train:\n",
    "            # self.x = torch.from_numpy(self.X_train)\n",
    "            self.x = torch.FloatTensor(self.X_train)\n",
    "            self.len=self.x.shape[0]\n",
    "        else:\n",
    "            # self.x = torch.from_numpy(self.X_test)\n",
    "            self.x = torch.FloatTensor(self.X_test)\n",
    "            self.len=self.x.shape[0]\n",
    "        del self.X_train\n",
    "        del self.X_test\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XBmJCKNTZ97V"
   },
   "outputs": [],
   "source": [
    "traindata_set=DataBuilder(DATA_PATH, train=True)\n",
    "testdata_set=DataBuilder(DATA_PATH, train=False)\n",
    "\n",
    "trainloader=DataLoader(dataset=traindata_set,batch_size=20000)\n",
    "testloader=DataLoader(dataset=testdata_set,batch_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5N7SNklZ97W",
    "outputId": "c3bb24d7-427e-440f-f5bd-02a9f191c99b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainloader.dataset.x), type(testloader.dataset.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWS4-fodZ97W",
    "outputId": "00af49bc-5cc2-4deb-8423-661e91be3029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7000, 8]), torch.Size([3000, 8]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset.x.shape, testloader.dataset.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seJZe9tOZ97W",
    "outputId": "4dc10e95-e381-43eb-8b8b-3528bcbffefe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8700, 0.2162, 0.9000,  ..., 1.0000, 1.0000, 0.3430],\n",
       "        [0.8600, 0.2568, 1.0000,  ..., 1.0000, 0.0000, 0.6317],\n",
       "        [0.6340, 0.2432, 0.3000,  ..., 1.0000, 1.0000, 0.9344],\n",
       "        ...,\n",
       "        [0.3860, 0.2568, 0.3000,  ..., 1.0000, 1.0000, 0.3946],\n",
       "        [0.4180, 0.3243, 0.7000,  ..., 1.0000, 1.0000, 0.9504],\n",
       "        [0.7880, 0.3378, 1.0000,  ..., 0.0000, 1.0000, 0.1211]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RFxhTMpZ97X",
    "outputId": "100d4db8-2a7a-42c8-f33d-04f8c5a2c019"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7860, 0.2973, 0.8000,  ..., 1.0000, 0.0000, 0.4745],\n",
       "        [0.2760, 0.0541, 0.6000,  ..., 1.0000, 1.0000, 0.3320],\n",
       "        [0.5320, 0.3378, 0.3000,  ..., 1.0000, 0.0000, 0.0938],\n",
       "        ...,\n",
       "        [0.5060, 0.1757, 0.8000,  ..., 1.0000, 1.0000, 0.8498],\n",
       "        [0.5540, 0.3514, 0.6000,  ..., 0.0000, 0.0000, 0.1765],\n",
       "        [0.5280, 0.2432, 0.1000,  ..., 1.0000, 0.0000, 0.7308]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader.dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aUqz2jxkZ97X"
   },
   "outputs": [],
   "source": [
    "latent_dims = 2\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WNN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773502691896258"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.sqrt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ggw(x):\n",
    "    return torch.sin(3.0 * x)+ torch.sin(0.3 * x)+  torch.sin(0.03 * x)\n",
    "\n",
    "def morlet_wavelet(x):\n",
    "#     print(x)\n",
    "    return (torch.cos(1.75 * x)) * torch.exp(-x**2/2)\n",
    "\n",
    "def gaussian_wavelet(x,sigma = 1, omega = 0.5 ):\n",
    "    return torch.exp(-0.5 * (x ** 2) / (sigma** 2)) * torch.cos(omega * x)\n",
    "\n",
    "def mexhican_hat_wavelet(x, sigma=2, omega=0.577):\n",
    "    return (torch.pi** (-0.25)*sigma*omega)*(1-x**2)*(torch.exp(-0.5 * (-x**2))) \n",
    "\n",
    "def shannon(x):\n",
    "    return torch.sin(torch.pi *(x-0.5)) - torch.sin(2*(x-0.5) * torch.pi) *(1/torch.pi*(x-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_A27zqDmZ97X"
   },
   "outputs": [],
   "source": [
    "#shannon(torch.tensor(3.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9ny7fCiZ97X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkQMmufvZ97Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pjUbEAZcZ97Y"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GiYWgxG8Z97Y"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LYREXtaZ97Y",
    "outputId": "a746cb87-adf9-4b94-98e3-d4c6004a6ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_Encoder tensor([[ 1.3372e+00, -1.4239e+00,  1.8790e+00,  ..., -3.7782e-01,\n",
      "         -1.8287e-01, -5.6388e-01],\n",
      "        [-2.0979e-01,  9.1405e-01,  2.3676e-01,  ...,  5.2883e-01,\n",
      "          1.0056e+00,  3.2725e-01],\n",
      "        [-1.5212e-01,  1.9923e+00, -1.9311e+00,  ...,  9.0922e-01,\n",
      "          1.7450e-01, -6.6999e-01],\n",
      "        ...,\n",
      "        [ 1.2353e+00, -4.2787e-01,  2.8472e-01,  ...,  6.8493e-01,\n",
      "         -3.8260e+00,  7.9895e-01],\n",
      "        [-4.0318e-01,  1.1398e-01, -2.0358e+00,  ...,  6.7130e-01,\n",
      "          5.2907e-01, -3.7280e-01],\n",
      "        [ 9.4088e-01,  1.7632e-03,  2.4348e-01,  ...,  2.0190e+00,\n",
      "          5.5376e-01, -1.5671e-03]])\n",
      "weights_Encoder_shape torch.Size([23, 50])\n"
     ]
    }
   ],
   "source": [
    "rx=torch.randn(23,50)\n",
    "weights = torch.Tensor(rx)\n",
    "print(\"weights_Encoder\",weights)\n",
    "print(\"weights_Encoder_shape\",weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSZmxJUsZ97Y",
    "outputId": "83369078-6fda-4f60-a450-53a5c5d0fed2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 23])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okOSFjAdZ97Z",
    "outputId": "a25f4fa0-1523-4095-86e2-5f49d2a31058"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1580,  0.7402,  0.4280, -0.7012, -0.6430,  0.2528,  0.6952,  1.1108,\n",
       "         -1.3987, -0.6881, -0.2364,  0.3753, -0.1826,  1.4371, -1.8403,  0.3403,\n",
       "         -2.1903, -1.1082,  1.1232,  0.4737,  1.4747, -0.3415, -1.4462,  1.0004,\n",
       "         -0.0087, -1.1245, -0.0549,  0.3759, -0.4917,  0.3742,  1.1552,  1.6551,\n",
       "          0.0372, -1.2024,  0.7052, -1.2852, -0.1183,  0.3929, -2.3329,  2.3912,\n",
       "          0.3313, -0.0394,  0.1156,  2.2958, -0.0735, -3.0611,  0.5383, -0.8258,\n",
       "          0.2341,  0.1108]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    x = torch.randn(50)\n",
    "    torch.Tensor(x).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udic2CrhZ97Z",
    "outputId": "60dd2045-d24f-4f57-a7c9-928d941946a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1580)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE2(nn.Module):\n",
    "    def __init__(self,D_in,latent_dim,fn,H=10,H2=15):\n",
    "\n",
    "        #Encoder\n",
    "        super(VAE2,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2=nn.Linear(H,H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "\n",
    "#         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H2, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "#         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "\n",
    "#         # Decoder\n",
    "        self.linear4=nn.Linear(H2,H)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear5=nn.Linear(H,D_in)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=D_in)\n",
    "        self.prev_seed =random.uniform(0,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        \n",
    "        self.fn=fn\n",
    "\n",
    "    def encode(self, x):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            lin1 = self.Tanh(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.Tanh(self.lin_bn2(self.linear2(lin1)))\n",
    "            \n",
    "        if self.fn=='relu':\n",
    "            lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "            \n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin2)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "\n",
    "        return r1, r2\n",
    "\n",
    "    def decode(self, z):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            fc3 = self.Tanh(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.Tanh(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin4 =self.Tanh(self.lin_bn4(self.linear4(fc4)))\n",
    "            #lin5 = self.Tanh(self.lin_bn5(self.linear5(lin4)))\n",
    "        if self.fn=='relu':\n",
    "            fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin4 =self.relu(self.lin_bn4(self.linear4(fc4)))\n",
    "            #lin5 = self.Tanh(self.lin_bn5(self.linear5(lin4)))\n",
    "        \n",
    "        return self.lin_bn5(self.linear5(lin4))\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu,sigma = self.encode(x)\n",
    "        prev_seed = self.prev_seed\n",
    "#         print('vae prev_seed',prev_seed)\n",
    "        z = self.reparameterize(mu,sigma)\n",
    "#         print(\"z\",z.shape)\n",
    "#         znew = sampling_vector(z,H)\n",
    "        return self.decode(z),mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE3(nn.Module):\n",
    "    def __init__(self,D_in,latent_dim,fn,H=10,H2=15):\n",
    "\n",
    "        #Encoder\n",
    "        super(VAE3,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2=nn.Linear(H,H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3=nn.Linear(H2,H2)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n",
    "\n",
    "#         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H2, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "#         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "\n",
    "#         # Decoder\n",
    "        self.linear4=nn.Linear(H2,H2)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear5=nn.Linear(H2,H)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear6=nn.Linear(H,D_in)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
    "        self.prev_seed =random.uniform(0,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        \n",
    "        self.fn=fn\n",
    "\n",
    "    def encode(self, x):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            lin1 = self.Tanh(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.Tanh(self.lin_bn2(self.linear2(lin1)))\n",
    "            lin3 = self.Tanh(self.lin_bn3(self.linear3(lin2)))\n",
    "        if self.fn=='relu':\n",
    "            lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "            lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin3)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "\n",
    "        return r1, r2\n",
    "\n",
    "    def decode(self, z):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            fc3 = self.Tanh(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.Tanh(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin4 =self.Tanh(self.lin_bn4(self.linear4(fc4)))\n",
    "            lin5 = self.Tanh(self.lin_bn5(self.linear5(lin4)))\n",
    "        if self.fn=='relu':\n",
    "            fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin4 =self.relu(self.lin_bn4(self.linear4(fc4)))\n",
    "            lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))\n",
    "        \n",
    "        return self.lin_bn6(self.linear6(lin5))\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu,sigma = self.encode(x)\n",
    "        prev_seed = self.prev_seed\n",
    "#         print('vae prev_seed',prev_seed)\n",
    "        z = self.reparameterize(mu,sigma)\n",
    "#         print(\"z\",z.shape)\n",
    "#         znew = sampling_vector(z,H)\n",
    "        return self.decode(z),mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE4(nn.Module):\n",
    "    def __init__(self,D_in,latent_dim,fn,H=10,H2=15,H3=20):\n",
    "\n",
    "        #Encoder\n",
    "        super(VAE4,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2=nn.Linear(H,H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3=nn.Linear(H2,H3)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H3)\n",
    "        self.linear4=nn.Linear(H3,H3)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H3)\n",
    "        \n",
    "\n",
    "#         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H3, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "#         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H3)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H3)\n",
    "\n",
    "#         # Decoder\n",
    "        self.linear5=nn.Linear(H3,H3)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H3)\n",
    "        self.linear6=nn.Linear(H3,H2)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear7=nn.Linear(H2,H)\n",
    "        self.lin_bn7 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear8=nn.Linear(H,D_in)\n",
    "        self.lin_bn8 = nn.BatchNorm1d(num_features=D_in)\n",
    "        self.prev_seed =random.uniform(0,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        \n",
    "        self.fn=fn\n",
    "\n",
    "    def encode(self, x):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            lin1 = self.Tanh(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.Tanh(self.lin_bn2(self.linear2(lin1)))\n",
    "            lin3 = self.Tanh(self.lin_bn3(self.linear3(lin2)))\n",
    "            lin4 = self.Tanh(self.lin_bn4(self.linear4(lin3)))\n",
    "        if self.fn=='relu':\n",
    "            lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "            lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "            lin4 = self.relu(self.lin_bn4(self.linear4(lin3)))\n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin4)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "\n",
    "        return r1, r2\n",
    "\n",
    "    def decode(self, z):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            fc3 = self.Tanh(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.Tanh(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin5 =self.Tanh(self.lin_bn5(self.linear5(fc4)))\n",
    "            lin6 = self.Tanh(self.lin_bn6(self.linear6(lin5)))\n",
    "            lin7 = self.Tanh(self.lin_bn7(self.linear7(lin6)))\n",
    "        if self.fn=='relu':\n",
    "            fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin5 =self.relu(self.lin_bn5(self.linear5(fc4)))\n",
    "            lin6 = self.relu(self.lin_bn6(self.linear6(lin5)))\n",
    "            lin7 = self.relu(self.lin_bn7(self.linear7(lin6)))\n",
    "        \n",
    "        return self.lin_bn8(self.linear8(lin7))\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu,sigma = self.encode(x)\n",
    "        prev_seed = self.prev_seed\n",
    "#         print('vae prev_seed',prev_seed)\n",
    "        z = self.reparameterize(mu,sigma)\n",
    "#         print(\"z\",z.shape)\n",
    "#         znew = sampling_vector(z,H)\n",
    "        return self.decode(z),mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "vyL5PM2VZ97b"
   },
   "outputs": [],
   "source": [
    "class sampling_vector(nn.Module):\n",
    "    def __init__(self, z,H2):\n",
    "        super().__init__()\n",
    "        self.z = z\n",
    "        self.fc3 = nn.Linear(self.z,H2)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(H2)\n",
    "#         self.fc4 = nn.Linear(latent_dims, H2)\n",
    "#         self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,z):\n",
    "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "        return fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "9CugFxDXZ97c"
   },
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, x_recon, x, mu, logvar):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return loss_MSE + loss_KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print('====> Epoch: {} Average training loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))\n",
    "        \n",
    "def test(epoch):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch_idx, data in enumerate(testloader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch = model(data)\n",
    "            loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "            if epoch % 100 == 0:\n",
    "                print('====> Epoch: {} Average test loss: {:.4f}'.format(\n",
    "                    epoch, test_loss / len(testloader.dataset)))\n",
    "            test_losses.append(test_loss / len(testloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "Gdse-DhdZ97c"
   },
   "outputs": [],
   "source": [
    "loss_mse = customLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = trainloader.dataset.x.shape[1]\n",
    "\n",
    "model = VAE2(D_in,2,'relu').to(device)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 100 Average training loss: 6.5007\n",
      "====> Epoch: 200 Average training loss: 5.3169\n",
      "====> Epoch: 300 Average training loss: 4.5437\n",
      "total_time taken is : 25.808106184005737\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "epochs=300\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "#     test(epoch)\n",
    "elapsed_time = time.time()-start\n",
    "print(\"total_time taken is :\",elapsed_time)\n",
    "#     test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.543669921875\n"
     ]
    }
   ],
   "source": [
    "print(train_losses[len(train_losses)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "global model\n",
    "global optimizer\n",
    "\n",
    "model = VAE2(D_in,2,'relu').to(device)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 100 Average training loss: 6.5124\n",
      "====> Epoch: 200 Average training loss: 5.3319\n",
      "====> Epoch: 300 Average training loss: 4.5747\n",
      "====> Epoch: 400 Average training loss: 4.0211\n",
      "====> Epoch: 500 Average training loss: 3.6102\n",
      "====> Epoch: 600 Average training loss: 3.2601\n",
      "====> Epoch: 700 Average training loss: 2.9828\n",
      "====> Epoch: 800 Average training loss: 2.7482\n",
      "====> Epoch: 900 Average training loss: 2.5478\n",
      "====> Epoch: 1000 Average training loss: 2.3659\n",
      "====> Epoch: 1100 Average training loss: 2.2119\n",
      "====> Epoch: 1200 Average training loss: 2.0804\n",
      "====> Epoch: 1300 Average training loss: 1.9603\n",
      "====> Epoch: 1400 Average training loss: 1.8624\n",
      "====> Epoch: 1500 Average training loss: 1.7757\n",
      "====> Epoch: 1600 Average training loss: 1.6861\n",
      "====> Epoch: 1700 Average training loss: 1.5988\n",
      "====> Epoch: 1800 Average training loss: 1.5313\n",
      "====> Epoch: 100 Average training loss: 6.5057\n",
      "====> Epoch: 200 Average training loss: 5.3293\n",
      "====> Epoch: 300 Average training loss: 4.5603\n",
      "====> Epoch: 400 Average training loss: 4.0257\n",
      "====> Epoch: 500 Average training loss: 3.5948\n",
      "====> Epoch: 600 Average training loss: 3.2613\n",
      "====> Epoch: 700 Average training loss: 2.9919\n",
      "====> Epoch: 800 Average training loss: 2.7189\n",
      "====> Epoch: 900 Average training loss: 2.4935\n",
      "====> Epoch: 1000 Average training loss: 2.1173\n",
      "====> Epoch: 1100 Average training loss: 2.0603\n",
      "====> Epoch: 1200 Average training loss: 1.9906\n",
      "====> Epoch: 1300 Average training loss: 1.8293\n",
      "====> Epoch: 1400 Average training loss: 1.7281\n",
      "====> Epoch: 1500 Average training loss: 1.6314\n",
      "====> Epoch: 1600 Average training loss: 1.5710\n",
      "====> Epoch: 1700 Average training loss: 1.4587\n",
      "====> Epoch: 1800 Average training loss: 1.4080\n",
      "====> Epoch: 100 Average training loss: 6.5079\n",
      "====> Epoch: 200 Average training loss: 5.3297\n",
      "====> Epoch: 300 Average training loss: 4.5755\n",
      "====> Epoch: 400 Average training loss: 4.0357\n",
      "====> Epoch: 500 Average training loss: 3.6147\n",
      "====> Epoch: 600 Average training loss: 3.2626\n",
      "====> Epoch: 700 Average training loss: 3.0009\n",
      "====> Epoch: 800 Average training loss: 2.7639\n",
      "====> Epoch: 900 Average training loss: 2.5484\n",
      "====> Epoch: 1000 Average training loss: 2.3812\n",
      "====> Epoch: 1100 Average training loss: 2.2184\n",
      "====> Epoch: 1200 Average training loss: 2.0697\n",
      "====> Epoch: 1300 Average training loss: 1.9632\n",
      "====> Epoch: 1400 Average training loss: 1.8498\n",
      "====> Epoch: 1500 Average training loss: 1.7627\n",
      "====> Epoch: 1600 Average training loss: 1.6795\n",
      "====> Epoch: 1700 Average training loss: 1.6009\n",
      "====> Epoch: 1800 Average training loss: 1.5286\n",
      "====> Epoch: 100 Average training loss: 6.5079\n",
      "====> Epoch: 200 Average training loss: 5.3267\n",
      "====> Epoch: 300 Average training loss: 4.5505\n",
      "====> Epoch: 400 Average training loss: 4.0260\n",
      "====> Epoch: 500 Average training loss: 3.5991\n",
      "====> Epoch: 600 Average training loss: 3.2504\n",
      "====> Epoch: 700 Average training loss: 2.9800\n",
      "====> Epoch: 800 Average training loss: 2.7458\n",
      "====> Epoch: 900 Average training loss: 2.5247\n",
      "====> Epoch: 1000 Average training loss: 2.3642\n",
      "====> Epoch: 1100 Average training loss: 2.2087\n",
      "====> Epoch: 1200 Average training loss: 2.0786\n",
      "====> Epoch: 1300 Average training loss: 1.9819\n",
      "====> Epoch: 1400 Average training loss: 1.8564\n",
      "====> Epoch: 1500 Average training loss: 1.7657\n",
      "====> Epoch: 1600 Average training loss: 1.6799\n",
      "====> Epoch: 1700 Average training loss: 1.6026\n",
      "====> Epoch: 1800 Average training loss: 1.5344\n",
      "====> Epoch: 100 Average training loss: 6.5698\n",
      "====> Epoch: 200 Average training loss: 5.3587\n",
      "====> Epoch: 300 Average training loss: 4.5853\n",
      "====> Epoch: 400 Average training loss: 4.0161\n",
      "====> Epoch: 500 Average training loss: 3.6010\n",
      "====> Epoch: 600 Average training loss: 3.2615\n",
      "====> Epoch: 700 Average training loss: 2.9801\n",
      "====> Epoch: 800 Average training loss: 2.7450\n",
      "====> Epoch: 900 Average training loss: 2.5382\n",
      "====> Epoch: 1000 Average training loss: 2.3607\n",
      "====> Epoch: 1100 Average training loss: 2.2057\n",
      "====> Epoch: 1200 Average training loss: 2.0742\n",
      "====> Epoch: 1300 Average training loss: 1.9568\n",
      "====> Epoch: 1400 Average training loss: 1.8532\n",
      "====> Epoch: 1500 Average training loss: 1.7570\n",
      "====> Epoch: 1600 Average training loss: 1.6737\n",
      "====> Epoch: 1700 Average training loss: 1.5838\n",
      "====> Epoch: 1800 Average training loss: 1.5250\n",
      "====> Epoch: 100 Average training loss: 6.5715\n",
      "====> Epoch: 200 Average training loss: 5.3845\n",
      "====> Epoch: 300 Average training loss: 4.6459\n",
      "====> Epoch: 400 Average training loss: 4.0839\n",
      "====> Epoch: 500 Average training loss: 3.6532\n",
      "====> Epoch: 600 Average training loss: 3.3116\n",
      "====> Epoch: 700 Average training loss: 3.0389\n",
      "====> Epoch: 800 Average training loss: 2.7925\n",
      "====> Epoch: 900 Average training loss: 2.5686\n",
      "====> Epoch: 1000 Average training loss: 2.4059\n",
      "====> Epoch: 1100 Average training loss: 2.2432\n",
      "====> Epoch: 1200 Average training loss: 2.1250\n",
      "====> Epoch: 1300 Average training loss: 1.9676\n",
      "====> Epoch: 1400 Average training loss: 1.8800\n",
      "====> Epoch: 1500 Average training loss: 1.7713\n",
      "====> Epoch: 1600 Average training loss: 1.6945\n",
      "====> Epoch: 1700 Average training loss: 1.5963\n",
      "====> Epoch: 1800 Average training loss: 1.5056\n",
      "====> Epoch: 100 Average training loss: 6.5871\n",
      "====> Epoch: 200 Average training loss: 5.3896\n",
      "====> Epoch: 300 Average training loss: 4.6288\n",
      "====> Epoch: 400 Average training loss: 4.0611\n",
      "====> Epoch: 500 Average training loss: 3.6340\n",
      "====> Epoch: 600 Average training loss: 3.2872\n",
      "====> Epoch: 700 Average training loss: 3.0059\n",
      "====> Epoch: 800 Average training loss: 2.7626\n",
      "====> Epoch: 900 Average training loss: 2.5505\n",
      "====> Epoch: 1000 Average training loss: 2.3762\n",
      "====> Epoch: 1100 Average training loss: 2.2253\n",
      "====> Epoch: 1200 Average training loss: 2.0778\n",
      "====> Epoch: 1300 Average training loss: 1.9719\n",
      "====> Epoch: 1400 Average training loss: 1.8523\n",
      "====> Epoch: 1500 Average training loss: 1.7656\n",
      "====> Epoch: 1600 Average training loss: 1.6897\n",
      "====> Epoch: 1700 Average training loss: 1.6050\n",
      "====> Epoch: 1800 Average training loss: 1.5343\n",
      "====> Epoch: 100 Average training loss: 6.4782\n",
      "====> Epoch: 200 Average training loss: 5.2958\n",
      "====> Epoch: 300 Average training loss: 4.5630\n",
      "====> Epoch: 400 Average training loss: 4.0169\n",
      "====> Epoch: 500 Average training loss: 3.5944\n",
      "====> Epoch: 600 Average training loss: 3.2716\n",
      "====> Epoch: 700 Average training loss: 2.9886\n",
      "====> Epoch: 800 Average training loss: 2.7457\n",
      "====> Epoch: 900 Average training loss: 2.5536\n",
      "====> Epoch: 1000 Average training loss: 2.3702\n",
      "====> Epoch: 1100 Average training loss: 2.2238\n",
      "====> Epoch: 1200 Average training loss: 2.0935\n",
      "====> Epoch: 1300 Average training loss: 1.9869\n",
      "====> Epoch: 1400 Average training loss: 1.8691\n",
      "====> Epoch: 1500 Average training loss: 1.7560\n",
      "====> Epoch: 1600 Average training loss: 1.6934\n",
      "====> Epoch: 1700 Average training loss: 1.5899\n",
      "====> Epoch: 1800 Average training loss: 1.4685\n",
      "====> Epoch: 100 Average training loss: 6.4610\n",
      "====> Epoch: 200 Average training loss: 5.2898\n",
      "====> Epoch: 300 Average training loss: 4.5488\n",
      "====> Epoch: 400 Average training loss: 4.0026\n",
      "====> Epoch: 500 Average training loss: 3.6005\n",
      "====> Epoch: 600 Average training loss: 3.2528\n",
      "====> Epoch: 700 Average training loss: 2.9660\n",
      "====> Epoch: 800 Average training loss: 2.7366\n",
      "====> Epoch: 900 Average training loss: 2.5166\n",
      "====> Epoch: 1000 Average training loss: 2.3568\n",
      "====> Epoch: 1100 Average training loss: 2.2092\n",
      "====> Epoch: 1200 Average training loss: 2.0705\n",
      "====> Epoch: 1300 Average training loss: 1.9500\n",
      "====> Epoch: 1400 Average training loss: 1.8495\n",
      "====> Epoch: 1500 Average training loss: 1.7406\n",
      "====> Epoch: 1600 Average training loss: 1.6729\n",
      "====> Epoch: 1700 Average training loss: 1.5931\n",
      "====> Epoch: 1800 Average training loss: 1.5233\n",
      "====> Epoch: 100 Average training loss: 6.4661\n",
      "====> Epoch: 200 Average training loss: 5.2989\n",
      "====> Epoch: 300 Average training loss: 4.5267\n",
      "====> Epoch: 400 Average training loss: 3.9985\n",
      "====> Epoch: 500 Average training loss: 3.5838\n",
      "====> Epoch: 600 Average training loss: 3.2345\n",
      "====> Epoch: 700 Average training loss: 2.9473\n",
      "====> Epoch: 800 Average training loss: 2.7246\n",
      "====> Epoch: 900 Average training loss: 2.5323\n",
      "====> Epoch: 1000 Average training loss: 2.3540\n",
      "====> Epoch: 1100 Average training loss: 2.2092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1200 Average training loss: 2.0524\n",
      "====> Epoch: 1300 Average training loss: 1.9504\n",
      "====> Epoch: 1400 Average training loss: 1.8642\n",
      "====> Epoch: 1500 Average training loss: 1.7687\n",
      "====> Epoch: 1600 Average training loss: 1.6662\n",
      "====> Epoch: 1700 Average training loss: 1.5971\n",
      "====> Epoch: 1800 Average training loss: 1.5352\n",
      "====> Epoch: 100 Average training loss: 6.7445\n",
      "====> Epoch: 200 Average training loss: 5.4593\n",
      "====> Epoch: 300 Average training loss: 4.6256\n",
      "====> Epoch: 400 Average training loss: 4.0711\n",
      "====> Epoch: 500 Average training loss: 3.6547\n",
      "====> Epoch: 600 Average training loss: 3.2907\n",
      "====> Epoch: 700 Average training loss: 3.0161\n",
      "====> Epoch: 800 Average training loss: 2.7609\n",
      "====> Epoch: 900 Average training loss: 2.5589\n",
      "====> Epoch: 1000 Average training loss: 2.3853\n",
      "====> Epoch: 1100 Average training loss: 2.2376\n",
      "====> Epoch: 1200 Average training loss: 2.0980\n",
      "====> Epoch: 1300 Average training loss: 1.9823\n",
      "====> Epoch: 1400 Average training loss: 1.8718\n",
      "====> Epoch: 1500 Average training loss: 1.7775\n",
      "====> Epoch: 1600 Average training loss: 1.7078\n",
      "====> Epoch: 1700 Average training loss: 1.6103\n",
      "====> Epoch: 1800 Average training loss: 1.5530\n",
      "====> Epoch: 100 Average training loss: 6.5549\n",
      "====> Epoch: 200 Average training loss: 5.3416\n",
      "====> Epoch: 300 Average training loss: 4.5730\n",
      "====> Epoch: 400 Average training loss: 4.0078\n",
      "====> Epoch: 500 Average training loss: 3.6072\n",
      "====> Epoch: 600 Average training loss: 3.2691\n",
      "====> Epoch: 700 Average training loss: 2.9799\n",
      "====> Epoch: 800 Average training loss: 2.7264\n",
      "====> Epoch: 900 Average training loss: 2.5369\n",
      "====> Epoch: 1000 Average training loss: 2.3657\n",
      "====> Epoch: 1100 Average training loss: 2.2200\n",
      "====> Epoch: 1200 Average training loss: 2.1027\n",
      "====> Epoch: 1300 Average training loss: 1.9582\n",
      "====> Epoch: 1400 Average training loss: 1.8671\n",
      "====> Epoch: 1500 Average training loss: 1.7718\n",
      "====> Epoch: 1600 Average training loss: 1.6811\n",
      "====> Epoch: 1700 Average training loss: 1.6077\n",
      "====> Epoch: 1800 Average training loss: 1.5398\n",
      "====> Epoch: 100 Average training loss: 6.4192\n",
      "====> Epoch: 200 Average training loss: 5.2832\n",
      "====> Epoch: 300 Average training loss: 4.5420\n",
      "====> Epoch: 400 Average training loss: 3.9914\n",
      "====> Epoch: 500 Average training loss: 3.5776\n",
      "====> Epoch: 600 Average training loss: 3.2258\n",
      "====> Epoch: 700 Average training loss: 2.9577\n",
      "====> Epoch: 800 Average training loss: 2.7169\n",
      "====> Epoch: 900 Average training loss: 2.5140\n",
      "====> Epoch: 1000 Average training loss: 2.3484\n",
      "====> Epoch: 1100 Average training loss: 2.1785\n",
      "====> Epoch: 1200 Average training loss: 2.0629\n",
      "====> Epoch: 1300 Average training loss: 1.9606\n",
      "====> Epoch: 1400 Average training loss: 1.8568\n",
      "====> Epoch: 1500 Average training loss: 1.7357\n",
      "====> Epoch: 1600 Average training loss: 1.6722\n",
      "====> Epoch: 1700 Average training loss: 1.5970\n",
      "====> Epoch: 1800 Average training loss: 1.5138\n",
      "====> Epoch: 100 Average training loss: 6.6978\n",
      "====> Epoch: 200 Average training loss: 5.4682\n",
      "====> Epoch: 300 Average training loss: 4.7001\n",
      "====> Epoch: 400 Average training loss: 4.1027\n",
      "====> Epoch: 500 Average training loss: 3.6464\n",
      "====> Epoch: 600 Average training loss: 3.3027\n",
      "====> Epoch: 700 Average training loss: 3.0197\n",
      "====> Epoch: 800 Average training loss: 2.7708\n",
      "====> Epoch: 900 Average training loss: 2.5600\n",
      "====> Epoch: 1000 Average training loss: 2.3766\n",
      "====> Epoch: 1100 Average training loss: 2.2244\n",
      "====> Epoch: 1200 Average training loss: 2.0928\n",
      "====> Epoch: 1300 Average training loss: 1.9773\n",
      "====> Epoch: 1400 Average training loss: 1.8753\n",
      "====> Epoch: 1500 Average training loss: 1.7784\n",
      "====> Epoch: 1600 Average training loss: 1.6932\n",
      "====> Epoch: 1700 Average training loss: 1.6095\n",
      "====> Epoch: 1800 Average training loss: 1.5563\n",
      "====> Epoch: 100 Average training loss: 6.6889\n",
      "====> Epoch: 200 Average training loss: 5.4727\n",
      "====> Epoch: 300 Average training loss: 4.7052\n",
      "====> Epoch: 400 Average training loss: 4.1557\n",
      "====> Epoch: 500 Average training loss: 3.6499\n",
      "====> Epoch: 600 Average training loss: 3.3198\n",
      "====> Epoch: 700 Average training loss: 3.0509\n",
      "====> Epoch: 800 Average training loss: 2.7786\n",
      "====> Epoch: 900 Average training loss: 2.5757\n",
      "====> Epoch: 1000 Average training loss: 2.4131\n",
      "====> Epoch: 1100 Average training loss: 2.2294\n",
      "====> Epoch: 1200 Average training loss: 2.1167\n",
      "====> Epoch: 1300 Average training loss: 1.9859\n",
      "====> Epoch: 1400 Average training loss: 1.8766\n",
      "====> Epoch: 1500 Average training loss: 1.7375\n",
      "====> Epoch: 1600 Average training loss: 1.6898\n",
      "====> Epoch: 1700 Average training loss: 1.5405\n",
      "====> Epoch: 1800 Average training loss: 1.4900\n",
      "====> Epoch: 100 Average training loss: 6.7006\n",
      "====> Epoch: 200 Average training loss: 5.4359\n",
      "====> Epoch: 300 Average training loss: 4.6776\n",
      "====> Epoch: 400 Average training loss: 4.0812\n",
      "====> Epoch: 500 Average training loss: 3.6364\n",
      "====> Epoch: 600 Average training loss: 3.3047\n",
      "====> Epoch: 700 Average training loss: 2.9921\n",
      "====> Epoch: 800 Average training loss: 2.7671\n",
      "====> Epoch: 900 Average training loss: 2.5521\n",
      "====> Epoch: 1000 Average training loss: 2.3750\n",
      "====> Epoch: 1100 Average training loss: 2.2321\n",
      "====> Epoch: 1200 Average training loss: 2.0830\n",
      "====> Epoch: 1300 Average training loss: 1.9861\n",
      "====> Epoch: 1400 Average training loss: 1.8436\n",
      "====> Epoch: 1500 Average training loss: 1.7824\n",
      "====> Epoch: 1600 Average training loss: 1.6500\n",
      "====> Epoch: 1700 Average training loss: 1.5818\n",
      "====> Epoch: 1800 Average training loss: 1.5083\n",
      "====> Epoch: 100 Average training loss: 6.6606\n",
      "====> Epoch: 200 Average training loss: 5.3862\n",
      "====> Epoch: 300 Average training loss: 4.6119\n",
      "====> Epoch: 400 Average training loss: 4.0526\n",
      "====> Epoch: 500 Average training loss: 3.6312\n",
      "====> Epoch: 600 Average training loss: 3.2970\n",
      "====> Epoch: 700 Average training loss: 2.9981\n",
      "====> Epoch: 800 Average training loss: 2.7731\n",
      "====> Epoch: 900 Average training loss: 2.5655\n",
      "====> Epoch: 1000 Average training loss: 2.3997\n",
      "====> Epoch: 1100 Average training loss: 2.2350\n",
      "====> Epoch: 1200 Average training loss: 2.0806\n",
      "====> Epoch: 1300 Average training loss: 1.9732\n",
      "====> Epoch: 1400 Average training loss: 1.8815\n",
      "====> Epoch: 1500 Average training loss: 1.7916\n",
      "====> Epoch: 1600 Average training loss: 1.6942\n",
      "====> Epoch: 1700 Average training loss: 1.6304\n",
      "====> Epoch: 1800 Average training loss: 1.5588\n",
      "====> Epoch: 100 Average training loss: 6.7375\n",
      "====> Epoch: 200 Average training loss: 5.4229\n",
      "====> Epoch: 300 Average training loss: 4.6339\n",
      "====> Epoch: 400 Average training loss: 4.0549\n",
      "====> Epoch: 500 Average training loss: 3.6363\n",
      "====> Epoch: 600 Average training loss: 3.2937\n",
      "====> Epoch: 700 Average training loss: 3.0071\n",
      "====> Epoch: 800 Average training loss: 2.7740\n",
      "====> Epoch: 900 Average training loss: 2.5655\n",
      "====> Epoch: 1000 Average training loss: 2.3849\n",
      "====> Epoch: 1100 Average training loss: 2.2281\n",
      "====> Epoch: 1200 Average training loss: 2.0802\n",
      "====> Epoch: 1300 Average training loss: 1.9728\n",
      "====> Epoch: 1400 Average training loss: 1.8692\n",
      "====> Epoch: 1500 Average training loss: 1.7727\n",
      "====> Epoch: 1600 Average training loss: 1.6925\n",
      "====> Epoch: 1700 Average training loss: 1.6236\n",
      "====> Epoch: 1800 Average training loss: 1.5622\n",
      "====> Epoch: 100 Average training loss: 6.4299\n",
      "====> Epoch: 200 Average training loss: 5.2746\n",
      "====> Epoch: 300 Average training loss: 4.5567\n",
      "====> Epoch: 400 Average training loss: 4.0001\n",
      "====> Epoch: 500 Average training loss: 3.5765\n",
      "====> Epoch: 600 Average training loss: 3.2518\n",
      "====> Epoch: 700 Average training loss: 2.9597\n",
      "====> Epoch: 800 Average training loss: 2.7282\n",
      "====> Epoch: 900 Average training loss: 2.5347\n",
      "====> Epoch: 1000 Average training loss: 2.3650\n",
      "====> Epoch: 1100 Average training loss: 2.2161\n",
      "====> Epoch: 1200 Average training loss: 2.0741\n",
      "====> Epoch: 1300 Average training loss: 1.9495\n",
      "====> Epoch: 1400 Average training loss: 1.8610\n",
      "====> Epoch: 1500 Average training loss: 1.7717\n",
      "====> Epoch: 1600 Average training loss: 1.6809\n",
      "====> Epoch: 1700 Average training loss: 1.6055\n",
      "====> Epoch: 1800 Average training loss: 1.5379\n",
      "====> Epoch: 100 Average training loss: 6.5117\n",
      "====> Epoch: 200 Average training loss: 5.3227\n",
      "====> Epoch: 300 Average training loss: 4.5906\n",
      "====> Epoch: 400 Average training loss: 4.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 500 Average training loss: 3.6114\n",
      "====> Epoch: 600 Average training loss: 3.2698\n",
      "====> Epoch: 700 Average training loss: 2.9991\n",
      "====> Epoch: 800 Average training loss: 2.7637\n",
      "====> Epoch: 900 Average training loss: 2.5526\n",
      "====> Epoch: 1000 Average training loss: 2.3764\n",
      "====> Epoch: 1100 Average training loss: 2.2256\n",
      "====> Epoch: 1200 Average training loss: 2.0946\n",
      "====> Epoch: 1300 Average training loss: 1.9808\n",
      "====> Epoch: 1400 Average training loss: 1.8580\n",
      "====> Epoch: 1500 Average training loss: 1.7663\n",
      "====> Epoch: 1600 Average training loss: 1.6796\n",
      "====> Epoch: 1700 Average training loss: 1.6064\n",
      "====> Epoch: 1800 Average training loss: 1.5398\n",
      "====> Epoch: 100 Average training loss: 6.6074\n",
      "====> Epoch: 200 Average training loss: 5.3640\n",
      "====> Epoch: 300 Average training loss: 4.5959\n",
      "====> Epoch: 400 Average training loss: 4.0347\n",
      "====> Epoch: 500 Average training loss: 3.6204\n",
      "====> Epoch: 600 Average training loss: 3.2704\n",
      "====> Epoch: 700 Average training loss: 2.9861\n",
      "====> Epoch: 800 Average training loss: 2.7572\n",
      "====> Epoch: 900 Average training loss: 2.5501\n",
      "====> Epoch: 1000 Average training loss: 2.3828\n",
      "====> Epoch: 1100 Average training loss: 2.2415\n",
      "====> Epoch: 1200 Average training loss: 2.1002\n",
      "====> Epoch: 1300 Average training loss: 1.9860\n",
      "====> Epoch: 1400 Average training loss: 1.9009\n",
      "====> Epoch: 1500 Average training loss: 1.7801\n",
      "====> Epoch: 1600 Average training loss: 1.6948\n",
      "====> Epoch: 1700 Average training loss: 1.6235\n",
      "====> Epoch: 1800 Average training loss: 1.5588\n",
      "====> Epoch: 100 Average training loss: 6.5685\n",
      "====> Epoch: 200 Average training loss: 5.4075\n",
      "====> Epoch: 300 Average training loss: 4.5873\n",
      "====> Epoch: 400 Average training loss: 4.0613\n",
      "====> Epoch: 500 Average training loss: 3.6226\n",
      "====> Epoch: 600 Average training loss: 3.2916\n",
      "====> Epoch: 700 Average training loss: 2.9876\n",
      "====> Epoch: 800 Average training loss: 2.7554\n",
      "====> Epoch: 900 Average training loss: 2.5566\n",
      "====> Epoch: 1000 Average training loss: 2.3837\n",
      "====> Epoch: 1100 Average training loss: 2.2399\n",
      "====> Epoch: 1200 Average training loss: 2.1011\n",
      "====> Epoch: 1300 Average training loss: 1.9953\n",
      "====> Epoch: 1400 Average training loss: 1.8705\n",
      "====> Epoch: 1500 Average training loss: 1.7777\n",
      "====> Epoch: 1600 Average training loss: 1.6934\n",
      "====> Epoch: 1700 Average training loss: 1.6173\n",
      "====> Epoch: 1800 Average training loss: 1.5347\n",
      "====> Epoch: 100 Average training loss: 6.6269\n",
      "====> Epoch: 200 Average training loss: 5.3801\n",
      "====> Epoch: 300 Average training loss: 4.5836\n",
      "====> Epoch: 400 Average training loss: 4.0456\n",
      "====> Epoch: 500 Average training loss: 3.5914\n",
      "====> Epoch: 600 Average training loss: 3.2474\n",
      "====> Epoch: 700 Average training loss: 2.9692\n",
      "====> Epoch: 800 Average training loss: 2.7356\n",
      "====> Epoch: 900 Average training loss: 2.5314\n",
      "====> Epoch: 1000 Average training loss: 2.3573\n",
      "====> Epoch: 1100 Average training loss: 2.2175\n",
      "====> Epoch: 1200 Average training loss: 2.0679\n",
      "====> Epoch: 1300 Average training loss: 1.9620\n",
      "====> Epoch: 1400 Average training loss: 1.8713\n",
      "====> Epoch: 1500 Average training loss: 1.7720\n",
      "====> Epoch: 1600 Average training loss: 1.6835\n",
      "====> Epoch: 1700 Average training loss: 1.6189\n",
      "====> Epoch: 1800 Average training loss: 1.5458\n",
      "====> Epoch: 100 Average training loss: 6.6676\n",
      "====> Epoch: 200 Average training loss: 5.4190\n",
      "====> Epoch: 300 Average training loss: 4.6163\n",
      "====> Epoch: 400 Average training loss: 4.0738\n",
      "====> Epoch: 500 Average training loss: 3.6351\n",
      "====> Epoch: 600 Average training loss: 3.2848\n",
      "====> Epoch: 700 Average training loss: 2.9908\n",
      "====> Epoch: 800 Average training loss: 2.7591\n",
      "====> Epoch: 900 Average training loss: 2.5563\n",
      "====> Epoch: 1000 Average training loss: 2.3800\n",
      "====> Epoch: 1100 Average training loss: 2.2295\n",
      "====> Epoch: 1200 Average training loss: 2.0940\n",
      "====> Epoch: 1300 Average training loss: 1.9756\n",
      "====> Epoch: 1400 Average training loss: 1.8654\n",
      "====> Epoch: 1500 Average training loss: 1.7780\n",
      "====> Epoch: 1600 Average training loss: 1.6907\n",
      "====> Epoch: 1700 Average training loss: 1.6135\n",
      "====> Epoch: 1800 Average training loss: 1.5466\n",
      "====> Epoch: 100 Average training loss: 6.8152\n",
      "====> Epoch: 200 Average training loss: 5.5600\n",
      "====> Epoch: 300 Average training loss: 4.7201\n",
      "====> Epoch: 400 Average training loss: 4.1535\n",
      "====> Epoch: 500 Average training loss: 3.6940\n",
      "====> Epoch: 600 Average training loss: 3.3369\n",
      "====> Epoch: 700 Average training loss: 3.0392\n",
      "====> Epoch: 800 Average training loss: 2.7917\n",
      "====> Epoch: 900 Average training loss: 2.5865\n",
      "====> Epoch: 1000 Average training loss: 2.4139\n",
      "====> Epoch: 1100 Average training loss: 2.2406\n",
      "====> Epoch: 1200 Average training loss: 2.1045\n",
      "====> Epoch: 1300 Average training loss: 1.9912\n",
      "====> Epoch: 1400 Average training loss: 1.8821\n",
      "====> Epoch: 1500 Average training loss: 1.7851\n",
      "====> Epoch: 1600 Average training loss: 1.6952\n",
      "====> Epoch: 1700 Average training loss: 1.6192\n",
      "====> Epoch: 1800 Average training loss: 1.5432\n",
      "====> Epoch: 100 Average training loss: 6.6143\n",
      "====> Epoch: 200 Average training loss: 5.3910\n",
      "====> Epoch: 300 Average training loss: 4.6138\n",
      "====> Epoch: 400 Average training loss: 4.0559\n",
      "====> Epoch: 500 Average training loss: 3.6305\n",
      "====> Epoch: 600 Average training loss: 3.2594\n",
      "====> Epoch: 700 Average training loss: 3.0010\n",
      "====> Epoch: 800 Average training loss: 2.7490\n",
      "====> Epoch: 900 Average training loss: 2.5505\n",
      "====> Epoch: 1000 Average training loss: 2.3722\n",
      "====> Epoch: 1100 Average training loss: 2.2182\n",
      "====> Epoch: 1200 Average training loss: 2.0924\n",
      "====> Epoch: 1300 Average training loss: 1.9682\n",
      "====> Epoch: 1400 Average training loss: 1.8736\n",
      "====> Epoch: 1500 Average training loss: 1.7744\n",
      "====> Epoch: 1600 Average training loss: 1.6774\n",
      "====> Epoch: 1700 Average training loss: 1.6036\n",
      "====> Epoch: 1800 Average training loss: 1.5467\n",
      "====> Epoch: 100 Average training loss: 6.7621\n",
      "====> Epoch: 200 Average training loss: 5.4870\n",
      "====> Epoch: 300 Average training loss: 4.7080\n",
      "====> Epoch: 400 Average training loss: 4.1177\n",
      "====> Epoch: 500 Average training loss: 3.6680\n",
      "====> Epoch: 600 Average training loss: 3.3253\n",
      "====> Epoch: 700 Average training loss: 3.0065\n",
      "====> Epoch: 800 Average training loss: 2.7737\n",
      "====> Epoch: 900 Average training loss: 2.5654\n",
      "====> Epoch: 1000 Average training loss: 2.3992\n",
      "====> Epoch: 1100 Average training loss: 2.2422\n",
      "====> Epoch: 1200 Average training loss: 2.0985\n",
      "====> Epoch: 1300 Average training loss: 1.9933\n",
      "====> Epoch: 1400 Average training loss: 1.8787\n",
      "====> Epoch: 1500 Average training loss: 1.7816\n",
      "====> Epoch: 1600 Average training loss: 1.6998\n",
      "====> Epoch: 1700 Average training loss: 1.6235\n",
      "====> Epoch: 1800 Average training loss: 1.5530\n",
      "====> Epoch: 100 Average training loss: 6.7305\n",
      "====> Epoch: 200 Average training loss: 5.4574\n",
      "====> Epoch: 300 Average training loss: 4.6464\n",
      "====> Epoch: 400 Average training loss: 4.0842\n",
      "====> Epoch: 500 Average training loss: 3.6547\n",
      "====> Epoch: 600 Average training loss: 3.2935\n",
      "====> Epoch: 700 Average training loss: 3.0167\n",
      "====> Epoch: 800 Average training loss: 2.7709\n",
      "====> Epoch: 900 Average training loss: 2.5781\n",
      "====> Epoch: 1000 Average training loss: 2.4061\n",
      "====> Epoch: 1100 Average training loss: 2.2371\n",
      "====> Epoch: 1200 Average training loss: 2.0927\n",
      "====> Epoch: 1300 Average training loss: 1.9749\n",
      "====> Epoch: 1400 Average training loss: 1.8855\n",
      "====> Epoch: 1500 Average training loss: 1.7749\n",
      "====> Epoch: 1600 Average training loss: 1.6869\n",
      "====> Epoch: 1700 Average training loss: 1.6138\n",
      "====> Epoch: 1800 Average training loss: 1.5486\n",
      "====> Epoch: 100 Average training loss: 6.8014\n",
      "====> Epoch: 200 Average training loss: 5.5221\n",
      "====> Epoch: 300 Average training loss: 4.7335\n",
      "====> Epoch: 400 Average training loss: 4.1664\n",
      "====> Epoch: 500 Average training loss: 3.7397\n",
      "====> Epoch: 600 Average training loss: 3.2777\n",
      "====> Epoch: 700 Average training loss: 3.0250\n",
      "====> Epoch: 800 Average training loss: 2.6429\n",
      "====> Epoch: 900 Average training loss: 2.5557\n",
      "====> Epoch: 1000 Average training loss: 2.2356\n",
      "====> Epoch: 1100 Average training loss: 2.1647\n",
      "====> Epoch: 1200 Average training loss: 1.9646\n",
      "====> Epoch: 1300 Average training loss: 1.9048\n",
      "====> Epoch: 1400 Average training loss: 1.7689\n",
      "====> Epoch: 1500 Average training loss: 1.5690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1600 Average training loss: 1.4673\n",
      "====> Epoch: 1700 Average training loss: 1.3806\n",
      "====> Epoch: 1800 Average training loss: 1.2933\n",
      "====> Epoch: 100 Average training loss: 7.0037\n",
      "====> Epoch: 200 Average training loss: 5.6370\n",
      "====> Epoch: 300 Average training loss: 4.8149\n",
      "====> Epoch: 400 Average training loss: 4.2061\n",
      "====> Epoch: 500 Average training loss: 3.7345\n",
      "====> Epoch: 600 Average training loss: 3.3690\n",
      "====> Epoch: 700 Average training loss: 3.0595\n",
      "====> Epoch: 800 Average training loss: 2.8075\n",
      "====> Epoch: 900 Average training loss: 2.5946\n",
      "====> Epoch: 1000 Average training loss: 2.4212\n",
      "====> Epoch: 1100 Average training loss: 2.2608\n",
      "====> Epoch: 1200 Average training loss: 2.1273\n",
      "====> Epoch: 1300 Average training loss: 2.0178\n",
      "====> Epoch: 1400 Average training loss: 1.8921\n",
      "====> Epoch: 1500 Average training loss: 1.7775\n",
      "====> Epoch: 1600 Average training loss: 1.6924\n",
      "====> Epoch: 1700 Average training loss: 1.6221\n",
      "====> Epoch: 1800 Average training loss: 1.5544\n",
      "====> Epoch: 100 Average training loss: 6.7144\n",
      "====> Epoch: 200 Average training loss: 5.4396\n",
      "====> Epoch: 300 Average training loss: 4.6355\n",
      "====> Epoch: 400 Average training loss: 4.0717\n",
      "====> Epoch: 500 Average training loss: 3.6053\n",
      "====> Epoch: 600 Average training loss: 3.2880\n",
      "====> Epoch: 700 Average training loss: 2.9892\n",
      "====> Epoch: 800 Average training loss: 2.7577\n",
      "====> Epoch: 900 Average training loss: 2.5452\n",
      "====> Epoch: 1000 Average training loss: 2.3902\n",
      "====> Epoch: 1100 Average training loss: 2.2316\n",
      "====> Epoch: 1200 Average training loss: 2.0917\n",
      "====> Epoch: 1300 Average training loss: 1.9748\n",
      "====> Epoch: 1400 Average training loss: 1.8814\n",
      "====> Epoch: 1500 Average training loss: 1.7701\n",
      "====> Epoch: 1600 Average training loss: 1.7026\n",
      "====> Epoch: 1700 Average training loss: 1.6265\n",
      "====> Epoch: 1800 Average training loss: 1.5637\n",
      "====> Epoch: 100 Average training loss: 6.6925\n",
      "====> Epoch: 200 Average training loss: 5.4310\n",
      "====> Epoch: 300 Average training loss: 4.6636\n",
      "====> Epoch: 400 Average training loss: 4.0730\n",
      "====> Epoch: 500 Average training loss: 3.6444\n",
      "====> Epoch: 600 Average training loss: 3.3070\n",
      "====> Epoch: 700 Average training loss: 3.0146\n",
      "====> Epoch: 800 Average training loss: 2.7554\n",
      "====> Epoch: 900 Average training loss: 2.5572\n",
      "====> Epoch: 1000 Average training loss: 2.3739\n",
      "====> Epoch: 1100 Average training loss: 2.2065\n",
      "====> Epoch: 1200 Average training loss: 2.0885\n",
      "====> Epoch: 1300 Average training loss: 1.9751\n",
      "====> Epoch: 1400 Average training loss: 1.8617\n",
      "====> Epoch: 1500 Average training loss: 1.7708\n",
      "====> Epoch: 1600 Average training loss: 1.6842\n",
      "====> Epoch: 1700 Average training loss: 1.6191\n",
      "====> Epoch: 1800 Average training loss: 1.5431\n",
      "====> Epoch: 100 Average training loss: 6.4058\n",
      "====> Epoch: 200 Average training loss: 5.2689\n",
      "====> Epoch: 300 Average training loss: 4.5438\n",
      "====> Epoch: 400 Average training loss: 3.9958\n",
      "====> Epoch: 500 Average training loss: 3.5908\n",
      "====> Epoch: 600 Average training loss: 3.2608\n",
      "====> Epoch: 700 Average training loss: 2.9763\n",
      "====> Epoch: 800 Average training loss: 2.7368\n",
      "====> Epoch: 900 Average training loss: 2.5297\n",
      "====> Epoch: 1000 Average training loss: 2.3603\n",
      "====> Epoch: 1100 Average training loss: 2.1983\n",
      "====> Epoch: 1200 Average training loss: 2.0726\n",
      "====> Epoch: 1300 Average training loss: 1.9510\n",
      "====> Epoch: 1400 Average training loss: 1.8540\n",
      "====> Epoch: 1500 Average training loss: 1.7626\n",
      "====> Epoch: 1600 Average training loss: 1.6734\n",
      "====> Epoch: 1700 Average training loss: 1.6051\n",
      "====> Epoch: 1800 Average training loss: 1.5265\n",
      "====> Epoch: 100 Average training loss: 6.9419\n",
      "====> Epoch: 200 Average training loss: 5.5880\n",
      "====> Epoch: 300 Average training loss: 4.7923\n",
      "====> Epoch: 400 Average training loss: 4.2060\n",
      "====> Epoch: 500 Average training loss: 3.7561\n",
      "====> Epoch: 600 Average training loss: 3.3794\n",
      "====> Epoch: 700 Average training loss: 3.0664\n",
      "====> Epoch: 800 Average training loss: 2.8086\n",
      "====> Epoch: 900 Average training loss: 2.6165\n",
      "====> Epoch: 1000 Average training loss: 2.4257\n",
      "====> Epoch: 1100 Average training loss: 2.2695\n",
      "====> Epoch: 1200 Average training loss: 2.1379\n",
      "====> Epoch: 1300 Average training loss: 2.0133\n",
      "====> Epoch: 1400 Average training loss: 1.8938\n",
      "====> Epoch: 1500 Average training loss: 1.8011\n",
      "====> Epoch: 1600 Average training loss: 1.7027\n",
      "====> Epoch: 1700 Average training loss: 1.6275\n",
      "====> Epoch: 1800 Average training loss: 1.5633\n",
      "====> Epoch: 100 Average training loss: 6.5594\n",
      "====> Epoch: 200 Average training loss: 5.3605\n",
      "====> Epoch: 300 Average training loss: 4.5981\n",
      "====> Epoch: 400 Average training loss: 4.0694\n",
      "====> Epoch: 500 Average training loss: 3.6252\n",
      "====> Epoch: 600 Average training loss: 3.2802\n",
      "====> Epoch: 700 Average training loss: 2.9823\n",
      "====> Epoch: 800 Average training loss: 2.7537\n",
      "====> Epoch: 900 Average training loss: 2.5480\n",
      "====> Epoch: 1000 Average training loss: 2.3770\n",
      "====> Epoch: 1100 Average training loss: 2.2208\n",
      "====> Epoch: 1200 Average training loss: 2.0987\n",
      "====> Epoch: 1300 Average training loss: 1.9663\n",
      "====> Epoch: 1400 Average training loss: 1.8640\n",
      "====> Epoch: 1500 Average training loss: 1.7680\n",
      "====> Epoch: 1600 Average training loss: 1.6817\n",
      "====> Epoch: 1700 Average training loss: 1.6065\n",
      "====> Epoch: 1800 Average training loss: 1.5476\n",
      "====> Epoch: 100 Average training loss: 6.5539\n",
      "====> Epoch: 200 Average training loss: 5.3497\n",
      "====> Epoch: 300 Average training loss: 4.5836\n",
      "====> Epoch: 400 Average training loss: 4.0308\n",
      "====> Epoch: 500 Average training loss: 3.6201\n",
      "====> Epoch: 600 Average training loss: 3.2668\n",
      "====> Epoch: 700 Average training loss: 2.9884\n",
      "====> Epoch: 800 Average training loss: 2.7614\n",
      "====> Epoch: 900 Average training loss: 2.5546\n",
      "====> Epoch: 1000 Average training loss: 2.3861\n",
      "====> Epoch: 1100 Average training loss: 2.2180\n",
      "====> Epoch: 1200 Average training loss: 2.0870\n",
      "====> Epoch: 1300 Average training loss: 1.9742\n",
      "====> Epoch: 1400 Average training loss: 1.8605\n",
      "====> Epoch: 1500 Average training loss: 1.7666\n",
      "====> Epoch: 1600 Average training loss: 1.6809\n",
      "====> Epoch: 1700 Average training loss: 1.6057\n",
      "====> Epoch: 1800 Average training loss: 1.5529\n",
      "====> Epoch: 100 Average training loss: 6.6481\n",
      "====> Epoch: 200 Average training loss: 5.4100\n",
      "====> Epoch: 300 Average training loss: 4.6160\n",
      "====> Epoch: 400 Average training loss: 4.0342\n",
      "====> Epoch: 500 Average training loss: 3.6149\n",
      "====> Epoch: 600 Average training loss: 3.2694\n",
      "====> Epoch: 700 Average training loss: 2.9823\n",
      "====> Epoch: 800 Average training loss: 2.7443\n",
      "====> Epoch: 900 Average training loss: 2.5476\n",
      "====> Epoch: 1000 Average training loss: 2.3742\n",
      "====> Epoch: 1100 Average training loss: 2.2172\n",
      "====> Epoch: 1200 Average training loss: 2.0939\n",
      "====> Epoch: 1300 Average training loss: 1.9654\n",
      "====> Epoch: 1400 Average training loss: 1.8626\n",
      "====> Epoch: 1500 Average training loss: 1.7686\n",
      "====> Epoch: 1600 Average training loss: 1.6845\n",
      "====> Epoch: 1700 Average training loss: 1.6186\n",
      "====> Epoch: 1800 Average training loss: 1.5435\n",
      "====> Epoch: 100 Average training loss: 6.5244\n",
      "====> Epoch: 200 Average training loss: 5.3145\n",
      "====> Epoch: 300 Average training loss: 4.5790\n",
      "====> Epoch: 400 Average training loss: 4.0290\n",
      "====> Epoch: 500 Average training loss: 3.6161\n",
      "====> Epoch: 600 Average training loss: 3.2625\n",
      "====> Epoch: 700 Average training loss: 2.9701\n",
      "====> Epoch: 800 Average training loss: 2.7402\n",
      "====> Epoch: 900 Average training loss: 2.5424\n",
      "====> Epoch: 1000 Average training loss: 2.3757\n",
      "====> Epoch: 1100 Average training loss: 2.2138\n",
      "====> Epoch: 1200 Average training loss: 2.0717\n",
      "====> Epoch: 1300 Average training loss: 1.9787\n",
      "====> Epoch: 1400 Average training loss: 1.8596\n",
      "====> Epoch: 1500 Average training loss: 1.7696\n",
      "====> Epoch: 1600 Average training loss: 1.6860\n",
      "====> Epoch: 1700 Average training loss: 1.6133\n",
      "====> Epoch: 1800 Average training loss: 1.5432\n",
      "====> Epoch: 100 Average training loss: 6.4288\n",
      "====> Epoch: 200 Average training loss: 5.2738\n",
      "====> Epoch: 300 Average training loss: 4.5447\n",
      "====> Epoch: 400 Average training loss: 4.0124\n",
      "====> Epoch: 500 Average training loss: 3.5668\n",
      "====> Epoch: 600 Average training loss: 3.2491\n",
      "====> Epoch: 700 Average training loss: 2.9553\n",
      "====> Epoch: 800 Average training loss: 2.7452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 900 Average training loss: 2.5386\n",
      "====> Epoch: 1000 Average training loss: 2.3639\n",
      "====> Epoch: 1100 Average training loss: 2.2077\n",
      "====> Epoch: 1200 Average training loss: 2.0959\n",
      "====> Epoch: 1300 Average training loss: 1.9548\n",
      "====> Epoch: 1400 Average training loss: 1.8512\n",
      "====> Epoch: 1500 Average training loss: 1.7649\n",
      "====> Epoch: 1600 Average training loss: 1.6783\n",
      "====> Epoch: 1700 Average training loss: 1.6140\n",
      "====> Epoch: 1800 Average training loss: 1.5393\n",
      "====> Epoch: 100 Average training loss: 6.4708\n",
      "====> Epoch: 200 Average training loss: 5.3164\n",
      "====> Epoch: 300 Average training loss: 4.6067\n",
      "====> Epoch: 400 Average training loss: 4.0276\n",
      "====> Epoch: 500 Average training loss: 3.5926\n",
      "====> Epoch: 600 Average training loss: 3.2831\n",
      "====> Epoch: 700 Average training loss: 2.9803\n",
      "====> Epoch: 800 Average training loss: 2.6482\n",
      "====> Epoch: 900 Average training loss: 2.4917\n",
      "====> Epoch: 1000 Average training loss: 2.3517\n",
      "====> Epoch: 1100 Average training loss: 2.1908\n",
      "====> Epoch: 1200 Average training loss: 2.0397\n",
      "====> Epoch: 1300 Average training loss: 1.9181\n",
      "====> Epoch: 1400 Average training loss: 1.7833\n",
      "====> Epoch: 1500 Average training loss: 1.7112\n",
      "====> Epoch: 1600 Average training loss: 1.6015\n",
      "====> Epoch: 1700 Average training loss: 1.5457\n",
      "====> Epoch: 1800 Average training loss: 1.4761\n",
      "====> Epoch: 100 Average training loss: 6.5497\n",
      "====> Epoch: 200 Average training loss: 5.3447\n",
      "====> Epoch: 300 Average training loss: 4.5747\n",
      "====> Epoch: 400 Average training loss: 4.0302\n",
      "====> Epoch: 500 Average training loss: 3.5865\n",
      "====> Epoch: 600 Average training loss: 3.2453\n",
      "====> Epoch: 700 Average training loss: 2.9757\n",
      "====> Epoch: 800 Average training loss: 2.7500\n",
      "====> Epoch: 900 Average training loss: 2.5462\n",
      "====> Epoch: 1000 Average training loss: 2.3767\n",
      "====> Epoch: 1100 Average training loss: 2.2233\n",
      "====> Epoch: 1200 Average training loss: 2.0886\n",
      "====> Epoch: 1300 Average training loss: 1.9497\n",
      "====> Epoch: 1400 Average training loss: 1.8609\n",
      "====> Epoch: 1500 Average training loss: 1.7805\n",
      "====> Epoch: 1600 Average training loss: 1.6870\n",
      "====> Epoch: 1700 Average training loss: 1.6047\n",
      "====> Epoch: 1800 Average training loss: 1.5534\n",
      "====> Epoch: 100 Average training loss: 6.5314\n",
      "====> Epoch: 200 Average training loss: 5.3307\n",
      "====> Epoch: 300 Average training loss: 4.5768\n",
      "====> Epoch: 400 Average training loss: 4.0337\n",
      "====> Epoch: 500 Average training loss: 3.5865\n",
      "====> Epoch: 600 Average training loss: 3.2561\n",
      "====> Epoch: 700 Average training loss: 2.9797\n",
      "====> Epoch: 800 Average training loss: 2.7477\n",
      "====> Epoch: 900 Average training loss: 2.5356\n",
      "====> Epoch: 1000 Average training loss: 2.3773\n",
      "====> Epoch: 1100 Average training loss: 2.2040\n",
      "====> Epoch: 1200 Average training loss: 2.0744\n",
      "====> Epoch: 1300 Average training loss: 1.9707\n",
      "====> Epoch: 1400 Average training loss: 1.8671\n",
      "====> Epoch: 1500 Average training loss: 1.7786\n",
      "====> Epoch: 1600 Average training loss: 1.6939\n",
      "====> Epoch: 1700 Average training loss: 1.6149\n",
      "====> Epoch: 1800 Average training loss: 1.5458\n",
      "====> Epoch: 100 Average training loss: 6.6814\n",
      "====> Epoch: 200 Average training loss: 5.4591\n",
      "====> Epoch: 300 Average training loss: 4.6661\n",
      "====> Epoch: 400 Average training loss: 4.1135\n",
      "====> Epoch: 500 Average training loss: 3.6636\n",
      "====> Epoch: 600 Average training loss: 3.3023\n",
      "====> Epoch: 700 Average training loss: 3.0197\n",
      "====> Epoch: 800 Average training loss: 2.7689\n",
      "====> Epoch: 900 Average training loss: 2.5717\n",
      "====> Epoch: 1000 Average training loss: 2.3867\n",
      "====> Epoch: 1100 Average training loss: 2.2308\n",
      "====> Epoch: 1200 Average training loss: 2.0960\n",
      "====> Epoch: 1300 Average training loss: 1.9739\n",
      "====> Epoch: 1400 Average training loss: 1.8697\n",
      "====> Epoch: 1500 Average training loss: 1.7732\n",
      "====> Epoch: 1600 Average training loss: 1.6843\n",
      "====> Epoch: 1700 Average training loss: 1.6143\n",
      "====> Epoch: 1800 Average training loss: 1.5444\n",
      "====> Epoch: 100 Average training loss: 6.5951\n",
      "====> Epoch: 200 Average training loss: 5.3934\n",
      "====> Epoch: 300 Average training loss: 4.6169\n",
      "====> Epoch: 400 Average training loss: 4.0643\n",
      "====> Epoch: 500 Average training loss: 3.6324\n",
      "====> Epoch: 600 Average training loss: 3.2823\n",
      "====> Epoch: 700 Average training loss: 2.9939\n",
      "====> Epoch: 800 Average training loss: 2.7584\n",
      "====> Epoch: 900 Average training loss: 2.5405\n",
      "====> Epoch: 1000 Average training loss: 2.3699\n",
      "====> Epoch: 1100 Average training loss: 2.2213\n",
      "====> Epoch: 1200 Average training loss: 2.0873\n",
      "====> Epoch: 1300 Average training loss: 1.9583\n",
      "====> Epoch: 1400 Average training loss: 1.8520\n",
      "====> Epoch: 1500 Average training loss: 1.7565\n",
      "====> Epoch: 1600 Average training loss: 1.6708\n",
      "====> Epoch: 1700 Average training loss: 1.6041\n",
      "====> Epoch: 1800 Average training loss: 1.5320\n",
      "====> Epoch: 100 Average training loss: 6.6002\n",
      "====> Epoch: 200 Average training loss: 5.3819\n",
      "====> Epoch: 300 Average training loss: 4.5995\n",
      "====> Epoch: 400 Average training loss: 4.0559\n",
      "====> Epoch: 500 Average training loss: 3.6437\n",
      "====> Epoch: 600 Average training loss: 3.2916\n",
      "====> Epoch: 700 Average training loss: 3.0095\n",
      "====> Epoch: 800 Average training loss: 2.7603\n",
      "====> Epoch: 900 Average training loss: 2.5614\n",
      "====> Epoch: 1000 Average training loss: 2.3861\n",
      "====> Epoch: 1100 Average training loss: 2.2517\n",
      "====> Epoch: 1200 Average training loss: 2.0990\n",
      "====> Epoch: 1300 Average training loss: 1.9711\n",
      "====> Epoch: 1400 Average training loss: 1.8563\n",
      "====> Epoch: 1500 Average training loss: 1.7783\n",
      "====> Epoch: 1600 Average training loss: 1.6909\n",
      "====> Epoch: 1700 Average training loss: 1.6278\n",
      "====> Epoch: 1800 Average training loss: 1.5485\n",
      "====> Epoch: 100 Average training loss: 6.4094\n",
      "====> Epoch: 200 Average training loss: 5.2599\n",
      "====> Epoch: 300 Average training loss: 4.5243\n",
      "====> Epoch: 400 Average training loss: 4.0082\n",
      "====> Epoch: 500 Average training loss: 3.5893\n",
      "====> Epoch: 600 Average training loss: 3.2526\n",
      "====> Epoch: 700 Average training loss: 2.9771\n",
      "====> Epoch: 800 Average training loss: 2.7368\n",
      "====> Epoch: 900 Average training loss: 2.5256\n",
      "====> Epoch: 1000 Average training loss: 2.3417\n",
      "====> Epoch: 1100 Average training loss: 2.1996\n",
      "====> Epoch: 1200 Average training loss: 2.0707\n",
      "====> Epoch: 1300 Average training loss: 1.9364\n",
      "====> Epoch: 1400 Average training loss: 1.8393\n",
      "====> Epoch: 1500 Average training loss: 1.7517\n",
      "====> Epoch: 1600 Average training loss: 1.6730\n",
      "====> Epoch: 1700 Average training loss: 1.6059\n",
      "====> Epoch: 1800 Average training loss: 1.5341\n",
      "====> Epoch: 100 Average training loss: 6.5686\n",
      "====> Epoch: 200 Average training loss: 5.3275\n",
      "====> Epoch: 300 Average training loss: 4.5690\n",
      "====> Epoch: 400 Average training loss: 4.0303\n",
      "====> Epoch: 500 Average training loss: 3.5890\n",
      "====> Epoch: 600 Average training loss: 3.2698\n",
      "====> Epoch: 700 Average training loss: 2.9784\n",
      "====> Epoch: 800 Average training loss: 2.7485\n",
      "====> Epoch: 900 Average training loss: 2.5579\n",
      "====> Epoch: 1000 Average training loss: 2.3841\n",
      "====> Epoch: 1100 Average training loss: 2.2264\n",
      "====> Epoch: 1200 Average training loss: 2.0980\n",
      "====> Epoch: 1300 Average training loss: 1.9762\n",
      "====> Epoch: 1400 Average training loss: 1.8762\n",
      "====> Epoch: 1500 Average training loss: 1.7758\n",
      "====> Epoch: 1600 Average training loss: 1.6894\n",
      "====> Epoch: 1700 Average training loss: 1.6142\n",
      "====> Epoch: 1800 Average training loss: 1.5452\n",
      "====> Epoch: 100 Average training loss: 6.7151\n",
      "====> Epoch: 200 Average training loss: 5.4527\n",
      "====> Epoch: 300 Average training loss: 4.6695\n",
      "====> Epoch: 400 Average training loss: 4.0901\n",
      "====> Epoch: 500 Average training loss: 3.6448\n",
      "====> Epoch: 600 Average training loss: 3.3018\n",
      "====> Epoch: 700 Average training loss: 3.0034\n",
      "====> Epoch: 800 Average training loss: 2.7739\n",
      "====> Epoch: 900 Average training loss: 2.5637\n",
      "====> Epoch: 1000 Average training loss: 2.3816\n",
      "====> Epoch: 1100 Average training loss: 2.2334\n",
      "====> Epoch: 1200 Average training loss: 2.0896\n",
      "====> Epoch: 1300 Average training loss: 1.9590\n",
      "====> Epoch: 1400 Average training loss: 1.8394\n",
      "====> Epoch: 1500 Average training loss: 1.7792\n",
      "====> Epoch: 1600 Average training loss: 1.6913\n",
      "====> Epoch: 1700 Average training loss: 1.6114\n",
      "====> Epoch: 1800 Average training loss: 1.5408\n",
      "====> Epoch: 100 Average training loss: 6.5329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 200 Average training loss: 5.3305\n",
      "====> Epoch: 300 Average training loss: 4.5619\n",
      "====> Epoch: 400 Average training loss: 4.0209\n",
      "====> Epoch: 500 Average training loss: 3.6027\n",
      "====> Epoch: 600 Average training loss: 3.2627\n",
      "====> Epoch: 700 Average training loss: 2.9741\n",
      "====> Epoch: 800 Average training loss: 2.7464\n",
      "====> Epoch: 900 Average training loss: 2.5526\n",
      "====> Epoch: 1000 Average training loss: 2.3791\n",
      "====> Epoch: 1100 Average training loss: 2.2074\n",
      "====> Epoch: 1200 Average training loss: 2.0912\n",
      "====> Epoch: 1300 Average training loss: 1.9626\n",
      "====> Epoch: 1400 Average training loss: 1.8802\n",
      "====> Epoch: 1500 Average training loss: 1.7832\n",
      "====> Epoch: 1600 Average training loss: 1.6879\n",
      "====> Epoch: 1700 Average training loss: 1.5753\n",
      "====> Epoch: 1800 Average training loss: 1.4814\n",
      "====> Epoch: 100 Average training loss: 6.5715\n",
      "====> Epoch: 200 Average training loss: 5.4023\n",
      "====> Epoch: 300 Average training loss: 4.6448\n",
      "====> Epoch: 400 Average training loss: 4.0886\n",
      "====> Epoch: 500 Average training loss: 3.6578\n",
      "====> Epoch: 600 Average training loss: 3.3032\n",
      "====> Epoch: 700 Average training loss: 3.0041\n",
      "====> Epoch: 800 Average training loss: 2.7784\n",
      "====> Epoch: 900 Average training loss: 2.5486\n",
      "====> Epoch: 1000 Average training loss: 2.3776\n",
      "====> Epoch: 1100 Average training loss: 2.2284\n",
      "====> Epoch: 1200 Average training loss: 2.0932\n",
      "====> Epoch: 1300 Average training loss: 1.9810\n",
      "====> Epoch: 1400 Average training loss: 1.8628\n",
      "====> Epoch: 1500 Average training loss: 1.7714\n",
      "====> Epoch: 1600 Average training loss: 1.6894\n",
      "====> Epoch: 1700 Average training loss: 1.6077\n",
      "====> Epoch: 1800 Average training loss: 1.5357\n",
      "====> Epoch: 100 Average training loss: 6.4968\n",
      "====> Epoch: 200 Average training loss: 5.2871\n",
      "====> Epoch: 300 Average training loss: 4.5274\n",
      "====> Epoch: 400 Average training loss: 3.9958\n",
      "====> Epoch: 500 Average training loss: 3.5921\n",
      "====> Epoch: 600 Average training loss: 3.2415\n",
      "====> Epoch: 700 Average training loss: 2.9613\n",
      "====> Epoch: 800 Average training loss: 2.7345\n",
      "====> Epoch: 900 Average training loss: 2.5412\n",
      "====> Epoch: 1000 Average training loss: 2.3690\n",
      "====> Epoch: 1100 Average training loss: 2.2098\n",
      "====> Epoch: 1200 Average training loss: 2.0781\n",
      "====> Epoch: 1300 Average training loss: 1.9517\n",
      "====> Epoch: 1400 Average training loss: 1.8511\n",
      "====> Epoch: 1500 Average training loss: 1.7583\n",
      "====> Epoch: 1600 Average training loss: 1.6698\n",
      "====> Epoch: 1700 Average training loss: 1.5993\n",
      "====> Epoch: 1800 Average training loss: 1.5306\n",
      "====> Epoch: 100 Average training loss: 6.5906\n",
      "====> Epoch: 200 Average training loss: 5.3348\n",
      "====> Epoch: 300 Average training loss: 4.5821\n",
      "====> Epoch: 400 Average training loss: 4.0586\n",
      "====> Epoch: 500 Average training loss: 3.6185\n",
      "====> Epoch: 600 Average training loss: 3.2662\n",
      "====> Epoch: 700 Average training loss: 2.9964\n",
      "====> Epoch: 800 Average training loss: 2.7380\n",
      "====> Epoch: 900 Average training loss: 2.5432\n",
      "====> Epoch: 1000 Average training loss: 2.3847\n",
      "====> Epoch: 1100 Average training loss: 2.2233\n",
      "====> Epoch: 1200 Average training loss: 2.0857\n",
      "====> Epoch: 1300 Average training loss: 1.9743\n",
      "====> Epoch: 1400 Average training loss: 1.8675\n",
      "====> Epoch: 1500 Average training loss: 1.7779\n",
      "====> Epoch: 1600 Average training loss: 1.6892\n",
      "====> Epoch: 1700 Average training loss: 1.6004\n",
      "====> Epoch: 1800 Average training loss: 1.5428\n",
      "====> Epoch: 100 Average training loss: 6.6428\n",
      "====> Epoch: 200 Average training loss: 5.4246\n",
      "====> Epoch: 300 Average training loss: 4.6090\n",
      "====> Epoch: 400 Average training loss: 4.0686\n",
      "====> Epoch: 500 Average training loss: 3.6218\n",
      "====> Epoch: 600 Average training loss: 3.3002\n",
      "====> Epoch: 700 Average training loss: 3.0028\n",
      "====> Epoch: 800 Average training loss: 2.7729\n",
      "====> Epoch: 900 Average training loss: 2.5580\n",
      "====> Epoch: 1000 Average training loss: 2.3876\n",
      "====> Epoch: 1100 Average training loss: 2.2361\n",
      "====> Epoch: 1200 Average training loss: 2.0866\n",
      "====> Epoch: 1300 Average training loss: 1.9838\n",
      "====> Epoch: 1400 Average training loss: 1.8606\n",
      "====> Epoch: 1500 Average training loss: 1.7820\n",
      "====> Epoch: 1600 Average training loss: 1.7027\n",
      "====> Epoch: 1700 Average training loss: 1.6143\n",
      "====> Epoch: 1800 Average training loss: 1.5529\n",
      "====> Epoch: 100 Average training loss: 6.6448\n",
      "====> Epoch: 200 Average training loss: 5.4077\n",
      "====> Epoch: 300 Average training loss: 4.6141\n",
      "====> Epoch: 400 Average training loss: 4.0655\n",
      "====> Epoch: 500 Average training loss: 3.6286\n",
      "====> Epoch: 600 Average training loss: 3.2940\n",
      "====> Epoch: 700 Average training loss: 3.0057\n",
      "====> Epoch: 800 Average training loss: 2.7670\n",
      "====> Epoch: 900 Average training loss: 2.5531\n",
      "====> Epoch: 1000 Average training loss: 2.3702\n",
      "====> Epoch: 1100 Average training loss: 2.2302\n",
      "====> Epoch: 1200 Average training loss: 2.0981\n",
      "====> Epoch: 1300 Average training loss: 1.9696\n",
      "====> Epoch: 1400 Average training loss: 1.8639\n",
      "====> Epoch: 1500 Average training loss: 1.7709\n",
      "====> Epoch: 1600 Average training loss: 1.7015\n",
      "====> Epoch: 1700 Average training loss: 1.6042\n",
      "====> Epoch: 1800 Average training loss: 1.5401\n",
      "====> Epoch: 100 Average training loss: 6.4666\n",
      "====> Epoch: 200 Average training loss: 5.2771\n",
      "====> Epoch: 300 Average training loss: 4.5214\n",
      "====> Epoch: 400 Average training loss: 4.0043\n",
      "====> Epoch: 500 Average training loss: 3.5716\n",
      "====> Epoch: 600 Average training loss: 3.2607\n",
      "====> Epoch: 700 Average training loss: 2.9508\n",
      "====> Epoch: 800 Average training loss: 2.7291\n",
      "====> Epoch: 900 Average training loss: 2.5383\n",
      "====> Epoch: 1000 Average training loss: 2.3504\n",
      "====> Epoch: 1100 Average training loss: 2.2085\n",
      "====> Epoch: 1200 Average training loss: 2.0703\n",
      "====> Epoch: 1300 Average training loss: 1.9576\n",
      "====> Epoch: 1400 Average training loss: 1.8575\n",
      "====> Epoch: 1500 Average training loss: 1.7560\n",
      "====> Epoch: 1600 Average training loss: 1.6722\n",
      "====> Epoch: 1700 Average training loss: 1.6027\n",
      "====> Epoch: 1800 Average training loss: 1.5321\n",
      "====> Epoch: 100 Average training loss: 6.6584\n",
      "====> Epoch: 200 Average training loss: 5.4054\n",
      "====> Epoch: 300 Average training loss: 4.6415\n",
      "====> Epoch: 400 Average training loss: 4.0607\n",
      "====> Epoch: 500 Average training loss: 3.6205\n",
      "====> Epoch: 600 Average training loss: 3.2880\n",
      "====> Epoch: 700 Average training loss: 3.0069\n",
      "====> Epoch: 800 Average training loss: 2.7657\n",
      "====> Epoch: 900 Average training loss: 2.5482\n",
      "====> Epoch: 1000 Average training loss: 2.3747\n",
      "====> Epoch: 1100 Average training loss: 2.2253\n",
      "====> Epoch: 1200 Average training loss: 2.0953\n",
      "====> Epoch: 1300 Average training loss: 1.9859\n",
      "====> Epoch: 1400 Average training loss: 1.8734\n",
      "====> Epoch: 1500 Average training loss: 1.7805\n",
      "====> Epoch: 1600 Average training loss: 1.6982\n",
      "====> Epoch: 1700 Average training loss: 1.6190\n",
      "====> Epoch: 1800 Average training loss: 1.5467\n",
      "====> Epoch: 100 Average training loss: 7.1645\n",
      "====> Epoch: 200 Average training loss: 5.7458\n",
      "====> Epoch: 300 Average training loss: 4.8896\n",
      "====> Epoch: 400 Average training loss: 4.2580\n",
      "====> Epoch: 500 Average training loss: 3.7900\n",
      "====> Epoch: 600 Average training loss: 3.3882\n",
      "====> Epoch: 700 Average training loss: 3.0839\n",
      "====> Epoch: 800 Average training loss: 2.8430\n",
      "====> Epoch: 900 Average training loss: 2.6046\n",
      "====> Epoch: 1000 Average training loss: 2.4182\n",
      "====> Epoch: 1100 Average training loss: 2.2768\n",
      "====> Epoch: 1200 Average training loss: 2.1305\n",
      "====> Epoch: 1300 Average training loss: 2.0053\n",
      "====> Epoch: 1400 Average training loss: 1.8807\n",
      "====> Epoch: 1500 Average training loss: 1.7971\n",
      "====> Epoch: 1600 Average training loss: 1.7004\n",
      "====> Epoch: 1700 Average training loss: 1.6308\n",
      "====> Epoch: 1800 Average training loss: 1.5583\n",
      "====> Epoch: 100 Average training loss: 6.8499\n",
      "====> Epoch: 200 Average training loss: 5.5794\n",
      "====> Epoch: 300 Average training loss: 4.7521\n",
      "====> Epoch: 400 Average training loss: 4.1722\n",
      "====> Epoch: 500 Average training loss: 3.7248\n",
      "====> Epoch: 600 Average training loss: 3.3590\n",
      "====> Epoch: 700 Average training loss: 3.0594\n",
      "====> Epoch: 800 Average training loss: 2.8197\n",
      "====> Epoch: 900 Average training loss: 2.5995\n",
      "====> Epoch: 1000 Average training loss: 2.3980\n",
      "====> Epoch: 1100 Average training loss: 2.2678\n",
      "====> Epoch: 1200 Average training loss: 2.1183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1300 Average training loss: 1.9849\n",
      "====> Epoch: 1400 Average training loss: 1.8807\n",
      "====> Epoch: 1500 Average training loss: 1.7802\n",
      "====> Epoch: 1600 Average training loss: 1.6983\n",
      "====> Epoch: 1700 Average training loss: 1.6271\n",
      "====> Epoch: 1800 Average training loss: 1.5522\n",
      "====> Epoch: 100 Average training loss: 6.6056\n",
      "====> Epoch: 200 Average training loss: 5.3324\n",
      "====> Epoch: 300 Average training loss: 4.5601\n",
      "====> Epoch: 400 Average training loss: 4.0030\n",
      "====> Epoch: 500 Average training loss: 3.6120\n",
      "====> Epoch: 600 Average training loss: 3.2659\n",
      "====> Epoch: 700 Average training loss: 2.9874\n",
      "====> Epoch: 800 Average training loss: 2.7419\n",
      "====> Epoch: 900 Average training loss: 2.5426\n",
      "====> Epoch: 1000 Average training loss: 2.3734\n",
      "====> Epoch: 1100 Average training loss: 2.2146\n",
      "====> Epoch: 1200 Average training loss: 2.0904\n",
      "====> Epoch: 1300 Average training loss: 1.9643\n",
      "====> Epoch: 1400 Average training loss: 1.8561\n",
      "====> Epoch: 1500 Average training loss: 1.7743\n",
      "====> Epoch: 1600 Average training loss: 1.6844\n",
      "====> Epoch: 1700 Average training loss: 1.6240\n",
      "====> Epoch: 1800 Average training loss: 1.5462\n",
      "====> Epoch: 100 Average training loss: 6.4750\n",
      "====> Epoch: 200 Average training loss: 5.3162\n",
      "====> Epoch: 300 Average training loss: 4.5408\n",
      "====> Epoch: 400 Average training loss: 3.9888\n",
      "====> Epoch: 500 Average training loss: 3.5910\n",
      "====> Epoch: 600 Average training loss: 3.2538\n",
      "====> Epoch: 700 Average training loss: 2.9722\n",
      "====> Epoch: 800 Average training loss: 2.7267\n",
      "====> Epoch: 900 Average training loss: 2.5236\n",
      "====> Epoch: 1000 Average training loss: 2.3681\n",
      "====> Epoch: 1100 Average training loss: 2.2128\n",
      "====> Epoch: 1200 Average training loss: 2.0699\n",
      "====> Epoch: 1300 Average training loss: 1.9630\n",
      "====> Epoch: 1400 Average training loss: 1.8553\n",
      "====> Epoch: 1500 Average training loss: 1.7684\n",
      "====> Epoch: 1600 Average training loss: 1.6836\n",
      "====> Epoch: 1700 Average training loss: 1.6107\n",
      "====> Epoch: 1800 Average training loss: 1.5577\n",
      "====> Epoch: 100 Average training loss: 6.7054\n",
      "====> Epoch: 200 Average training loss: 5.4669\n",
      "====> Epoch: 300 Average training loss: 4.6489\n",
      "====> Epoch: 400 Average training loss: 4.0855\n",
      "====> Epoch: 500 Average training loss: 3.6387\n",
      "====> Epoch: 600 Average training loss: 3.2882\n",
      "====> Epoch: 700 Average training loss: 3.0023\n",
      "====> Epoch: 800 Average training loss: 2.7804\n",
      "====> Epoch: 900 Average training loss: 2.5666\n",
      "====> Epoch: 1000 Average training loss: 2.3909\n",
      "====> Epoch: 1100 Average training loss: 2.2384\n",
      "====> Epoch: 1200 Average training loss: 2.0956\n",
      "====> Epoch: 1300 Average training loss: 1.9906\n",
      "====> Epoch: 1400 Average training loss: 1.8946\n",
      "====> Epoch: 1500 Average training loss: 1.7905\n",
      "====> Epoch: 1600 Average training loss: 1.7148\n",
      "====> Epoch: 1700 Average training loss: 1.6349\n",
      "====> Epoch: 1800 Average training loss: 1.5619\n",
      "====> Epoch: 100 Average training loss: 6.5314\n",
      "====> Epoch: 200 Average training loss: 5.3077\n",
      "====> Epoch: 300 Average training loss: 4.5422\n",
      "====> Epoch: 400 Average training loss: 4.0212\n",
      "====> Epoch: 500 Average training loss: 3.6094\n",
      "====> Epoch: 600 Average training loss: 3.1594\n",
      "====> Epoch: 700 Average training loss: 2.8403\n",
      "====> Epoch: 800 Average training loss: 2.6558\n",
      "====> Epoch: 900 Average training loss: 2.4660\n",
      "====> Epoch: 1000 Average training loss: 2.2678\n",
      "====> Epoch: 1100 Average training loss: 2.0937\n",
      "====> Epoch: 1200 Average training loss: 1.9593\n",
      "====> Epoch: 1300 Average training loss: 1.8508\n",
      "====> Epoch: 1400 Average training loss: 1.7465\n",
      "====> Epoch: 1500 Average training loss: 1.6674\n",
      "====> Epoch: 1600 Average training loss: 1.5911\n",
      "====> Epoch: 1700 Average training loss: 1.5193\n",
      "====> Epoch: 1800 Average training loss: 1.4537\n",
      "====> Epoch: 100 Average training loss: 6.7153\n",
      "====> Epoch: 200 Average training loss: 5.4619\n",
      "====> Epoch: 300 Average training loss: 4.6590\n",
      "====> Epoch: 400 Average training loss: 4.0533\n",
      "====> Epoch: 500 Average training loss: 3.6094\n",
      "====> Epoch: 600 Average training loss: 3.2699\n",
      "====> Epoch: 700 Average training loss: 2.9814\n",
      "====> Epoch: 800 Average training loss: 2.7413\n",
      "====> Epoch: 900 Average training loss: 2.5466\n",
      "====> Epoch: 1000 Average training loss: 2.3602\n",
      "====> Epoch: 1100 Average training loss: 2.2115\n",
      "====> Epoch: 1200 Average training loss: 2.0700\n",
      "====> Epoch: 1300 Average training loss: 1.9571\n",
      "====> Epoch: 1400 Average training loss: 1.8586\n",
      "====> Epoch: 1500 Average training loss: 1.7651\n",
      "====> Epoch: 1600 Average training loss: 1.6829\n",
      "====> Epoch: 1700 Average training loss: 1.6150\n",
      "====> Epoch: 1800 Average training loss: 1.5395\n",
      "====> Epoch: 100 Average training loss: 6.4700\n",
      "====> Epoch: 200 Average training loss: 5.2944\n",
      "====> Epoch: 300 Average training loss: 4.5435\n",
      "====> Epoch: 400 Average training loss: 4.0232\n",
      "====> Epoch: 500 Average training loss: 3.6012\n",
      "====> Epoch: 600 Average training loss: 3.2520\n",
      "====> Epoch: 700 Average training loss: 2.9716\n",
      "====> Epoch: 800 Average training loss: 2.7434\n",
      "====> Epoch: 900 Average training loss: 2.5378\n",
      "====> Epoch: 1000 Average training loss: 2.3735\n",
      "====> Epoch: 1100 Average training loss: 2.2165\n",
      "====> Epoch: 1200 Average training loss: 2.0893\n",
      "====> Epoch: 1300 Average training loss: 1.9576\n",
      "====> Epoch: 1400 Average training loss: 1.8500\n",
      "====> Epoch: 1500 Average training loss: 1.7643\n",
      "====> Epoch: 1600 Average training loss: 1.6872\n",
      "====> Epoch: 1700 Average training loss: 1.6103\n",
      "====> Epoch: 1800 Average training loss: 1.5351\n",
      "====> Epoch: 100 Average training loss: 6.6092\n",
      "====> Epoch: 200 Average training loss: 5.3514\n",
      "====> Epoch: 300 Average training loss: 4.5901\n",
      "====> Epoch: 400 Average training loss: 4.0292\n",
      "====> Epoch: 500 Average training loss: 3.5954\n",
      "====> Epoch: 600 Average training loss: 3.2703\n",
      "====> Epoch: 700 Average training loss: 2.9802\n",
      "====> Epoch: 800 Average training loss: 2.7434\n",
      "====> Epoch: 900 Average training loss: 2.5444\n",
      "====> Epoch: 1000 Average training loss: 2.3649\n",
      "====> Epoch: 1100 Average training loss: 2.2087\n",
      "====> Epoch: 1200 Average training loss: 2.0868\n",
      "====> Epoch: 1300 Average training loss: 1.9750\n",
      "====> Epoch: 1400 Average training loss: 1.8605\n",
      "====> Epoch: 1500 Average training loss: 1.7781\n",
      "====> Epoch: 1600 Average training loss: 1.6870\n",
      "====> Epoch: 1700 Average training loss: 1.6156\n",
      "====> Epoch: 1800 Average training loss: 1.5501\n",
      "====> Epoch: 100 Average training loss: 6.4933\n",
      "====> Epoch: 200 Average training loss: 5.3087\n",
      "====> Epoch: 300 Average training loss: 4.5616\n",
      "====> Epoch: 400 Average training loss: 4.0009\n",
      "====> Epoch: 500 Average training loss: 3.5993\n",
      "====> Epoch: 600 Average training loss: 3.2314\n",
      "====> Epoch: 700 Average training loss: 2.9620\n",
      "====> Epoch: 800 Average training loss: 2.7476\n",
      "====> Epoch: 900 Average training loss: 2.5214\n",
      "====> Epoch: 1000 Average training loss: 2.3681\n",
      "====> Epoch: 1100 Average training loss: 2.2069\n",
      "====> Epoch: 1200 Average training loss: 2.0682\n",
      "====> Epoch: 1300 Average training loss: 1.9264\n",
      "====> Epoch: 1400 Average training loss: 1.7667\n",
      "====> Epoch: 1500 Average training loss: 1.6888\n",
      "====> Epoch: 1600 Average training loss: 1.5840\n",
      "====> Epoch: 1700 Average training loss: 1.5298\n",
      "====> Epoch: 1800 Average training loss: 1.4547\n",
      "====> Epoch: 100 Average training loss: 6.8209\n",
      "====> Epoch: 200 Average training loss: 5.4859\n",
      "====> Epoch: 300 Average training loss: 4.6932\n",
      "====> Epoch: 400 Average training loss: 4.0855\n",
      "====> Epoch: 500 Average training loss: 3.6413\n",
      "====> Epoch: 600 Average training loss: 3.3114\n",
      "====> Epoch: 700 Average training loss: 3.0170\n",
      "====> Epoch: 800 Average training loss: 2.7646\n",
      "====> Epoch: 900 Average training loss: 2.5742\n",
      "====> Epoch: 1000 Average training loss: 2.3941\n",
      "====> Epoch: 1100 Average training loss: 2.2340\n",
      "====> Epoch: 1200 Average training loss: 2.0978\n",
      "====> Epoch: 1300 Average training loss: 1.9806\n",
      "====> Epoch: 1400 Average training loss: 1.8808\n",
      "====> Epoch: 1500 Average training loss: 1.7859\n",
      "====> Epoch: 1600 Average training loss: 1.7013\n",
      "====> Epoch: 1700 Average training loss: 1.6220\n",
      "====> Epoch: 1800 Average training loss: 1.5447\n",
      "====> Epoch: 100 Average training loss: 6.5936\n",
      "====> Epoch: 200 Average training loss: 5.3610\n",
      "====> Epoch: 300 Average training loss: 4.5975\n",
      "====> Epoch: 400 Average training loss: 4.0456\n",
      "====> Epoch: 500 Average training loss: 3.6203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 600 Average training loss: 3.2701\n",
      "====> Epoch: 700 Average training loss: 2.9713\n",
      "====> Epoch: 800 Average training loss: 2.7588\n",
      "====> Epoch: 900 Average training loss: 2.5392\n",
      "====> Epoch: 1000 Average training loss: 2.3657\n",
      "====> Epoch: 1100 Average training loss: 2.2298\n",
      "====> Epoch: 1200 Average training loss: 2.0919\n",
      "====> Epoch: 1300 Average training loss: 1.9745\n",
      "====> Epoch: 1400 Average training loss: 1.8659\n",
      "====> Epoch: 1500 Average training loss: 1.7821\n",
      "====> Epoch: 1600 Average training loss: 1.6846\n",
      "====> Epoch: 1700 Average training loss: 1.6079\n",
      "====> Epoch: 1800 Average training loss: 1.5517\n",
      "====> Epoch: 100 Average training loss: 6.5077\n",
      "====> Epoch: 200 Average training loss: 5.3068\n",
      "====> Epoch: 300 Average training loss: 4.5564\n",
      "====> Epoch: 400 Average training loss: 4.0301\n",
      "====> Epoch: 500 Average training loss: 3.5943\n",
      "====> Epoch: 600 Average training loss: 3.2604\n",
      "====> Epoch: 700 Average training loss: 2.9897\n",
      "====> Epoch: 800 Average training loss: 2.7399\n",
      "====> Epoch: 900 Average training loss: 2.5559\n",
      "====> Epoch: 1000 Average training loss: 2.3851\n",
      "====> Epoch: 1100 Average training loss: 2.2258\n",
      "====> Epoch: 1200 Average training loss: 2.1014\n",
      "====> Epoch: 1300 Average training loss: 1.9675\n",
      "====> Epoch: 1400 Average training loss: 1.8656\n",
      "====> Epoch: 1500 Average training loss: 1.7698\n",
      "====> Epoch: 1600 Average training loss: 1.6920\n",
      "====> Epoch: 1700 Average training loss: 1.6204\n",
      "====> Epoch: 1800 Average training loss: 1.5547\n",
      "====> Epoch: 100 Average training loss: 6.5649\n",
      "====> Epoch: 200 Average training loss: 5.3733\n",
      "====> Epoch: 300 Average training loss: 4.5939\n",
      "====> Epoch: 400 Average training loss: 4.0500\n",
      "====> Epoch: 500 Average training loss: 3.6205\n",
      "====> Epoch: 600 Average training loss: 3.2710\n",
      "====> Epoch: 700 Average training loss: 2.9797\n",
      "====> Epoch: 800 Average training loss: 2.7548\n",
      "====> Epoch: 900 Average training loss: 2.5389\n",
      "====> Epoch: 1000 Average training loss: 2.3858\n",
      "====> Epoch: 1100 Average training loss: 2.2167\n",
      "====> Epoch: 1200 Average training loss: 2.0916\n",
      "====> Epoch: 1300 Average training loss: 1.9697\n",
      "====> Epoch: 1400 Average training loss: 1.8595\n",
      "====> Epoch: 1500 Average training loss: 1.7646\n",
      "====> Epoch: 1600 Average training loss: 1.6771\n",
      "====> Epoch: 1700 Average training loss: 1.6132\n",
      "====> Epoch: 1800 Average training loss: 1.5421\n",
      "====> Epoch: 100 Average training loss: 6.6209\n",
      "====> Epoch: 200 Average training loss: 5.3935\n",
      "====> Epoch: 300 Average training loss: 4.6084\n",
      "====> Epoch: 400 Average training loss: 4.0654\n",
      "====> Epoch: 500 Average training loss: 3.6421\n",
      "====> Epoch: 600 Average training loss: 3.2941\n",
      "====> Epoch: 700 Average training loss: 3.0079\n",
      "====> Epoch: 800 Average training loss: 2.7657\n",
      "====> Epoch: 900 Average training loss: 2.5699\n",
      "====> Epoch: 1000 Average training loss: 2.3789\n",
      "====> Epoch: 1100 Average training loss: 2.2200\n",
      "====> Epoch: 1200 Average training loss: 2.0967\n",
      "====> Epoch: 1300 Average training loss: 1.9685\n",
      "====> Epoch: 1400 Average training loss: 1.8721\n",
      "====> Epoch: 1500 Average training loss: 1.7700\n",
      "====> Epoch: 1600 Average training loss: 1.6774\n",
      "====> Epoch: 1700 Average training loss: 1.6049\n",
      "====> Epoch: 1800 Average training loss: 1.5366\n",
      "====> Epoch: 100 Average training loss: 6.7247\n",
      "====> Epoch: 200 Average training loss: 5.4806\n",
      "====> Epoch: 300 Average training loss: 4.6588\n",
      "====> Epoch: 400 Average training loss: 4.0828\n",
      "====> Epoch: 500 Average training loss: 3.6406\n",
      "====> Epoch: 600 Average training loss: 3.2827\n",
      "====> Epoch: 700 Average training loss: 3.0078\n",
      "====> Epoch: 800 Average training loss: 2.7589\n",
      "====> Epoch: 900 Average training loss: 2.5654\n",
      "====> Epoch: 1000 Average training loss: 2.3692\n",
      "====> Epoch: 1100 Average training loss: 2.2255\n",
      "====> Epoch: 1200 Average training loss: 2.0996\n",
      "====> Epoch: 1300 Average training loss: 1.9761\n",
      "====> Epoch: 1400 Average training loss: 1.8802\n",
      "====> Epoch: 1500 Average training loss: 1.7827\n",
      "====> Epoch: 1600 Average training loss: 1.6896\n",
      "====> Epoch: 1700 Average training loss: 1.6132\n",
      "====> Epoch: 1800 Average training loss: 1.5512\n",
      "====> Epoch: 100 Average training loss: 6.5429\n",
      "====> Epoch: 200 Average training loss: 5.3131\n",
      "====> Epoch: 300 Average training loss: 4.5695\n",
      "====> Epoch: 400 Average training loss: 3.9900\n",
      "====> Epoch: 500 Average training loss: 3.5636\n",
      "====> Epoch: 600 Average training loss: 3.2355\n",
      "====> Epoch: 700 Average training loss: 2.9637\n",
      "====> Epoch: 800 Average training loss: 2.7707\n",
      "====> Epoch: 900 Average training loss: 2.4098\n",
      "====> Epoch: 1000 Average training loss: 2.0963\n",
      "====> Epoch: 1100 Average training loss: 2.1722\n",
      "====> Epoch: 1200 Average training loss: 1.8029\n",
      "====> Epoch: 1300 Average training loss: 1.8100\n",
      "====> Epoch: 1400 Average training loss: 1.5803\n",
      "====> Epoch: 1500 Average training loss: 1.6633\n",
      "====> Epoch: 1600 Average training loss: 1.5609\n",
      "====> Epoch: 1700 Average training loss: 1.3653\n",
      "====> Epoch: 1800 Average training loss: 1.4020\n",
      "====> Epoch: 100 Average training loss: 6.8402\n",
      "====> Epoch: 200 Average training loss: 5.5371\n",
      "====> Epoch: 300 Average training loss: 4.7261\n",
      "====> Epoch: 400 Average training loss: 4.1390\n",
      "====> Epoch: 500 Average training loss: 3.6724\n",
      "====> Epoch: 600 Average training loss: 3.3247\n",
      "====> Epoch: 700 Average training loss: 3.0206\n",
      "====> Epoch: 800 Average training loss: 2.7910\n",
      "====> Epoch: 900 Average training loss: 2.5514\n",
      "====> Epoch: 1000 Average training loss: 2.3990\n",
      "====> Epoch: 1100 Average training loss: 2.2407\n",
      "====> Epoch: 1200 Average training loss: 2.0964\n",
      "====> Epoch: 1300 Average training loss: 1.9824\n",
      "====> Epoch: 1400 Average training loss: 1.8799\n",
      "====> Epoch: 1500 Average training loss: 1.7778\n",
      "====> Epoch: 1600 Average training loss: 1.7003\n",
      "====> Epoch: 1700 Average training loss: 1.6144\n",
      "====> Epoch: 1800 Average training loss: 1.5602\n",
      "====> Epoch: 100 Average training loss: 6.5855\n",
      "====> Epoch: 200 Average training loss: 5.3574\n",
      "====> Epoch: 300 Average training loss: 4.6057\n",
      "====> Epoch: 400 Average training loss: 4.0425\n",
      "====> Epoch: 500 Average training loss: 3.6175\n",
      "====> Epoch: 600 Average training loss: 3.2697\n",
      "====> Epoch: 700 Average training loss: 2.9719\n",
      "====> Epoch: 800 Average training loss: 2.7313\n",
      "====> Epoch: 900 Average training loss: 2.5307\n",
      "====> Epoch: 1000 Average training loss: 2.3708\n",
      "====> Epoch: 1100 Average training loss: 2.2241\n",
      "====> Epoch: 1200 Average training loss: 2.0834\n",
      "====> Epoch: 1300 Average training loss: 1.9770\n",
      "====> Epoch: 1400 Average training loss: 1.8527\n",
      "====> Epoch: 1500 Average training loss: 1.7691\n",
      "====> Epoch: 1600 Average training loss: 1.6916\n",
      "====> Epoch: 1700 Average training loss: 1.6253\n",
      "====> Epoch: 1800 Average training loss: 1.5582\n",
      "====> Epoch: 100 Average training loss: 6.8378\n",
      "====> Epoch: 200 Average training loss: 5.5855\n",
      "====> Epoch: 300 Average training loss: 4.7530\n",
      "====> Epoch: 400 Average training loss: 4.1763\n",
      "====> Epoch: 500 Average training loss: 3.7294\n",
      "====> Epoch: 600 Average training loss: 3.3504\n",
      "====> Epoch: 700 Average training loss: 3.0372\n",
      "====> Epoch: 800 Average training loss: 2.7962\n",
      "====> Epoch: 900 Average training loss: 2.5818\n",
      "====> Epoch: 1000 Average training loss: 2.3966\n",
      "====> Epoch: 1100 Average training loss: 2.2476\n",
      "====> Epoch: 1200 Average training loss: 2.1071\n",
      "====> Epoch: 1300 Average training loss: 1.9821\n",
      "====> Epoch: 1400 Average training loss: 1.8725\n",
      "====> Epoch: 1500 Average training loss: 1.7748\n",
      "====> Epoch: 1600 Average training loss: 1.6964\n",
      "====> Epoch: 1700 Average training loss: 1.6225\n",
      "====> Epoch: 1800 Average training loss: 1.5389\n",
      "====> Epoch: 100 Average training loss: 6.6073\n",
      "====> Epoch: 200 Average training loss: 5.3687\n",
      "====> Epoch: 300 Average training loss: 4.6218\n",
      "====> Epoch: 400 Average training loss: 4.0382\n",
      "====> Epoch: 500 Average training loss: 3.6148\n",
      "====> Epoch: 600 Average training loss: 3.2914\n",
      "====> Epoch: 700 Average training loss: 3.0133\n",
      "====> Epoch: 800 Average training loss: 2.7585\n",
      "====> Epoch: 900 Average training loss: 2.5642\n",
      "====> Epoch: 1000 Average training loss: 2.3923\n",
      "====> Epoch: 1100 Average training loss: 2.2403\n",
      "====> Epoch: 1200 Average training loss: 2.0971\n",
      "====> Epoch: 1300 Average training loss: 1.9800\n",
      "====> Epoch: 1400 Average training loss: 1.8935\n",
      "====> Epoch: 1500 Average training loss: 1.7857\n",
      "====> Epoch: 1600 Average training loss: 1.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1700 Average training loss: 1.6325\n",
      "====> Epoch: 1800 Average training loss: 1.5556\n",
      "====> Epoch: 100 Average training loss: 6.5948\n",
      "====> Epoch: 200 Average training loss: 5.4058\n",
      "====> Epoch: 300 Average training loss: 4.6234\n",
      "====> Epoch: 400 Average training loss: 4.0739\n",
      "====> Epoch: 500 Average training loss: 3.6604\n",
      "====> Epoch: 600 Average training loss: 3.2878\n",
      "====> Epoch: 700 Average training loss: 3.0023\n",
      "====> Epoch: 800 Average training loss: 2.7900\n",
      "====> Epoch: 900 Average training loss: 2.5604\n",
      "====> Epoch: 1000 Average training loss: 2.3839\n",
      "====> Epoch: 1100 Average training loss: 2.2315\n",
      "====> Epoch: 1200 Average training loss: 2.1080\n",
      "====> Epoch: 1300 Average training loss: 1.9863\n",
      "====> Epoch: 1400 Average training loss: 1.8802\n",
      "====> Epoch: 1500 Average training loss: 1.7610\n",
      "====> Epoch: 1600 Average training loss: 1.6868\n",
      "====> Epoch: 1700 Average training loss: 1.6206\n",
      "====> Epoch: 1800 Average training loss: 1.5498\n",
      "====> Epoch: 100 Average training loss: 6.5710\n",
      "====> Epoch: 200 Average training loss: 5.3508\n",
      "====> Epoch: 300 Average training loss: 4.5936\n",
      "====> Epoch: 400 Average training loss: 4.0260\n",
      "====> Epoch: 500 Average training loss: 3.5888\n",
      "====> Epoch: 600 Average training loss: 3.2701\n",
      "====> Epoch: 700 Average training loss: 2.9853\n",
      "====> Epoch: 800 Average training loss: 2.7431\n",
      "====> Epoch: 900 Average training loss: 2.5341\n",
      "====> Epoch: 1000 Average training loss: 2.3682\n",
      "====> Epoch: 1100 Average training loss: 2.2166\n",
      "====> Epoch: 1200 Average training loss: 2.0690\n",
      "====> Epoch: 1300 Average training loss: 1.9730\n",
      "====> Epoch: 1400 Average training loss: 1.8561\n",
      "====> Epoch: 1500 Average training loss: 1.7660\n",
      "====> Epoch: 1600 Average training loss: 1.6881\n",
      "====> Epoch: 1700 Average training loss: 1.5991\n",
      "====> Epoch: 1800 Average training loss: 1.5389\n",
      "====> Epoch: 100 Average training loss: 6.7060\n",
      "====> Epoch: 200 Average training loss: 5.4666\n",
      "====> Epoch: 300 Average training loss: 4.6690\n",
      "====> Epoch: 400 Average training loss: 4.0985\n",
      "====> Epoch: 500 Average training loss: 3.6356\n",
      "====> Epoch: 600 Average training loss: 3.3053\n",
      "====> Epoch: 700 Average training loss: 2.9907\n",
      "====> Epoch: 800 Average training loss: 2.7692\n",
      "====> Epoch: 900 Average training loss: 2.5440\n",
      "====> Epoch: 1000 Average training loss: 2.3727\n",
      "====> Epoch: 1100 Average training loss: 2.2147\n",
      "====> Epoch: 1200 Average training loss: 2.0881\n",
      "====> Epoch: 1300 Average training loss: 1.9668\n",
      "====> Epoch: 1400 Average training loss: 1.8601\n",
      "====> Epoch: 1500 Average training loss: 1.7530\n",
      "====> Epoch: 1600 Average training loss: 1.6780\n",
      "====> Epoch: 1700 Average training loss: 1.5957\n",
      "====> Epoch: 1800 Average training loss: 1.5268\n",
      "====> Epoch: 100 Average training loss: 6.7095\n",
      "====> Epoch: 200 Average training loss: 5.4800\n",
      "====> Epoch: 300 Average training loss: 4.6725\n",
      "====> Epoch: 400 Average training loss: 4.1232\n",
      "====> Epoch: 500 Average training loss: 3.6670\n",
      "====> Epoch: 600 Average training loss: 3.3233\n",
      "====> Epoch: 700 Average training loss: 3.0301\n",
      "====> Epoch: 800 Average training loss: 2.7686\n",
      "====> Epoch: 900 Average training loss: 2.5640\n",
      "====> Epoch: 1000 Average training loss: 2.4026\n",
      "====> Epoch: 1100 Average training loss: 2.2147\n",
      "====> Epoch: 1200 Average training loss: 2.0926\n",
      "====> Epoch: 1300 Average training loss: 1.9819\n",
      "====> Epoch: 1400 Average training loss: 1.8767\n",
      "====> Epoch: 1500 Average training loss: 1.7873\n",
      "====> Epoch: 1600 Average training loss: 1.7041\n",
      "====> Epoch: 1700 Average training loss: 1.6175\n",
      "====> Epoch: 1800 Average training loss: 1.5317\n",
      "====> Epoch: 100 Average training loss: 6.9034\n",
      "====> Epoch: 200 Average training loss: 5.5233\n",
      "====> Epoch: 300 Average training loss: 4.7087\n",
      "====> Epoch: 400 Average training loss: 4.1169\n",
      "====> Epoch: 500 Average training loss: 3.6943\n",
      "====> Epoch: 600 Average training loss: 3.3255\n",
      "====> Epoch: 700 Average training loss: 3.0436\n",
      "====> Epoch: 800 Average training loss: 2.7983\n",
      "====> Epoch: 900 Average training loss: 2.5835\n",
      "====> Epoch: 1000 Average training loss: 2.4195\n",
      "====> Epoch: 1100 Average training loss: 2.2436\n",
      "====> Epoch: 1200 Average training loss: 2.1089\n",
      "====> Epoch: 1300 Average training loss: 1.9941\n",
      "====> Epoch: 1400 Average training loss: 1.8889\n",
      "====> Epoch: 1500 Average training loss: 1.7859\n",
      "====> Epoch: 1600 Average training loss: 1.7121\n",
      "====> Epoch: 1700 Average training loss: 1.6289\n",
      "====> Epoch: 1800 Average training loss: 1.5648\n",
      "====> Epoch: 100 Average training loss: 6.5750\n",
      "====> Epoch: 200 Average training loss: 5.3762\n",
      "====> Epoch: 300 Average training loss: 4.6207\n",
      "====> Epoch: 400 Average training loss: 4.0604\n",
      "====> Epoch: 500 Average training loss: 3.6542\n",
      "====> Epoch: 600 Average training loss: 3.3000\n",
      "====> Epoch: 700 Average training loss: 3.0089\n",
      "====> Epoch: 800 Average training loss: 2.7586\n",
      "====> Epoch: 900 Average training loss: 2.5685\n",
      "====> Epoch: 1000 Average training loss: 2.3810\n",
      "====> Epoch: 1100 Average training loss: 2.2188\n",
      "====> Epoch: 1200 Average training loss: 2.0934\n",
      "====> Epoch: 1300 Average training loss: 1.9649\n",
      "====> Epoch: 1400 Average training loss: 1.8648\n",
      "====> Epoch: 1500 Average training loss: 1.7675\n",
      "====> Epoch: 1600 Average training loss: 1.6789\n",
      "====> Epoch: 1700 Average training loss: 1.6103\n",
      "====> Epoch: 1800 Average training loss: 1.5436\n",
      "====> Epoch: 100 Average training loss: 6.9103\n",
      "====> Epoch: 200 Average training loss: 5.6191\n",
      "====> Epoch: 300 Average training loss: 4.7664\n",
      "====> Epoch: 400 Average training loss: 4.2083\n",
      "====> Epoch: 500 Average training loss: 3.7430\n",
      "====> Epoch: 600 Average training loss: 3.3907\n",
      "====> Epoch: 700 Average training loss: 3.0912\n",
      "====> Epoch: 800 Average training loss: 2.8534\n",
      "====> Epoch: 900 Average training loss: 2.6181\n",
      "====> Epoch: 1000 Average training loss: 2.4225\n",
      "====> Epoch: 1100 Average training loss: 2.2566\n",
      "====> Epoch: 1200 Average training loss: 2.1082\n",
      "====> Epoch: 1300 Average training loss: 1.9803\n",
      "====> Epoch: 1400 Average training loss: 1.8842\n",
      "====> Epoch: 1500 Average training loss: 1.7884\n",
      "====> Epoch: 1600 Average training loss: 1.7028\n",
      "====> Epoch: 1700 Average training loss: 1.6036\n",
      "====> Epoch: 1800 Average training loss: 1.5601\n",
      "====> Epoch: 100 Average training loss: 6.9839\n",
      "====> Epoch: 200 Average training loss: 5.6449\n",
      "====> Epoch: 300 Average training loss: 4.8054\n",
      "====> Epoch: 400 Average training loss: 4.2120\n",
      "====> Epoch: 500 Average training loss: 3.7278\n",
      "====> Epoch: 600 Average training loss: 3.3425\n",
      "====> Epoch: 700 Average training loss: 3.0492\n",
      "====> Epoch: 800 Average training loss: 2.7793\n",
      "====> Epoch: 900 Average training loss: 2.5799\n",
      "====> Epoch: 1000 Average training loss: 2.3836\n",
      "====> Epoch: 1100 Average training loss: 2.2388\n",
      "====> Epoch: 1200 Average training loss: 2.0998\n",
      "====> Epoch: 1300 Average training loss: 1.9837\n",
      "====> Epoch: 1400 Average training loss: 1.8799\n",
      "====> Epoch: 1500 Average training loss: 1.7837\n",
      "====> Epoch: 1600 Average training loss: 1.6949\n",
      "====> Epoch: 1700 Average training loss: 1.6042\n",
      "====> Epoch: 1800 Average training loss: 1.5367\n",
      "====> Epoch: 100 Average training loss: 6.7515\n",
      "====> Epoch: 200 Average training loss: 5.4730\n",
      "====> Epoch: 300 Average training loss: 4.6717\n",
      "====> Epoch: 400 Average training loss: 4.0819\n",
      "====> Epoch: 500 Average training loss: 3.6525\n",
      "====> Epoch: 600 Average training loss: 3.2902\n",
      "====> Epoch: 700 Average training loss: 3.0152\n",
      "====> Epoch: 800 Average training loss: 2.7738\n",
      "====> Epoch: 900 Average training loss: 2.5585\n",
      "====> Epoch: 1000 Average training loss: 2.3857\n",
      "====> Epoch: 1100 Average training loss: 2.2213\n",
      "====> Epoch: 1200 Average training loss: 2.1003\n",
      "====> Epoch: 1300 Average training loss: 1.9770\n",
      "====> Epoch: 1400 Average training loss: 1.8717\n",
      "====> Epoch: 1500 Average training loss: 1.7691\n",
      "====> Epoch: 1600 Average training loss: 1.6761\n",
      "====> Epoch: 1700 Average training loss: 1.6076\n",
      "====> Epoch: 1800 Average training loss: 1.5436\n",
      "====> Epoch: 100 Average training loss: 6.5314\n",
      "====> Epoch: 200 Average training loss: 5.3736\n",
      "====> Epoch: 300 Average training loss: 4.5852\n",
      "====> Epoch: 400 Average training loss: 4.0259\n",
      "====> Epoch: 500 Average training loss: 3.6359\n",
      "====> Epoch: 600 Average training loss: 3.2431\n",
      "====> Epoch: 700 Average training loss: 2.9902\n",
      "====> Epoch: 800 Average training loss: 2.6837\n",
      "====> Epoch: 900 Average training loss: 2.3823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average training loss: 2.2430\n",
      "====> Epoch: 1100 Average training loss: 2.1554\n",
      "====> Epoch: 1200 Average training loss: 1.9363\n",
      "====> Epoch: 1300 Average training loss: 1.8826\n",
      "====> Epoch: 1400 Average training loss: 1.7620\n",
      "====> Epoch: 1500 Average training loss: 1.6950\n",
      "====> Epoch: 1600 Average training loss: 1.5860\n",
      "====> Epoch: 1700 Average training loss: 1.5233\n",
      "====> Epoch: 1800 Average training loss: 1.4583\n",
      "====> Epoch: 100 Average training loss: 6.8176\n",
      "====> Epoch: 200 Average training loss: 5.5520\n",
      "====> Epoch: 300 Average training loss: 4.7931\n",
      "====> Epoch: 400 Average training loss: 4.1849\n",
      "====> Epoch: 500 Average training loss: 3.7555\n",
      "====> Epoch: 600 Average training loss: 3.3911\n",
      "====> Epoch: 700 Average training loss: 3.0863\n",
      "====> Epoch: 800 Average training loss: 2.8397\n",
      "====> Epoch: 900 Average training loss: 2.6135\n",
      "====> Epoch: 1000 Average training loss: 2.4439\n",
      "====> Epoch: 1100 Average training loss: 2.2900\n",
      "====> Epoch: 1200 Average training loss: 2.1304\n",
      "====> Epoch: 1300 Average training loss: 2.0193\n",
      "====> Epoch: 1400 Average training loss: 1.9068\n",
      "====> Epoch: 1500 Average training loss: 1.7055\n",
      "====> Epoch: 1600 Average training loss: 1.6851\n",
      "====> Epoch: 1700 Average training loss: 1.6216\n",
      "====> Epoch: 1800 Average training loss: 1.5349\n",
      "====> Epoch: 100 Average training loss: 6.7466\n",
      "====> Epoch: 200 Average training loss: 5.4878\n",
      "====> Epoch: 300 Average training loss: 4.6856\n",
      "====> Epoch: 400 Average training loss: 4.0677\n",
      "====> Epoch: 500 Average training loss: 3.6392\n",
      "====> Epoch: 600 Average training loss: 3.2914\n",
      "====> Epoch: 700 Average training loss: 2.9962\n",
      "====> Epoch: 800 Average training loss: 2.7497\n",
      "====> Epoch: 900 Average training loss: 2.5443\n",
      "====> Epoch: 1000 Average training loss: 2.3691\n",
      "====> Epoch: 1100 Average training loss: 2.2186\n",
      "====> Epoch: 1200 Average training loss: 2.0882\n",
      "====> Epoch: 1300 Average training loss: 1.9761\n",
      "====> Epoch: 1400 Average training loss: 1.8764\n",
      "====> Epoch: 1500 Average training loss: 1.7729\n",
      "====> Epoch: 1600 Average training loss: 1.6933\n",
      "====> Epoch: 1700 Average training loss: 1.6173\n",
      "====> Epoch: 1800 Average training loss: 1.5471\n",
      "====> Epoch: 100 Average training loss: 6.4884\n",
      "====> Epoch: 200 Average training loss: 5.2963\n",
      "====> Epoch: 300 Average training loss: 4.5562\n",
      "====> Epoch: 400 Average training loss: 4.0103\n",
      "====> Epoch: 500 Average training loss: 3.6098\n",
      "====> Epoch: 600 Average training loss: 3.2774\n",
      "====> Epoch: 700 Average training loss: 2.9797\n",
      "====> Epoch: 800 Average training loss: 2.7659\n",
      "====> Epoch: 900 Average training loss: 2.5334\n",
      "====> Epoch: 1000 Average training loss: 2.3788\n",
      "====> Epoch: 1100 Average training loss: 2.2262\n",
      "====> Epoch: 1200 Average training loss: 2.0763\n",
      "====> Epoch: 1300 Average training loss: 1.9630\n",
      "====> Epoch: 1400 Average training loss: 1.8222\n",
      "====> Epoch: 1500 Average training loss: 1.7727\n",
      "====> Epoch: 1600 Average training loss: 1.6786\n",
      "====> Epoch: 1700 Average training loss: 1.6160\n",
      "====> Epoch: 1800 Average training loss: 1.5195\n",
      "====> Epoch: 100 Average training loss: 6.6407\n",
      "====> Epoch: 200 Average training loss: 5.4365\n",
      "====> Epoch: 300 Average training loss: 4.6809\n",
      "====> Epoch: 400 Average training loss: 4.1123\n",
      "====> Epoch: 500 Average training loss: 3.6644\n",
      "====> Epoch: 600 Average training loss: 3.3135\n",
      "====> Epoch: 700 Average training loss: 3.0279\n",
      "====> Epoch: 800 Average training loss: 2.7653\n",
      "====> Epoch: 900 Average training loss: 2.5623\n",
      "====> Epoch: 1000 Average training loss: 2.3889\n",
      "====> Epoch: 1100 Average training loss: 2.2279\n",
      "====> Epoch: 1200 Average training loss: 2.0916\n",
      "====> Epoch: 1300 Average training loss: 1.9771\n",
      "====> Epoch: 1400 Average training loss: 1.8727\n",
      "====> Epoch: 1500 Average training loss: 1.7696\n",
      "====> Epoch: 1600 Average training loss: 1.6871\n",
      "====> Epoch: 1700 Average training loss: 1.6094\n",
      "====> Epoch: 1800 Average training loss: 1.5340\n",
      "====> Epoch: 100 Average training loss: 6.5476\n",
      "====> Epoch: 200 Average training loss: 5.3598\n",
      "====> Epoch: 300 Average training loss: 4.5893\n",
      "====> Epoch: 400 Average training loss: 4.0499\n",
      "====> Epoch: 500 Average training loss: 3.6333\n",
      "====> Epoch: 600 Average training loss: 3.2675\n",
      "====> Epoch: 700 Average training loss: 2.9880\n",
      "====> Epoch: 800 Average training loss: 2.7577\n",
      "====> Epoch: 900 Average training loss: 2.5658\n",
      "====> Epoch: 1000 Average training loss: 2.3803\n",
      "====> Epoch: 1100 Average training loss: 2.2281\n",
      "====> Epoch: 1200 Average training loss: 2.0818\n",
      "====> Epoch: 1300 Average training loss: 1.9629\n",
      "====> Epoch: 1400 Average training loss: 1.8669\n",
      "====> Epoch: 1500 Average training loss: 1.7660\n",
      "====> Epoch: 1600 Average training loss: 1.6873\n",
      "====> Epoch: 1700 Average training loss: 1.6014\n",
      "====> Epoch: 1800 Average training loss: 1.5437\n",
      "====> Epoch: 100 Average training loss: 6.5702\n",
      "====> Epoch: 200 Average training loss: 5.3357\n",
      "====> Epoch: 300 Average training loss: 4.6142\n",
      "====> Epoch: 400 Average training loss: 4.0430\n",
      "====> Epoch: 500 Average training loss: 3.6259\n",
      "====> Epoch: 600 Average training loss: 3.2723\n",
      "====> Epoch: 700 Average training loss: 2.9996\n",
      "====> Epoch: 800 Average training loss: 2.7485\n",
      "====> Epoch: 900 Average training loss: 2.5489\n",
      "====> Epoch: 1000 Average training loss: 2.3671\n",
      "====> Epoch: 1100 Average training loss: 2.2182\n",
      "====> Epoch: 1200 Average training loss: 2.0779\n",
      "====> Epoch: 1300 Average training loss: 1.9566\n",
      "====> Epoch: 1400 Average training loss: 1.8581\n",
      "====> Epoch: 1500 Average training loss: 1.7562\n",
      "====> Epoch: 1600 Average training loss: 1.6753\n",
      "====> Epoch: 1700 Average training loss: 1.6028\n",
      "====> Epoch: 1800 Average training loss: 1.5467\n",
      "====> Epoch: 100 Average training loss: 6.5975\n",
      "====> Epoch: 200 Average training loss: 5.3865\n",
      "====> Epoch: 300 Average training loss: 4.6181\n",
      "====> Epoch: 400 Average training loss: 4.0503\n",
      "====> Epoch: 500 Average training loss: 3.6229\n",
      "====> Epoch: 600 Average training loss: 3.2724\n",
      "====> Epoch: 700 Average training loss: 2.9934\n",
      "====> Epoch: 800 Average training loss: 2.7674\n",
      "====> Epoch: 900 Average training loss: 2.5540\n",
      "====> Epoch: 1000 Average training loss: 2.3837\n",
      "====> Epoch: 1100 Average training loss: 2.2120\n",
      "====> Epoch: 1200 Average training loss: 2.0814\n",
      "====> Epoch: 1300 Average training loss: 1.9661\n",
      "====> Epoch: 1400 Average training loss: 1.8691\n",
      "====> Epoch: 1500 Average training loss: 1.7743\n",
      "====> Epoch: 1600 Average training loss: 1.6837\n",
      "====> Epoch: 1700 Average training loss: 1.6006\n",
      "====> Epoch: 1800 Average training loss: 1.5411\n",
      "====> Epoch: 100 Average training loss: 6.4316\n",
      "====> Epoch: 200 Average training loss: 5.2708\n",
      "====> Epoch: 300 Average training loss: 4.5452\n",
      "====> Epoch: 400 Average training loss: 3.9843\n",
      "====> Epoch: 500 Average training loss: 3.5802\n",
      "====> Epoch: 600 Average training loss: 3.2425\n",
      "====> Epoch: 700 Average training loss: 2.9652\n",
      "====> Epoch: 800 Average training loss: 2.7324\n",
      "====> Epoch: 900 Average training loss: 2.5359\n",
      "====> Epoch: 1000 Average training loss: 2.3399\n",
      "====> Epoch: 1100 Average training loss: 2.1909\n",
      "====> Epoch: 1200 Average training loss: 2.0619\n",
      "====> Epoch: 1300 Average training loss: 1.9590\n",
      "====> Epoch: 1400 Average training loss: 1.8353\n",
      "====> Epoch: 1500 Average training loss: 1.7482\n",
      "====> Epoch: 1600 Average training loss: 1.6654\n",
      "====> Epoch: 1700 Average training loss: 1.5971\n",
      "====> Epoch: 1800 Average training loss: 1.5329\n",
      "====> Epoch: 100 Average training loss: 6.4583\n",
      "====> Epoch: 200 Average training loss: 5.2940\n",
      "====> Epoch: 300 Average training loss: 4.5729\n",
      "====> Epoch: 400 Average training loss: 4.0382\n",
      "====> Epoch: 500 Average training loss: 3.5890\n",
      "====> Epoch: 600 Average training loss: 3.2628\n",
      "====> Epoch: 700 Average training loss: 2.9807\n",
      "====> Epoch: 800 Average training loss: 2.7457\n",
      "====> Epoch: 900 Average training loss: 2.5357\n",
      "====> Epoch: 1000 Average training loss: 2.3621\n",
      "====> Epoch: 1100 Average training loss: 2.1982\n",
      "====> Epoch: 1200 Average training loss: 2.0687\n",
      "====> Epoch: 1300 Average training loss: 1.9426\n",
      "====> Epoch: 1400 Average training loss: 1.8538\n",
      "====> Epoch: 1500 Average training loss: 1.7505\n",
      "====> Epoch: 1600 Average training loss: 1.6720\n",
      "====> Epoch: 1700 Average training loss: 1.5927\n",
      "====> Epoch: 1800 Average training loss: 1.5394\n",
      "====> Epoch: 100 Average training loss: 6.5856\n",
      "====> Epoch: 200 Average training loss: 5.3893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average training loss: 4.6003\n",
      "====> Epoch: 400 Average training loss: 4.0434\n",
      "====> Epoch: 500 Average training loss: 3.6093\n",
      "====> Epoch: 600 Average training loss: 3.2626\n",
      "====> Epoch: 700 Average training loss: 3.0063\n",
      "====> Epoch: 800 Average training loss: 2.7628\n",
      "====> Epoch: 900 Average training loss: 2.5504\n",
      "====> Epoch: 1000 Average training loss: 2.3827\n",
      "====> Epoch: 1100 Average training loss: 2.2062\n",
      "====> Epoch: 1200 Average training loss: 2.0867\n",
      "====> Epoch: 1300 Average training loss: 1.9594\n",
      "====> Epoch: 1400 Average training loss: 1.8672\n",
      "====> Epoch: 1500 Average training loss: 1.7838\n",
      "====> Epoch: 1600 Average training loss: 1.6952\n",
      "====> Epoch: 1700 Average training loss: 1.6147\n",
      "====> Epoch: 1800 Average training loss: 1.5432\n",
      "====> Epoch: 100 Average training loss: 6.9451\n",
      "====> Epoch: 200 Average training loss: 5.6230\n",
      "====> Epoch: 300 Average training loss: 4.7844\n",
      "====> Epoch: 400 Average training loss: 4.1960\n",
      "====> Epoch: 500 Average training loss: 3.7277\n",
      "====> Epoch: 600 Average training loss: 3.3604\n",
      "====> Epoch: 700 Average training loss: 3.0510\n",
      "====> Epoch: 800 Average training loss: 2.7937\n",
      "====> Epoch: 900 Average training loss: 2.5880\n",
      "====> Epoch: 1000 Average training loss: 2.4068\n",
      "====> Epoch: 1100 Average training loss: 2.2394\n",
      "====> Epoch: 1200 Average training loss: 2.1049\n",
      "====> Epoch: 1300 Average training loss: 1.9737\n",
      "====> Epoch: 1400 Average training loss: 1.8712\n",
      "====> Epoch: 1500 Average training loss: 1.7767\n",
      "====> Epoch: 1600 Average training loss: 1.6963\n",
      "====> Epoch: 1700 Average training loss: 1.6242\n",
      "====> Epoch: 1800 Average training loss: 1.5383\n",
      "====> Epoch: 100 Average training loss: 6.4846\n",
      "====> Epoch: 200 Average training loss: 5.2994\n",
      "====> Epoch: 300 Average training loss: 4.5619\n",
      "====> Epoch: 400 Average training loss: 4.0252\n",
      "====> Epoch: 500 Average training loss: 3.5983\n",
      "====> Epoch: 600 Average training loss: 3.2705\n",
      "====> Epoch: 700 Average training loss: 2.9685\n",
      "====> Epoch: 800 Average training loss: 2.7528\n",
      "====> Epoch: 900 Average training loss: 2.5326\n",
      "====> Epoch: 1000 Average training loss: 2.3734\n",
      "====> Epoch: 1100 Average training loss: 2.2052\n",
      "====> Epoch: 1200 Average training loss: 2.0693\n",
      "====> Epoch: 1300 Average training loss: 1.9573\n",
      "====> Epoch: 1400 Average training loss: 1.8473\n",
      "====> Epoch: 1500 Average training loss: 1.7603\n",
      "====> Epoch: 1600 Average training loss: 1.6816\n",
      "====> Epoch: 1700 Average training loss: 1.6055\n",
      "====> Epoch: 1800 Average training loss: 1.5354\n",
      "====> Epoch: 100 Average training loss: 6.5804\n",
      "====> Epoch: 200 Average training loss: 5.3781\n",
      "====> Epoch: 300 Average training loss: 4.6127\n",
      "====> Epoch: 400 Average training loss: 4.0577\n",
      "====> Epoch: 500 Average training loss: 3.6467\n",
      "====> Epoch: 600 Average training loss: 3.3053\n",
      "====> Epoch: 700 Average training loss: 3.0178\n",
      "====> Epoch: 800 Average training loss: 2.7681\n",
      "====> Epoch: 900 Average training loss: 2.5566\n",
      "====> Epoch: 1000 Average training loss: 2.3779\n",
      "====> Epoch: 1100 Average training loss: 2.2341\n",
      "====> Epoch: 1200 Average training loss: 2.1008\n",
      "====> Epoch: 1300 Average training loss: 1.9838\n",
      "====> Epoch: 1400 Average training loss: 1.8721\n",
      "====> Epoch: 1500 Average training loss: 1.7836\n",
      "====> Epoch: 1600 Average training loss: 1.6903\n",
      "====> Epoch: 1700 Average training loss: 1.6100\n",
      "====> Epoch: 1800 Average training loss: 1.5497\n",
      "====> Epoch: 100 Average training loss: 6.6399\n",
      "====> Epoch: 200 Average training loss: 5.3977\n",
      "====> Epoch: 300 Average training loss: 4.6266\n",
      "====> Epoch: 400 Average training loss: 4.0658\n",
      "====> Epoch: 500 Average training loss: 3.6383\n",
      "====> Epoch: 600 Average training loss: 3.2787\n",
      "====> Epoch: 700 Average training loss: 2.9813\n",
      "====> Epoch: 800 Average training loss: 2.7458\n",
      "====> Epoch: 900 Average training loss: 2.5415\n",
      "====> Epoch: 1000 Average training loss: 2.3571\n",
      "====> Epoch: 1100 Average training loss: 2.1983\n",
      "====> Epoch: 1200 Average training loss: 2.0833\n",
      "====> Epoch: 1300 Average training loss: 1.9727\n",
      "====> Epoch: 1400 Average training loss: 1.8597\n",
      "====> Epoch: 1500 Average training loss: 1.7563\n",
      "====> Epoch: 1600 Average training loss: 1.6859\n",
      "====> Epoch: 1700 Average training loss: 1.6111\n",
      "====> Epoch: 1800 Average training loss: 1.5435\n",
      "====> Epoch: 100 Average training loss: 6.6838\n",
      "====> Epoch: 200 Average training loss: 5.4066\n",
      "====> Epoch: 300 Average training loss: 4.6164\n",
      "====> Epoch: 400 Average training loss: 4.0511\n",
      "====> Epoch: 500 Average training loss: 3.6360\n",
      "====> Epoch: 600 Average training loss: 3.2784\n",
      "====> Epoch: 700 Average training loss: 3.0167\n",
      "====> Epoch: 800 Average training loss: 2.7553\n",
      "====> Epoch: 900 Average training loss: 2.5521\n",
      "====> Epoch: 1000 Average training loss: 2.3671\n",
      "====> Epoch: 1100 Average training loss: 2.2159\n",
      "====> Epoch: 1200 Average training loss: 2.0927\n",
      "====> Epoch: 1300 Average training loss: 1.9614\n",
      "====> Epoch: 1400 Average training loss: 1.8591\n",
      "====> Epoch: 1500 Average training loss: 1.7612\n",
      "====> Epoch: 1600 Average training loss: 1.6807\n",
      "====> Epoch: 1700 Average training loss: 1.6080\n",
      "====> Epoch: 1800 Average training loss: 1.5507\n",
      "====> Epoch: 100 Average training loss: 6.5667\n",
      "====> Epoch: 200 Average training loss: 5.3473\n",
      "====> Epoch: 300 Average training loss: 4.6047\n",
      "====> Epoch: 400 Average training loss: 4.0464\n",
      "====> Epoch: 500 Average training loss: 3.6237\n",
      "====> Epoch: 600 Average training loss: 3.2606\n",
      "====> Epoch: 700 Average training loss: 2.9750\n",
      "====> Epoch: 800 Average training loss: 2.7546\n",
      "====> Epoch: 900 Average training loss: 2.5515\n",
      "====> Epoch: 1000 Average training loss: 2.3773\n",
      "====> Epoch: 1100 Average training loss: 2.2221\n",
      "====> Epoch: 1200 Average training loss: 2.0880\n",
      "====> Epoch: 1300 Average training loss: 1.9645\n",
      "====> Epoch: 1400 Average training loss: 1.8619\n",
      "====> Epoch: 1500 Average training loss: 1.7510\n",
      "====> Epoch: 1600 Average training loss: 1.6804\n",
      "====> Epoch: 1700 Average training loss: 1.6181\n",
      "====> Epoch: 1800 Average training loss: 1.5429\n",
      "====> Epoch: 100 Average training loss: 6.5684\n",
      "====> Epoch: 200 Average training loss: 5.3577\n",
      "====> Epoch: 300 Average training loss: 4.5985\n",
      "====> Epoch: 400 Average training loss: 4.0437\n",
      "====> Epoch: 500 Average training loss: 3.6349\n",
      "====> Epoch: 600 Average training loss: 3.2833\n",
      "====> Epoch: 700 Average training loss: 2.9984\n",
      "====> Epoch: 800 Average training loss: 2.7636\n",
      "====> Epoch: 900 Average training loss: 2.5549\n",
      "====> Epoch: 1000 Average training loss: 2.3684\n",
      "====> Epoch: 1100 Average training loss: 2.2329\n",
      "====> Epoch: 1200 Average training loss: 2.0943\n",
      "====> Epoch: 1300 Average training loss: 1.9712\n",
      "====> Epoch: 1400 Average training loss: 1.8639\n",
      "====> Epoch: 1500 Average training loss: 1.7629\n",
      "====> Epoch: 1600 Average training loss: 1.6844\n",
      "====> Epoch: 1700 Average training loss: 1.6216\n",
      "====> Epoch: 1800 Average training loss: 1.5399\n",
      "====> Epoch: 100 Average training loss: 6.5455\n",
      "====> Epoch: 200 Average training loss: 5.3128\n",
      "====> Epoch: 300 Average training loss: 4.5645\n",
      "====> Epoch: 400 Average training loss: 4.0187\n",
      "====> Epoch: 500 Average training loss: 3.6108\n",
      "====> Epoch: 600 Average training loss: 3.2701\n",
      "====> Epoch: 700 Average training loss: 2.9808\n",
      "====> Epoch: 800 Average training loss: 2.7570\n",
      "====> Epoch: 900 Average training loss: 2.5594\n",
      "====> Epoch: 1000 Average training loss: 2.3685\n",
      "====> Epoch: 1100 Average training loss: 2.2120\n",
      "====> Epoch: 1200 Average training loss: 2.0839\n",
      "====> Epoch: 1300 Average training loss: 1.9590\n",
      "====> Epoch: 1400 Average training loss: 1.8475\n",
      "====> Epoch: 1500 Average training loss: 1.7531\n",
      "====> Epoch: 1600 Average training loss: 1.6807\n",
      "====> Epoch: 1700 Average training loss: 1.6072\n",
      "====> Epoch: 1800 Average training loss: 1.5515\n",
      "====> Epoch: 100 Average training loss: 6.5099\n",
      "====> Epoch: 200 Average training loss: 5.3201\n",
      "====> Epoch: 300 Average training loss: 4.5809\n",
      "====> Epoch: 400 Average training loss: 4.0347\n",
      "====> Epoch: 500 Average training loss: 3.6246\n",
      "====> Epoch: 600 Average training loss: 3.2716\n",
      "====> Epoch: 700 Average training loss: 2.9800\n",
      "====> Epoch: 800 Average training loss: 2.7762\n",
      "====> Epoch: 900 Average training loss: 2.5595\n",
      "====> Epoch: 1000 Average training loss: 2.3883\n",
      "====> Epoch: 1100 Average training loss: 2.2358\n",
      "====> Epoch: 1200 Average training loss: 2.0499\n",
      "====> Epoch: 1300 Average training loss: 1.9798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1400 Average training loss: 1.8342\n",
      "====> Epoch: 1500 Average training loss: 1.7564\n",
      "====> Epoch: 1600 Average training loss: 1.6994\n",
      "====> Epoch: 1700 Average training loss: 1.6172\n",
      "====> Epoch: 1800 Average training loss: 1.4926\n",
      "====> Epoch: 100 Average training loss: 6.5294\n",
      "====> Epoch: 200 Average training loss: 5.3245\n",
      "====> Epoch: 300 Average training loss: 4.5552\n",
      "====> Epoch: 400 Average training loss: 4.0237\n",
      "====> Epoch: 500 Average training loss: 3.5972\n",
      "====> Epoch: 600 Average training loss: 3.2764\n",
      "====> Epoch: 700 Average training loss: 2.9791\n",
      "====> Epoch: 800 Average training loss: 2.7495\n",
      "====> Epoch: 900 Average training loss: 2.5438\n",
      "====> Epoch: 1000 Average training loss: 2.3655\n",
      "====> Epoch: 1100 Average training loss: 2.2316\n",
      "====> Epoch: 1200 Average training loss: 2.0870\n",
      "====> Epoch: 1300 Average training loss: 1.9680\n",
      "====> Epoch: 1400 Average training loss: 1.8663\n",
      "====> Epoch: 1500 Average training loss: 1.7702\n",
      "====> Epoch: 1600 Average training loss: 1.6779\n",
      "====> Epoch: 1700 Average training loss: 1.6050\n",
      "====> Epoch: 1800 Average training loss: 1.5541\n",
      "====> Epoch: 100 Average training loss: 6.5592\n",
      "====> Epoch: 200 Average training loss: 5.3746\n",
      "====> Epoch: 300 Average training loss: 4.6117\n",
      "====> Epoch: 400 Average training loss: 4.0497\n",
      "====> Epoch: 500 Average training loss: 3.6038\n",
      "====> Epoch: 600 Average training loss: 3.2958\n",
      "====> Epoch: 700 Average training loss: 2.9841\n",
      "====> Epoch: 800 Average training loss: 2.7572\n",
      "====> Epoch: 900 Average training loss: 2.5466\n",
      "====> Epoch: 1000 Average training loss: 2.3795\n",
      "====> Epoch: 1100 Average training loss: 2.2201\n",
      "====> Epoch: 1200 Average training loss: 2.0801\n",
      "====> Epoch: 1300 Average training loss: 1.9632\n",
      "====> Epoch: 1400 Average training loss: 1.8674\n",
      "====> Epoch: 1500 Average training loss: 1.7640\n",
      "====> Epoch: 1600 Average training loss: 1.6790\n",
      "====> Epoch: 1700 Average training loss: 1.6120\n",
      "====> Epoch: 1800 Average training loss: 1.5483\n",
      "====> Epoch: 100 Average training loss: 6.4442\n",
      "====> Epoch: 200 Average training loss: 5.2795\n",
      "====> Epoch: 300 Average training loss: 4.5118\n",
      "====> Epoch: 400 Average training loss: 3.9931\n",
      "====> Epoch: 500 Average training loss: 3.5636\n",
      "====> Epoch: 600 Average training loss: 3.2331\n",
      "====> Epoch: 700 Average training loss: 2.9482\n",
      "====> Epoch: 800 Average training loss: 2.7194\n",
      "====> Epoch: 900 Average training loss: 2.5383\n",
      "====> Epoch: 1000 Average training loss: 2.3692\n",
      "====> Epoch: 1100 Average training loss: 2.2048\n",
      "====> Epoch: 1200 Average training loss: 2.0881\n",
      "====> Epoch: 1300 Average training loss: 1.9625\n",
      "====> Epoch: 1400 Average training loss: 1.8434\n",
      "====> Epoch: 1500 Average training loss: 1.7764\n",
      "====> Epoch: 1600 Average training loss: 1.6810\n",
      "====> Epoch: 1700 Average training loss: 1.6247\n",
      "====> Epoch: 1800 Average training loss: 1.5409\n",
      "====> Epoch: 100 Average training loss: 6.4905\n",
      "====> Epoch: 200 Average training loss: 5.2835\n",
      "====> Epoch: 300 Average training loss: 4.5534\n",
      "====> Epoch: 400 Average training loss: 4.0081\n",
      "====> Epoch: 500 Average training loss: 3.5916\n",
      "====> Epoch: 600 Average training loss: 3.2638\n",
      "====> Epoch: 700 Average training loss: 2.9920\n",
      "====> Epoch: 800 Average training loss: 2.7719\n",
      "====> Epoch: 900 Average training loss: 2.5290\n",
      "====> Epoch: 1000 Average training loss: 2.3366\n",
      "====> Epoch: 1100 Average training loss: 2.0754\n",
      "====> Epoch: 1200 Average training loss: 2.0024\n",
      "====> Epoch: 1300 Average training loss: 1.8583\n",
      "====> Epoch: 1400 Average training loss: 1.8400\n",
      "====> Epoch: 1500 Average training loss: 1.6466\n",
      "====> Epoch: 1600 Average training loss: 1.6447\n",
      "====> Epoch: 1700 Average training loss: 1.5609\n",
      "====> Epoch: 1800 Average training loss: 1.4791\n",
      "====> Epoch: 100 Average training loss: 6.5066\n",
      "====> Epoch: 200 Average training loss: 5.3174\n",
      "====> Epoch: 300 Average training loss: 4.5605\n",
      "====> Epoch: 400 Average training loss: 4.0207\n",
      "====> Epoch: 500 Average training loss: 3.5866\n",
      "====> Epoch: 600 Average training loss: 3.2512\n",
      "====> Epoch: 700 Average training loss: 2.9754\n",
      "====> Epoch: 800 Average training loss: 2.7520\n",
      "====> Epoch: 900 Average training loss: 2.5334\n",
      "====> Epoch: 1000 Average training loss: 2.3591\n",
      "====> Epoch: 1100 Average training loss: 2.2104\n",
      "====> Epoch: 1200 Average training loss: 2.0810\n",
      "====> Epoch: 1300 Average training loss: 1.9633\n",
      "====> Epoch: 1400 Average training loss: 1.8570\n",
      "====> Epoch: 1500 Average training loss: 1.7633\n",
      "====> Epoch: 1600 Average training loss: 1.6914\n",
      "====> Epoch: 1700 Average training loss: 1.6090\n",
      "====> Epoch: 1800 Average training loss: 1.5430\n",
      "====> Epoch: 100 Average training loss: 6.5558\n",
      "====> Epoch: 200 Average training loss: 5.3752\n",
      "====> Epoch: 300 Average training loss: 4.5880\n",
      "====> Epoch: 400 Average training loss: 4.0637\n",
      "====> Epoch: 500 Average training loss: 3.6245\n",
      "====> Epoch: 600 Average training loss: 3.2890\n",
      "====> Epoch: 700 Average training loss: 2.9961\n",
      "====> Epoch: 800 Average training loss: 2.7506\n",
      "====> Epoch: 900 Average training loss: 2.5483\n",
      "====> Epoch: 1000 Average training loss: 2.3719\n",
      "====> Epoch: 1100 Average training loss: 2.2119\n",
      "====> Epoch: 1200 Average training loss: 2.0820\n",
      "====> Epoch: 1300 Average training loss: 1.9561\n",
      "====> Epoch: 1400 Average training loss: 1.8520\n",
      "====> Epoch: 1500 Average training loss: 1.7645\n",
      "====> Epoch: 1600 Average training loss: 1.6746\n",
      "====> Epoch: 1700 Average training loss: 1.6101\n",
      "====> Epoch: 1800 Average training loss: 1.5434\n",
      "====> Epoch: 100 Average training loss: 6.5488\n",
      "====> Epoch: 200 Average training loss: 5.3405\n",
      "====> Epoch: 300 Average training loss: 4.5880\n",
      "====> Epoch: 400 Average training loss: 4.0541\n",
      "====> Epoch: 500 Average training loss: 3.6031\n",
      "====> Epoch: 600 Average training loss: 3.2580\n",
      "====> Epoch: 700 Average training loss: 2.9791\n",
      "====> Epoch: 800 Average training loss: 2.7468\n",
      "====> Epoch: 900 Average training loss: 2.5377\n",
      "====> Epoch: 1000 Average training loss: 2.3625\n",
      "====> Epoch: 1100 Average training loss: 2.2230\n",
      "====> Epoch: 1200 Average training loss: 2.0797\n",
      "====> Epoch: 1300 Average training loss: 1.9779\n",
      "====> Epoch: 1400 Average training loss: 1.8612\n",
      "====> Epoch: 1500 Average training loss: 1.7605\n",
      "====> Epoch: 1600 Average training loss: 1.6757\n",
      "====> Epoch: 1700 Average training loss: 1.6089\n",
      "====> Epoch: 1800 Average training loss: 1.5368\n",
      "====> Epoch: 100 Average training loss: 6.6919\n",
      "====> Epoch: 200 Average training loss: 5.3997\n",
      "====> Epoch: 300 Average training loss: 4.6195\n",
      "====> Epoch: 400 Average training loss: 4.0498\n",
      "====> Epoch: 500 Average training loss: 3.6289\n",
      "====> Epoch: 600 Average training loss: 3.2895\n",
      "====> Epoch: 700 Average training loss: 3.0127\n",
      "====> Epoch: 800 Average training loss: 2.7562\n",
      "====> Epoch: 900 Average training loss: 2.5670\n",
      "====> Epoch: 1000 Average training loss: 2.3851\n",
      "====> Epoch: 1100 Average training loss: 2.2271\n",
      "====> Epoch: 1200 Average training loss: 2.0984\n",
      "====> Epoch: 1300 Average training loss: 1.9778\n",
      "====> Epoch: 1400 Average training loss: 1.8647\n",
      "====> Epoch: 1500 Average training loss: 1.7679\n",
      "====> Epoch: 1600 Average training loss: 1.6841\n",
      "====> Epoch: 1700 Average training loss: 1.6175\n",
      "====> Epoch: 1800 Average training loss: 1.5574\n",
      "====> Epoch: 100 Average training loss: 6.4442\n",
      "====> Epoch: 200 Average training loss: 5.2847\n",
      "====> Epoch: 300 Average training loss: 4.5425\n",
      "====> Epoch: 400 Average training loss: 4.0034\n",
      "====> Epoch: 500 Average training loss: 3.5740\n",
      "====> Epoch: 600 Average training loss: 3.2601\n",
      "====> Epoch: 700 Average training loss: 2.9638\n",
      "====> Epoch: 800 Average training loss: 2.7438\n",
      "====> Epoch: 900 Average training loss: 2.5398\n",
      "====> Epoch: 1000 Average training loss: 2.3499\n",
      "====> Epoch: 1100 Average training loss: 2.2132\n",
      "====> Epoch: 1200 Average training loss: 2.0896\n",
      "====> Epoch: 1300 Average training loss: 1.9565\n",
      "====> Epoch: 1400 Average training loss: 1.8558\n",
      "====> Epoch: 1500 Average training loss: 1.7649\n",
      "====> Epoch: 1600 Average training loss: 1.6704\n",
      "====> Epoch: 1700 Average training loss: 1.5989\n",
      "====> Epoch: 1800 Average training loss: 1.5323\n",
      "====> Epoch: 100 Average training loss: 6.4879\n",
      "====> Epoch: 200 Average training loss: 5.3165\n",
      "====> Epoch: 300 Average training loss: 4.5781\n",
      "====> Epoch: 400 Average training loss: 4.0316\n",
      "====> Epoch: 500 Average training loss: 3.6079\n",
      "====> Epoch: 600 Average training loss: 3.2647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 700 Average training loss: 2.9798\n",
      "====> Epoch: 800 Average training loss: 2.7529\n",
      "====> Epoch: 900 Average training loss: 2.5440\n",
      "====> Epoch: 1000 Average training loss: 2.3731\n",
      "====> Epoch: 1100 Average training loss: 2.2123\n",
      "====> Epoch: 1200 Average training loss: 2.0868\n",
      "====> Epoch: 1300 Average training loss: 1.9688\n",
      "====> Epoch: 1400 Average training loss: 1.8655\n",
      "====> Epoch: 1500 Average training loss: 1.7686\n",
      "====> Epoch: 1600 Average training loss: 1.6856\n",
      "====> Epoch: 1700 Average training loss: 1.6145\n",
      "====> Epoch: 1800 Average training loss: 1.5411\n",
      "====> Epoch: 100 Average training loss: 6.5041\n",
      "====> Epoch: 200 Average training loss: 5.3115\n",
      "====> Epoch: 300 Average training loss: 4.5630\n",
      "====> Epoch: 400 Average training loss: 4.0088\n",
      "====> Epoch: 500 Average training loss: 3.5889\n",
      "====> Epoch: 600 Average training loss: 3.2536\n",
      "====> Epoch: 700 Average training loss: 2.9636\n",
      "====> Epoch: 800 Average training loss: 2.7171\n",
      "====> Epoch: 900 Average training loss: 2.5123\n",
      "====> Epoch: 1000 Average training loss: 2.3527\n",
      "====> Epoch: 1100 Average training loss: 2.1995\n",
      "====> Epoch: 1200 Average training loss: 2.0852\n",
      "====> Epoch: 1300 Average training loss: 1.9662\n",
      "====> Epoch: 1400 Average training loss: 1.8422\n",
      "====> Epoch: 1500 Average training loss: 1.7687\n",
      "====> Epoch: 1600 Average training loss: 1.6726\n",
      "====> Epoch: 1700 Average training loss: 1.6113\n",
      "====> Epoch: 1800 Average training loss: 1.5322\n",
      "====> Epoch: 100 Average training loss: 6.4828\n",
      "====> Epoch: 200 Average training loss: 5.3239\n",
      "====> Epoch: 300 Average training loss: 4.5816\n",
      "====> Epoch: 400 Average training loss: 4.0190\n",
      "====> Epoch: 500 Average training loss: 3.6053\n",
      "====> Epoch: 600 Average training loss: 3.2681\n",
      "====> Epoch: 700 Average training loss: 2.9859\n",
      "====> Epoch: 800 Average training loss: 2.7527\n",
      "====> Epoch: 900 Average training loss: 2.5406\n",
      "====> Epoch: 1000 Average training loss: 2.3686\n",
      "====> Epoch: 1100 Average training loss: 2.2088\n",
      "====> Epoch: 1200 Average training loss: 2.0825\n",
      "====> Epoch: 1300 Average training loss: 1.9791\n",
      "====> Epoch: 1400 Average training loss: 1.8550\n",
      "====> Epoch: 1500 Average training loss: 1.7635\n",
      "====> Epoch: 1600 Average training loss: 1.6856\n",
      "====> Epoch: 1700 Average training loss: 1.6115\n",
      "====> Epoch: 1800 Average training loss: 1.5549\n",
      "====> Epoch: 100 Average training loss: 6.4557\n",
      "====> Epoch: 200 Average training loss: 5.2865\n",
      "====> Epoch: 300 Average training loss: 4.5323\n",
      "====> Epoch: 400 Average training loss: 4.0044\n",
      "====> Epoch: 500 Average training loss: 3.5641\n",
      "====> Epoch: 600 Average training loss: 3.2364\n",
      "====> Epoch: 700 Average training loss: 2.9584\n",
      "====> Epoch: 800 Average training loss: 2.7230\n",
      "====> Epoch: 900 Average training loss: 2.5170\n",
      "====> Epoch: 1000 Average training loss: 2.3493\n",
      "====> Epoch: 1100 Average training loss: 2.2052\n",
      "====> Epoch: 1200 Average training loss: 2.0875\n",
      "====> Epoch: 1300 Average training loss: 1.9544\n",
      "====> Epoch: 1400 Average training loss: 1.8667\n",
      "====> Epoch: 1500 Average training loss: 1.7573\n",
      "====> Epoch: 1600 Average training loss: 1.6815\n",
      "====> Epoch: 1700 Average training loss: 1.6159\n",
      "====> Epoch: 1800 Average training loss: 1.5360\n",
      "====> Epoch: 100 Average training loss: 6.5991\n",
      "====> Epoch: 200 Average training loss: 5.3647\n",
      "====> Epoch: 300 Average training loss: 4.6118\n",
      "====> Epoch: 400 Average training loss: 4.0494\n",
      "====> Epoch: 500 Average training loss: 3.6283\n",
      "====> Epoch: 600 Average training loss: 3.2779\n",
      "====> Epoch: 700 Average training loss: 3.0013\n",
      "====> Epoch: 800 Average training loss: 2.7552\n",
      "====> Epoch: 900 Average training loss: 2.5457\n",
      "====> Epoch: 1000 Average training loss: 2.3720\n",
      "====> Epoch: 1100 Average training loss: 2.2176\n",
      "====> Epoch: 1200 Average training loss: 2.0788\n",
      "====> Epoch: 1300 Average training loss: 1.9570\n",
      "====> Epoch: 1400 Average training loss: 1.8637\n",
      "====> Epoch: 1500 Average training loss: 1.7655\n",
      "====> Epoch: 1600 Average training loss: 1.6740\n",
      "====> Epoch: 1700 Average training loss: 1.6027\n",
      "====> Epoch: 1800 Average training loss: 1.5304\n",
      "====> Epoch: 100 Average training loss: 6.7815\n",
      "====> Epoch: 200 Average training loss: 5.5254\n",
      "====> Epoch: 300 Average training loss: 4.7389\n",
      "====> Epoch: 400 Average training loss: 4.1419\n",
      "====> Epoch: 500 Average training loss: 3.6985\n",
      "====> Epoch: 600 Average training loss: 3.3378\n",
      "====> Epoch: 700 Average training loss: 3.0840\n",
      "====> Epoch: 800 Average training loss: 2.8042\n",
      "====> Epoch: 900 Average training loss: 2.6066\n",
      "====> Epoch: 1000 Average training loss: 2.4117\n",
      "====> Epoch: 1100 Average training loss: 2.2405\n",
      "====> Epoch: 1200 Average training loss: 2.1223\n",
      "====> Epoch: 1300 Average training loss: 1.9924\n",
      "====> Epoch: 1400 Average training loss: 1.8878\n",
      "====> Epoch: 1500 Average training loss: 1.7788\n",
      "====> Epoch: 1600 Average training loss: 1.7115\n",
      "====> Epoch: 1700 Average training loss: 1.6225\n",
      "====> Epoch: 1800 Average training loss: 1.5461\n",
      "====> Epoch: 100 Average training loss: 6.7377\n",
      "====> Epoch: 200 Average training loss: 5.5074\n",
      "====> Epoch: 300 Average training loss: 4.7033\n",
      "====> Epoch: 400 Average training loss: 4.1371\n",
      "====> Epoch: 500 Average training loss: 3.6693\n",
      "====> Epoch: 600 Average training loss: 3.3516\n",
      "====> Epoch: 700 Average training loss: 3.0313\n",
      "====> Epoch: 800 Average training loss: 2.7712\n",
      "====> Epoch: 900 Average training loss: 2.5618\n",
      "====> Epoch: 1000 Average training loss: 2.3950\n",
      "====> Epoch: 1100 Average training loss: 2.2262\n",
      "====> Epoch: 1200 Average training loss: 2.0978\n",
      "====> Epoch: 1300 Average training loss: 1.9648\n",
      "====> Epoch: 1400 Average training loss: 1.8723\n",
      "====> Epoch: 1500 Average training loss: 1.7723\n",
      "====> Epoch: 1600 Average training loss: 1.6765\n",
      "====> Epoch: 1700 Average training loss: 1.5957\n",
      "====> Epoch: 1800 Average training loss: 1.5303\n",
      "====> Epoch: 100 Average training loss: 6.5392\n",
      "====> Epoch: 200 Average training loss: 5.3393\n",
      "====> Epoch: 300 Average training loss: 4.5658\n",
      "====> Epoch: 400 Average training loss: 4.0168\n",
      "====> Epoch: 500 Average training loss: 3.6029\n",
      "====> Epoch: 600 Average training loss: 3.2696\n",
      "====> Epoch: 700 Average training loss: 2.9829\n",
      "====> Epoch: 800 Average training loss: 2.7490\n",
      "====> Epoch: 900 Average training loss: 2.5340\n",
      "====> Epoch: 1000 Average training loss: 2.3685\n",
      "====> Epoch: 1100 Average training loss: 2.2142\n",
      "====> Epoch: 1200 Average training loss: 2.0834\n",
      "====> Epoch: 1300 Average training loss: 1.9586\n",
      "====> Epoch: 1400 Average training loss: 1.8610\n",
      "====> Epoch: 1500 Average training loss: 1.7597\n",
      "====> Epoch: 1600 Average training loss: 1.6891\n",
      "====> Epoch: 1700 Average training loss: 1.6103\n",
      "====> Epoch: 1800 Average training loss: 1.5374\n",
      "====> Epoch: 100 Average training loss: 6.6503\n",
      "====> Epoch: 200 Average training loss: 5.4246\n",
      "====> Epoch: 300 Average training loss: 4.6304\n",
      "====> Epoch: 400 Average training loss: 4.0958\n",
      "====> Epoch: 500 Average training loss: 3.6452\n",
      "====> Epoch: 600 Average training loss: 3.2847\n",
      "====> Epoch: 700 Average training loss: 3.0071\n",
      "====> Epoch: 800 Average training loss: 2.7699\n",
      "====> Epoch: 900 Average training loss: 2.5794\n",
      "====> Epoch: 1000 Average training loss: 2.3941\n",
      "====> Epoch: 1100 Average training loss: 2.2181\n",
      "====> Epoch: 1200 Average training loss: 2.1151\n",
      "====> Epoch: 1300 Average training loss: 1.9670\n",
      "====> Epoch: 1400 Average training loss: 1.8613\n",
      "====> Epoch: 1500 Average training loss: 1.7673\n",
      "====> Epoch: 1600 Average training loss: 1.6887\n",
      "====> Epoch: 1700 Average training loss: 1.6036\n",
      "====> Epoch: 1800 Average training loss: 1.5428\n",
      "====> Epoch: 100 Average training loss: 6.6677\n",
      "====> Epoch: 200 Average training loss: 5.4181\n",
      "====> Epoch: 300 Average training loss: 4.6409\n",
      "====> Epoch: 400 Average training loss: 4.0643\n",
      "====> Epoch: 500 Average training loss: 3.6213\n",
      "====> Epoch: 600 Average training loss: 3.2924\n",
      "====> Epoch: 700 Average training loss: 2.9916\n",
      "====> Epoch: 800 Average training loss: 2.7410\n",
      "====> Epoch: 900 Average training loss: 2.5513\n",
      "====> Epoch: 1000 Average training loss: 2.3688\n",
      "====> Epoch: 1100 Average training loss: 2.2172\n",
      "====> Epoch: 1200 Average training loss: 2.0814\n",
      "====> Epoch: 1300 Average training loss: 1.9636\n",
      "====> Epoch: 1400 Average training loss: 1.8632\n",
      "====> Epoch: 1500 Average training loss: 1.7712\n",
      "====> Epoch: 1600 Average training loss: 1.6838\n",
      "====> Epoch: 1700 Average training loss: 1.6128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1800 Average training loss: 1.5395\n",
      "====> Epoch: 100 Average training loss: 6.7683\n",
      "====> Epoch: 200 Average training loss: 5.5146\n",
      "====> Epoch: 300 Average training loss: 4.7296\n",
      "====> Epoch: 400 Average training loss: 4.1603\n",
      "====> Epoch: 500 Average training loss: 3.7200\n",
      "====> Epoch: 600 Average training loss: 3.3487\n",
      "====> Epoch: 700 Average training loss: 3.0551\n",
      "====> Epoch: 800 Average training loss: 2.8057\n",
      "====> Epoch: 900 Average training loss: 2.5984\n",
      "====> Epoch: 1000 Average training loss: 2.3999\n",
      "====> Epoch: 1100 Average training loss: 2.2460\n",
      "====> Epoch: 1200 Average training loss: 2.1130\n",
      "====> Epoch: 1300 Average training loss: 1.9968\n",
      "====> Epoch: 1400 Average training loss: 1.8875\n",
      "====> Epoch: 1500 Average training loss: 1.7828\n",
      "====> Epoch: 1600 Average training loss: 1.7170\n",
      "====> Epoch: 1700 Average training loss: 1.6194\n",
      "====> Epoch: 1800 Average training loss: 1.5539\n",
      "====> Epoch: 100 Average training loss: 6.5206\n",
      "====> Epoch: 200 Average training loss: 5.3068\n",
      "====> Epoch: 300 Average training loss: 4.6167\n",
      "====> Epoch: 400 Average training loss: 4.0301\n",
      "====> Epoch: 500 Average training loss: 3.6141\n",
      "====> Epoch: 600 Average training loss: 3.2559\n",
      "====> Epoch: 700 Average training loss: 2.9859\n",
      "====> Epoch: 800 Average training loss: 2.6740\n",
      "====> Epoch: 900 Average training loss: 2.5726\n",
      "====> Epoch: 1000 Average training loss: 2.3897\n",
      "====> Epoch: 1100 Average training loss: 2.2215\n",
      "====> Epoch: 1200 Average training loss: 2.0283\n",
      "====> Epoch: 1300 Average training loss: 1.8381\n",
      "====> Epoch: 1400 Average training loss: 1.8497\n",
      "====> Epoch: 1500 Average training loss: 1.7325\n",
      "====> Epoch: 1600 Average training loss: 1.6686\n",
      "====> Epoch: 1700 Average training loss: 1.5677\n",
      "====> Epoch: 1800 Average training loss: 1.4547\n",
      "====> Epoch: 100 Average training loss: 6.6016\n",
      "====> Epoch: 200 Average training loss: 5.3788\n",
      "====> Epoch: 300 Average training loss: 4.5882\n",
      "====> Epoch: 400 Average training loss: 4.0677\n",
      "====> Epoch: 500 Average training loss: 3.6182\n",
      "====> Epoch: 600 Average training loss: 3.2701\n",
      "====> Epoch: 700 Average training loss: 3.0042\n",
      "====> Epoch: 800 Average training loss: 2.7797\n",
      "====> Epoch: 900 Average training loss: 2.5596\n",
      "====> Epoch: 1000 Average training loss: 2.3763\n",
      "====> Epoch: 1100 Average training loss: 2.2263\n",
      "====> Epoch: 1200 Average training loss: 2.0722\n",
      "====> Epoch: 1300 Average training loss: 1.9680\n",
      "====> Epoch: 1400 Average training loss: 1.8649\n",
      "====> Epoch: 1500 Average training loss: 1.7912\n",
      "====> Epoch: 1600 Average training loss: 1.6626\n",
      "====> Epoch: 1700 Average training loss: 1.5963\n",
      "====> Epoch: 1800 Average training loss: 1.4795\n",
      "====> Epoch: 100 Average training loss: 6.7168\n",
      "====> Epoch: 200 Average training loss: 5.4829\n",
      "====> Epoch: 300 Average training loss: 4.6926\n",
      "====> Epoch: 400 Average training loss: 4.1127\n",
      "====> Epoch: 500 Average training loss: 3.6772\n",
      "====> Epoch: 600 Average training loss: 3.3148\n",
      "====> Epoch: 700 Average training loss: 3.0348\n",
      "====> Epoch: 800 Average training loss: 2.7837\n",
      "====> Epoch: 900 Average training loss: 2.5604\n",
      "====> Epoch: 1000 Average training loss: 2.3787\n",
      "====> Epoch: 1100 Average training loss: 2.2407\n",
      "====> Epoch: 1200 Average training loss: 2.1071\n",
      "====> Epoch: 1300 Average training loss: 1.9676\n",
      "====> Epoch: 1400 Average training loss: 1.8720\n",
      "====> Epoch: 1500 Average training loss: 1.7731\n",
      "====> Epoch: 1600 Average training loss: 1.7083\n",
      "====> Epoch: 1700 Average training loss: 1.6250\n",
      "====> Epoch: 1800 Average training loss: 1.4936\n",
      "====> Epoch: 100 Average training loss: 6.6730\n",
      "====> Epoch: 200 Average training loss: 5.3901\n",
      "====> Epoch: 300 Average training loss: 4.6216\n",
      "====> Epoch: 400 Average training loss: 4.0618\n",
      "====> Epoch: 500 Average training loss: 3.6421\n",
      "====> Epoch: 600 Average training loss: 3.2812\n",
      "====> Epoch: 700 Average training loss: 3.0090\n",
      "====> Epoch: 800 Average training loss: 2.7704\n",
      "====> Epoch: 900 Average training loss: 2.5537\n",
      "====> Epoch: 1000 Average training loss: 2.3908\n",
      "====> Epoch: 1100 Average training loss: 2.2429\n",
      "====> Epoch: 1200 Average training loss: 2.0965\n",
      "====> Epoch: 1300 Average training loss: 1.9784\n",
      "====> Epoch: 1400 Average training loss: 1.8770\n",
      "====> Epoch: 1500 Average training loss: 1.7739\n",
      "====> Epoch: 1600 Average training loss: 1.6866\n",
      "====> Epoch: 1700 Average training loss: 1.6222\n",
      "====> Epoch: 1800 Average training loss: 1.5483\n",
      "====> Epoch: 100 Average training loss: 6.4613\n",
      "====> Epoch: 200 Average training loss: 5.3048\n",
      "====> Epoch: 300 Average training loss: 4.5497\n",
      "====> Epoch: 400 Average training loss: 4.0169\n",
      "====> Epoch: 500 Average training loss: 3.5886\n",
      "====> Epoch: 600 Average training loss: 3.2720\n",
      "====> Epoch: 700 Average training loss: 2.9713\n",
      "====> Epoch: 800 Average training loss: 2.7537\n",
      "====> Epoch: 900 Average training loss: 2.5347\n",
      "====> Epoch: 1000 Average training loss: 2.3575\n",
      "====> Epoch: 1100 Average training loss: 2.2180\n",
      "====> Epoch: 1200 Average training loss: 2.0767\n",
      "====> Epoch: 1300 Average training loss: 1.9647\n",
      "====> Epoch: 1400 Average training loss: 1.8661\n",
      "====> Epoch: 1500 Average training loss: 1.7702\n",
      "====> Epoch: 1600 Average training loss: 1.6690\n",
      "====> Epoch: 1700 Average training loss: 1.6025\n",
      "====> Epoch: 1800 Average training loss: 1.5328\n",
      "====> Epoch: 100 Average training loss: 6.8164\n",
      "====> Epoch: 200 Average training loss: 5.5472\n",
      "====> Epoch: 300 Average training loss: 4.7377\n",
      "====> Epoch: 400 Average training loss: 4.1337\n",
      "====> Epoch: 500 Average training loss: 3.6698\n",
      "====> Epoch: 600 Average training loss: 3.3034\n",
      "====> Epoch: 700 Average training loss: 3.0220\n",
      "====> Epoch: 800 Average training loss: 2.7656\n",
      "====> Epoch: 900 Average training loss: 2.5726\n",
      "====> Epoch: 1000 Average training loss: 2.3913\n",
      "====> Epoch: 1100 Average training loss: 2.2383\n",
      "====> Epoch: 1200 Average training loss: 2.0940\n",
      "====> Epoch: 1300 Average training loss: 1.9747\n",
      "====> Epoch: 1400 Average training loss: 1.8654\n",
      "====> Epoch: 1500 Average training loss: 1.7895\n",
      "====> Epoch: 1600 Average training loss: 1.6895\n",
      "====> Epoch: 1700 Average training loss: 1.6132\n",
      "====> Epoch: 1800 Average training loss: 1.5444\n",
      "====> Epoch: 100 Average training loss: 6.7024\n",
      "====> Epoch: 200 Average training loss: 5.4784\n",
      "====> Epoch: 300 Average training loss: 4.6674\n",
      "====> Epoch: 400 Average training loss: 4.0868\n",
      "====> Epoch: 500 Average training loss: 3.6460\n",
      "====> Epoch: 600 Average training loss: 3.2812\n",
      "====> Epoch: 700 Average training loss: 3.0083\n",
      "====> Epoch: 800 Average training loss: 2.7527\n",
      "====> Epoch: 900 Average training loss: 2.5559\n",
      "====> Epoch: 1000 Average training loss: 2.3759\n",
      "====> Epoch: 1100 Average training loss: 2.2219\n",
      "====> Epoch: 1200 Average training loss: 2.0848\n",
      "====> Epoch: 1300 Average training loss: 1.9673\n",
      "====> Epoch: 1400 Average training loss: 1.8578\n",
      "====> Epoch: 1500 Average training loss: 1.7536\n",
      "====> Epoch: 1600 Average training loss: 1.6806\n",
      "====> Epoch: 1700 Average training loss: 1.6107\n",
      "====> Epoch: 1800 Average training loss: 1.5383\n",
      "====> Epoch: 100 Average training loss: 6.4035\n",
      "====> Epoch: 200 Average training loss: 5.2650\n",
      "====> Epoch: 300 Average training loss: 4.5421\n",
      "====> Epoch: 400 Average training loss: 3.9889\n",
      "====> Epoch: 500 Average training loss: 3.5722\n",
      "====> Epoch: 600 Average training loss: 3.2418\n",
      "====> Epoch: 700 Average training loss: 2.9548\n",
      "====> Epoch: 800 Average training loss: 2.7231\n",
      "====> Epoch: 900 Average training loss: 2.5300\n",
      "====> Epoch: 1000 Average training loss: 2.3607\n",
      "====> Epoch: 1100 Average training loss: 2.2052\n",
      "====> Epoch: 1200 Average training loss: 2.0747\n",
      "====> Epoch: 1300 Average training loss: 1.9597\n",
      "====> Epoch: 1400 Average training loss: 1.8476\n",
      "====> Epoch: 1500 Average training loss: 1.7538\n",
      "====> Epoch: 1600 Average training loss: 1.6675\n",
      "====> Epoch: 1700 Average training loss: 1.5980\n",
      "====> Epoch: 1800 Average training loss: 1.5303\n",
      "====> Epoch: 100 Average training loss: 6.9319\n",
      "====> Epoch: 200 Average training loss: 5.6501\n",
      "====> Epoch: 300 Average training loss: 4.8384\n",
      "====> Epoch: 400 Average training loss: 4.2141\n",
      "====> Epoch: 500 Average training loss: 3.7507\n",
      "====> Epoch: 600 Average training loss: 3.3733\n",
      "====> Epoch: 700 Average training loss: 3.0614\n",
      "====> Epoch: 800 Average training loss: 2.8060\n",
      "====> Epoch: 900 Average training loss: 2.5998\n",
      "====> Epoch: 1000 Average training loss: 2.3918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1100 Average training loss: 2.2380\n",
      "====> Epoch: 1200 Average training loss: 2.1049\n",
      "====> Epoch: 1300 Average training loss: 1.9843\n",
      "====> Epoch: 1400 Average training loss: 1.8851\n",
      "====> Epoch: 1500 Average training loss: 1.7836\n",
      "====> Epoch: 1600 Average training loss: 1.7021\n",
      "====> Epoch: 1700 Average training loss: 1.6262\n",
      "====> Epoch: 1800 Average training loss: 1.5613\n",
      "====> Epoch: 100 Average training loss: 6.4786\n",
      "====> Epoch: 200 Average training loss: 5.2615\n",
      "====> Epoch: 300 Average training loss: 4.5481\n",
      "====> Epoch: 400 Average training loss: 3.9978\n",
      "====> Epoch: 500 Average training loss: 3.5912\n",
      "====> Epoch: 600 Average training loss: 3.2602\n",
      "====> Epoch: 700 Average training loss: 2.9836\n",
      "====> Epoch: 800 Average training loss: 2.7472\n",
      "====> Epoch: 900 Average training loss: 2.5426\n",
      "====> Epoch: 1000 Average training loss: 2.3686\n",
      "====> Epoch: 1100 Average training loss: 2.2115\n",
      "====> Epoch: 1200 Average training loss: 2.0800\n",
      "====> Epoch: 1300 Average training loss: 1.9623\n",
      "====> Epoch: 1400 Average training loss: 1.8598\n",
      "====> Epoch: 1500 Average training loss: 1.7591\n",
      "====> Epoch: 1600 Average training loss: 1.6689\n",
      "====> Epoch: 1700 Average training loss: 1.6010\n",
      "====> Epoch: 1800 Average training loss: 1.5327\n",
      "====> Epoch: 100 Average training loss: 6.6221\n",
      "====> Epoch: 200 Average training loss: 5.3888\n",
      "====> Epoch: 300 Average training loss: 4.6191\n",
      "====> Epoch: 400 Average training loss: 4.0612\n",
      "====> Epoch: 500 Average training loss: 3.6367\n",
      "====> Epoch: 600 Average training loss: 3.2973\n",
      "====> Epoch: 700 Average training loss: 3.0052\n",
      "====> Epoch: 800 Average training loss: 2.7825\n",
      "====> Epoch: 900 Average training loss: 2.5555\n",
      "====> Epoch: 1000 Average training loss: 2.3922\n",
      "====> Epoch: 1100 Average training loss: 2.2294\n",
      "====> Epoch: 1200 Average training loss: 2.1019\n",
      "====> Epoch: 1300 Average training loss: 1.9746\n",
      "====> Epoch: 1400 Average training loss: 1.8754\n",
      "====> Epoch: 1500 Average training loss: 1.7859\n",
      "====> Epoch: 1600 Average training loss: 1.6897\n",
      "====> Epoch: 1700 Average training loss: 1.6158\n",
      "====> Epoch: 1800 Average training loss: 1.5632\n",
      "====> Epoch: 100 Average training loss: 6.5584\n",
      "====> Epoch: 200 Average training loss: 5.3378\n",
      "====> Epoch: 300 Average training loss: 4.5717\n",
      "====> Epoch: 400 Average training loss: 4.0301\n",
      "====> Epoch: 500 Average training loss: 3.6131\n",
      "====> Epoch: 600 Average training loss: 3.2703\n",
      "====> Epoch: 700 Average training loss: 2.9846\n",
      "====> Epoch: 800 Average training loss: 2.7599\n",
      "====> Epoch: 900 Average training loss: 2.5571\n",
      "====> Epoch: 1000 Average training loss: 2.3792\n",
      "====> Epoch: 1100 Average training loss: 2.2213\n",
      "====> Epoch: 1200 Average training loss: 2.0880\n",
      "====> Epoch: 1300 Average training loss: 1.9759\n",
      "====> Epoch: 1400 Average training loss: 1.8716\n",
      "====> Epoch: 1500 Average training loss: 1.7709\n",
      "====> Epoch: 1600 Average training loss: 1.6866\n",
      "====> Epoch: 1700 Average training loss: 1.6233\n",
      "====> Epoch: 1800 Average training loss: 1.5502\n",
      "====> Epoch: 100 Average training loss: 6.5710\n",
      "====> Epoch: 200 Average training loss: 5.3446\n",
      "====> Epoch: 300 Average training loss: 4.5947\n",
      "====> Epoch: 400 Average training loss: 4.0644\n",
      "====> Epoch: 500 Average training loss: 3.6315\n",
      "====> Epoch: 600 Average training loss: 3.2776\n",
      "====> Epoch: 700 Average training loss: 3.0070\n",
      "====> Epoch: 800 Average training loss: 2.7682\n",
      "====> Epoch: 900 Average training loss: 2.5561\n",
      "====> Epoch: 1000 Average training loss: 2.3762\n",
      "====> Epoch: 1100 Average training loss: 2.2317\n",
      "====> Epoch: 1200 Average training loss: 2.0886\n",
      "====> Epoch: 1300 Average training loss: 1.9715\n",
      "====> Epoch: 1400 Average training loss: 1.8718\n",
      "====> Epoch: 1500 Average training loss: 1.7812\n",
      "====> Epoch: 1600 Average training loss: 1.6865\n",
      "====> Epoch: 1700 Average training loss: 1.6093\n",
      "====> Epoch: 1800 Average training loss: 1.5501\n",
      "====> Epoch: 100 Average training loss: 6.7471\n",
      "====> Epoch: 200 Average training loss: 5.4644\n",
      "====> Epoch: 300 Average training loss: 4.6462\n",
      "====> Epoch: 400 Average training loss: 4.0563\n",
      "====> Epoch: 500 Average training loss: 3.6273\n",
      "====> Epoch: 600 Average training loss: 3.2797\n",
      "====> Epoch: 700 Average training loss: 2.9893\n",
      "====> Epoch: 800 Average training loss: 2.7580\n",
      "====> Epoch: 900 Average training loss: 2.5653\n",
      "====> Epoch: 1000 Average training loss: 2.3784\n",
      "====> Epoch: 1100 Average training loss: 2.2317\n",
      "====> Epoch: 1200 Average training loss: 2.0895\n",
      "====> Epoch: 1300 Average training loss: 1.9750\n",
      "====> Epoch: 1400 Average training loss: 1.8531\n",
      "====> Epoch: 1500 Average training loss: 1.7709\n",
      "====> Epoch: 1600 Average training loss: 1.6839\n",
      "====> Epoch: 1700 Average training loss: 1.6170\n",
      "====> Epoch: 1800 Average training loss: 1.5451\n",
      "====> Epoch: 100 Average training loss: 6.8498\n",
      "====> Epoch: 200 Average training loss: 5.6522\n",
      "====> Epoch: 300 Average training loss: 4.8201\n",
      "====> Epoch: 400 Average training loss: 4.2092\n",
      "====> Epoch: 500 Average training loss: 3.7406\n",
      "====> Epoch: 600 Average training loss: 3.3466\n",
      "====> Epoch: 700 Average training loss: 3.0169\n",
      "====> Epoch: 800 Average training loss: 2.7821\n",
      "====> Epoch: 900 Average training loss: 2.5628\n",
      "====> Epoch: 1000 Average training loss: 2.3926\n",
      "====> Epoch: 1100 Average training loss: 2.2297\n",
      "====> Epoch: 1200 Average training loss: 2.1073\n",
      "====> Epoch: 1300 Average training loss: 1.9905\n",
      "====> Epoch: 1400 Average training loss: 1.8669\n",
      "====> Epoch: 1500 Average training loss: 1.7968\n",
      "====> Epoch: 1600 Average training loss: 1.7019\n",
      "====> Epoch: 1700 Average training loss: 1.6083\n",
      "====> Epoch: 1800 Average training loss: 1.5431\n",
      "====> Epoch: 100 Average training loss: 6.7563\n",
      "====> Epoch: 200 Average training loss: 5.5280\n",
      "====> Epoch: 300 Average training loss: 4.7524\n",
      "====> Epoch: 400 Average training loss: 4.1708\n",
      "====> Epoch: 500 Average training loss: 3.7356\n",
      "====> Epoch: 600 Average training loss: 3.3761\n",
      "====> Epoch: 700 Average training loss: 3.0767\n",
      "====> Epoch: 800 Average training loss: 2.8237\n",
      "====> Epoch: 900 Average training loss: 2.6084\n",
      "====> Epoch: 1000 Average training loss: 2.4188\n",
      "====> Epoch: 1100 Average training loss: 2.2685\n",
      "====> Epoch: 1200 Average training loss: 2.1204\n",
      "====> Epoch: 1300 Average training loss: 2.0004\n",
      "====> Epoch: 1400 Average training loss: 1.8816\n",
      "====> Epoch: 1500 Average training loss: 1.7935\n",
      "====> Epoch: 1600 Average training loss: 1.7009\n",
      "====> Epoch: 1700 Average training loss: 1.6265\n",
      "====> Epoch: 1800 Average training loss: 1.5533\n",
      "====> Epoch: 100 Average training loss: 6.6347\n",
      "====> Epoch: 200 Average training loss: 5.3957\n",
      "====> Epoch: 300 Average training loss: 4.6128\n",
      "====> Epoch: 400 Average training loss: 4.0398\n",
      "====> Epoch: 500 Average training loss: 3.6357\n",
      "====> Epoch: 600 Average training loss: 3.2938\n",
      "====> Epoch: 700 Average training loss: 3.0050\n",
      "====> Epoch: 800 Average training loss: 2.7664\n",
      "====> Epoch: 900 Average training loss: 2.5656\n",
      "====> Epoch: 1000 Average training loss: 2.3818\n",
      "====> Epoch: 1100 Average training loss: 2.2434\n",
      "====> Epoch: 1200 Average training loss: 2.1019\n",
      "====> Epoch: 1300 Average training loss: 1.9799\n",
      "====> Epoch: 1400 Average training loss: 1.8743\n",
      "====> Epoch: 1500 Average training loss: 1.7853\n",
      "====> Epoch: 1600 Average training loss: 1.7143\n",
      "====> Epoch: 1700 Average training loss: 1.6216\n",
      "====> Epoch: 1800 Average training loss: 1.5585\n",
      "====> Epoch: 100 Average training loss: 6.4895\n",
      "====> Epoch: 200 Average training loss: 5.2728\n",
      "====> Epoch: 300 Average training loss: 4.5470\n",
      "====> Epoch: 400 Average training loss: 3.9983\n",
      "====> Epoch: 500 Average training loss: 3.5964\n",
      "====> Epoch: 600 Average training loss: 3.2569\n",
      "====> Epoch: 700 Average training loss: 2.9700\n",
      "====> Epoch: 800 Average training loss: 2.7199\n",
      "====> Epoch: 900 Average training loss: 2.5268\n",
      "====> Epoch: 1000 Average training loss: 2.3698\n",
      "====> Epoch: 1100 Average training loss: 2.2226\n",
      "====> Epoch: 1200 Average training loss: 2.0760\n",
      "====> Epoch: 1300 Average training loss: 1.9625\n",
      "====> Epoch: 1400 Average training loss: 1.8640\n",
      "====> Epoch: 1500 Average training loss: 1.7577\n",
      "====> Epoch: 1600 Average training loss: 1.6861\n",
      "====> Epoch: 1700 Average training loss: 1.6072\n",
      "====> Epoch: 1800 Average training loss: 1.5263\n",
      "====> Epoch: 100 Average training loss: 6.5961\n",
      "====> Epoch: 200 Average training loss: 5.3691\n",
      "====> Epoch: 300 Average training loss: 4.5765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 400 Average training loss: 4.0435\n",
      "====> Epoch: 500 Average training loss: 3.6243\n",
      "====> Epoch: 600 Average training loss: 3.2671\n",
      "====> Epoch: 700 Average training loss: 2.9941\n",
      "====> Epoch: 800 Average training loss: 2.7517\n",
      "====> Epoch: 900 Average training loss: 2.5602\n",
      "====> Epoch: 1000 Average training loss: 2.3765\n",
      "====> Epoch: 1100 Average training loss: 2.2206\n",
      "====> Epoch: 1200 Average training loss: 2.0981\n",
      "====> Epoch: 1300 Average training loss: 1.9551\n",
      "====> Epoch: 1400 Average training loss: 1.8580\n",
      "====> Epoch: 1500 Average training loss: 1.7780\n",
      "====> Epoch: 1600 Average training loss: 1.7004\n",
      "====> Epoch: 1700 Average training loss: 1.6114\n",
      "====> Epoch: 1800 Average training loss: 1.5339\n",
      "====> Epoch: 100 Average training loss: 6.9473\n",
      "====> Epoch: 200 Average training loss: 5.6946\n",
      "====> Epoch: 300 Average training loss: 4.9003\n",
      "====> Epoch: 400 Average training loss: 4.3030\n",
      "====> Epoch: 500 Average training loss: 3.8525\n",
      "====> Epoch: 600 Average training loss: 3.4722\n",
      "====> Epoch: 700 Average training loss: 3.1621\n",
      "====> Epoch: 800 Average training loss: 2.8952\n",
      "====> Epoch: 900 Average training loss: 2.6971\n",
      "====> Epoch: 1000 Average training loss: 2.4956\n",
      "====> Epoch: 1100 Average training loss: 2.3133\n",
      "====> Epoch: 1200 Average training loss: 2.1622\n",
      "====> Epoch: 1300 Average training loss: 2.0473\n",
      "====> Epoch: 1400 Average training loss: 1.8906\n",
      "====> Epoch: 1500 Average training loss: 1.7452\n",
      "====> Epoch: 1600 Average training loss: 1.7379\n",
      "====> Epoch: 1700 Average training loss: 1.5785\n",
      "====> Epoch: 1800 Average training loss: 1.5344\n",
      "====> Epoch: 100 Average training loss: 6.5146\n",
      "====> Epoch: 200 Average training loss: 5.3224\n",
      "====> Epoch: 300 Average training loss: 4.5755\n",
      "====> Epoch: 400 Average training loss: 4.0225\n",
      "====> Epoch: 500 Average training loss: 3.6006\n",
      "====> Epoch: 600 Average training loss: 3.2702\n",
      "====> Epoch: 700 Average training loss: 2.9702\n",
      "====> Epoch: 800 Average training loss: 2.7396\n",
      "====> Epoch: 900 Average training loss: 2.5443\n",
      "====> Epoch: 1000 Average training loss: 2.3626\n",
      "====> Epoch: 1100 Average training loss: 2.2160\n",
      "====> Epoch: 1200 Average training loss: 2.0521\n",
      "====> Epoch: 1300 Average training loss: 1.9504\n",
      "====> Epoch: 1400 Average training loss: 1.8478\n",
      "====> Epoch: 1500 Average training loss: 1.7574\n",
      "====> Epoch: 1600 Average training loss: 1.6669\n",
      "====> Epoch: 1700 Average training loss: 1.5943\n",
      "====> Epoch: 1800 Average training loss: 1.5355\n",
      "====> Epoch: 100 Average training loss: 6.5520\n",
      "====> Epoch: 200 Average training loss: 5.3462\n",
      "====> Epoch: 300 Average training loss: 4.5982\n",
      "====> Epoch: 400 Average training loss: 4.0635\n",
      "====> Epoch: 500 Average training loss: 3.6311\n",
      "====> Epoch: 600 Average training loss: 3.2807\n",
      "====> Epoch: 700 Average training loss: 2.9955\n",
      "====> Epoch: 800 Average training loss: 2.7750\n",
      "====> Epoch: 900 Average training loss: 2.5565\n",
      "====> Epoch: 1000 Average training loss: 2.3842\n",
      "====> Epoch: 1100 Average training loss: 2.2176\n",
      "====> Epoch: 1200 Average training loss: 2.0927\n",
      "====> Epoch: 1300 Average training loss: 1.9789\n",
      "====> Epoch: 1400 Average training loss: 1.8718\n",
      "====> Epoch: 1500 Average training loss: 1.7800\n",
      "====> Epoch: 1600 Average training loss: 1.6856\n",
      "====> Epoch: 1700 Average training loss: 1.6082\n",
      "====> Epoch: 1800 Average training loss: 1.5495\n",
      "====> Epoch: 100 Average training loss: 6.8697\n",
      "====> Epoch: 200 Average training loss: 5.5534\n",
      "====> Epoch: 300 Average training loss: 4.7162\n",
      "====> Epoch: 400 Average training loss: 4.1208\n",
      "====> Epoch: 500 Average training loss: 3.6906\n",
      "====> Epoch: 600 Average training loss: 3.3153\n",
      "====> Epoch: 700 Average training loss: 3.0123\n",
      "====> Epoch: 800 Average training loss: 2.7668\n",
      "====> Epoch: 900 Average training loss: 2.5670\n",
      "====> Epoch: 1000 Average training loss: 2.3736\n",
      "====> Epoch: 1100 Average training loss: 2.2228\n",
      "====> Epoch: 1200 Average training loss: 2.0947\n",
      "====> Epoch: 1300 Average training loss: 1.9647\n",
      "====> Epoch: 1400 Average training loss: 1.8624\n",
      "====> Epoch: 1500 Average training loss: 1.7658\n",
      "====> Epoch: 1600 Average training loss: 1.6829\n",
      "====> Epoch: 1700 Average training loss: 1.6150\n",
      "====> Epoch: 1800 Average training loss: 1.5403\n",
      "====> Epoch: 100 Average training loss: 6.5422\n",
      "====> Epoch: 200 Average training loss: 5.3198\n",
      "====> Epoch: 300 Average training loss: 4.5605\n",
      "====> Epoch: 400 Average training loss: 4.0169\n",
      "====> Epoch: 500 Average training loss: 3.5893\n",
      "====> Epoch: 600 Average training loss: 3.2624\n",
      "====> Epoch: 700 Average training loss: 2.9821\n",
      "====> Epoch: 800 Average training loss: 2.7496\n",
      "====> Epoch: 900 Average training loss: 2.5350\n",
      "====> Epoch: 1000 Average training loss: 2.3884\n",
      "====> Epoch: 1100 Average training loss: 2.2260\n",
      "====> Epoch: 1200 Average training loss: 2.0847\n",
      "====> Epoch: 1300 Average training loss: 1.9865\n",
      "====> Epoch: 1400 Average training loss: 1.8804\n",
      "====> Epoch: 1500 Average training loss: 1.7709\n",
      "====> Epoch: 1600 Average training loss: 1.6839\n",
      "====> Epoch: 1700 Average training loss: 1.6221\n",
      "====> Epoch: 1800 Average training loss: 1.5326\n",
      "====> Epoch: 100 Average training loss: 6.4530\n",
      "====> Epoch: 200 Average training loss: 5.2931\n",
      "====> Epoch: 300 Average training loss: 4.5599\n",
      "====> Epoch: 400 Average training loss: 3.9961\n",
      "====> Epoch: 500 Average training loss: 3.5470\n",
      "====> Epoch: 600 Average training loss: 3.1626\n",
      "====> Epoch: 700 Average training loss: 2.7290\n",
      "====> Epoch: 800 Average training loss: 2.5180\n",
      "====> Epoch: 900 Average training loss: 2.4185\n",
      "====> Epoch: 1000 Average training loss: 2.2614\n",
      "====> Epoch: 1100 Average training loss: 2.0447\n",
      "====> Epoch: 1200 Average training loss: 1.9445\n",
      "====> Epoch: 1300 Average training loss: 1.8517\n",
      "====> Epoch: 1400 Average training loss: 1.7522\n",
      "====> Epoch: 1500 Average training loss: 1.6420\n",
      "====> Epoch: 1600 Average training loss: 1.5573\n",
      "====> Epoch: 1700 Average training loss: 1.4967\n",
      "====> Epoch: 1800 Average training loss: 1.4664\n",
      "====> Epoch: 100 Average training loss: 6.4952\n",
      "====> Epoch: 200 Average training loss: 5.3198\n",
      "====> Epoch: 300 Average training loss: 4.5793\n",
      "====> Epoch: 400 Average training loss: 4.0238\n",
      "====> Epoch: 500 Average training loss: 3.5999\n",
      "====> Epoch: 600 Average training loss: 3.2568\n",
      "====> Epoch: 700 Average training loss: 2.9797\n",
      "====> Epoch: 800 Average training loss: 2.7533\n",
      "====> Epoch: 900 Average training loss: 2.5454\n",
      "====> Epoch: 1000 Average training loss: 2.3712\n",
      "====> Epoch: 1100 Average training loss: 2.2100\n",
      "====> Epoch: 1200 Average training loss: 2.0803\n",
      "====> Epoch: 1300 Average training loss: 1.9621\n",
      "====> Epoch: 1400 Average training loss: 1.8614\n",
      "====> Epoch: 1500 Average training loss: 1.7508\n",
      "====> Epoch: 1600 Average training loss: 1.6812\n",
      "====> Epoch: 1700 Average training loss: 1.5953\n",
      "====> Epoch: 1800 Average training loss: 1.5281\n",
      "====> Epoch: 100 Average training loss: 6.6769\n",
      "====> Epoch: 200 Average training loss: 5.4074\n",
      "====> Epoch: 300 Average training loss: 4.6099\n",
      "====> Epoch: 400 Average training loss: 4.0559\n",
      "====> Epoch: 500 Average training loss: 3.6105\n",
      "====> Epoch: 600 Average training loss: 3.2740\n",
      "====> Epoch: 700 Average training loss: 2.9941\n",
      "====> Epoch: 800 Average training loss: 2.7590\n",
      "====> Epoch: 900 Average training loss: 2.5426\n",
      "====> Epoch: 1000 Average training loss: 2.3827\n",
      "====> Epoch: 1100 Average training loss: 2.2346\n",
      "====> Epoch: 1200 Average training loss: 2.1012\n",
      "====> Epoch: 1300 Average training loss: 1.9673\n",
      "====> Epoch: 1400 Average training loss: 1.8692\n",
      "====> Epoch: 1500 Average training loss: 1.7677\n",
      "====> Epoch: 1600 Average training loss: 1.6997\n",
      "====> Epoch: 1700 Average training loss: 1.6201\n",
      "====> Epoch: 1800 Average training loss: 1.5448\n",
      "====> Epoch: 100 Average training loss: 6.8868\n",
      "====> Epoch: 200 Average training loss: 5.5994\n",
      "====> Epoch: 300 Average training loss: 4.7844\n",
      "====> Epoch: 400 Average training loss: 4.2182\n",
      "====> Epoch: 500 Average training loss: 3.7645\n",
      "====> Epoch: 600 Average training loss: 3.3839\n",
      "====> Epoch: 700 Average training loss: 3.0958\n",
      "====> Epoch: 800 Average training loss: 2.8387\n",
      "====> Epoch: 900 Average training loss: 2.6239\n",
      "====> Epoch: 1000 Average training loss: 2.4421\n",
      "====> Epoch: 1100 Average training loss: 2.2749\n",
      "====> Epoch: 1200 Average training loss: 2.1318\n",
      "====> Epoch: 1300 Average training loss: 2.0012\n",
      "====> Epoch: 1400 Average training loss: 1.8870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1500 Average training loss: 1.7960\n",
      "====> Epoch: 1600 Average training loss: 1.7084\n",
      "====> Epoch: 1700 Average training loss: 1.6309\n",
      "====> Epoch: 1800 Average training loss: 1.5654\n",
      "====> Epoch: 100 Average training loss: 6.5062\n",
      "====> Epoch: 200 Average training loss: 5.3056\n",
      "====> Epoch: 300 Average training loss: 4.5390\n",
      "====> Epoch: 400 Average training loss: 4.0122\n",
      "====> Epoch: 500 Average training loss: 3.5929\n",
      "====> Epoch: 600 Average training loss: 3.2496\n",
      "====> Epoch: 700 Average training loss: 2.9570\n",
      "====> Epoch: 800 Average training loss: 2.7322\n",
      "====> Epoch: 900 Average training loss: 2.5417\n",
      "====> Epoch: 1000 Average training loss: 2.3574\n",
      "====> Epoch: 1100 Average training loss: 2.2015\n",
      "====> Epoch: 1200 Average training loss: 2.0685\n",
      "====> Epoch: 1300 Average training loss: 1.9542\n",
      "====> Epoch: 1400 Average training loss: 1.8639\n",
      "====> Epoch: 1500 Average training loss: 1.7546\n",
      "====> Epoch: 1600 Average training loss: 1.6844\n",
      "====> Epoch: 1700 Average training loss: 1.6003\n",
      "====> Epoch: 1800 Average training loss: 1.5406\n",
      "====> Epoch: 100 Average training loss: 6.5069\n",
      "====> Epoch: 200 Average training loss: 5.3221\n",
      "====> Epoch: 300 Average training loss: 4.5779\n",
      "====> Epoch: 400 Average training loss: 4.0335\n",
      "====> Epoch: 500 Average training loss: 3.6107\n",
      "====> Epoch: 600 Average training loss: 3.2714\n",
      "====> Epoch: 700 Average training loss: 2.9958\n",
      "====> Epoch: 800 Average training loss: 2.7409\n",
      "====> Epoch: 900 Average training loss: 2.5532\n",
      "====> Epoch: 1000 Average training loss: 2.3860\n",
      "====> Epoch: 1100 Average training loss: 2.2064\n",
      "====> Epoch: 1200 Average training loss: 2.0771\n",
      "====> Epoch: 1300 Average training loss: 1.9639\n",
      "====> Epoch: 1400 Average training loss: 1.8545\n",
      "====> Epoch: 1500 Average training loss: 1.7726\n",
      "====> Epoch: 1600 Average training loss: 1.6904\n",
      "====> Epoch: 1700 Average training loss: 1.6119\n",
      "====> Epoch: 1800 Average training loss: 1.5335\n",
      "====> Epoch: 100 Average training loss: 6.5263\n",
      "====> Epoch: 200 Average training loss: 5.3299\n",
      "====> Epoch: 300 Average training loss: 4.5617\n",
      "====> Epoch: 400 Average training loss: 4.0315\n",
      "====> Epoch: 500 Average training loss: 3.6045\n",
      "====> Epoch: 600 Average training loss: 3.2683\n",
      "====> Epoch: 700 Average training loss: 2.9859\n",
      "====> Epoch: 800 Average training loss: 2.7387\n",
      "====> Epoch: 900 Average training loss: 2.5229\n",
      "====> Epoch: 1000 Average training loss: 2.3662\n",
      "====> Epoch: 1100 Average training loss: 2.2190\n",
      "====> Epoch: 1200 Average training loss: 2.0851\n",
      "====> Epoch: 1300 Average training loss: 1.9555\n",
      "====> Epoch: 1400 Average training loss: 1.8572\n",
      "====> Epoch: 1500 Average training loss: 1.7561\n",
      "====> Epoch: 1600 Average training loss: 1.6910\n",
      "====> Epoch: 1700 Average training loss: 1.6090\n",
      "====> Epoch: 1800 Average training loss: 1.5446\n",
      "====> Epoch: 100 Average training loss: 6.4986\n",
      "====> Epoch: 200 Average training loss: 5.3299\n",
      "====> Epoch: 300 Average training loss: 4.5742\n",
      "====> Epoch: 400 Average training loss: 4.0338\n",
      "====> Epoch: 500 Average training loss: 3.6070\n",
      "====> Epoch: 600 Average training loss: 3.2558\n",
      "====> Epoch: 700 Average training loss: 2.9721\n",
      "====> Epoch: 800 Average training loss: 2.7493\n",
      "====> Epoch: 900 Average training loss: 2.5302\n",
      "====> Epoch: 1000 Average training loss: 2.3799\n",
      "====> Epoch: 1100 Average training loss: 2.2188\n",
      "====> Epoch: 1200 Average training loss: 2.0872\n",
      "====> Epoch: 1300 Average training loss: 1.9639\n",
      "====> Epoch: 1400 Average training loss: 1.8690\n",
      "====> Epoch: 1500 Average training loss: 1.7654\n",
      "====> Epoch: 1600 Average training loss: 1.6836\n",
      "====> Epoch: 1700 Average training loss: 1.6151\n",
      "====> Epoch: 1800 Average training loss: 1.5487\n",
      "====> Epoch: 100 Average training loss: 6.6545\n",
      "====> Epoch: 200 Average training loss: 5.3879\n",
      "====> Epoch: 300 Average training loss: 4.6191\n",
      "====> Epoch: 400 Average training loss: 4.0645\n",
      "====> Epoch: 500 Average training loss: 3.6124\n",
      "====> Epoch: 600 Average training loss: 3.2680\n",
      "====> Epoch: 700 Average training loss: 2.9837\n",
      "====> Epoch: 800 Average training loss: 2.7577\n",
      "====> Epoch: 900 Average training loss: 2.5357\n",
      "====> Epoch: 1000 Average training loss: 2.3639\n",
      "====> Epoch: 1100 Average training loss: 2.2172\n",
      "====> Epoch: 1200 Average training loss: 2.0726\n",
      "====> Epoch: 1300 Average training loss: 1.9639\n",
      "====> Epoch: 1400 Average training loss: 1.8689\n",
      "====> Epoch: 1500 Average training loss: 1.7762\n",
      "====> Epoch: 1600 Average training loss: 1.6739\n",
      "====> Epoch: 1700 Average training loss: 1.6176\n",
      "====> Epoch: 1800 Average training loss: 1.5489\n",
      "====> Epoch: 100 Average training loss: 6.5843\n",
      "====> Epoch: 200 Average training loss: 5.3728\n",
      "====> Epoch: 300 Average training loss: 4.6082\n",
      "====> Epoch: 400 Average training loss: 4.0410\n",
      "====> Epoch: 500 Average training loss: 3.6176\n",
      "====> Epoch: 600 Average training loss: 3.2536\n",
      "====> Epoch: 700 Average training loss: 2.9665\n",
      "====> Epoch: 800 Average training loss: 2.7343\n",
      "====> Epoch: 900 Average training loss: 2.5531\n",
      "====> Epoch: 1000 Average training loss: 2.3567\n",
      "====> Epoch: 1100 Average training loss: 2.2020\n",
      "====> Epoch: 1200 Average training loss: 2.0839\n",
      "====> Epoch: 1300 Average training loss: 1.9457\n",
      "====> Epoch: 1400 Average training loss: 1.8495\n",
      "====> Epoch: 1500 Average training loss: 1.7583\n",
      "====> Epoch: 1600 Average training loss: 1.6738\n",
      "====> Epoch: 1700 Average training loss: 1.6036\n",
      "====> Epoch: 1800 Average training loss: 1.5376\n",
      "====> Epoch: 100 Average training loss: 6.5392\n",
      "====> Epoch: 200 Average training loss: 5.3434\n",
      "====> Epoch: 300 Average training loss: 4.5721\n",
      "====> Epoch: 400 Average training loss: 4.0378\n",
      "====> Epoch: 500 Average training loss: 3.5957\n",
      "====> Epoch: 600 Average training loss: 3.2681\n",
      "====> Epoch: 700 Average training loss: 2.9778\n",
      "====> Epoch: 800 Average training loss: 2.7512\n",
      "====> Epoch: 900 Average training loss: 2.5345\n",
      "====> Epoch: 1000 Average training loss: 2.3668\n",
      "====> Epoch: 1100 Average training loss: 2.2202\n",
      "====> Epoch: 1200 Average training loss: 2.0877\n",
      "====> Epoch: 1300 Average training loss: 1.9687\n",
      "====> Epoch: 1400 Average training loss: 1.8738\n",
      "====> Epoch: 1500 Average training loss: 1.7730\n",
      "====> Epoch: 1600 Average training loss: 1.6844\n",
      "====> Epoch: 1700 Average training loss: 1.6141\n",
      "====> Epoch: 1800 Average training loss: 1.5462\n",
      "====> Epoch: 100 Average training loss: 6.5082\n",
      "====> Epoch: 200 Average training loss: 5.3214\n",
      "====> Epoch: 300 Average training loss: 4.5530\n",
      "====> Epoch: 400 Average training loss: 4.0226\n",
      "====> Epoch: 500 Average training loss: 3.5918\n",
      "====> Epoch: 600 Average training loss: 3.2577\n",
      "====> Epoch: 700 Average training loss: 2.9803\n",
      "====> Epoch: 800 Average training loss: 2.7436\n",
      "====> Epoch: 900 Average training loss: 2.5372\n",
      "====> Epoch: 1000 Average training loss: 2.3735\n",
      "====> Epoch: 1100 Average training loss: 2.2166\n",
      "====> Epoch: 1200 Average training loss: 2.0877\n",
      "====> Epoch: 1300 Average training loss: 1.9629\n",
      "====> Epoch: 1400 Average training loss: 1.8552\n",
      "====> Epoch: 1500 Average training loss: 1.7716\n",
      "====> Epoch: 1600 Average training loss: 1.6901\n",
      "====> Epoch: 1700 Average training loss: 1.6114\n",
      "====> Epoch: 1800 Average training loss: 1.5420\n",
      "====> Epoch: 100 Average training loss: 6.6242\n",
      "====> Epoch: 200 Average training loss: 5.3476\n",
      "====> Epoch: 300 Average training loss: 4.5679\n",
      "====> Epoch: 400 Average training loss: 4.0030\n",
      "====> Epoch: 500 Average training loss: 3.5988\n",
      "====> Epoch: 600 Average training loss: 3.2565\n",
      "====> Epoch: 700 Average training loss: 2.9832\n",
      "====> Epoch: 800 Average training loss: 2.7452\n",
      "====> Epoch: 900 Average training loss: 2.5405\n",
      "====> Epoch: 1000 Average training loss: 2.3577\n",
      "====> Epoch: 1100 Average training loss: 2.2079\n",
      "====> Epoch: 1200 Average training loss: 2.0783\n",
      "====> Epoch: 1300 Average training loss: 1.9554\n",
      "====> Epoch: 1400 Average training loss: 1.8701\n",
      "====> Epoch: 1500 Average training loss: 1.7657\n",
      "====> Epoch: 1600 Average training loss: 1.6778\n",
      "====> Epoch: 1700 Average training loss: 1.6153\n",
      "====> Epoch: 1800 Average training loss: 1.5426\n",
      "====> Epoch: 100 Average training loss: 6.5756\n",
      "====> Epoch: 200 Average training loss: 5.3534\n",
      "====> Epoch: 300 Average training loss: 4.5791\n",
      "====> Epoch: 400 Average training loss: 4.0620\n",
      "====> Epoch: 500 Average training loss: 3.6199\n",
      "====> Epoch: 600 Average training loss: 3.2863\n",
      "====> Epoch: 700 Average training loss: 3.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 800 Average training loss: 2.7398\n",
      "====> Epoch: 900 Average training loss: 2.5605\n",
      "====> Epoch: 1000 Average training loss: 2.3877\n",
      "====> Epoch: 1100 Average training loss: 2.1300\n",
      "====> Epoch: 1200 Average training loss: 2.0552\n",
      "====> Epoch: 1300 Average training loss: 1.8547\n",
      "====> Epoch: 1400 Average training loss: 1.7991\n",
      "====> Epoch: 1500 Average training loss: 1.6918\n",
      "====> Epoch: 1600 Average training loss: 1.6522\n",
      "====> Epoch: 1700 Average training loss: 1.5626\n",
      "====> Epoch: 1800 Average training loss: 1.5146\n",
      "====> Epoch: 100 Average training loss: 6.6954\n",
      "====> Epoch: 200 Average training loss: 5.4351\n",
      "====> Epoch: 300 Average training loss: 4.6679\n",
      "====> Epoch: 400 Average training loss: 4.1200\n",
      "====> Epoch: 500 Average training loss: 3.6635\n",
      "====> Epoch: 600 Average training loss: 3.3299\n",
      "====> Epoch: 700 Average training loss: 3.0408\n",
      "====> Epoch: 800 Average training loss: 2.7724\n",
      "====> Epoch: 900 Average training loss: 2.5809\n",
      "====> Epoch: 1000 Average training loss: 2.4156\n",
      "====> Epoch: 1100 Average training loss: 2.2444\n",
      "====> Epoch: 1200 Average training loss: 2.1011\n",
      "====> Epoch: 1300 Average training loss: 1.9797\n",
      "====> Epoch: 1400 Average training loss: 1.8803\n",
      "====> Epoch: 1500 Average training loss: 1.7709\n",
      "====> Epoch: 1600 Average training loss: 1.6898\n",
      "====> Epoch: 1700 Average training loss: 1.6208\n",
      "====> Epoch: 1800 Average training loss: 1.5519\n",
      "====> Epoch: 100 Average training loss: 6.6007\n",
      "====> Epoch: 200 Average training loss: 5.3516\n",
      "====> Epoch: 300 Average training loss: 4.5911\n",
      "====> Epoch: 400 Average training loss: 4.0130\n",
      "====> Epoch: 500 Average training loss: 3.6102\n",
      "====> Epoch: 600 Average training loss: 3.2504\n",
      "====> Epoch: 700 Average training loss: 2.9771\n",
      "====> Epoch: 800 Average training loss: 2.7233\n",
      "====> Epoch: 900 Average training loss: 2.5371\n",
      "====> Epoch: 1000 Average training loss: 2.3572\n",
      "====> Epoch: 1100 Average training loss: 2.1933\n",
      "====> Epoch: 1200 Average training loss: 2.0731\n",
      "====> Epoch: 1300 Average training loss: 1.9548\n",
      "====> Epoch: 1400 Average training loss: 1.8615\n",
      "====> Epoch: 1500 Average training loss: 1.7528\n",
      "====> Epoch: 1600 Average training loss: 1.6808\n",
      "====> Epoch: 1700 Average training loss: 1.6095\n",
      "====> Epoch: 1800 Average training loss: 1.5414\n",
      "====> Epoch: 100 Average training loss: 6.7325\n",
      "====> Epoch: 200 Average training loss: 5.5307\n",
      "====> Epoch: 300 Average training loss: 4.6980\n",
      "====> Epoch: 400 Average training loss: 4.0017\n",
      "====> Epoch: 500 Average training loss: 3.6643\n",
      "====> Epoch: 600 Average training loss: 3.2828\n",
      "====> Epoch: 700 Average training loss: 3.0324\n",
      "====> Epoch: 800 Average training loss: 2.6984\n",
      "====> Epoch: 900 Average training loss: 2.3911\n",
      "====> Epoch: 1000 Average training loss: 2.2969\n",
      "====> Epoch: 1100 Average training loss: 2.1254\n",
      "====> Epoch: 1200 Average training loss: 2.0020\n",
      "====> Epoch: 1300 Average training loss: 1.8807\n",
      "====> Epoch: 1400 Average training loss: 1.7838\n",
      "====> Epoch: 1500 Average training loss: 1.6883\n",
      "====> Epoch: 1600 Average training loss: 1.6145\n",
      "====> Epoch: 1700 Average training loss: 1.5350\n",
      "====> Epoch: 1800 Average training loss: 1.4715\n",
      "====> Epoch: 100 Average training loss: 6.9331\n",
      "====> Epoch: 200 Average training loss: 5.5530\n",
      "====> Epoch: 300 Average training loss: 4.7847\n",
      "====> Epoch: 400 Average training loss: 4.1932\n",
      "====> Epoch: 500 Average training loss: 3.7053\n",
      "====> Epoch: 600 Average training loss: 3.3328\n",
      "====> Epoch: 700 Average training loss: 3.0472\n",
      "====> Epoch: 800 Average training loss: 2.7955\n",
      "====> Epoch: 900 Average training loss: 2.5199\n",
      "====> Epoch: 1000 Average training loss: 2.3553\n",
      "====> Epoch: 1100 Average training loss: 2.2463\n",
      "====> Epoch: 1200 Average training loss: 2.1146\n",
      "====> Epoch: 1300 Average training loss: 2.0017\n",
      "====> Epoch: 1400 Average training loss: 1.8815\n",
      "====> Epoch: 1500 Average training loss: 1.7687\n",
      "====> Epoch: 1600 Average training loss: 1.6938\n",
      "====> Epoch: 1700 Average training loss: 1.6310\n",
      "====> Epoch: 1800 Average training loss: 1.5511\n",
      "====> Epoch: 100 Average training loss: 6.5049\n",
      "====> Epoch: 200 Average training loss: 5.3075\n",
      "====> Epoch: 300 Average training loss: 4.5491\n",
      "====> Epoch: 400 Average training loss: 4.0007\n",
      "====> Epoch: 500 Average training loss: 3.5843\n",
      "====> Epoch: 600 Average training loss: 3.2396\n",
      "====> Epoch: 700 Average training loss: 2.9708\n",
      "====> Epoch: 800 Average training loss: 2.7394\n",
      "====> Epoch: 900 Average training loss: 2.5420\n",
      "====> Epoch: 1000 Average training loss: 2.3679\n",
      "====> Epoch: 1100 Average training loss: 2.2142\n",
      "====> Epoch: 1200 Average training loss: 2.0703\n",
      "====> Epoch: 1300 Average training loss: 1.9489\n",
      "====> Epoch: 1400 Average training loss: 1.8684\n",
      "====> Epoch: 1500 Average training loss: 1.7663\n",
      "====> Epoch: 1600 Average training loss: 1.6755\n",
      "====> Epoch: 1700 Average training loss: 1.6074\n",
      "====> Epoch: 1800 Average training loss: 1.5251\n",
      "====> Epoch: 100 Average training loss: 6.6257\n",
      "====> Epoch: 200 Average training loss: 5.3854\n",
      "====> Epoch: 300 Average training loss: 4.6200\n",
      "====> Epoch: 400 Average training loss: 4.0510\n",
      "====> Epoch: 500 Average training loss: 3.6243\n",
      "====> Epoch: 600 Average training loss: 3.2691\n",
      "====> Epoch: 700 Average training loss: 2.9949\n",
      "====> Epoch: 800 Average training loss: 2.7607\n",
      "====> Epoch: 900 Average training loss: 2.5500\n",
      "====> Epoch: 1000 Average training loss: 2.3756\n",
      "====> Epoch: 1100 Average training loss: 2.2166\n",
      "====> Epoch: 1200 Average training loss: 2.0845\n",
      "====> Epoch: 1300 Average training loss: 1.9649\n",
      "====> Epoch: 1400 Average training loss: 1.8661\n",
      "====> Epoch: 1500 Average training loss: 1.7559\n",
      "====> Epoch: 1600 Average training loss: 1.6729\n",
      "====> Epoch: 1700 Average training loss: 1.6067\n",
      "====> Epoch: 1800 Average training loss: 1.5358\n",
      "====> Epoch: 100 Average training loss: 6.4747\n",
      "====> Epoch: 200 Average training loss: 5.2966\n",
      "====> Epoch: 300 Average training loss: 4.5346\n",
      "====> Epoch: 400 Average training loss: 4.0062\n",
      "====> Epoch: 500 Average training loss: 3.5838\n",
      "====> Epoch: 600 Average training loss: 3.2403\n",
      "====> Epoch: 700 Average training loss: 2.9555\n",
      "====> Epoch: 800 Average training loss: 2.7212\n",
      "====> Epoch: 900 Average training loss: 2.5262\n",
      "====> Epoch: 1000 Average training loss: 2.3506\n",
      "====> Epoch: 1100 Average training loss: 2.1956\n",
      "====> Epoch: 1200 Average training loss: 2.0627\n",
      "====> Epoch: 1300 Average training loss: 1.9473\n",
      "====> Epoch: 1400 Average training loss: 1.8402\n",
      "====> Epoch: 1500 Average training loss: 1.7449\n",
      "====> Epoch: 1600 Average training loss: 1.6526\n",
      "====> Epoch: 1700 Average training loss: 1.5978\n",
      "====> Epoch: 1800 Average training loss: 1.5193\n",
      "====> Epoch: 100 Average training loss: 6.4305\n",
      "====> Epoch: 200 Average training loss: 5.2804\n",
      "====> Epoch: 300 Average training loss: 4.5299\n",
      "====> Epoch: 400 Average training loss: 4.0061\n",
      "====> Epoch: 500 Average training loss: 3.5865\n",
      "====> Epoch: 600 Average training loss: 3.2555\n",
      "====> Epoch: 700 Average training loss: 2.9796\n",
      "====> Epoch: 800 Average training loss: 2.7498\n",
      "====> Epoch: 900 Average training loss: 2.5479\n",
      "====> Epoch: 1000 Average training loss: 2.3592\n",
      "====> Epoch: 1100 Average training loss: 2.2106\n",
      "====> Epoch: 1200 Average training loss: 2.0681\n",
      "====> Epoch: 1300 Average training loss: 1.9667\n",
      "====> Epoch: 1400 Average training loss: 1.8666\n",
      "====> Epoch: 1500 Average training loss: 1.7650\n",
      "====> Epoch: 1600 Average training loss: 1.6791\n",
      "====> Epoch: 1700 Average training loss: 1.5982\n",
      "====> Epoch: 1800 Average training loss: 1.5363\n",
      "====> Epoch: 100 Average training loss: 6.5319\n",
      "====> Epoch: 200 Average training loss: 5.3505\n",
      "====> Epoch: 300 Average training loss: 4.5829\n",
      "====> Epoch: 400 Average training loss: 4.0558\n",
      "====> Epoch: 500 Average training loss: 3.6278\n",
      "====> Epoch: 600 Average training loss: 3.2810\n",
      "====> Epoch: 700 Average training loss: 2.9911\n",
      "====> Epoch: 800 Average training loss: 2.7570\n",
      "====> Epoch: 900 Average training loss: 2.5639\n",
      "====> Epoch: 1000 Average training loss: 2.3837\n",
      "====> Epoch: 1100 Average training loss: 2.2330\n",
      "====> Epoch: 1200 Average training loss: 2.0882\n",
      "====> Epoch: 1300 Average training loss: 1.9634\n",
      "====> Epoch: 1400 Average training loss: 1.8735\n",
      "====> Epoch: 1500 Average training loss: 1.7639\n",
      "====> Epoch: 1600 Average training loss: 1.6922\n",
      "====> Epoch: 1700 Average training loss: 1.6141\n",
      "====> Epoch: 1800 Average training loss: 1.5416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 100 Average training loss: 6.5747\n",
      "====> Epoch: 200 Average training loss: 5.3358\n",
      "====> Epoch: 300 Average training loss: 4.5979\n",
      "====> Epoch: 400 Average training loss: 4.0515\n",
      "====> Epoch: 500 Average training loss: 3.6300\n",
      "====> Epoch: 600 Average training loss: 3.2848\n",
      "====> Epoch: 700 Average training loss: 3.0038\n",
      "====> Epoch: 800 Average training loss: 2.7560\n",
      "====> Epoch: 900 Average training loss: 2.5474\n",
      "====> Epoch: 1000 Average training loss: 2.3726\n",
      "====> Epoch: 1100 Average training loss: 2.2254\n",
      "====> Epoch: 1200 Average training loss: 2.0886\n",
      "====> Epoch: 1300 Average training loss: 1.9747\n",
      "====> Epoch: 1400 Average training loss: 1.8632\n",
      "====> Epoch: 1500 Average training loss: 1.7847\n",
      "====> Epoch: 1600 Average training loss: 1.6941\n",
      "====> Epoch: 1700 Average training loss: 1.6103\n",
      "====> Epoch: 1800 Average training loss: 1.5435\n",
      "====> Epoch: 100 Average training loss: 6.4993\n",
      "====> Epoch: 200 Average training loss: 5.3413\n",
      "====> Epoch: 300 Average training loss: 4.5884\n",
      "====> Epoch: 400 Average training loss: 4.0343\n",
      "====> Epoch: 500 Average training loss: 3.6015\n",
      "====> Epoch: 600 Average training loss: 3.2667\n",
      "====> Epoch: 700 Average training loss: 2.9618\n",
      "====> Epoch: 800 Average training loss: 2.7354\n",
      "====> Epoch: 900 Average training loss: 2.5357\n",
      "====> Epoch: 1000 Average training loss: 2.3538\n",
      "====> Epoch: 1100 Average training loss: 2.2230\n",
      "====> Epoch: 1200 Average training loss: 2.0802\n",
      "====> Epoch: 1300 Average training loss: 1.9690\n",
      "====> Epoch: 1400 Average training loss: 1.8509\n",
      "====> Epoch: 1500 Average training loss: 1.7588\n",
      "====> Epoch: 1600 Average training loss: 1.6693\n",
      "====> Epoch: 1700 Average training loss: 1.6078\n",
      "====> Epoch: 1800 Average training loss: 1.5464\n",
      "====> Epoch: 100 Average training loss: 6.9236\n",
      "====> Epoch: 200 Average training loss: 5.6653\n",
      "====> Epoch: 300 Average training loss: 4.8515\n",
      "====> Epoch: 400 Average training loss: 4.2366\n",
      "====> Epoch: 500 Average training loss: 3.7848\n",
      "====> Epoch: 600 Average training loss: 3.4440\n",
      "====> Epoch: 700 Average training loss: 3.1123\n",
      "====> Epoch: 800 Average training loss: 2.8581\n",
      "====> Epoch: 900 Average training loss: 2.6536\n",
      "====> Epoch: 1000 Average training loss: 2.4412\n",
      "====> Epoch: 1100 Average training loss: 2.2724\n",
      "====> Epoch: 1200 Average training loss: 2.1333\n",
      "====> Epoch: 1300 Average training loss: 2.0157\n",
      "====> Epoch: 1400 Average training loss: 1.8847\n",
      "====> Epoch: 1500 Average training loss: 1.8040\n",
      "====> Epoch: 1600 Average training loss: 1.7123\n",
      "====> Epoch: 1700 Average training loss: 1.6437\n",
      "====> Epoch: 1800 Average training loss: 1.5620\n",
      "====> Epoch: 100 Average training loss: 6.6199\n",
      "====> Epoch: 200 Average training loss: 5.3808\n",
      "====> Epoch: 300 Average training loss: 4.6310\n",
      "====> Epoch: 400 Average training loss: 4.0522\n",
      "====> Epoch: 500 Average training loss: 3.6105\n",
      "====> Epoch: 600 Average training loss: 3.2595\n",
      "====> Epoch: 700 Average training loss: 2.9803\n",
      "====> Epoch: 800 Average training loss: 2.7491\n",
      "====> Epoch: 900 Average training loss: 2.5491\n",
      "====> Epoch: 1000 Average training loss: 2.3740\n",
      "====> Epoch: 1100 Average training loss: 2.2147\n",
      "====> Epoch: 1200 Average training loss: 2.0964\n",
      "====> Epoch: 1300 Average training loss: 1.9784\n",
      "====> Epoch: 1400 Average training loss: 1.8712\n",
      "====> Epoch: 1500 Average training loss: 1.7723\n",
      "====> Epoch: 1600 Average training loss: 1.6802\n",
      "====> Epoch: 1700 Average training loss: 1.6257\n",
      "====> Epoch: 1800 Average training loss: 1.5375\n",
      "====> Epoch: 100 Average training loss: 6.5360\n",
      "====> Epoch: 200 Average training loss: 5.3434\n",
      "====> Epoch: 300 Average training loss: 4.5716\n",
      "====> Epoch: 400 Average training loss: 4.0120\n",
      "====> Epoch: 500 Average training loss: 3.5903\n",
      "====> Epoch: 600 Average training loss: 3.2619\n",
      "====> Epoch: 700 Average training loss: 2.9599\n",
      "====> Epoch: 800 Average training loss: 2.7253\n",
      "====> Epoch: 900 Average training loss: 2.5228\n",
      "====> Epoch: 1000 Average training loss: 2.3530\n",
      "====> Epoch: 1100 Average training loss: 2.2172\n",
      "====> Epoch: 1200 Average training loss: 2.0707\n",
      "====> Epoch: 1300 Average training loss: 1.9627\n",
      "====> Epoch: 1400 Average training loss: 1.8676\n",
      "====> Epoch: 1500 Average training loss: 1.7707\n",
      "====> Epoch: 1600 Average training loss: 1.6737\n",
      "====> Epoch: 1700 Average training loss: 1.6007\n",
      "====> Epoch: 1800 Average training loss: 1.5316\n",
      "====> Epoch: 100 Average training loss: 6.5706\n",
      "====> Epoch: 200 Average training loss: 5.3438\n",
      "====> Epoch: 300 Average training loss: 4.5688\n",
      "====> Epoch: 400 Average training loss: 4.0300\n",
      "====> Epoch: 500 Average training loss: 3.6042\n",
      "====> Epoch: 600 Average training loss: 3.2646\n",
      "====> Epoch: 700 Average training loss: 2.9744\n",
      "====> Epoch: 800 Average training loss: 2.7634\n",
      "====> Epoch: 900 Average training loss: 2.5387\n",
      "====> Epoch: 1000 Average training loss: 2.3527\n",
      "====> Epoch: 1100 Average training loss: 2.2246\n",
      "====> Epoch: 1200 Average training loss: 2.0734\n",
      "====> Epoch: 1300 Average training loss: 1.9731\n",
      "====> Epoch: 1400 Average training loss: 1.8721\n",
      "====> Epoch: 1500 Average training loss: 1.7659\n",
      "====> Epoch: 1600 Average training loss: 1.7065\n",
      "====> Epoch: 1700 Average training loss: 1.6115\n",
      "====> Epoch: 1800 Average training loss: 1.5561\n",
      "====> Epoch: 100 Average training loss: 6.6789\n",
      "====> Epoch: 200 Average training loss: 5.4566\n",
      "====> Epoch: 300 Average training loss: 4.6599\n",
      "====> Epoch: 400 Average training loss: 4.1012\n",
      "====> Epoch: 500 Average training loss: 3.6611\n",
      "====> Epoch: 600 Average training loss: 3.3008\n",
      "====> Epoch: 700 Average training loss: 3.0158\n",
      "====> Epoch: 800 Average training loss: 2.7742\n",
      "====> Epoch: 900 Average training loss: 2.5712\n",
      "====> Epoch: 1000 Average training loss: 2.4009\n",
      "====> Epoch: 1100 Average training loss: 2.2421\n",
      "====> Epoch: 1200 Average training loss: 2.1067\n",
      "====> Epoch: 1300 Average training loss: 1.9810\n",
      "====> Epoch: 1400 Average training loss: 1.8693\n",
      "====> Epoch: 1500 Average training loss: 1.7814\n",
      "====> Epoch: 1600 Average training loss: 1.6960\n",
      "====> Epoch: 1700 Average training loss: 1.6179\n",
      "====> Epoch: 1800 Average training loss: 1.5519\n",
      "====> Epoch: 100 Average training loss: 6.5768\n",
      "====> Epoch: 200 Average training loss: 5.3438\n",
      "====> Epoch: 300 Average training loss: 4.5790\n",
      "====> Epoch: 400 Average training loss: 4.0283\n",
      "====> Epoch: 500 Average training loss: 3.5995\n",
      "====> Epoch: 600 Average training loss: 3.2473\n",
      "====> Epoch: 700 Average training loss: 2.9842\n",
      "====> Epoch: 800 Average training loss: 2.7427\n",
      "====> Epoch: 900 Average training loss: 2.5397\n",
      "====> Epoch: 1000 Average training loss: 2.3536\n",
      "====> Epoch: 1100 Average training loss: 2.1543\n",
      "====> Epoch: 1200 Average training loss: 2.0316\n",
      "====> Epoch: 1300 Average training loss: 1.9351\n",
      "====> Epoch: 1400 Average training loss: 1.7684\n",
      "====> Epoch: 1500 Average training loss: 1.6957\n",
      "====> Epoch: 1600 Average training loss: 1.6070\n",
      "====> Epoch: 1700 Average training loss: 1.4420\n",
      "====> Epoch: 1800 Average training loss: 1.4000\n",
      "====> Epoch: 100 Average training loss: 6.7054\n",
      "====> Epoch: 200 Average training loss: 5.4150\n",
      "====> Epoch: 300 Average training loss: 4.6401\n",
      "====> Epoch: 400 Average training loss: 4.0589\n",
      "====> Epoch: 500 Average training loss: 3.6354\n",
      "====> Epoch: 600 Average training loss: 3.2731\n",
      "====> Epoch: 700 Average training loss: 2.9931\n",
      "====> Epoch: 800 Average training loss: 2.7503\n",
      "====> Epoch: 900 Average training loss: 2.5429\n",
      "====> Epoch: 1000 Average training loss: 2.3823\n",
      "====> Epoch: 1100 Average training loss: 2.2059\n",
      "====> Epoch: 1200 Average training loss: 2.1050\n",
      "====> Epoch: 1300 Average training loss: 1.9650\n",
      "====> Epoch: 1400 Average training loss: 1.8649\n",
      "====> Epoch: 1500 Average training loss: 1.7708\n",
      "====> Epoch: 1600 Average training loss: 1.6740\n",
      "====> Epoch: 1700 Average training loss: 1.6046\n",
      "====> Epoch: 1800 Average training loss: 1.5341\n",
      "====> Epoch: 100 Average training loss: 6.7498\n",
      "====> Epoch: 200 Average training loss: 5.4880\n",
      "====> Epoch: 300 Average training loss: 4.7153\n",
      "====> Epoch: 400 Average training loss: 4.1525\n",
      "====> Epoch: 500 Average training loss: 3.7037\n",
      "====> Epoch: 600 Average training loss: 3.3558\n",
      "====> Epoch: 700 Average training loss: 3.0732\n",
      "====> Epoch: 800 Average training loss: 2.8092\n",
      "====> Epoch: 900 Average training loss: 2.5966\n",
      "====> Epoch: 1000 Average training loss: 2.4119\n",
      "====> Epoch: 1100 Average training loss: 2.2553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1200 Average training loss: 2.1163\n",
      "====> Epoch: 1300 Average training loss: 2.0023\n",
      "====> Epoch: 1400 Average training loss: 1.8861\n",
      "====> Epoch: 1500 Average training loss: 1.7793\n",
      "====> Epoch: 1600 Average training loss: 1.7020\n",
      "====> Epoch: 1700 Average training loss: 1.6151\n",
      "====> Epoch: 1800 Average training loss: 1.5601\n",
      "====> Epoch: 100 Average training loss: 6.7009\n",
      "====> Epoch: 200 Average training loss: 5.4276\n",
      "====> Epoch: 300 Average training loss: 4.6440\n",
      "====> Epoch: 400 Average training loss: 4.0584\n",
      "====> Epoch: 500 Average training loss: 3.6209\n",
      "====> Epoch: 600 Average training loss: 3.2750\n",
      "====> Epoch: 700 Average training loss: 2.9848\n",
      "====> Epoch: 800 Average training loss: 2.7399\n",
      "====> Epoch: 900 Average training loss: 2.5422\n",
      "====> Epoch: 1000 Average training loss: 2.3620\n",
      "====> Epoch: 1100 Average training loss: 2.1992\n",
      "====> Epoch: 1200 Average training loss: 2.0840\n",
      "====> Epoch: 1300 Average training loss: 1.9652\n",
      "====> Epoch: 1400 Average training loss: 1.8687\n",
      "====> Epoch: 1500 Average training loss: 1.7642\n",
      "====> Epoch: 1600 Average training loss: 1.6918\n",
      "====> Epoch: 1700 Average training loss: 1.6118\n",
      "====> Epoch: 1800 Average training loss: 1.5461\n",
      "====> Epoch: 100 Average training loss: 6.4890\n",
      "====> Epoch: 200 Average training loss: 5.3337\n",
      "====> Epoch: 300 Average training loss: 4.5909\n",
      "====> Epoch: 400 Average training loss: 4.0483\n",
      "====> Epoch: 500 Average training loss: 3.6176\n",
      "====> Epoch: 600 Average training loss: 3.2779\n",
      "====> Epoch: 700 Average training loss: 2.9942\n",
      "====> Epoch: 800 Average training loss: 2.7547\n",
      "====> Epoch: 900 Average training loss: 2.5571\n",
      "====> Epoch: 1000 Average training loss: 2.3669\n",
      "====> Epoch: 1100 Average training loss: 2.2289\n",
      "====> Epoch: 1200 Average training loss: 2.0754\n",
      "====> Epoch: 1300 Average training loss: 1.9631\n",
      "====> Epoch: 1400 Average training loss: 1.8639\n",
      "====> Epoch: 1500 Average training loss: 1.7603\n",
      "====> Epoch: 1600 Average training loss: 1.6881\n",
      "====> Epoch: 1700 Average training loss: 1.6067\n",
      "====> Epoch: 1800 Average training loss: 1.5362\n",
      "====> Epoch: 100 Average training loss: 6.6146\n",
      "====> Epoch: 200 Average training loss: 5.4000\n",
      "====> Epoch: 300 Average training loss: 4.6284\n",
      "====> Epoch: 400 Average training loss: 4.0594\n",
      "====> Epoch: 500 Average training loss: 3.6308\n",
      "====> Epoch: 600 Average training loss: 3.2738\n",
      "====> Epoch: 700 Average training loss: 3.0042\n",
      "====> Epoch: 800 Average training loss: 2.7470\n",
      "====> Epoch: 900 Average training loss: 2.5499\n",
      "====> Epoch: 1000 Average training loss: 2.3454\n",
      "====> Epoch: 1100 Average training loss: 2.1846\n",
      "====> Epoch: 1200 Average training loss: 2.0071\n",
      "====> Epoch: 1300 Average training loss: 1.8319\n",
      "====> Epoch: 1400 Average training loss: 1.7671\n",
      "====> Epoch: 1500 Average training loss: 1.6693\n",
      "====> Epoch: 1600 Average training loss: 1.5948\n",
      "====> Epoch: 1700 Average training loss: 1.5213\n",
      "====> Epoch: 1800 Average training loss: 1.4557\n",
      "====> Epoch: 100 Average training loss: 6.5706\n",
      "====> Epoch: 200 Average training loss: 5.3513\n",
      "====> Epoch: 300 Average training loss: 4.5694\n",
      "====> Epoch: 400 Average training loss: 4.0466\n",
      "====> Epoch: 500 Average training loss: 3.5896\n",
      "====> Epoch: 600 Average training loss: 3.2546\n",
      "====> Epoch: 700 Average training loss: 2.9673\n",
      "====> Epoch: 800 Average training loss: 2.7547\n",
      "====> Epoch: 900 Average training loss: 2.5158\n",
      "====> Epoch: 1000 Average training loss: 2.3699\n",
      "====> Epoch: 1100 Average training loss: 2.2069\n",
      "====> Epoch: 1200 Average training loss: 2.0691\n",
      "====> Epoch: 1300 Average training loss: 1.9150\n",
      "====> Epoch: 1400 Average training loss: 1.7626\n",
      "====> Epoch: 1500 Average training loss: 1.6887\n",
      "====> Epoch: 1600 Average training loss: 1.6067\n",
      "====> Epoch: 1700 Average training loss: 1.5310\n",
      "====> Epoch: 1800 Average training loss: 1.4521\n",
      "====> Epoch: 100 Average training loss: 6.5532\n",
      "====> Epoch: 200 Average training loss: 5.3494\n",
      "====> Epoch: 300 Average training loss: 4.5958\n",
      "====> Epoch: 400 Average training loss: 4.0517\n",
      "====> Epoch: 500 Average training loss: 3.6184\n",
      "====> Epoch: 600 Average training loss: 3.2731\n",
      "====> Epoch: 700 Average training loss: 2.9871\n",
      "====> Epoch: 800 Average training loss: 2.7512\n",
      "====> Epoch: 900 Average training loss: 2.5578\n",
      "====> Epoch: 1000 Average training loss: 2.3701\n",
      "====> Epoch: 1100 Average training loss: 2.2152\n",
      "====> Epoch: 1200 Average training loss: 2.0834\n",
      "====> Epoch: 1300 Average training loss: 1.9707\n",
      "====> Epoch: 1400 Average training loss: 1.8605\n",
      "====> Epoch: 1500 Average training loss: 1.7625\n",
      "====> Epoch: 1600 Average training loss: 1.6790\n",
      "====> Epoch: 1700 Average training loss: 1.5988\n",
      "====> Epoch: 1800 Average training loss: 1.5279\n",
      "====> Epoch: 100 Average training loss: 6.6863\n",
      "====> Epoch: 200 Average training loss: 5.4376\n",
      "====> Epoch: 300 Average training loss: 4.6553\n",
      "====> Epoch: 400 Average training loss: 4.0811\n",
      "====> Epoch: 500 Average training loss: 3.6575\n",
      "====> Epoch: 600 Average training loss: 3.3147\n",
      "====> Epoch: 700 Average training loss: 2.8480\n",
      "====> Epoch: 800 Average training loss: 2.5650\n",
      "====> Epoch: 900 Average training loss: 2.4474\n",
      "====> Epoch: 1000 Average training loss: 2.2576\n",
      "====> Epoch: 1100 Average training loss: 2.0903\n",
      "====> Epoch: 1200 Average training loss: 1.9435\n",
      "====> Epoch: 1300 Average training loss: 1.8312\n",
      "====> Epoch: 1400 Average training loss: 1.7530\n",
      "====> Epoch: 1500 Average training loss: 1.6565\n",
      "====> Epoch: 1600 Average training loss: 1.5810\n",
      "====> Epoch: 1700 Average training loss: 1.5193\n",
      "====> Epoch: 1800 Average training loss: 1.4463\n",
      "====> Epoch: 100 Average training loss: 6.7723\n",
      "====> Epoch: 200 Average training loss: 5.5302\n",
      "====> Epoch: 300 Average training loss: 4.7131\n",
      "====> Epoch: 400 Average training loss: 4.1400\n",
      "====> Epoch: 500 Average training loss: 3.7096\n",
      "====> Epoch: 600 Average training loss: 3.3399\n",
      "====> Epoch: 700 Average training loss: 3.0557\n",
      "====> Epoch: 800 Average training loss: 2.8069\n",
      "====> Epoch: 900 Average training loss: 2.5972\n",
      "====> Epoch: 1000 Average training loss: 2.4162\n",
      "====> Epoch: 1100 Average training loss: 2.2545\n",
      "====> Epoch: 1200 Average training loss: 2.1308\n",
      "====> Epoch: 1300 Average training loss: 2.0020\n",
      "====> Epoch: 1400 Average training loss: 1.8891\n",
      "====> Epoch: 1500 Average training loss: 1.7883\n",
      "====> Epoch: 1600 Average training loss: 1.6981\n",
      "====> Epoch: 1700 Average training loss: 1.6226\n",
      "====> Epoch: 1800 Average training loss: 1.5493\n",
      "====> Epoch: 100 Average training loss: 6.4800\n",
      "====> Epoch: 200 Average training loss: 5.3023\n",
      "====> Epoch: 300 Average training loss: 4.5626\n",
      "====> Epoch: 400 Average training loss: 4.0309\n",
      "====> Epoch: 500 Average training loss: 3.6022\n",
      "====> Epoch: 600 Average training loss: 3.2632\n",
      "====> Epoch: 700 Average training loss: 2.9748\n",
      "====> Epoch: 800 Average training loss: 2.7382\n",
      "====> Epoch: 900 Average training loss: 2.5274\n",
      "====> Epoch: 1000 Average training loss: 2.3511\n",
      "====> Epoch: 1100 Average training loss: 2.2067\n",
      "====> Epoch: 1200 Average training loss: 2.0685\n",
      "====> Epoch: 1300 Average training loss: 1.9566\n",
      "====> Epoch: 1400 Average training loss: 1.8458\n",
      "====> Epoch: 1500 Average training loss: 1.7614\n",
      "====> Epoch: 1600 Average training loss: 1.6897\n",
      "====> Epoch: 1700 Average training loss: 1.6063\n",
      "====> Epoch: 1800 Average training loss: 1.5315\n",
      "====> Epoch: 100 Average training loss: 6.8869\n",
      "====> Epoch: 200 Average training loss: 5.5774\n",
      "====> Epoch: 300 Average training loss: 4.7429\n",
      "====> Epoch: 400 Average training loss: 4.1579\n",
      "====> Epoch: 500 Average training loss: 3.7092\n",
      "====> Epoch: 600 Average training loss: 3.3534\n",
      "====> Epoch: 700 Average training loss: 3.0490\n",
      "====> Epoch: 800 Average training loss: 2.7862\n",
      "====> Epoch: 900 Average training loss: 2.5737\n",
      "====> Epoch: 1000 Average training loss: 2.3947\n",
      "====> Epoch: 1100 Average training loss: 2.2212\n",
      "====> Epoch: 1200 Average training loss: 2.0973\n",
      "====> Epoch: 1300 Average training loss: 1.9820\n",
      "====> Epoch: 1400 Average training loss: 1.8722\n",
      "====> Epoch: 1500 Average training loss: 1.7745\n",
      "====> Epoch: 1600 Average training loss: 1.6923\n",
      "====> Epoch: 1700 Average training loss: 1.6122\n",
      "====> Epoch: 1800 Average training loss: 1.5445\n",
      "====> Epoch: 100 Average training loss: 6.5687\n",
      "====> Epoch: 200 Average training loss: 5.3560\n",
      "====> Epoch: 300 Average training loss: 4.5865\n",
      "====> Epoch: 400 Average training loss: 4.0601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 500 Average training loss: 3.6030\n",
      "====> Epoch: 600 Average training loss: 3.2738\n",
      "====> Epoch: 700 Average training loss: 2.9951\n",
      "====> Epoch: 800 Average training loss: 2.7564\n",
      "====> Epoch: 900 Average training loss: 2.5542\n",
      "====> Epoch: 1000 Average training loss: 2.3652\n",
      "====> Epoch: 1100 Average training loss: 2.2271\n",
      "====> Epoch: 1200 Average training loss: 2.0769\n",
      "====> Epoch: 1300 Average training loss: 1.9647\n",
      "====> Epoch: 1400 Average training loss: 1.8628\n",
      "====> Epoch: 1500 Average training loss: 1.7728\n",
      "====> Epoch: 1600 Average training loss: 1.7022\n",
      "====> Epoch: 1700 Average training loss: 1.6195\n",
      "====> Epoch: 1800 Average training loss: 1.5419\n",
      "====> Epoch: 100 Average training loss: 6.6679\n",
      "====> Epoch: 200 Average training loss: 5.4468\n",
      "====> Epoch: 300 Average training loss: 4.6444\n",
      "====> Epoch: 400 Average training loss: 4.1064\n",
      "====> Epoch: 500 Average training loss: 3.6756\n",
      "====> Epoch: 600 Average training loss: 3.2988\n",
      "====> Epoch: 700 Average training loss: 3.0044\n",
      "====> Epoch: 800 Average training loss: 2.7715\n",
      "====> Epoch: 900 Average training loss: 2.5637\n",
      "====> Epoch: 1000 Average training loss: 2.3931\n",
      "====> Epoch: 1100 Average training loss: 2.2253\n",
      "====> Epoch: 1200 Average training loss: 2.0941\n",
      "====> Epoch: 1300 Average training loss: 1.9667\n",
      "====> Epoch: 1400 Average training loss: 1.8536\n",
      "====> Epoch: 1500 Average training loss: 1.7765\n",
      "====> Epoch: 1600 Average training loss: 1.6878\n",
      "====> Epoch: 1700 Average training loss: 1.6041\n",
      "====> Epoch: 1800 Average training loss: 1.5401\n",
      "====> Epoch: 100 Average training loss: 6.6883\n",
      "====> Epoch: 200 Average training loss: 5.5150\n",
      "====> Epoch: 300 Average training loss: 4.7015\n",
      "====> Epoch: 400 Average training loss: 4.1459\n",
      "====> Epoch: 500 Average training loss: 3.6986\n",
      "====> Epoch: 600 Average training loss: 3.3386\n",
      "====> Epoch: 700 Average training loss: 3.0519\n",
      "====> Epoch: 800 Average training loss: 2.8066\n",
      "====> Epoch: 900 Average training loss: 2.6078\n",
      "====> Epoch: 1000 Average training loss: 2.4097\n",
      "====> Epoch: 1100 Average training loss: 2.2408\n",
      "====> Epoch: 1200 Average training loss: 2.1018\n",
      "====> Epoch: 1300 Average training loss: 1.9902\n",
      "====> Epoch: 1400 Average training loss: 1.8751\n",
      "====> Epoch: 1500 Average training loss: 1.7794\n",
      "====> Epoch: 1600 Average training loss: 1.6958\n",
      "====> Epoch: 1700 Average training loss: 1.6227\n",
      "====> Epoch: 1800 Average training loss: 1.5443\n",
      "====> Epoch: 100 Average training loss: 6.8007\n",
      "====> Epoch: 200 Average training loss: 5.5585\n",
      "====> Epoch: 300 Average training loss: 4.7667\n",
      "====> Epoch: 400 Average training loss: 4.1830\n",
      "====> Epoch: 500 Average training loss: 3.7467\n",
      "====> Epoch: 600 Average training loss: 3.3600\n",
      "====> Epoch: 700 Average training loss: 3.0741\n",
      "====> Epoch: 800 Average training loss: 2.8143\n",
      "====> Epoch: 900 Average training loss: 2.6075\n",
      "====> Epoch: 1000 Average training loss: 2.4239\n",
      "====> Epoch: 1100 Average training loss: 2.2586\n",
      "====> Epoch: 1200 Average training loss: 2.1185\n",
      "====> Epoch: 1300 Average training loss: 1.9980\n",
      "====> Epoch: 1400 Average training loss: 1.9014\n",
      "====> Epoch: 1500 Average training loss: 1.7817\n",
      "====> Epoch: 1600 Average training loss: 1.7075\n",
      "====> Epoch: 1700 Average training loss: 1.6253\n",
      "====> Epoch: 1800 Average training loss: 1.5520\n",
      "====> Epoch: 100 Average training loss: 6.6190\n",
      "====> Epoch: 200 Average training loss: 5.4324\n",
      "====> Epoch: 300 Average training loss: 4.6416\n",
      "====> Epoch: 400 Average training loss: 4.0842\n",
      "====> Epoch: 500 Average training loss: 3.6471\n",
      "====> Epoch: 600 Average training loss: 3.2950\n",
      "====> Epoch: 700 Average training loss: 3.0132\n",
      "====> Epoch: 800 Average training loss: 2.7722\n",
      "====> Epoch: 900 Average training loss: 2.5632\n",
      "====> Epoch: 1000 Average training loss: 2.3831\n",
      "====> Epoch: 1100 Average training loss: 2.2202\n",
      "====> Epoch: 1200 Average training loss: 2.0772\n",
      "====> Epoch: 1300 Average training loss: 1.9765\n",
      "====> Epoch: 1400 Average training loss: 1.8613\n",
      "====> Epoch: 1500 Average training loss: 1.7749\n",
      "====> Epoch: 1600 Average training loss: 1.6894\n",
      "====> Epoch: 1700 Average training loss: 1.5989\n",
      "====> Epoch: 1800 Average training loss: 1.5376\n",
      "====> Epoch: 100 Average training loss: 6.5556\n",
      "====> Epoch: 200 Average training loss: 5.3521\n",
      "====> Epoch: 300 Average training loss: 4.5977\n",
      "====> Epoch: 400 Average training loss: 4.0704\n",
      "====> Epoch: 500 Average training loss: 3.6398\n",
      "====> Epoch: 600 Average training loss: 3.2901\n",
      "====> Epoch: 700 Average training loss: 2.9943\n",
      "====> Epoch: 800 Average training loss: 2.7701\n",
      "====> Epoch: 900 Average training loss: 2.5650\n",
      "====> Epoch: 1000 Average training loss: 2.3872\n",
      "====> Epoch: 1100 Average training loss: 2.2311\n",
      "====> Epoch: 1200 Average training loss: 2.0846\n",
      "====> Epoch: 1300 Average training loss: 1.9577\n",
      "====> Epoch: 1400 Average training loss: 1.8750\n",
      "====> Epoch: 1500 Average training loss: 1.7748\n",
      "====> Epoch: 1600 Average training loss: 1.6918\n",
      "====> Epoch: 1700 Average training loss: 1.6199\n",
      "====> Epoch: 1800 Average training loss: 1.5429\n",
      "====> Epoch: 100 Average training loss: 6.4010\n",
      "====> Epoch: 200 Average training loss: 5.2754\n",
      "====> Epoch: 300 Average training loss: 4.5424\n",
      "====> Epoch: 400 Average training loss: 3.9850\n",
      "====> Epoch: 500 Average training loss: 3.5846\n",
      "====> Epoch: 600 Average training loss: 3.2491\n",
      "====> Epoch: 700 Average training loss: 2.9715\n",
      "====> Epoch: 800 Average training loss: 2.7257\n",
      "====> Epoch: 900 Average training loss: 2.5391\n",
      "====> Epoch: 1000 Average training loss: 2.3632\n",
      "====> Epoch: 1100 Average training loss: 2.2091\n",
      "====> Epoch: 1200 Average training loss: 2.0872\n",
      "====> Epoch: 1300 Average training loss: 1.9643\n",
      "====> Epoch: 1400 Average training loss: 1.8522\n",
      "====> Epoch: 1500 Average training loss: 1.7627\n",
      "====> Epoch: 1600 Average training loss: 1.6637\n",
      "====> Epoch: 1700 Average training loss: 1.6082\n",
      "====> Epoch: 1800 Average training loss: 1.5270\n",
      "====> Epoch: 100 Average training loss: 6.7087\n",
      "====> Epoch: 200 Average training loss: 5.4581\n",
      "====> Epoch: 300 Average training loss: 4.6772\n",
      "====> Epoch: 400 Average training loss: 3.9976\n",
      "====> Epoch: 500 Average training loss: 3.5382\n",
      "====> Epoch: 600 Average training loss: 3.0610\n",
      "====> Epoch: 700 Average training loss: 2.7878\n",
      "====> Epoch: 800 Average training loss: 2.5485\n",
      "====> Epoch: 900 Average training loss: 2.3616\n",
      "====> Epoch: 1000 Average training loss: 2.2190\n",
      "====> Epoch: 1100 Average training loss: 2.0154\n",
      "====> Epoch: 1200 Average training loss: 1.9060\n",
      "====> Epoch: 1300 Average training loss: 1.7226\n",
      "====> Epoch: 1400 Average training loss: 1.6311\n",
      "====> Epoch: 1500 Average training loss: 1.5562\n",
      "====> Epoch: 1600 Average training loss: 1.4972\n",
      "====> Epoch: 1700 Average training loss: 1.4155\n",
      "====> Epoch: 1800 Average training loss: 1.3595\n",
      "====> Epoch: 100 Average training loss: 6.6192\n",
      "====> Epoch: 200 Average training loss: 5.3762\n",
      "====> Epoch: 300 Average training loss: 4.5843\n",
      "====> Epoch: 400 Average training loss: 4.0365\n",
      "====> Epoch: 500 Average training loss: 3.6433\n",
      "====> Epoch: 600 Average training loss: 3.2807\n",
      "====> Epoch: 700 Average training loss: 2.9821\n",
      "====> Epoch: 800 Average training loss: 2.7557\n",
      "====> Epoch: 900 Average training loss: 2.5559\n",
      "====> Epoch: 1000 Average training loss: 2.3664\n",
      "====> Epoch: 1100 Average training loss: 2.2342\n",
      "====> Epoch: 1200 Average training loss: 2.0929\n",
      "====> Epoch: 1300 Average training loss: 1.9664\n",
      "====> Epoch: 1400 Average training loss: 1.8757\n",
      "====> Epoch: 1500 Average training loss: 1.7703\n",
      "====> Epoch: 1600 Average training loss: 1.6922\n",
      "====> Epoch: 1700 Average training loss: 1.6047\n",
      "====> Epoch: 1800 Average training loss: 1.5382\n",
      "====> Epoch: 100 Average training loss: 6.5287\n",
      "====> Epoch: 200 Average training loss: 5.3203\n",
      "====> Epoch: 300 Average training loss: 4.5646\n",
      "====> Epoch: 400 Average training loss: 4.0097\n",
      "====> Epoch: 500 Average training loss: 3.5962\n",
      "====> Epoch: 600 Average training loss: 3.2607\n",
      "====> Epoch: 700 Average training loss: 2.9862\n",
      "====> Epoch: 800 Average training loss: 2.7561\n",
      "====> Epoch: 900 Average training loss: 2.5597\n",
      "====> Epoch: 1000 Average training loss: 2.3683\n",
      "====> Epoch: 1100 Average training loss: 2.2099\n",
      "====> Epoch: 1200 Average training loss: 2.0996\n",
      "====> Epoch: 1300 Average training loss: 1.9690\n",
      "====> Epoch: 1400 Average training loss: 1.8830\n",
      "====> Epoch: 1500 Average training loss: 1.7850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1600 Average training loss: 1.7092\n",
      "====> Epoch: 1700 Average training loss: 1.6249\n",
      "====> Epoch: 1800 Average training loss: 1.5540\n",
      "====> Epoch: 100 Average training loss: 6.6200\n",
      "====> Epoch: 200 Average training loss: 5.3990\n",
      "====> Epoch: 300 Average training loss: 4.6134\n",
      "====> Epoch: 400 Average training loss: 4.0499\n",
      "====> Epoch: 500 Average training loss: 3.6316\n",
      "====> Epoch: 600 Average training loss: 3.2725\n",
      "====> Epoch: 700 Average training loss: 3.0080\n",
      "====> Epoch: 800 Average training loss: 2.7448\n",
      "====> Epoch: 900 Average training loss: 2.5489\n",
      "====> Epoch: 1000 Average training loss: 2.3614\n",
      "====> Epoch: 1100 Average training loss: 2.2147\n",
      "====> Epoch: 1200 Average training loss: 2.0942\n",
      "====> Epoch: 1300 Average training loss: 1.9686\n",
      "====> Epoch: 1400 Average training loss: 1.8569\n",
      "====> Epoch: 1500 Average training loss: 1.7698\n",
      "====> Epoch: 1600 Average training loss: 1.6858\n",
      "====> Epoch: 1700 Average training loss: 1.6075\n",
      "====> Epoch: 1800 Average training loss: 1.5445\n",
      "====> Epoch: 100 Average training loss: 6.5959\n",
      "====> Epoch: 200 Average training loss: 5.3549\n",
      "====> Epoch: 300 Average training loss: 4.5675\n",
      "====> Epoch: 400 Average training loss: 4.0320\n",
      "====> Epoch: 500 Average training loss: 3.5731\n",
      "====> Epoch: 600 Average training loss: 3.2471\n",
      "====> Epoch: 700 Average training loss: 2.9652\n",
      "====> Epoch: 800 Average training loss: 2.7335\n",
      "====> Epoch: 900 Average training loss: 2.5460\n",
      "====> Epoch: 1000 Average training loss: 2.3607\n",
      "====> Epoch: 1100 Average training loss: 2.2141\n",
      "====> Epoch: 1200 Average training loss: 2.0789\n",
      "====> Epoch: 1300 Average training loss: 1.9715\n",
      "====> Epoch: 1400 Average training loss: 1.8668\n",
      "====> Epoch: 1500 Average training loss: 1.7836\n",
      "====> Epoch: 1600 Average training loss: 1.6857\n",
      "====> Epoch: 1700 Average training loss: 1.6038\n",
      "====> Epoch: 1800 Average training loss: 1.5491\n",
      "====> Epoch: 100 Average training loss: 7.1502\n",
      "====> Epoch: 200 Average training loss: 5.8162\n",
      "====> Epoch: 300 Average training loss: 4.9792\n",
      "====> Epoch: 400 Average training loss: 4.3339\n",
      "====> Epoch: 500 Average training loss: 3.8608\n",
      "====> Epoch: 600 Average training loss: 3.4369\n",
      "====> Epoch: 700 Average training loss: 3.1182\n",
      "====> Epoch: 800 Average training loss: 2.8822\n",
      "====> Epoch: 900 Average training loss: 2.6342\n",
      "====> Epoch: 1000 Average training loss: 2.4403\n",
      "====> Epoch: 1100 Average training loss: 2.2774\n",
      "====> Epoch: 1200 Average training loss: 2.1163\n",
      "====> Epoch: 1300 Average training loss: 1.9914\n",
      "====> Epoch: 1400 Average training loss: 1.8724\n",
      "====> Epoch: 1500 Average training loss: 1.7833\n",
      "====> Epoch: 1600 Average training loss: 1.6917\n",
      "====> Epoch: 1700 Average training loss: 1.6202\n",
      "====> Epoch: 1800 Average training loss: 1.5427\n",
      "====> Epoch: 100 Average training loss: 6.6457\n",
      "====> Epoch: 200 Average training loss: 5.3877\n",
      "====> Epoch: 300 Average training loss: 4.6056\n",
      "====> Epoch: 400 Average training loss: 4.0349\n",
      "====> Epoch: 500 Average training loss: 3.6192\n",
      "====> Epoch: 600 Average training loss: 3.2669\n",
      "====> Epoch: 700 Average training loss: 2.9763\n",
      "====> Epoch: 800 Average training loss: 2.7377\n",
      "====> Epoch: 900 Average training loss: 2.5294\n",
      "====> Epoch: 1000 Average training loss: 2.3681\n",
      "====> Epoch: 1100 Average training loss: 2.2022\n",
      "====> Epoch: 1200 Average training loss: 2.0901\n",
      "====> Epoch: 1300 Average training loss: 1.9555\n",
      "====> Epoch: 1400 Average training loss: 1.8801\n",
      "====> Epoch: 1500 Average training loss: 1.7779\n",
      "====> Epoch: 1600 Average training loss: 1.6912\n",
      "====> Epoch: 1700 Average training loss: 1.6199\n",
      "====> Epoch: 1800 Average training loss: 1.5464\n",
      "====> Epoch: 100 Average training loss: 6.6729\n",
      "====> Epoch: 200 Average training loss: 5.4400\n",
      "====> Epoch: 300 Average training loss: 4.6690\n",
      "====> Epoch: 400 Average training loss: 4.1027\n",
      "====> Epoch: 500 Average training loss: 3.6819\n",
      "====> Epoch: 600 Average training loss: 3.3044\n",
      "====> Epoch: 700 Average training loss: 3.0214\n",
      "====> Epoch: 800 Average training loss: 2.7828\n",
      "====> Epoch: 900 Average training loss: 2.5785\n",
      "====> Epoch: 1000 Average training loss: 2.3995\n",
      "====> Epoch: 1100 Average training loss: 2.2365\n",
      "====> Epoch: 1200 Average training loss: 2.0893\n",
      "====> Epoch: 1300 Average training loss: 1.9863\n",
      "====> Epoch: 1400 Average training loss: 1.8723\n",
      "====> Epoch: 1500 Average training loss: 1.7749\n",
      "====> Epoch: 1600 Average training loss: 1.6888\n",
      "====> Epoch: 1700 Average training loss: 1.6064\n",
      "====> Epoch: 1800 Average training loss: 1.5366\n",
      "====> Epoch: 100 Average training loss: 6.5628\n",
      "====> Epoch: 200 Average training loss: 5.3849\n",
      "====> Epoch: 300 Average training loss: 4.6120\n",
      "====> Epoch: 400 Average training loss: 4.0538\n",
      "====> Epoch: 500 Average training loss: 3.6242\n",
      "====> Epoch: 600 Average training loss: 3.2843\n",
      "====> Epoch: 700 Average training loss: 2.9849\n",
      "====> Epoch: 800 Average training loss: 2.7423\n",
      "====> Epoch: 900 Average training loss: 2.5332\n",
      "====> Epoch: 1000 Average training loss: 2.3467\n",
      "====> Epoch: 1100 Average training loss: 2.2318\n",
      "====> Epoch: 1200 Average training loss: 2.0744\n",
      "====> Epoch: 1300 Average training loss: 1.9641\n",
      "====> Epoch: 1400 Average training loss: 1.8645\n",
      "====> Epoch: 1500 Average training loss: 1.7585\n",
      "====> Epoch: 1600 Average training loss: 1.6843\n",
      "====> Epoch: 1700 Average training loss: 1.6063\n",
      "====> Epoch: 1800 Average training loss: 1.5377\n",
      "====> Epoch: 100 Average training loss: 6.5444\n",
      "====> Epoch: 200 Average training loss: 5.3562\n",
      "====> Epoch: 300 Average training loss: 4.6088\n",
      "====> Epoch: 400 Average training loss: 3.9823\n",
      "====> Epoch: 500 Average training loss: 3.6299\n",
      "====> Epoch: 600 Average training loss: 3.3033\n",
      "====> Epoch: 700 Average training loss: 2.9802\n",
      "====> Epoch: 800 Average training loss: 2.6550\n",
      "====> Epoch: 900 Average training loss: 2.4480\n",
      "====> Epoch: 1000 Average training loss: 2.2498\n",
      "====> Epoch: 1100 Average training loss: 2.1136\n",
      "====> Epoch: 1200 Average training loss: 2.0271\n",
      "====> Epoch: 1300 Average training loss: 1.9062\n",
      "====> Epoch: 1400 Average training loss: 1.7712\n",
      "====> Epoch: 1500 Average training loss: 1.6798\n",
      "====> Epoch: 1600 Average training loss: 1.6129\n",
      "====> Epoch: 1700 Average training loss: 1.5526\n",
      "====> Epoch: 1800 Average training loss: 1.4771\n",
      "====> Epoch: 100 Average training loss: 6.6350\n",
      "====> Epoch: 200 Average training loss: 5.3782\n",
      "====> Epoch: 300 Average training loss: 4.5967\n",
      "====> Epoch: 400 Average training loss: 4.0576\n",
      "====> Epoch: 500 Average training loss: 3.6200\n",
      "====> Epoch: 600 Average training loss: 3.2641\n",
      "====> Epoch: 700 Average training loss: 2.9812\n",
      "====> Epoch: 800 Average training loss: 2.7510\n",
      "====> Epoch: 900 Average training loss: 2.5495\n",
      "====> Epoch: 1000 Average training loss: 2.3611\n",
      "====> Epoch: 1100 Average training loss: 2.2282\n",
      "====> Epoch: 1200 Average training loss: 2.0894\n",
      "====> Epoch: 1300 Average training loss: 1.9625\n",
      "====> Epoch: 1400 Average training loss: 1.8554\n",
      "====> Epoch: 1500 Average training loss: 1.7642\n",
      "====> Epoch: 1600 Average training loss: 1.6848\n",
      "====> Epoch: 1700 Average training loss: 1.6032\n",
      "====> Epoch: 1800 Average training loss: 1.5441\n",
      "====> Epoch: 100 Average training loss: 6.5799\n",
      "====> Epoch: 200 Average training loss: 5.3583\n",
      "====> Epoch: 300 Average training loss: 4.6105\n",
      "====> Epoch: 400 Average training loss: 4.0535\n",
      "====> Epoch: 500 Average training loss: 3.6117\n",
      "====> Epoch: 600 Average training loss: 3.2740\n",
      "====> Epoch: 700 Average training loss: 2.9954\n",
      "====> Epoch: 800 Average training loss: 2.7632\n",
      "====> Epoch: 900 Average training loss: 2.5536\n",
      "====> Epoch: 1000 Average training loss: 2.3798\n",
      "====> Epoch: 1100 Average training loss: 2.2346\n",
      "====> Epoch: 1200 Average training loss: 2.1159\n",
      "====> Epoch: 1300 Average training loss: 1.9699\n",
      "====> Epoch: 1400 Average training loss: 1.8781\n",
      "====> Epoch: 1500 Average training loss: 1.7935\n",
      "====> Epoch: 1600 Average training loss: 1.6969\n",
      "====> Epoch: 1700 Average training loss: 1.6273\n",
      "====> Epoch: 1800 Average training loss: 1.5568\n",
      "====> Epoch: 100 Average training loss: 6.8050\n",
      "====> Epoch: 200 Average training loss: 5.5155\n",
      "====> Epoch: 300 Average training loss: 4.6727\n",
      "====> Epoch: 400 Average training loss: 4.1272\n",
      "====> Epoch: 500 Average training loss: 3.6962\n",
      "====> Epoch: 600 Average training loss: 3.3190\n",
      "====> Epoch: 700 Average training loss: 3.0205\n",
      "====> Epoch: 800 Average training loss: 2.7816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 900 Average training loss: 2.5767\n",
      "====> Epoch: 1000 Average training loss: 2.3899\n",
      "====> Epoch: 1100 Average training loss: 2.2261\n",
      "====> Epoch: 1200 Average training loss: 2.0980\n",
      "====> Epoch: 1300 Average training loss: 1.9804\n",
      "====> Epoch: 1400 Average training loss: 1.8655\n",
      "====> Epoch: 1500 Average training loss: 1.7567\n",
      "====> Epoch: 1600 Average training loss: 1.6932\n",
      "====> Epoch: 1700 Average training loss: 1.6091\n",
      "====> Epoch: 1800 Average training loss: 1.5477\n",
      "====> Epoch: 100 Average training loss: 6.5199\n",
      "====> Epoch: 200 Average training loss: 5.2878\n",
      "====> Epoch: 300 Average training loss: 4.5480\n",
      "====> Epoch: 400 Average training loss: 3.9972\n",
      "====> Epoch: 500 Average training loss: 3.5758\n",
      "====> Epoch: 600 Average training loss: 3.2435\n",
      "====> Epoch: 700 Average training loss: 2.9628\n",
      "====> Epoch: 800 Average training loss: 2.7397\n",
      "====> Epoch: 900 Average training loss: 2.5330\n",
      "====> Epoch: 1000 Average training loss: 2.3564\n",
      "====> Epoch: 1100 Average training loss: 2.2142\n",
      "====> Epoch: 1200 Average training loss: 2.0809\n",
      "====> Epoch: 1300 Average training loss: 1.9721\n",
      "====> Epoch: 1400 Average training loss: 1.8552\n",
      "====> Epoch: 1500 Average training loss: 1.7691\n",
      "====> Epoch: 1600 Average training loss: 1.6784\n",
      "====> Epoch: 1700 Average training loss: 1.6081\n",
      "====> Epoch: 1800 Average training loss: 1.5383\n",
      "====> Epoch: 100 Average training loss: 6.6032\n",
      "====> Epoch: 200 Average training loss: 5.3632\n",
      "====> Epoch: 300 Average training loss: 4.5927\n",
      "====> Epoch: 400 Average training loss: 4.0260\n",
      "====> Epoch: 500 Average training loss: 3.6169\n",
      "====> Epoch: 600 Average training loss: 3.2793\n",
      "====> Epoch: 700 Average training loss: 2.9967\n",
      "====> Epoch: 800 Average training loss: 2.7587\n",
      "====> Epoch: 900 Average training loss: 2.5522\n",
      "====> Epoch: 1000 Average training loss: 2.3756\n",
      "====> Epoch: 1100 Average training loss: 2.2415\n",
      "====> Epoch: 1200 Average training loss: 2.0940\n",
      "====> Epoch: 1300 Average training loss: 1.9794\n",
      "====> Epoch: 1400 Average training loss: 1.8837\n",
      "====> Epoch: 1500 Average training loss: 1.7748\n",
      "====> Epoch: 1600 Average training loss: 1.6895\n",
      "====> Epoch: 1700 Average training loss: 1.6166\n",
      "====> Epoch: 1800 Average training loss: 1.5507\n",
      "====> Epoch: 100 Average training loss: 6.5777\n",
      "====> Epoch: 200 Average training loss: 5.3956\n",
      "====> Epoch: 300 Average training loss: 4.6257\n",
      "====> Epoch: 400 Average training loss: 4.0764\n",
      "====> Epoch: 500 Average training loss: 3.6411\n",
      "====> Epoch: 600 Average training loss: 3.2956\n",
      "====> Epoch: 700 Average training loss: 2.9998\n",
      "====> Epoch: 800 Average training loss: 2.7635\n",
      "====> Epoch: 900 Average training loss: 2.5587\n",
      "====> Epoch: 1000 Average training loss: 2.3874\n",
      "====> Epoch: 1100 Average training loss: 2.2397\n",
      "====> Epoch: 1200 Average training loss: 2.0860\n",
      "====> Epoch: 1300 Average training loss: 1.9761\n",
      "====> Epoch: 1400 Average training loss: 1.8601\n",
      "====> Epoch: 1500 Average training loss: 1.7625\n",
      "====> Epoch: 1600 Average training loss: 1.6957\n",
      "====> Epoch: 1700 Average training loss: 1.6122\n",
      "====> Epoch: 1800 Average training loss: 1.5441\n",
      "====> Epoch: 100 Average training loss: 6.5819\n",
      "====> Epoch: 200 Average training loss: 5.3755\n",
      "====> Epoch: 300 Average training loss: 4.6011\n",
      "====> Epoch: 400 Average training loss: 4.0342\n",
      "====> Epoch: 500 Average training loss: 3.6110\n",
      "====> Epoch: 600 Average training loss: 3.2507\n",
      "====> Epoch: 700 Average training loss: 2.9843\n",
      "====> Epoch: 800 Average training loss: 2.7509\n",
      "====> Epoch: 900 Average training loss: 2.5518\n",
      "====> Epoch: 1000 Average training loss: 2.3571\n",
      "====> Epoch: 1100 Average training loss: 2.2242\n",
      "====> Epoch: 1200 Average training loss: 2.0783\n",
      "====> Epoch: 1300 Average training loss: 1.9687\n",
      "====> Epoch: 1400 Average training loss: 1.8618\n",
      "====> Epoch: 1500 Average training loss: 1.7549\n",
      "====> Epoch: 1600 Average training loss: 1.6805\n",
      "====> Epoch: 1700 Average training loss: 1.6068\n",
      "====> Epoch: 1800 Average training loss: 1.5462\n",
      "====> Epoch: 100 Average training loss: 6.6806\n",
      "====> Epoch: 200 Average training loss: 5.4053\n",
      "====> Epoch: 300 Average training loss: 4.3467\n",
      "====> Epoch: 400 Average training loss: 3.9849\n",
      "====> Epoch: 500 Average training loss: 3.5750\n",
      "====> Epoch: 600 Average training loss: 3.1204\n",
      "====> Epoch: 700 Average training loss: 2.8209\n",
      "====> Epoch: 800 Average training loss: 2.5689\n",
      "====> Epoch: 900 Average training loss: 2.3774\n",
      "====> Epoch: 1000 Average training loss: 2.2517\n",
      "====> Epoch: 1100 Average training loss: 2.0730\n",
      "====> Epoch: 1200 Average training loss: 1.9472\n",
      "====> Epoch: 1300 Average training loss: 1.8666\n",
      "====> Epoch: 1400 Average training loss: 1.7525\n",
      "====> Epoch: 1500 Average training loss: 1.6798\n",
      "====> Epoch: 1600 Average training loss: 1.5811\n",
      "====> Epoch: 1700 Average training loss: 1.5335\n",
      "====> Epoch: 1800 Average training loss: 1.4805\n",
      "====> Epoch: 100 Average training loss: 6.5211\n",
      "====> Epoch: 200 Average training loss: 5.3545\n",
      "====> Epoch: 300 Average training loss: 4.5975\n",
      "====> Epoch: 400 Average training loss: 4.0516\n",
      "====> Epoch: 500 Average training loss: 3.6327\n",
      "====> Epoch: 600 Average training loss: 3.2862\n",
      "====> Epoch: 700 Average training loss: 2.9805\n",
      "====> Epoch: 800 Average training loss: 2.7402\n",
      "====> Epoch: 900 Average training loss: 2.5426\n",
      "====> Epoch: 1000 Average training loss: 2.3698\n",
      "====> Epoch: 1100 Average training loss: 2.2241\n",
      "====> Epoch: 1200 Average training loss: 2.0850\n",
      "====> Epoch: 1300 Average training loss: 1.9628\n",
      "====> Epoch: 1400 Average training loss: 1.8580\n",
      "====> Epoch: 1500 Average training loss: 1.7610\n",
      "====> Epoch: 1600 Average training loss: 1.6999\n",
      "====> Epoch: 1700 Average training loss: 1.6010\n",
      "====> Epoch: 1800 Average training loss: 1.5390\n",
      "====> Epoch: 100 Average training loss: 6.8234\n",
      "====> Epoch: 200 Average training loss: 5.4797\n",
      "====> Epoch: 300 Average training loss: 4.6856\n",
      "====> Epoch: 400 Average training loss: 4.1215\n",
      "====> Epoch: 500 Average training loss: 3.6677\n",
      "====> Epoch: 600 Average training loss: 3.3072\n",
      "====> Epoch: 700 Average training loss: 3.0298\n",
      "====> Epoch: 800 Average training loss: 2.6696\n",
      "====> Epoch: 900 Average training loss: 2.3954\n",
      "====> Epoch: 1000 Average training loss: 2.2033\n",
      "====> Epoch: 1100 Average training loss: 2.0654\n",
      "====> Epoch: 1200 Average training loss: 1.9373\n",
      "====> Epoch: 1300 Average training loss: 1.8194\n",
      "====> Epoch: 1400 Average training loss: 1.7311\n",
      "====> Epoch: 1500 Average training loss: 1.6544\n",
      "====> Epoch: 1600 Average training loss: 1.5750\n",
      "====> Epoch: 1700 Average training loss: 1.5031\n",
      "====> Epoch: 1800 Average training loss: 1.4570\n",
      "====> Epoch: 100 Average training loss: 6.6050\n",
      "====> Epoch: 200 Average training loss: 5.3594\n",
      "====> Epoch: 300 Average training loss: 4.5719\n",
      "====> Epoch: 400 Average training loss: 4.0176\n",
      "====> Epoch: 500 Average training loss: 3.5851\n",
      "====> Epoch: 600 Average training loss: 3.2633\n",
      "====> Epoch: 700 Average training loss: 2.9871\n",
      "====> Epoch: 800 Average training loss: 2.7328\n",
      "====> Epoch: 900 Average training loss: 2.5578\n",
      "====> Epoch: 1000 Average training loss: 2.3715\n",
      "====> Epoch: 1100 Average training loss: 2.2154\n",
      "====> Epoch: 1200 Average training loss: 2.0799\n",
      "====> Epoch: 1300 Average training loss: 1.9724\n",
      "====> Epoch: 1400 Average training loss: 1.8592\n",
      "====> Epoch: 1500 Average training loss: 1.7794\n",
      "====> Epoch: 1600 Average training loss: 1.6800\n",
      "====> Epoch: 1700 Average training loss: 1.6224\n",
      "====> Epoch: 1800 Average training loss: 1.5627\n",
      "====> Epoch: 100 Average training loss: 6.4347\n",
      "====> Epoch: 200 Average training loss: 5.2595\n",
      "====> Epoch: 300 Average training loss: 4.5333\n",
      "====> Epoch: 400 Average training loss: 4.0072\n",
      "====> Epoch: 500 Average training loss: 3.5931\n",
      "====> Epoch: 600 Average training loss: 3.2391\n",
      "====> Epoch: 700 Average training loss: 2.9781\n",
      "====> Epoch: 800 Average training loss: 2.7423\n",
      "====> Epoch: 900 Average training loss: 2.5425\n",
      "====> Epoch: 1000 Average training loss: 2.3633\n",
      "====> Epoch: 1100 Average training loss: 2.2094\n",
      "====> Epoch: 1200 Average training loss: 2.0662\n",
      "====> Epoch: 1300 Average training loss: 1.9639\n",
      "====> Epoch: 1400 Average training loss: 1.8651\n",
      "====> Epoch: 1500 Average training loss: 1.7724\n",
      "====> Epoch: 1600 Average training loss: 1.6858\n",
      "====> Epoch: 1700 Average training loss: 1.5880\n",
      "====> Epoch: 1800 Average training loss: 1.5394\n",
      "====> Epoch: 100 Average training loss: 6.5948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 200 Average training loss: 5.3641\n",
      "====> Epoch: 300 Average training loss: 4.5978\n",
      "====> Epoch: 400 Average training loss: 4.0436\n",
      "====> Epoch: 500 Average training loss: 3.6088\n",
      "====> Epoch: 600 Average training loss: 3.2675\n",
      "====> Epoch: 700 Average training loss: 2.9836\n",
      "====> Epoch: 800 Average training loss: 2.7398\n",
      "====> Epoch: 900 Average training loss: 2.5429\n",
      "====> Epoch: 1000 Average training loss: 2.3763\n",
      "====> Epoch: 1100 Average training loss: 2.2149\n",
      "====> Epoch: 1200 Average training loss: 2.0776\n",
      "====> Epoch: 1300 Average training loss: 1.9641\n",
      "====> Epoch: 1400 Average training loss: 1.8602\n",
      "====> Epoch: 1500 Average training loss: 1.7689\n",
      "====> Epoch: 1600 Average training loss: 1.6849\n",
      "====> Epoch: 1700 Average training loss: 1.5972\n",
      "====> Epoch: 1800 Average training loss: 1.5355\n",
      "====> Epoch: 100 Average training loss: 6.5693\n",
      "====> Epoch: 200 Average training loss: 5.3612\n",
      "====> Epoch: 300 Average training loss: 4.5618\n",
      "====> Epoch: 400 Average training loss: 4.0241\n",
      "====> Epoch: 500 Average training loss: 3.6165\n",
      "====> Epoch: 600 Average training loss: 3.2514\n",
      "====> Epoch: 700 Average training loss: 2.9762\n",
      "====> Epoch: 800 Average training loss: 2.7326\n",
      "====> Epoch: 900 Average training loss: 2.5278\n",
      "====> Epoch: 1000 Average training loss: 2.3669\n",
      "====> Epoch: 1100 Average training loss: 2.2036\n",
      "====> Epoch: 1200 Average training loss: 2.0668\n",
      "====> Epoch: 1300 Average training loss: 1.9607\n",
      "====> Epoch: 1400 Average training loss: 1.8512\n",
      "====> Epoch: 1500 Average training loss: 1.7651\n",
      "====> Epoch: 1600 Average training loss: 1.6868\n",
      "====> Epoch: 1700 Average training loss: 1.5929\n",
      "====> Epoch: 1800 Average training loss: 1.5358\n",
      "====> Epoch: 100 Average training loss: 6.7372\n",
      "====> Epoch: 200 Average training loss: 5.4563\n",
      "====> Epoch: 300 Average training loss: 4.6630\n",
      "====> Epoch: 400 Average training loss: 4.0661\n",
      "====> Epoch: 500 Average training loss: 3.6436\n",
      "====> Epoch: 600 Average training loss: 3.2983\n",
      "====> Epoch: 700 Average training loss: 3.0114\n",
      "====> Epoch: 800 Average training loss: 2.7892\n",
      "====> Epoch: 900 Average training loss: 2.5707\n",
      "====> Epoch: 1000 Average training loss: 2.3869\n",
      "====> Epoch: 1100 Average training loss: 2.2367\n",
      "====> Epoch: 1200 Average training loss: 2.1048\n",
      "====> Epoch: 1300 Average training loss: 1.9888\n",
      "====> Epoch: 1400 Average training loss: 1.8846\n",
      "====> Epoch: 1500 Average training loss: 1.7887\n",
      "====> Epoch: 1600 Average training loss: 1.7068\n",
      "====> Epoch: 1700 Average training loss: 1.6173\n",
      "====> Epoch: 1800 Average training loss: 1.5675\n",
      "====> Epoch: 100 Average training loss: 6.7941\n",
      "====> Epoch: 200 Average training loss: 5.5473\n",
      "====> Epoch: 300 Average training loss: 4.7447\n",
      "====> Epoch: 400 Average training loss: 4.1569\n",
      "====> Epoch: 500 Average training loss: 3.6938\n",
      "====> Epoch: 600 Average training loss: 3.3409\n",
      "====> Epoch: 700 Average training loss: 3.0468\n",
      "====> Epoch: 800 Average training loss: 2.7921\n",
      "====> Epoch: 900 Average training loss: 2.5662\n",
      "====> Epoch: 1000 Average training loss: 2.3880\n",
      "====> Epoch: 1100 Average training loss: 2.2358\n",
      "====> Epoch: 1200 Average training loss: 2.0976\n",
      "====> Epoch: 1300 Average training loss: 1.9685\n",
      "====> Epoch: 1400 Average training loss: 1.8723\n",
      "====> Epoch: 1500 Average training loss: 1.7728\n",
      "====> Epoch: 1600 Average training loss: 1.6865\n",
      "====> Epoch: 1700 Average training loss: 1.6047\n",
      "====> Epoch: 1800 Average training loss: 1.5422\n",
      "====> Epoch: 100 Average training loss: 6.5387\n",
      "====> Epoch: 200 Average training loss: 5.3281\n",
      "====> Epoch: 300 Average training loss: 4.5554\n",
      "====> Epoch: 400 Average training loss: 4.0130\n",
      "====> Epoch: 500 Average training loss: 3.6089\n",
      "====> Epoch: 600 Average training loss: 3.2606\n",
      "====> Epoch: 700 Average training loss: 2.9970\n",
      "====> Epoch: 800 Average training loss: 2.7614\n",
      "====> Epoch: 900 Average training loss: 2.5489\n",
      "====> Epoch: 1000 Average training loss: 2.3684\n",
      "====> Epoch: 1100 Average training loss: 2.2046\n",
      "====> Epoch: 1200 Average training loss: 2.0899\n",
      "====> Epoch: 1300 Average training loss: 1.9615\n",
      "====> Epoch: 1400 Average training loss: 1.8618\n",
      "====> Epoch: 1500 Average training loss: 1.7733\n",
      "====> Epoch: 1600 Average training loss: 1.6815\n",
      "====> Epoch: 1700 Average training loss: 1.6049\n",
      "====> Epoch: 1800 Average training loss: 1.5508\n",
      "====> Epoch: 100 Average training loss: 6.8464\n",
      "====> Epoch: 200 Average training loss: 5.3792\n",
      "====> Epoch: 300 Average training loss: 4.6652\n",
      "====> Epoch: 400 Average training loss: 4.1015\n",
      "====> Epoch: 500 Average training loss: 3.6520\n",
      "====> Epoch: 600 Average training loss: 3.2688\n",
      "====> Epoch: 700 Average training loss: 2.9721\n",
      "====> Epoch: 800 Average training loss: 2.5323\n",
      "====> Epoch: 900 Average training loss: 2.4353\n",
      "====> Epoch: 1000 Average training loss: 2.2566\n",
      "====> Epoch: 1100 Average training loss: 2.1117\n",
      "====> Epoch: 1200 Average training loss: 1.9813\n",
      "====> Epoch: 1300 Average training loss: 1.8884\n",
      "====> Epoch: 1400 Average training loss: 1.7707\n",
      "====> Epoch: 1500 Average training loss: 1.6809\n",
      "====> Epoch: 1600 Average training loss: 1.6025\n",
      "====> Epoch: 1700 Average training loss: 1.5249\n",
      "====> Epoch: 1800 Average training loss: 1.4861\n",
      "====> Epoch: 100 Average training loss: 6.9257\n",
      "====> Epoch: 200 Average training loss: 5.6345\n",
      "====> Epoch: 300 Average training loss: 4.8148\n",
      "====> Epoch: 400 Average training loss: 4.2456\n",
      "====> Epoch: 500 Average training loss: 3.7613\n",
      "====> Epoch: 600 Average training loss: 3.4141\n",
      "====> Epoch: 700 Average training loss: 3.1078\n",
      "====> Epoch: 800 Average training loss: 2.8600\n",
      "====> Epoch: 900 Average training loss: 2.6467\n",
      "====> Epoch: 1000 Average training loss: 2.4411\n",
      "====> Epoch: 1100 Average training loss: 2.2624\n",
      "====> Epoch: 1200 Average training loss: 2.1315\n",
      "====> Epoch: 1300 Average training loss: 2.0007\n",
      "====> Epoch: 1400 Average training loss: 1.8867\n",
      "====> Epoch: 1500 Average training loss: 1.7858\n",
      "====> Epoch: 1600 Average training loss: 1.7251\n",
      "====> Epoch: 1700 Average training loss: 1.6250\n",
      "====> Epoch: 1800 Average training loss: 1.5497\n",
      "====> Epoch: 100 Average training loss: 6.5127\n",
      "====> Epoch: 200 Average training loss: 5.3393\n",
      "====> Epoch: 300 Average training loss: 4.5990\n",
      "====> Epoch: 400 Average training loss: 4.0399\n",
      "====> Epoch: 500 Average training loss: 3.6133\n",
      "====> Epoch: 600 Average training loss: 3.2577\n",
      "====> Epoch: 700 Average training loss: 2.9749\n",
      "====> Epoch: 800 Average training loss: 2.7642\n",
      "====> Epoch: 900 Average training loss: 2.5272\n",
      "====> Epoch: 1000 Average training loss: 2.3762\n",
      "====> Epoch: 1100 Average training loss: 2.2136\n",
      "====> Epoch: 1200 Average training loss: 2.0830\n",
      "====> Epoch: 1300 Average training loss: 1.9672\n",
      "====> Epoch: 1400 Average training loss: 1.8569\n",
      "====> Epoch: 1500 Average training loss: 1.7778\n",
      "====> Epoch: 1600 Average training loss: 1.6900\n",
      "====> Epoch: 1700 Average training loss: 1.6081\n",
      "====> Epoch: 1800 Average training loss: 1.5435\n",
      "====> Epoch: 100 Average training loss: 6.5983\n",
      "====> Epoch: 200 Average training loss: 5.3974\n",
      "====> Epoch: 300 Average training loss: 4.6209\n",
      "====> Epoch: 400 Average training loss: 4.0606\n",
      "====> Epoch: 500 Average training loss: 3.6149\n",
      "====> Epoch: 600 Average training loss: 3.2795\n",
      "====> Epoch: 700 Average training loss: 2.9873\n",
      "====> Epoch: 800 Average training loss: 2.7731\n",
      "====> Epoch: 900 Average training loss: 2.5571\n",
      "====> Epoch: 1000 Average training loss: 2.3697\n",
      "====> Epoch: 1100 Average training loss: 2.2197\n",
      "====> Epoch: 1200 Average training loss: 2.0839\n",
      "====> Epoch: 1300 Average training loss: 1.9803\n",
      "====> Epoch: 1400 Average training loss: 1.8569\n",
      "====> Epoch: 1500 Average training loss: 1.7746\n",
      "====> Epoch: 1600 Average training loss: 1.6776\n",
      "====> Epoch: 1700 Average training loss: 1.6045\n",
      "====> Epoch: 1800 Average training loss: 1.5369\n",
      "====> Epoch: 100 Average training loss: 6.8049\n",
      "====> Epoch: 200 Average training loss: 5.5148\n",
      "====> Epoch: 300 Average training loss: 4.7072\n",
      "====> Epoch: 400 Average training loss: 4.1502\n",
      "====> Epoch: 500 Average training loss: 3.6947\n",
      "====> Epoch: 600 Average training loss: 3.3256\n",
      "====> Epoch: 700 Average training loss: 3.0340\n",
      "====> Epoch: 800 Average training loss: 2.7882\n",
      "====> Epoch: 900 Average training loss: 2.5942\n",
      "====> Epoch: 1000 Average training loss: 2.3995\n",
      "====> Epoch: 1100 Average training loss: 2.2533\n",
      "====> Epoch: 1200 Average training loss: 2.1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1300 Average training loss: 1.9823\n",
      "====> Epoch: 1400 Average training loss: 1.8749\n",
      "====> Epoch: 1500 Average training loss: 1.7894\n",
      "====> Epoch: 1600 Average training loss: 1.6901\n",
      "====> Epoch: 1700 Average training loss: 1.6154\n",
      "====> Epoch: 1800 Average training loss: 1.5506\n",
      "====> Epoch: 100 Average training loss: 6.4279\n",
      "====> Epoch: 200 Average training loss: 5.2809\n",
      "====> Epoch: 300 Average training loss: 4.5501\n",
      "====> Epoch: 400 Average training loss: 4.0070\n",
      "====> Epoch: 500 Average training loss: 3.5938\n",
      "====> Epoch: 600 Average training loss: 3.2436\n",
      "====> Epoch: 700 Average training loss: 2.9706\n",
      "====> Epoch: 800 Average training loss: 2.7267\n",
      "====> Epoch: 900 Average training loss: 2.5486\n",
      "====> Epoch: 1000 Average training loss: 2.3582\n",
      "====> Epoch: 1100 Average training loss: 2.2145\n",
      "====> Epoch: 1200 Average training loss: 2.0842\n",
      "====> Epoch: 1300 Average training loss: 1.9637\n",
      "====> Epoch: 1400 Average training loss: 1.8538\n",
      "====> Epoch: 1500 Average training loss: 1.7595\n",
      "====> Epoch: 1600 Average training loss: 1.6739\n",
      "====> Epoch: 1700 Average training loss: 1.6158\n",
      "====> Epoch: 1800 Average training loss: 1.5347\n",
      "====> Epoch: 100 Average training loss: 6.6108\n",
      "====> Epoch: 200 Average training loss: 5.3565\n",
      "====> Epoch: 300 Average training loss: 4.5971\n",
      "====> Epoch: 400 Average training loss: 4.0242\n",
      "====> Epoch: 500 Average training loss: 3.5965\n",
      "====> Epoch: 600 Average training loss: 3.2459\n",
      "====> Epoch: 700 Average training loss: 2.9557\n",
      "====> Epoch: 800 Average training loss: 2.7355\n",
      "====> Epoch: 900 Average training loss: 2.5103\n",
      "====> Epoch: 1000 Average training loss: 2.3424\n",
      "====> Epoch: 1100 Average training loss: 2.2046\n",
      "====> Epoch: 1200 Average training loss: 2.0609\n",
      "====> Epoch: 1300 Average training loss: 1.9414\n",
      "====> Epoch: 1400 Average training loss: 1.8466\n",
      "====> Epoch: 1500 Average training loss: 1.7564\n",
      "====> Epoch: 1600 Average training loss: 1.6692\n",
      "====> Epoch: 1700 Average training loss: 1.5983\n",
      "====> Epoch: 1800 Average training loss: 1.5215\n",
      "====> Epoch: 100 Average training loss: 6.5816\n",
      "====> Epoch: 200 Average training loss: 5.3764\n",
      "====> Epoch: 300 Average training loss: 4.6259\n",
      "====> Epoch: 400 Average training loss: 4.0706\n",
      "====> Epoch: 500 Average training loss: 3.6559\n",
      "====> Epoch: 600 Average training loss: 3.3074\n",
      "====> Epoch: 700 Average training loss: 3.0293\n",
      "====> Epoch: 800 Average training loss: 2.7645\n",
      "====> Epoch: 900 Average training loss: 2.5662\n",
      "====> Epoch: 1000 Average training loss: 2.3931\n",
      "====> Epoch: 1100 Average training loss: 2.2346\n",
      "====> Epoch: 1200 Average training loss: 2.0996\n",
      "====> Epoch: 1300 Average training loss: 1.9770\n",
      "====> Epoch: 1400 Average training loss: 1.8647\n",
      "====> Epoch: 1500 Average training loss: 1.7775\n",
      "====> Epoch: 1600 Average training loss: 1.6967\n",
      "====> Epoch: 1700 Average training loss: 1.6206\n",
      "====> Epoch: 1800 Average training loss: 1.5413\n",
      "====> Epoch: 100 Average training loss: 6.6575\n",
      "====> Epoch: 200 Average training loss: 5.3984\n",
      "====> Epoch: 300 Average training loss: 4.6241\n",
      "====> Epoch: 400 Average training loss: 4.0504\n",
      "====> Epoch: 500 Average training loss: 3.6312\n",
      "====> Epoch: 600 Average training loss: 3.2801\n",
      "====> Epoch: 700 Average training loss: 3.0027\n",
      "====> Epoch: 800 Average training loss: 2.7587\n",
      "====> Epoch: 900 Average training loss: 2.5641\n",
      "====> Epoch: 1000 Average training loss: 2.3806\n",
      "====> Epoch: 1100 Average training loss: 2.2198\n",
      "====> Epoch: 1200 Average training loss: 2.0929\n",
      "====> Epoch: 1300 Average training loss: 1.9746\n",
      "====> Epoch: 1400 Average training loss: 1.8729\n",
      "====> Epoch: 1500 Average training loss: 1.7793\n",
      "====> Epoch: 1600 Average training loss: 1.6920\n",
      "====> Epoch: 1700 Average training loss: 1.6161\n",
      "====> Epoch: 1800 Average training loss: 1.5491\n",
      "====> Epoch: 100 Average training loss: 6.5441\n",
      "====> Epoch: 200 Average training loss: 5.3837\n",
      "====> Epoch: 300 Average training loss: 4.6347\n",
      "====> Epoch: 400 Average training loss: 4.0792\n",
      "====> Epoch: 500 Average training loss: 3.6412\n",
      "====> Epoch: 600 Average training loss: 3.3013\n",
      "====> Epoch: 700 Average training loss: 3.0149\n",
      "====> Epoch: 800 Average training loss: 2.7682\n",
      "====> Epoch: 900 Average training loss: 2.5641\n",
      "====> Epoch: 1000 Average training loss: 2.3865\n",
      "====> Epoch: 1100 Average training loss: 2.2366\n",
      "====> Epoch: 1200 Average training loss: 2.0907\n",
      "====> Epoch: 1300 Average training loss: 1.9717\n",
      "====> Epoch: 1400 Average training loss: 1.8788\n",
      "====> Epoch: 1500 Average training loss: 1.7729\n",
      "====> Epoch: 1600 Average training loss: 1.6939\n",
      "====> Epoch: 1700 Average training loss: 1.6306\n",
      "====> Epoch: 1800 Average training loss: 1.5571\n",
      "====> Epoch: 100 Average training loss: 6.8611\n",
      "====> Epoch: 200 Average training loss: 5.5606\n",
      "====> Epoch: 300 Average training loss: 4.7611\n",
      "====> Epoch: 400 Average training loss: 4.1571\n",
      "====> Epoch: 500 Average training loss: 3.7068\n",
      "====> Epoch: 600 Average training loss: 3.3313\n",
      "====> Epoch: 700 Average training loss: 3.0436\n",
      "====> Epoch: 800 Average training loss: 2.7986\n",
      "====> Epoch: 900 Average training loss: 2.5844\n",
      "====> Epoch: 1000 Average training loss: 2.3824\n",
      "====> Epoch: 1100 Average training loss: 2.2470\n",
      "====> Epoch: 1200 Average training loss: 2.1021\n",
      "====> Epoch: 1300 Average training loss: 1.9693\n",
      "====> Epoch: 1400 Average training loss: 1.8606\n",
      "====> Epoch: 1500 Average training loss: 1.7754\n",
      "====> Epoch: 1600 Average training loss: 1.6825\n",
      "====> Epoch: 1700 Average training loss: 1.6193\n",
      "====> Epoch: 1800 Average training loss: 1.5364\n",
      "====> Epoch: 100 Average training loss: 6.5715\n",
      "====> Epoch: 200 Average training loss: 5.3379\n",
      "====> Epoch: 300 Average training loss: 4.5784\n",
      "====> Epoch: 400 Average training loss: 4.0398\n",
      "====> Epoch: 500 Average training loss: 3.5973\n",
      "====> Epoch: 600 Average training loss: 3.2722\n",
      "====> Epoch: 700 Average training loss: 2.9711\n",
      "====> Epoch: 800 Average training loss: 2.7417\n",
      "====> Epoch: 900 Average training loss: 2.5344\n",
      "====> Epoch: 1000 Average training loss: 2.3705\n",
      "====> Epoch: 1100 Average training loss: 2.2230\n",
      "====> Epoch: 1200 Average training loss: 2.0979\n",
      "====> Epoch: 1300 Average training loss: 1.9573\n",
      "====> Epoch: 1400 Average training loss: 1.8736\n",
      "====> Epoch: 1500 Average training loss: 1.7707\n",
      "====> Epoch: 1600 Average training loss: 1.7092\n",
      "====> Epoch: 1700 Average training loss: 1.6085\n",
      "====> Epoch: 1800 Average training loss: 1.5557\n",
      "====> Epoch: 100 Average training loss: 6.5236\n",
      "====> Epoch: 200 Average training loss: 5.3475\n",
      "====> Epoch: 300 Average training loss: 4.6121\n",
      "====> Epoch: 400 Average training loss: 4.0247\n",
      "====> Epoch: 500 Average training loss: 3.6110\n",
      "====> Epoch: 600 Average training loss: 3.2723\n",
      "====> Epoch: 700 Average training loss: 2.9939\n",
      "====> Epoch: 800 Average training loss: 2.7360\n",
      "====> Epoch: 900 Average training loss: 2.5477\n",
      "====> Epoch: 1000 Average training loss: 2.3796\n",
      "====> Epoch: 1100 Average training loss: 2.2130\n",
      "====> Epoch: 1200 Average training loss: 2.0921\n",
      "====> Epoch: 1300 Average training loss: 1.9661\n",
      "====> Epoch: 1400 Average training loss: 1.8538\n",
      "====> Epoch: 1500 Average training loss: 1.7676\n",
      "====> Epoch: 1600 Average training loss: 1.6877\n",
      "====> Epoch: 1700 Average training loss: 1.6086\n",
      "====> Epoch: 1800 Average training loss: 1.5383\n",
      "====> Epoch: 100 Average training loss: 6.5872\n",
      "====> Epoch: 200 Average training loss: 5.3701\n",
      "====> Epoch: 300 Average training loss: 4.6204\n",
      "====> Epoch: 400 Average training loss: 4.0356\n",
      "====> Epoch: 500 Average training loss: 3.6059\n",
      "====> Epoch: 600 Average training loss: 3.2696\n",
      "====> Epoch: 700 Average training loss: 2.9922\n",
      "====> Epoch: 800 Average training loss: 2.7515\n",
      "====> Epoch: 900 Average training loss: 2.5557\n",
      "====> Epoch: 1000 Average training loss: 2.3733\n",
      "====> Epoch: 1100 Average training loss: 2.2122\n",
      "====> Epoch: 1200 Average training loss: 2.0731\n",
      "====> Epoch: 1300 Average training loss: 1.9673\n",
      "====> Epoch: 1400 Average training loss: 1.8481\n",
      "====> Epoch: 1500 Average training loss: 1.7684\n",
      "====> Epoch: 1600 Average training loss: 1.6728\n",
      "====> Epoch: 1700 Average training loss: 1.6069\n",
      "====> Epoch: 1800 Average training loss: 1.5371\n",
      "====> Epoch: 100 Average training loss: 6.6460\n",
      "====> Epoch: 200 Average training loss: 5.4257\n",
      "====> Epoch: 300 Average training loss: 4.6534\n",
      "====> Epoch: 400 Average training loss: 4.0597\n",
      "====> Epoch: 500 Average training loss: 3.6402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 600 Average training loss: 3.2858\n",
      "====> Epoch: 700 Average training loss: 2.9912\n",
      "====> Epoch: 800 Average training loss: 2.7407\n",
      "====> Epoch: 900 Average training loss: 2.5524\n",
      "====> Epoch: 1000 Average training loss: 2.3523\n",
      "====> Epoch: 1100 Average training loss: 2.2085\n",
      "====> Epoch: 1200 Average training loss: 2.0697\n",
      "====> Epoch: 1300 Average training loss: 1.9785\n",
      "====> Epoch: 1400 Average training loss: 1.8530\n",
      "====> Epoch: 1500 Average training loss: 1.7633\n",
      "====> Epoch: 1600 Average training loss: 1.6758\n",
      "====> Epoch: 1700 Average training loss: 1.6052\n",
      "====> Epoch: 1800 Average training loss: 1.5325\n",
      "====> Epoch: 100 Average training loss: 6.4954\n",
      "====> Epoch: 200 Average training loss: 5.3393\n",
      "====> Epoch: 300 Average training loss: 4.5779\n",
      "====> Epoch: 400 Average training loss: 4.0494\n",
      "====> Epoch: 500 Average training loss: 3.6204\n",
      "====> Epoch: 600 Average training loss: 3.2874\n",
      "====> Epoch: 700 Average training loss: 3.0052\n",
      "====> Epoch: 800 Average training loss: 2.7627\n",
      "====> Epoch: 900 Average training loss: 2.5567\n",
      "====> Epoch: 1000 Average training loss: 2.3761\n",
      "====> Epoch: 1100 Average training loss: 2.2233\n",
      "====> Epoch: 1200 Average training loss: 2.0951\n",
      "====> Epoch: 1300 Average training loss: 1.9652\n",
      "====> Epoch: 1400 Average training loss: 1.8631\n",
      "====> Epoch: 1500 Average training loss: 1.7673\n",
      "====> Epoch: 1600 Average training loss: 1.6831\n",
      "====> Epoch: 1700 Average training loss: 1.6056\n",
      "====> Epoch: 1800 Average training loss: 1.5378\n",
      "====> Epoch: 100 Average training loss: 6.5321\n",
      "====> Epoch: 200 Average training loss: 5.2821\n",
      "====> Epoch: 300 Average training loss: 4.5313\n",
      "====> Epoch: 400 Average training loss: 3.9768\n",
      "====> Epoch: 500 Average training loss: 3.5562\n",
      "====> Epoch: 600 Average training loss: 3.2234\n",
      "====> Epoch: 700 Average training loss: 2.9425\n",
      "====> Epoch: 800 Average training loss: 2.7331\n",
      "====> Epoch: 900 Average training loss: 2.5274\n",
      "====> Epoch: 1000 Average training loss: 2.3462\n",
      "====> Epoch: 1100 Average training loss: 2.2193\n",
      "====> Epoch: 1200 Average training loss: 2.0764\n",
      "====> Epoch: 1300 Average training loss: 1.9454\n",
      "====> Epoch: 1400 Average training loss: 1.8527\n",
      "====> Epoch: 1500 Average training loss: 1.7525\n",
      "====> Epoch: 1600 Average training loss: 1.6803\n",
      "====> Epoch: 1700 Average training loss: 1.6155\n",
      "====> Epoch: 1800 Average training loss: 1.5429\n",
      "====> Epoch: 100 Average training loss: 6.6363\n",
      "====> Epoch: 200 Average training loss: 5.4189\n",
      "====> Epoch: 300 Average training loss: 4.6189\n",
      "====> Epoch: 400 Average training loss: 4.0608\n",
      "====> Epoch: 500 Average training loss: 3.6111\n",
      "====> Epoch: 600 Average training loss: 3.2652\n",
      "====> Epoch: 700 Average training loss: 3.0012\n",
      "====> Epoch: 800 Average training loss: 2.6803\n",
      "====> Epoch: 900 Average training loss: 2.5136\n",
      "====> Epoch: 1000 Average training loss: 2.3024\n",
      "====> Epoch: 1100 Average training loss: 2.0790\n",
      "====> Epoch: 1200 Average training loss: 1.9925\n",
      "====> Epoch: 1300 Average training loss: 1.9175\n",
      "====> Epoch: 1400 Average training loss: 1.7833\n",
      "====> Epoch: 1500 Average training loss: 1.6911\n",
      "====> Epoch: 1600 Average training loss: 1.6143\n",
      "====> Epoch: 1700 Average training loss: 1.5471\n",
      "====> Epoch: 1800 Average training loss: 1.4753\n",
      "====> Epoch: 100 Average training loss: 6.8488\n",
      "====> Epoch: 200 Average training loss: 5.5711\n",
      "====> Epoch: 300 Average training loss: 4.7535\n",
      "====> Epoch: 400 Average training loss: 4.1325\n",
      "====> Epoch: 500 Average training loss: 3.6911\n",
      "====> Epoch: 600 Average training loss: 3.3040\n",
      "====> Epoch: 700 Average training loss: 3.0016\n",
      "====> Epoch: 800 Average training loss: 2.7603\n",
      "====> Epoch: 900 Average training loss: 2.5521\n",
      "====> Epoch: 1000 Average training loss: 2.3614\n",
      "====> Epoch: 1100 Average training loss: 2.2141\n",
      "====> Epoch: 1200 Average training loss: 2.0852\n",
      "====> Epoch: 1300 Average training loss: 1.9559\n",
      "====> Epoch: 1400 Average training loss: 1.8503\n",
      "====> Epoch: 1500 Average training loss: 1.7717\n",
      "====> Epoch: 1600 Average training loss: 1.6842\n",
      "====> Epoch: 1700 Average training loss: 1.6068\n",
      "====> Epoch: 1800 Average training loss: 1.5398\n",
      "====> Epoch: 100 Average training loss: 6.6914\n",
      "====> Epoch: 200 Average training loss: 5.4678\n",
      "====> Epoch: 300 Average training loss: 4.6730\n",
      "====> Epoch: 400 Average training loss: 4.0981\n",
      "====> Epoch: 500 Average training loss: 3.6601\n",
      "====> Epoch: 600 Average training loss: 3.3301\n",
      "====> Epoch: 700 Average training loss: 3.0483\n",
      "====> Epoch: 800 Average training loss: 2.7547\n",
      "====> Epoch: 900 Average training loss: 2.5811\n",
      "====> Epoch: 1000 Average training loss: 2.3771\n",
      "====> Epoch: 1100 Average training loss: 2.1711\n",
      "====> Epoch: 1200 Average training loss: 1.9521\n",
      "====> Epoch: 1300 Average training loss: 1.8846\n",
      "====> Epoch: 1400 Average training loss: 1.7689\n",
      "====> Epoch: 1500 Average training loss: 1.6686\n",
      "====> Epoch: 1600 Average training loss: 1.5943\n",
      "====> Epoch: 1700 Average training loss: 1.5238\n",
      "====> Epoch: 1800 Average training loss: 1.4557\n",
      "====> Epoch: 100 Average training loss: 6.6837\n",
      "====> Epoch: 200 Average training loss: 5.4499\n",
      "====> Epoch: 300 Average training loss: 4.6734\n",
      "====> Epoch: 400 Average training loss: 4.0986\n",
      "====> Epoch: 500 Average training loss: 3.6738\n",
      "====> Epoch: 600 Average training loss: 3.3005\n",
      "====> Epoch: 700 Average training loss: 3.0213\n",
      "====> Epoch: 800 Average training loss: 2.7768\n",
      "====> Epoch: 900 Average training loss: 2.5626\n",
      "====> Epoch: 1000 Average training loss: 2.3883\n",
      "====> Epoch: 1100 Average training loss: 2.2331\n",
      "====> Epoch: 1200 Average training loss: 2.0975\n",
      "====> Epoch: 1300 Average training loss: 1.9771\n",
      "====> Epoch: 1400 Average training loss: 1.8563\n",
      "====> Epoch: 1500 Average training loss: 1.7803\n",
      "====> Epoch: 1600 Average training loss: 1.6790\n",
      "====> Epoch: 1700 Average training loss: 1.6154\n",
      "====> Epoch: 1800 Average training loss: 1.5467\n",
      "====> Epoch: 100 Average training loss: 6.9765\n",
      "====> Epoch: 200 Average training loss: 5.6458\n",
      "====> Epoch: 300 Average training loss: 4.8106\n",
      "====> Epoch: 400 Average training loss: 4.1996\n",
      "====> Epoch: 500 Average training loss: 3.7333\n",
      "====> Epoch: 600 Average training loss: 3.3407\n",
      "====> Epoch: 700 Average training loss: 3.0533\n",
      "====> Epoch: 800 Average training loss: 2.7905\n",
      "====> Epoch: 900 Average training loss: 2.5832\n",
      "====> Epoch: 1000 Average training loss: 2.3927\n",
      "====> Epoch: 1100 Average training loss: 2.2353\n",
      "====> Epoch: 1200 Average training loss: 2.1005\n",
      "====> Epoch: 1300 Average training loss: 1.9784\n",
      "====> Epoch: 1400 Average training loss: 1.8672\n",
      "====> Epoch: 1500 Average training loss: 1.7684\n",
      "====> Epoch: 1600 Average training loss: 1.7039\n",
      "====> Epoch: 1700 Average training loss: 1.6177\n",
      "====> Epoch: 1800 Average training loss: 1.5649\n",
      "====> Epoch: 100 Average training loss: 6.4817\n",
      "====> Epoch: 200 Average training loss: 5.3105\n",
      "====> Epoch: 300 Average training loss: 4.5537\n",
      "====> Epoch: 400 Average training loss: 4.0039\n",
      "====> Epoch: 500 Average training loss: 3.5894\n",
      "====> Epoch: 600 Average training loss: 3.2472\n",
      "====> Epoch: 700 Average training loss: 2.9674\n",
      "====> Epoch: 800 Average training loss: 2.7261\n",
      "====> Epoch: 900 Average training loss: 2.5380\n",
      "====> Epoch: 1000 Average training loss: 2.3584\n",
      "====> Epoch: 1100 Average training loss: 2.2036\n",
      "====> Epoch: 1200 Average training loss: 2.0778\n",
      "====> Epoch: 1300 Average training loss: 1.9594\n",
      "====> Epoch: 1400 Average training loss: 1.8481\n",
      "====> Epoch: 1500 Average training loss: 1.7648\n",
      "====> Epoch: 1600 Average training loss: 1.6719\n",
      "====> Epoch: 1700 Average training loss: 1.5864\n",
      "====> Epoch: 1800 Average training loss: 1.5377\n",
      "====> Epoch: 100 Average training loss: 6.5463\n",
      "====> Epoch: 200 Average training loss: 5.3408\n",
      "====> Epoch: 300 Average training loss: 4.5831\n",
      "====> Epoch: 400 Average training loss: 4.0323\n",
      "====> Epoch: 500 Average training loss: 3.6033\n",
      "====> Epoch: 600 Average training loss: 3.2791\n",
      "====> Epoch: 700 Average training loss: 2.9895\n",
      "====> Epoch: 800 Average training loss: 2.7500\n",
      "====> Epoch: 900 Average training loss: 2.5296\n",
      "====> Epoch: 1000 Average training loss: 2.3756\n",
      "====> Epoch: 1100 Average training loss: 2.2222\n",
      "====> Epoch: 1200 Average training loss: 2.0944\n",
      "====> Epoch: 1300 Average training loss: 1.9625\n",
      "====> Epoch: 1400 Average training loss: 1.8618\n",
      "====> Epoch: 1500 Average training loss: 1.7753\n",
      "====> Epoch: 1600 Average training loss: 1.6860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1700 Average training loss: 1.6087\n",
      "====> Epoch: 1800 Average training loss: 1.5356\n",
      "====> Epoch: 100 Average training loss: 6.6172\n",
      "====> Epoch: 200 Average training loss: 5.3835\n",
      "====> Epoch: 300 Average training loss: 4.5706\n",
      "====> Epoch: 400 Average training loss: 4.0404\n",
      "====> Epoch: 500 Average training loss: 3.6140\n",
      "====> Epoch: 600 Average training loss: 3.2651\n",
      "====> Epoch: 700 Average training loss: 2.9835\n",
      "====> Epoch: 800 Average training loss: 2.7422\n",
      "====> Epoch: 900 Average training loss: 2.5456\n",
      "====> Epoch: 1000 Average training loss: 2.3802\n",
      "====> Epoch: 1100 Average training loss: 2.2246\n",
      "====> Epoch: 1200 Average training loss: 2.0861\n",
      "====> Epoch: 1300 Average training loss: 1.9696\n",
      "====> Epoch: 1400 Average training loss: 1.8644\n",
      "====> Epoch: 1500 Average training loss: 1.7653\n",
      "====> Epoch: 1600 Average training loss: 1.6913\n",
      "====> Epoch: 1700 Average training loss: 1.6044\n",
      "====> Epoch: 1800 Average training loss: 1.5484\n",
      "====> Epoch: 100 Average training loss: 6.6564\n",
      "====> Epoch: 200 Average training loss: 5.4359\n",
      "====> Epoch: 300 Average training loss: 4.6380\n",
      "====> Epoch: 400 Average training loss: 4.0779\n",
      "====> Epoch: 500 Average training loss: 3.6488\n",
      "====> Epoch: 600 Average training loss: 3.2830\n",
      "====> Epoch: 700 Average training loss: 2.9997\n",
      "====> Epoch: 800 Average training loss: 2.7728\n",
      "====> Epoch: 900 Average training loss: 2.5577\n",
      "====> Epoch: 1000 Average training loss: 2.3858\n",
      "====> Epoch: 1100 Average training loss: 2.2206\n",
      "====> Epoch: 1200 Average training loss: 2.0904\n",
      "====> Epoch: 1300 Average training loss: 1.9696\n",
      "====> Epoch: 1400 Average training loss: 1.8657\n",
      "====> Epoch: 1500 Average training loss: 1.7755\n",
      "====> Epoch: 1600 Average training loss: 1.6873\n",
      "====> Epoch: 1700 Average training loss: 1.6059\n",
      "====> Epoch: 1800 Average training loss: 1.5315\n",
      "====> Epoch: 100 Average training loss: 6.8110\n",
      "====> Epoch: 200 Average training loss: 5.5171\n",
      "====> Epoch: 300 Average training loss: 4.7251\n",
      "====> Epoch: 400 Average training loss: 4.1373\n",
      "====> Epoch: 500 Average training loss: 3.6753\n",
      "====> Epoch: 600 Average training loss: 3.3343\n",
      "====> Epoch: 700 Average training loss: 3.0568\n",
      "====> Epoch: 800 Average training loss: 2.8049\n",
      "====> Epoch: 900 Average training loss: 2.5768\n",
      "====> Epoch: 1000 Average training loss: 2.4107\n",
      "====> Epoch: 1100 Average training loss: 2.2440\n",
      "====> Epoch: 1200 Average training loss: 2.1197\n",
      "====> Epoch: 1300 Average training loss: 1.9838\n",
      "====> Epoch: 1400 Average training loss: 1.8829\n",
      "====> Epoch: 1500 Average training loss: 1.7829\n",
      "====> Epoch: 1600 Average training loss: 1.7084\n",
      "====> Epoch: 1700 Average training loss: 1.6345\n",
      "====> Epoch: 1800 Average training loss: 1.5583\n",
      "====> Epoch: 100 Average training loss: 6.5789\n",
      "====> Epoch: 200 Average training loss: 5.3939\n",
      "====> Epoch: 300 Average training loss: 4.6278\n",
      "====> Epoch: 400 Average training loss: 4.0836\n",
      "====> Epoch: 500 Average training loss: 3.6514\n",
      "====> Epoch: 600 Average training loss: 3.3162\n",
      "====> Epoch: 700 Average training loss: 3.0274\n",
      "====> Epoch: 800 Average training loss: 2.7742\n",
      "====> Epoch: 900 Average training loss: 2.5616\n",
      "====> Epoch: 1000 Average training loss: 2.3856\n",
      "====> Epoch: 1100 Average training loss: 2.2239\n",
      "====> Epoch: 1200 Average training loss: 2.0949\n",
      "====> Epoch: 1300 Average training loss: 1.9815\n",
      "====> Epoch: 1400 Average training loss: 1.8766\n",
      "====> Epoch: 1500 Average training loss: 1.7820\n",
      "====> Epoch: 1600 Average training loss: 1.7055\n",
      "====> Epoch: 1700 Average training loss: 1.6250\n",
      "====> Epoch: 1800 Average training loss: 1.5415\n",
      "====> Epoch: 100 Average training loss: 6.4330\n",
      "====> Epoch: 200 Average training loss: 5.2714\n",
      "====> Epoch: 300 Average training loss: 4.5398\n",
      "====> Epoch: 400 Average training loss: 3.9911\n",
      "====> Epoch: 500 Average training loss: 3.5832\n",
      "====> Epoch: 600 Average training loss: 3.2593\n",
      "====> Epoch: 700 Average training loss: 2.9721\n",
      "====> Epoch: 800 Average training loss: 2.7325\n",
      "====> Epoch: 900 Average training loss: 2.5313\n",
      "====> Epoch: 1000 Average training loss: 2.3515\n",
      "====> Epoch: 1100 Average training loss: 2.2137\n",
      "====> Epoch: 1200 Average training loss: 2.0803\n",
      "====> Epoch: 1300 Average training loss: 1.9540\n",
      "====> Epoch: 1400 Average training loss: 1.8601\n",
      "====> Epoch: 1500 Average training loss: 1.7669\n",
      "====> Epoch: 1600 Average training loss: 1.6787\n",
      "====> Epoch: 1700 Average training loss: 1.6031\n",
      "====> Epoch: 1800 Average training loss: 1.5288\n",
      "====> Epoch: 100 Average training loss: 6.6304\n",
      "====> Epoch: 200 Average training loss: 5.4371\n",
      "====> Epoch: 300 Average training loss: 4.6830\n",
      "====> Epoch: 400 Average training loss: 4.0914\n",
      "====> Epoch: 500 Average training loss: 3.6546\n",
      "====> Epoch: 600 Average training loss: 3.3197\n",
      "====> Epoch: 700 Average training loss: 3.0264\n",
      "====> Epoch: 800 Average training loss: 2.7791\n",
      "====> Epoch: 900 Average training loss: 2.5693\n",
      "====> Epoch: 1000 Average training loss: 2.3897\n",
      "====> Epoch: 1100 Average training loss: 2.2257\n",
      "====> Epoch: 1200 Average training loss: 2.0984\n",
      "====> Epoch: 1300 Average training loss: 1.9936\n",
      "====> Epoch: 1400 Average training loss: 1.8590\n",
      "====> Epoch: 1500 Average training loss: 1.7764\n",
      "====> Epoch: 1600 Average training loss: 1.6911\n",
      "====> Epoch: 1700 Average training loss: 1.6138\n",
      "====> Epoch: 1800 Average training loss: 1.5394\n",
      "====> Epoch: 100 Average training loss: 6.7622\n",
      "====> Epoch: 200 Average training loss: 5.5142\n",
      "====> Epoch: 300 Average training loss: 4.6904\n",
      "====> Epoch: 400 Average training loss: 4.1089\n",
      "====> Epoch: 500 Average training loss: 3.6791\n",
      "====> Epoch: 600 Average training loss: 3.3216\n",
      "====> Epoch: 700 Average training loss: 3.0223\n",
      "====> Epoch: 800 Average training loss: 2.7771\n",
      "====> Epoch: 900 Average training loss: 2.5754\n",
      "====> Epoch: 1000 Average training loss: 2.3806\n",
      "====> Epoch: 1100 Average training loss: 2.2475\n",
      "====> Epoch: 1200 Average training loss: 2.1084\n",
      "====> Epoch: 1300 Average training loss: 1.9811\n",
      "====> Epoch: 1400 Average training loss: 1.8757\n",
      "====> Epoch: 1500 Average training loss: 1.7778\n",
      "====> Epoch: 1600 Average training loss: 1.6952\n",
      "====> Epoch: 1700 Average training loss: 1.6242\n",
      "====> Epoch: 1800 Average training loss: 1.5568\n",
      "====> Epoch: 100 Average training loss: 6.4866\n",
      "====> Epoch: 200 Average training loss: 5.3103\n",
      "====> Epoch: 300 Average training loss: 4.5618\n",
      "====> Epoch: 400 Average training loss: 4.0257\n",
      "====> Epoch: 500 Average training loss: 3.5941\n",
      "====> Epoch: 600 Average training loss: 3.2542\n",
      "====> Epoch: 700 Average training loss: 2.9739\n",
      "====> Epoch: 800 Average training loss: 2.7210\n",
      "====> Epoch: 900 Average training loss: 2.5270\n",
      "====> Epoch: 1000 Average training loss: 2.3645\n",
      "====> Epoch: 1100 Average training loss: 2.1917\n",
      "====> Epoch: 1200 Average training loss: 2.0756\n",
      "====> Epoch: 1300 Average training loss: 1.9755\n",
      "====> Epoch: 1400 Average training loss: 1.8534\n",
      "====> Epoch: 1500 Average training loss: 1.7624\n",
      "====> Epoch: 1600 Average training loss: 1.6675\n",
      "====> Epoch: 1700 Average training loss: 1.6186\n",
      "====> Epoch: 1800 Average training loss: 1.5420\n",
      "====> Epoch: 100 Average training loss: 7.0429\n",
      "====> Epoch: 200 Average training loss: 5.6913\n",
      "====> Epoch: 300 Average training loss: 4.8103\n",
      "====> Epoch: 400 Average training loss: 4.2116\n",
      "====> Epoch: 500 Average training loss: 3.7484\n",
      "====> Epoch: 600 Average training loss: 3.3709\n",
      "====> Epoch: 700 Average training loss: 3.0820\n",
      "====> Epoch: 800 Average training loss: 2.7866\n",
      "====> Epoch: 900 Average training loss: 2.6115\n",
      "====> Epoch: 1000 Average training loss: 2.4205\n",
      "====> Epoch: 1100 Average training loss: 2.2558\n",
      "====> Epoch: 1200 Average training loss: 2.1209\n",
      "====> Epoch: 1300 Average training loss: 1.9991\n",
      "====> Epoch: 1400 Average training loss: 1.8896\n",
      "====> Epoch: 1500 Average training loss: 1.7915\n",
      "====> Epoch: 1600 Average training loss: 1.7027\n",
      "====> Epoch: 1700 Average training loss: 1.6184\n",
      "====> Epoch: 1800 Average training loss: 1.4911\n",
      "====> Epoch: 100 Average training loss: 6.6200\n",
      "====> Epoch: 200 Average training loss: 5.4056\n",
      "====> Epoch: 300 Average training loss: 4.6299\n",
      "====> Epoch: 400 Average training loss: 4.1013\n",
      "====> Epoch: 500 Average training loss: 3.6514\n",
      "====> Epoch: 600 Average training loss: 3.3007\n",
      "====> Epoch: 700 Average training loss: 3.0180\n",
      "====> Epoch: 800 Average training loss: 2.7757\n",
      "====> Epoch: 900 Average training loss: 2.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average training loss: 2.3982\n",
      "====> Epoch: 1100 Average training loss: 2.2435\n",
      "====> Epoch: 1200 Average training loss: 2.1155\n",
      "====> Epoch: 1300 Average training loss: 1.9803\n",
      "====> Epoch: 1400 Average training loss: 1.8838\n",
      "====> Epoch: 1500 Average training loss: 1.7978\n",
      "====> Epoch: 1600 Average training loss: 1.6966\n",
      "====> Epoch: 1700 Average training loss: 1.6319\n",
      "====> Epoch: 1800 Average training loss: 1.5617\n",
      "====> Epoch: 100 Average training loss: 6.7394\n",
      "====> Epoch: 200 Average training loss: 5.4935\n",
      "====> Epoch: 300 Average training loss: 4.7021\n",
      "====> Epoch: 400 Average training loss: 4.1054\n",
      "====> Epoch: 500 Average training loss: 3.6230\n",
      "====> Epoch: 600 Average training loss: 3.2774\n",
      "====> Epoch: 700 Average training loss: 2.9877\n",
      "====> Epoch: 800 Average training loss: 2.7413\n",
      "====> Epoch: 900 Average training loss: 2.5489\n",
      "====> Epoch: 1000 Average training loss: 2.3819\n",
      "====> Epoch: 1100 Average training loss: 2.2114\n",
      "====> Epoch: 1200 Average training loss: 2.0985\n",
      "====> Epoch: 1300 Average training loss: 1.9643\n",
      "====> Epoch: 1400 Average training loss: 1.8672\n",
      "====> Epoch: 1500 Average training loss: 1.7736\n",
      "====> Epoch: 1600 Average training loss: 1.6911\n",
      "====> Epoch: 1700 Average training loss: 1.6183\n",
      "====> Epoch: 1800 Average training loss: 1.5277\n",
      "====> Epoch: 100 Average training loss: 6.6608\n",
      "====> Epoch: 200 Average training loss: 5.4294\n",
      "====> Epoch: 300 Average training loss: 4.6273\n",
      "====> Epoch: 400 Average training loss: 4.0972\n",
      "====> Epoch: 500 Average training loss: 3.5767\n",
      "====> Epoch: 600 Average training loss: 3.0768\n",
      "====> Epoch: 700 Average training loss: 2.7488\n",
      "====> Epoch: 800 Average training loss: 2.5971\n",
      "====> Epoch: 900 Average training loss: 2.4210\n",
      "====> Epoch: 1000 Average training loss: 2.2313\n",
      "====> Epoch: 1100 Average training loss: 2.0887\n",
      "====> Epoch: 1200 Average training loss: 1.9661\n",
      "====> Epoch: 1300 Average training loss: 1.8475\n",
      "====> Epoch: 1400 Average training loss: 1.7680\n",
      "====> Epoch: 1500 Average training loss: 1.6641\n",
      "====> Epoch: 1600 Average training loss: 1.5932\n",
      "====> Epoch: 1700 Average training loss: 1.5229\n",
      "====> Epoch: 1800 Average training loss: 1.4805\n",
      "====> Epoch: 100 Average training loss: 6.5451\n",
      "====> Epoch: 200 Average training loss: 5.3609\n",
      "====> Epoch: 300 Average training loss: 4.5743\n",
      "====> Epoch: 400 Average training loss: 4.0242\n",
      "====> Epoch: 500 Average training loss: 3.5951\n",
      "====> Epoch: 600 Average training loss: 3.2456\n",
      "====> Epoch: 700 Average training loss: 2.9610\n",
      "====> Epoch: 800 Average training loss: 2.7297\n",
      "====> Epoch: 900 Average training loss: 2.5496\n",
      "====> Epoch: 1000 Average training loss: 2.3659\n",
      "====> Epoch: 1100 Average training loss: 2.2241\n",
      "====> Epoch: 1200 Average training loss: 2.1072\n",
      "====> Epoch: 1300 Average training loss: 1.9707\n",
      "====> Epoch: 1400 Average training loss: 1.8720\n",
      "====> Epoch: 1500 Average training loss: 1.7667\n",
      "====> Epoch: 1600 Average training loss: 1.6858\n",
      "====> Epoch: 1700 Average training loss: 1.6309\n",
      "====> Epoch: 1800 Average training loss: 1.5516\n",
      "====> Epoch: 100 Average training loss: 7.0147\n",
      "====> Epoch: 200 Average training loss: 5.6948\n",
      "====> Epoch: 300 Average training loss: 4.8774\n",
      "====> Epoch: 400 Average training loss: 4.2751\n",
      "====> Epoch: 500 Average training loss: 3.8033\n",
      "====> Epoch: 600 Average training loss: 3.4148\n",
      "====> Epoch: 700 Average training loss: 3.1125\n",
      "====> Epoch: 800 Average training loss: 2.8587\n",
      "====> Epoch: 900 Average training loss: 2.6125\n",
      "====> Epoch: 1000 Average training loss: 2.4409\n",
      "====> Epoch: 1100 Average training loss: 2.2810\n",
      "====> Epoch: 1200 Average training loss: 2.1265\n",
      "====> Epoch: 1300 Average training loss: 2.0183\n",
      "====> Epoch: 1400 Average training loss: 1.9132\n",
      "====> Epoch: 1500 Average training loss: 1.7986\n",
      "====> Epoch: 1600 Average training loss: 1.7111\n",
      "====> Epoch: 1700 Average training loss: 1.6256\n",
      "====> Epoch: 1800 Average training loss: 1.5543\n",
      "====> Epoch: 100 Average training loss: 6.6201\n",
      "====> Epoch: 200 Average training loss: 5.3169\n",
      "====> Epoch: 300 Average training loss: 4.5640\n",
      "====> Epoch: 400 Average training loss: 4.0316\n",
      "====> Epoch: 500 Average training loss: 3.5899\n",
      "====> Epoch: 600 Average training loss: 3.2626\n",
      "====> Epoch: 700 Average training loss: 2.9806\n",
      "====> Epoch: 800 Average training loss: 2.7494\n",
      "====> Epoch: 900 Average training loss: 2.5335\n",
      "====> Epoch: 1000 Average training loss: 2.3726\n",
      "====> Epoch: 1100 Average training loss: 2.2151\n",
      "====> Epoch: 1200 Average training loss: 2.0888\n",
      "====> Epoch: 1300 Average training loss: 1.9702\n",
      "====> Epoch: 1400 Average training loss: 1.8550\n",
      "====> Epoch: 1500 Average training loss: 1.7717\n",
      "====> Epoch: 1600 Average training loss: 1.6990\n",
      "====> Epoch: 1700 Average training loss: 1.6151\n",
      "====> Epoch: 1800 Average training loss: 1.5456\n",
      "====> Epoch: 100 Average training loss: 6.4474\n",
      "====> Epoch: 200 Average training loss: 5.2882\n",
      "====> Epoch: 300 Average training loss: 4.5549\n",
      "====> Epoch: 400 Average training loss: 4.0522\n",
      "====> Epoch: 500 Average training loss: 3.6065\n",
      "====> Epoch: 600 Average training loss: 3.2467\n",
      "====> Epoch: 700 Average training loss: 2.9717\n",
      "====> Epoch: 800 Average training loss: 2.7414\n",
      "====> Epoch: 900 Average training loss: 2.5368\n",
      "====> Epoch: 1000 Average training loss: 2.3538\n",
      "====> Epoch: 1100 Average training loss: 2.2416\n",
      "====> Epoch: 1200 Average training loss: 1.9950\n",
      "====> Epoch: 1300 Average training loss: 1.9314\n",
      "====> Epoch: 1400 Average training loss: 1.8427\n",
      "====> Epoch: 1500 Average training loss: 1.6622\n",
      "====> Epoch: 1600 Average training loss: 1.6198\n",
      "====> Epoch: 1700 Average training loss: 1.5372\n",
      "====> Epoch: 1800 Average training loss: 1.5255\n",
      "====> Epoch: 100 Average training loss: 6.5456\n",
      "====> Epoch: 200 Average training loss: 5.3374\n",
      "====> Epoch: 300 Average training loss: 4.5930\n",
      "====> Epoch: 400 Average training loss: 4.0435\n",
      "====> Epoch: 500 Average training loss: 3.6210\n",
      "====> Epoch: 600 Average training loss: 3.2737\n",
      "====> Epoch: 700 Average training loss: 3.0088\n",
      "====> Epoch: 800 Average training loss: 2.7517\n",
      "====> Epoch: 900 Average training loss: 2.5544\n",
      "====> Epoch: 1000 Average training loss: 2.3691\n",
      "====> Epoch: 1100 Average training loss: 2.2286\n",
      "====> Epoch: 1200 Average training loss: 2.0889\n",
      "====> Epoch: 1300 Average training loss: 1.9665\n",
      "====> Epoch: 1400 Average training loss: 1.8647\n",
      "====> Epoch: 1500 Average training loss: 1.7700\n",
      "====> Epoch: 1600 Average training loss: 1.6864\n",
      "====> Epoch: 1700 Average training loss: 1.6140\n",
      "====> Epoch: 1800 Average training loss: 1.5510\n",
      "====> Epoch: 100 Average training loss: 6.9209\n",
      "====> Epoch: 200 Average training loss: 5.6125\n",
      "====> Epoch: 300 Average training loss: 4.7320\n",
      "====> Epoch: 400 Average training loss: 4.1170\n",
      "====> Epoch: 500 Average training loss: 3.6734\n",
      "====> Epoch: 600 Average training loss: 3.3217\n",
      "====> Epoch: 700 Average training loss: 3.0145\n",
      "====> Epoch: 800 Average training loss: 2.7880\n",
      "====> Epoch: 900 Average training loss: 2.5810\n",
      "====> Epoch: 1000 Average training loss: 2.3996\n",
      "====> Epoch: 1100 Average training loss: 2.2474\n",
      "====> Epoch: 1200 Average training loss: 2.1083\n",
      "====> Epoch: 1300 Average training loss: 1.9902\n",
      "====> Epoch: 1400 Average training loss: 1.8847\n",
      "====> Epoch: 1500 Average training loss: 1.7919\n",
      "====> Epoch: 1600 Average training loss: 1.7024\n",
      "====> Epoch: 1700 Average training loss: 1.6298\n",
      "====> Epoch: 1800 Average training loss: 1.5501\n",
      "====> Epoch: 100 Average training loss: 6.6244\n",
      "====> Epoch: 200 Average training loss: 5.3766\n",
      "====> Epoch: 300 Average training loss: 4.6028\n",
      "====> Epoch: 400 Average training loss: 3.9484\n",
      "====> Epoch: 500 Average training loss: 3.3033\n",
      "====> Epoch: 600 Average training loss: 2.9712\n",
      "====> Epoch: 700 Average training loss: 2.8214\n",
      "====> Epoch: 800 Average training loss: 2.5639\n",
      "====> Epoch: 900 Average training loss: 2.3633\n",
      "====> Epoch: 1000 Average training loss: 2.1905\n",
      "====> Epoch: 1100 Average training loss: 2.0556\n",
      "====> Epoch: 1200 Average training loss: 1.9240\n",
      "====> Epoch: 1300 Average training loss: 1.8187\n",
      "====> Epoch: 1400 Average training loss: 1.7368\n",
      "====> Epoch: 1500 Average training loss: 1.6425\n",
      "====> Epoch: 1600 Average training loss: 1.5865\n",
      "====> Epoch: 1700 Average training loss: 1.5083\n",
      "====> Epoch: 1800 Average training loss: 1.4502\n",
      "====> Epoch: 100 Average training loss: 6.5803\n",
      "====> Epoch: 200 Average training loss: 5.3556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average training loss: 4.6091\n",
      "====> Epoch: 400 Average training loss: 4.0545\n",
      "====> Epoch: 500 Average training loss: 3.6226\n",
      "====> Epoch: 600 Average training loss: 3.2755\n",
      "====> Epoch: 700 Average training loss: 2.9985\n",
      "====> Epoch: 800 Average training loss: 2.7556\n",
      "====> Epoch: 900 Average training loss: 2.5601\n",
      "====> Epoch: 1000 Average training loss: 2.3734\n",
      "====> Epoch: 1100 Average training loss: 2.2272\n",
      "====> Epoch: 1200 Average training loss: 2.0797\n",
      "====> Epoch: 1300 Average training loss: 1.9680\n",
      "====> Epoch: 1400 Average training loss: 1.8610\n",
      "====> Epoch: 1500 Average training loss: 1.7688\n",
      "====> Epoch: 1600 Average training loss: 1.6904\n",
      "====> Epoch: 1700 Average training loss: 1.6111\n",
      "====> Epoch: 1800 Average training loss: 1.5402\n",
      "====> Epoch: 100 Average training loss: 6.6193\n",
      "====> Epoch: 200 Average training loss: 5.3536\n",
      "====> Epoch: 300 Average training loss: 4.5889\n",
      "====> Epoch: 400 Average training loss: 4.0449\n",
      "====> Epoch: 500 Average training loss: 3.6246\n",
      "====> Epoch: 600 Average training loss: 3.2649\n",
      "====> Epoch: 700 Average training loss: 2.9896\n",
      "====> Epoch: 800 Average training loss: 2.7471\n",
      "====> Epoch: 900 Average training loss: 2.5402\n",
      "====> Epoch: 1000 Average training loss: 2.3803\n",
      "====> Epoch: 1100 Average training loss: 2.2212\n",
      "====> Epoch: 1200 Average training loss: 2.0874\n",
      "====> Epoch: 1300 Average training loss: 1.9735\n",
      "====> Epoch: 1400 Average training loss: 1.8593\n",
      "====> Epoch: 1500 Average training loss: 1.7569\n",
      "====> Epoch: 1600 Average training loss: 1.6924\n",
      "====> Epoch: 1700 Average training loss: 1.6078\n",
      "====> Epoch: 1800 Average training loss: 1.5402\n",
      "====> Epoch: 100 Average training loss: 6.8257\n",
      "====> Epoch: 200 Average training loss: 5.5880\n",
      "====> Epoch: 300 Average training loss: 4.7771\n",
      "====> Epoch: 400 Average training loss: 4.1555\n",
      "====> Epoch: 500 Average training loss: 3.6972\n",
      "====> Epoch: 600 Average training loss: 3.3358\n",
      "====> Epoch: 700 Average training loss: 3.0199\n",
      "====> Epoch: 800 Average training loss: 2.7832\n",
      "====> Epoch: 900 Average training loss: 2.5774\n",
      "====> Epoch: 1000 Average training loss: 2.3930\n",
      "====> Epoch: 1100 Average training loss: 2.2453\n",
      "====> Epoch: 1200 Average training loss: 2.1211\n",
      "====> Epoch: 1300 Average training loss: 1.9880\n",
      "====> Epoch: 1400 Average training loss: 1.8798\n",
      "====> Epoch: 1500 Average training loss: 1.7856\n",
      "====> Epoch: 1600 Average training loss: 1.7035\n",
      "====> Epoch: 1700 Average training loss: 1.6220\n",
      "====> Epoch: 1800 Average training loss: 1.5503\n",
      "====> Epoch: 100 Average training loss: 6.6610\n",
      "====> Epoch: 200 Average training loss: 5.4085\n",
      "====> Epoch: 300 Average training loss: 4.5957\n",
      "====> Epoch: 400 Average training loss: 4.0590\n",
      "====> Epoch: 500 Average training loss: 3.6153\n",
      "====> Epoch: 600 Average training loss: 3.2799\n",
      "====> Epoch: 700 Average training loss: 2.9809\n",
      "====> Epoch: 800 Average training loss: 2.7485\n",
      "====> Epoch: 900 Average training loss: 2.5512\n",
      "====> Epoch: 1000 Average training loss: 2.3658\n",
      "====> Epoch: 1100 Average training loss: 2.2269\n",
      "====> Epoch: 1200 Average training loss: 2.0831\n",
      "====> Epoch: 1300 Average training loss: 1.9627\n",
      "====> Epoch: 1400 Average training loss: 1.8691\n",
      "====> Epoch: 1500 Average training loss: 1.7763\n",
      "====> Epoch: 1600 Average training loss: 1.6845\n",
      "====> Epoch: 1700 Average training loss: 1.6040\n",
      "====> Epoch: 1800 Average training loss: 1.5455\n",
      "====> Epoch: 100 Average training loss: 6.7094\n",
      "====> Epoch: 200 Average training loss: 5.4469\n",
      "====> Epoch: 300 Average training loss: 4.6578\n",
      "====> Epoch: 400 Average training loss: 4.0836\n",
      "====> Epoch: 500 Average training loss: 3.6296\n",
      "====> Epoch: 600 Average training loss: 3.2847\n",
      "====> Epoch: 700 Average training loss: 3.0070\n",
      "====> Epoch: 800 Average training loss: 2.7661\n",
      "====> Epoch: 900 Average training loss: 2.5455\n",
      "====> Epoch: 1000 Average training loss: 2.3865\n",
      "====> Epoch: 1100 Average training loss: 2.2310\n",
      "====> Epoch: 1200 Average training loss: 2.0876\n",
      "====> Epoch: 1300 Average training loss: 1.9688\n",
      "====> Epoch: 1400 Average training loss: 1.8617\n",
      "====> Epoch: 1500 Average training loss: 1.7703\n",
      "====> Epoch: 1600 Average training loss: 1.6854\n",
      "====> Epoch: 1700 Average training loss: 1.6116\n",
      "====> Epoch: 1800 Average training loss: 1.5456\n",
      "====> Epoch: 100 Average training loss: 6.4334\n",
      "====> Epoch: 200 Average training loss: 5.2455\n",
      "====> Epoch: 300 Average training loss: 4.5305\n",
      "====> Epoch: 400 Average training loss: 3.9824\n",
      "====> Epoch: 500 Average training loss: 3.5844\n",
      "====> Epoch: 600 Average training loss: 3.2551\n",
      "====> Epoch: 700 Average training loss: 2.9687\n",
      "====> Epoch: 800 Average training loss: 2.7377\n",
      "====> Epoch: 900 Average training loss: 2.5414\n",
      "====> Epoch: 1000 Average training loss: 2.3612\n",
      "====> Epoch: 1100 Average training loss: 2.2118\n",
      "====> Epoch: 1200 Average training loss: 2.0805\n",
      "====> Epoch: 1300 Average training loss: 1.9521\n",
      "====> Epoch: 1400 Average training loss: 1.8604\n",
      "====> Epoch: 1500 Average training loss: 1.7356\n",
      "====> Epoch: 1600 Average training loss: 1.6704\n",
      "====> Epoch: 1700 Average training loss: 1.5343\n",
      "====> Epoch: 1800 Average training loss: 1.4721\n",
      "====> Epoch: 100 Average training loss: 6.7263\n",
      "====> Epoch: 200 Average training loss: 5.4682\n",
      "====> Epoch: 300 Average training loss: 4.6372\n",
      "====> Epoch: 400 Average training loss: 4.0649\n",
      "====> Epoch: 500 Average training loss: 3.6251\n",
      "====> Epoch: 600 Average training loss: 3.2692\n",
      "====> Epoch: 700 Average training loss: 2.9877\n",
      "====> Epoch: 800 Average training loss: 2.7420\n",
      "====> Epoch: 900 Average training loss: 2.5448\n",
      "====> Epoch: 1000 Average training loss: 2.3638\n",
      "====> Epoch: 1100 Average training loss: 2.2268\n",
      "====> Epoch: 1200 Average training loss: 2.0873\n",
      "====> Epoch: 1300 Average training loss: 1.9678\n",
      "====> Epoch: 1400 Average training loss: 1.8595\n",
      "====> Epoch: 1500 Average training loss: 1.7679\n",
      "====> Epoch: 1600 Average training loss: 1.6922\n",
      "====> Epoch: 1700 Average training loss: 1.6048\n",
      "====> Epoch: 1800 Average training loss: 1.5530\n",
      "====> Epoch: 100 Average training loss: 6.4404\n",
      "====> Epoch: 200 Average training loss: 5.2960\n",
      "====> Epoch: 300 Average training loss: 4.5538\n",
      "====> Epoch: 400 Average training loss: 3.9970\n",
      "====> Epoch: 500 Average training loss: 3.5933\n",
      "====> Epoch: 600 Average training loss: 3.2469\n",
      "====> Epoch: 700 Average training loss: 2.9749\n",
      "====> Epoch: 800 Average training loss: 2.7238\n",
      "====> Epoch: 900 Average training loss: 2.5319\n",
      "====> Epoch: 1000 Average training loss: 2.3575\n",
      "====> Epoch: 1100 Average training loss: 2.2054\n",
      "====> Epoch: 1200 Average training loss: 2.0714\n",
      "====> Epoch: 1300 Average training loss: 1.9589\n",
      "====> Epoch: 1400 Average training loss: 1.8416\n",
      "====> Epoch: 1500 Average training loss: 1.7571\n",
      "====> Epoch: 1600 Average training loss: 1.6772\n",
      "====> Epoch: 1700 Average training loss: 1.6079\n",
      "====> Epoch: 1800 Average training loss: 1.5292\n",
      "====> Epoch: 100 Average training loss: 6.4205\n",
      "====> Epoch: 200 Average training loss: 5.2456\n",
      "====> Epoch: 300 Average training loss: 4.5304\n",
      "====> Epoch: 400 Average training loss: 4.0004\n",
      "====> Epoch: 500 Average training loss: 3.5737\n",
      "====> Epoch: 600 Average training loss: 3.2447\n",
      "====> Epoch: 700 Average training loss: 2.9699\n",
      "====> Epoch: 800 Average training loss: 2.7172\n",
      "====> Epoch: 900 Average training loss: 2.5347\n",
      "====> Epoch: 1000 Average training loss: 2.3464\n",
      "====> Epoch: 1100 Average training loss: 2.2021\n",
      "====> Epoch: 1200 Average training loss: 2.0728\n",
      "====> Epoch: 1300 Average training loss: 1.9492\n",
      "====> Epoch: 1400 Average training loss: 1.8564\n",
      "====> Epoch: 1500 Average training loss: 1.7584\n",
      "====> Epoch: 1600 Average training loss: 1.6652\n",
      "====> Epoch: 1700 Average training loss: 1.5993\n",
      "====> Epoch: 1800 Average training loss: 1.5327\n",
      "====> Epoch: 100 Average training loss: 6.6567\n",
      "====> Epoch: 200 Average training loss: 5.4103\n",
      "====> Epoch: 300 Average training loss: 4.6241\n",
      "====> Epoch: 400 Average training loss: 4.0584\n",
      "====> Epoch: 500 Average training loss: 3.6279\n",
      "====> Epoch: 600 Average training loss: 3.2855\n",
      "====> Epoch: 700 Average training loss: 2.9815\n",
      "====> Epoch: 800 Average training loss: 2.6728\n",
      "====> Epoch: 900 Average training loss: 2.4290\n",
      "====> Epoch: 1000 Average training loss: 2.2022\n",
      "====> Epoch: 1100 Average training loss: 2.0705\n",
      "====> Epoch: 1200 Average training loss: 2.0017\n",
      "====> Epoch: 1300 Average training loss: 1.8704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1400 Average training loss: 1.7647\n",
      "====> Epoch: 1500 Average training loss: 1.6716\n",
      "====> Epoch: 1600 Average training loss: 1.5873\n",
      "====> Epoch: 1700 Average training loss: 1.5206\n",
      "====> Epoch: 1800 Average training loss: 1.4564\n",
      "====> Epoch: 100 Average training loss: 6.8521\n",
      "====> Epoch: 200 Average training loss: 5.5843\n",
      "====> Epoch: 300 Average training loss: 4.7856\n",
      "====> Epoch: 400 Average training loss: 4.1579\n",
      "====> Epoch: 500 Average training loss: 3.7166\n",
      "====> Epoch: 600 Average training loss: 3.3438\n",
      "====> Epoch: 700 Average training loss: 3.0556\n",
      "====> Epoch: 800 Average training loss: 2.7783\n",
      "====> Epoch: 900 Average training loss: 2.5854\n",
      "====> Epoch: 1000 Average training loss: 2.4012\n",
      "====> Epoch: 1100 Average training loss: 2.2460\n",
      "====> Epoch: 1200 Average training loss: 2.0970\n",
      "====> Epoch: 1300 Average training loss: 1.9860\n",
      "====> Epoch: 1400 Average training loss: 1.8797\n",
      "====> Epoch: 1500 Average training loss: 1.7569\n",
      "====> Epoch: 1600 Average training loss: 1.6880\n",
      "====> Epoch: 1700 Average training loss: 1.5953\n",
      "====> Epoch: 1800 Average training loss: 1.5131\n",
      "====> Epoch: 100 Average training loss: 7.1092\n",
      "====> Epoch: 200 Average training loss: 5.7881\n",
      "====> Epoch: 300 Average training loss: 4.9238\n",
      "====> Epoch: 400 Average training loss: 4.3467\n",
      "====> Epoch: 500 Average training loss: 3.8543\n",
      "====> Epoch: 600 Average training loss: 3.4660\n",
      "====> Epoch: 700 Average training loss: 3.1356\n",
      "====> Epoch: 800 Average training loss: 2.8287\n",
      "====> Epoch: 900 Average training loss: 2.6149\n",
      "====> Epoch: 1000 Average training loss: 2.4201\n",
      "====> Epoch: 1100 Average training loss: 2.2573\n",
      "====> Epoch: 1200 Average training loss: 2.1232\n",
      "====> Epoch: 1300 Average training loss: 1.9935\n",
      "====> Epoch: 1400 Average training loss: 1.8865\n",
      "====> Epoch: 1500 Average training loss: 1.7905\n",
      "====> Epoch: 1600 Average training loss: 1.6998\n",
      "====> Epoch: 1700 Average training loss: 1.6227\n",
      "====> Epoch: 1800 Average training loss: 1.5466\n",
      "====> Epoch: 100 Average training loss: 6.5665\n",
      "====> Epoch: 200 Average training loss: 5.3500\n",
      "====> Epoch: 300 Average training loss: 4.5883\n",
      "====> Epoch: 400 Average training loss: 4.0232\n",
      "====> Epoch: 500 Average training loss: 3.6064\n",
      "====> Epoch: 600 Average training loss: 3.2598\n",
      "====> Epoch: 700 Average training loss: 2.9690\n",
      "====> Epoch: 800 Average training loss: 2.7507\n",
      "====> Epoch: 900 Average training loss: 2.5343\n",
      "====> Epoch: 1000 Average training loss: 2.3696\n",
      "====> Epoch: 1100 Average training loss: 2.2146\n",
      "====> Epoch: 1200 Average training loss: 2.0918\n",
      "====> Epoch: 1300 Average training loss: 1.9663\n",
      "====> Epoch: 1400 Average training loss: 1.8644\n",
      "====> Epoch: 1500 Average training loss: 1.7635\n",
      "====> Epoch: 1600 Average training loss: 1.6821\n",
      "====> Epoch: 1700 Average training loss: 1.6145\n",
      "====> Epoch: 1800 Average training loss: 1.5403\n",
      "====> Epoch: 100 Average training loss: 6.4870\n",
      "====> Epoch: 200 Average training loss: 5.2996\n",
      "====> Epoch: 300 Average training loss: 4.5570\n",
      "====> Epoch: 400 Average training loss: 3.9996\n",
      "====> Epoch: 500 Average training loss: 3.5911\n",
      "====> Epoch: 600 Average training loss: 3.2432\n",
      "====> Epoch: 700 Average training loss: 2.9777\n",
      "====> Epoch: 800 Average training loss: 2.7342\n",
      "====> Epoch: 900 Average training loss: 2.5477\n",
      "====> Epoch: 1000 Average training loss: 2.3822\n",
      "====> Epoch: 1100 Average training loss: 2.2169\n",
      "====> Epoch: 1200 Average training loss: 2.0849\n",
      "====> Epoch: 1300 Average training loss: 1.9677\n",
      "====> Epoch: 1400 Average training loss: 1.8638\n",
      "====> Epoch: 1500 Average training loss: 1.7674\n",
      "====> Epoch: 1600 Average training loss: 1.6899\n",
      "====> Epoch: 1700 Average training loss: 1.6217\n",
      "====> Epoch: 1800 Average training loss: 1.5435\n",
      "====> Epoch: 100 Average training loss: 6.4980\n",
      "====> Epoch: 200 Average training loss: 5.3308\n",
      "====> Epoch: 300 Average training loss: 4.5670\n",
      "====> Epoch: 400 Average training loss: 4.0317\n",
      "====> Epoch: 500 Average training loss: 3.5835\n",
      "====> Epoch: 600 Average training loss: 3.2605\n",
      "====> Epoch: 700 Average training loss: 2.9857\n",
      "====> Epoch: 800 Average training loss: 2.7366\n",
      "====> Epoch: 900 Average training loss: 2.5112\n",
      "====> Epoch: 1000 Average training loss: 2.2611\n",
      "====> Epoch: 1100 Average training loss: 2.1289\n",
      "====> Epoch: 1200 Average training loss: 2.0204\n",
      "====> Epoch: 1300 Average training loss: 1.8149\n",
      "====> Epoch: 1400 Average training loss: 1.8180\n",
      "====> Epoch: 1500 Average training loss: 1.6571\n",
      "====> Epoch: 1600 Average training loss: 1.5931\n",
      "====> Epoch: 1700 Average training loss: 1.5240\n",
      "====> Epoch: 1800 Average training loss: 1.4889\n",
      "====> Epoch: 100 Average training loss: 6.4682\n",
      "====> Epoch: 200 Average training loss: 5.3055\n",
      "====> Epoch: 300 Average training loss: 4.5670\n",
      "====> Epoch: 400 Average training loss: 4.0182\n",
      "====> Epoch: 500 Average training loss: 3.5897\n",
      "====> Epoch: 600 Average training loss: 3.2567\n",
      "====> Epoch: 700 Average training loss: 2.9953\n",
      "====> Epoch: 800 Average training loss: 2.7402\n",
      "====> Epoch: 900 Average training loss: 2.5490\n",
      "====> Epoch: 1000 Average training loss: 2.3758\n",
      "====> Epoch: 1100 Average training loss: 2.2127\n",
      "====> Epoch: 1200 Average training loss: 2.0831\n",
      "====> Epoch: 1300 Average training loss: 1.9872\n",
      "====> Epoch: 1400 Average training loss: 1.8613\n",
      "====> Epoch: 1500 Average training loss: 1.7642\n",
      "====> Epoch: 1600 Average training loss: 1.6840\n",
      "====> Epoch: 1700 Average training loss: 1.6076\n",
      "====> Epoch: 1800 Average training loss: 1.5447\n",
      "====> Epoch: 100 Average training loss: 6.8547\n",
      "====> Epoch: 200 Average training loss: 5.5969\n",
      "====> Epoch: 300 Average training loss: 4.7768\n",
      "====> Epoch: 400 Average training loss: 4.1735\n",
      "====> Epoch: 500 Average training loss: 3.6179\n",
      "====> Epoch: 600 Average training loss: 3.2383\n",
      "====> Epoch: 700 Average training loss: 2.8789\n",
      "====> Epoch: 800 Average training loss: 2.6013\n",
      "====> Epoch: 900 Average training loss: 2.4424\n",
      "====> Epoch: 1000 Average training loss: 2.2458\n",
      "====> Epoch: 1100 Average training loss: 2.0903\n",
      "====> Epoch: 1200 Average training loss: 1.9583\n",
      "====> Epoch: 1300 Average training loss: 1.8558\n",
      "====> Epoch: 1400 Average training loss: 1.7476\n",
      "====> Epoch: 1500 Average training loss: 1.6759\n",
      "====> Epoch: 1600 Average training loss: 1.5853\n",
      "====> Epoch: 1700 Average training loss: 1.5219\n",
      "====> Epoch: 1800 Average training loss: 1.4630\n",
      "====> Epoch: 100 Average training loss: 6.4305\n",
      "====> Epoch: 200 Average training loss: 5.2706\n",
      "====> Epoch: 300 Average training loss: 4.5353\n",
      "====> Epoch: 400 Average training loss: 3.9931\n",
      "====> Epoch: 500 Average training loss: 3.5779\n",
      "====> Epoch: 600 Average training loss: 3.2432\n",
      "====> Epoch: 700 Average training loss: 2.9705\n",
      "====> Epoch: 800 Average training loss: 2.7251\n",
      "====> Epoch: 900 Average training loss: 2.5255\n",
      "====> Epoch: 1000 Average training loss: 2.3460\n",
      "====> Epoch: 1100 Average training loss: 2.2105\n",
      "====> Epoch: 1200 Average training loss: 2.0804\n",
      "====> Epoch: 1300 Average training loss: 1.9443\n",
      "====> Epoch: 1400 Average training loss: 1.8542\n",
      "====> Epoch: 1500 Average training loss: 1.7488\n",
      "====> Epoch: 1600 Average training loss: 1.6662\n",
      "====> Epoch: 1700 Average training loss: 1.5999\n",
      "====> Epoch: 1800 Average training loss: 1.5361\n",
      "====> Epoch: 100 Average training loss: 6.6664\n",
      "====> Epoch: 200 Average training loss: 5.4033\n",
      "====> Epoch: 300 Average training loss: 4.5714\n",
      "====> Epoch: 400 Average training loss: 4.0244\n",
      "====> Epoch: 500 Average training loss: 3.5860\n",
      "====> Epoch: 600 Average training loss: 3.2634\n",
      "====> Epoch: 700 Average training loss: 2.9729\n",
      "====> Epoch: 800 Average training loss: 2.7423\n",
      "====> Epoch: 900 Average training loss: 2.5452\n",
      "====> Epoch: 1000 Average training loss: 2.3694\n",
      "====> Epoch: 1100 Average training loss: 2.2254\n",
      "====> Epoch: 1200 Average training loss: 2.0837\n",
      "====> Epoch: 1300 Average training loss: 1.9567\n",
      "====> Epoch: 1400 Average training loss: 1.8692\n",
      "====> Epoch: 1500 Average training loss: 1.7670\n",
      "====> Epoch: 1600 Average training loss: 1.6805\n",
      "====> Epoch: 1700 Average training loss: 1.6103\n",
      "====> Epoch: 1800 Average training loss: 1.5490\n",
      "====> Epoch: 100 Average training loss: 6.7490\n",
      "====> Epoch: 200 Average training loss: 5.5056\n",
      "====> Epoch: 300 Average training loss: 4.7252\n",
      "====> Epoch: 400 Average training loss: 4.1329\n",
      "====> Epoch: 500 Average training loss: 3.6674\n",
      "====> Epoch: 600 Average training loss: 3.3254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 700 Average training loss: 3.0584\n",
      "====> Epoch: 800 Average training loss: 2.8043\n",
      "====> Epoch: 900 Average training loss: 2.5963\n",
      "====> Epoch: 1000 Average training loss: 2.4216\n",
      "====> Epoch: 1100 Average training loss: 2.2533\n",
      "====> Epoch: 1200 Average training loss: 2.1241\n",
      "====> Epoch: 1300 Average training loss: 1.9360\n",
      "====> Epoch: 1400 Average training loss: 1.8906\n",
      "====> Epoch: 1500 Average training loss: 1.7990\n",
      "====> Epoch: 1600 Average training loss: 1.7007\n",
      "====> Epoch: 1700 Average training loss: 1.6298\n",
      "====> Epoch: 1800 Average training loss: 1.5469\n",
      "====> Epoch: 100 Average training loss: 6.5628\n",
      "====> Epoch: 200 Average training loss: 5.3367\n",
      "====> Epoch: 300 Average training loss: 4.5845\n",
      "====> Epoch: 400 Average training loss: 4.0145\n",
      "====> Epoch: 500 Average training loss: 3.5934\n",
      "====> Epoch: 600 Average training loss: 3.2580\n",
      "====> Epoch: 700 Average training loss: 2.9534\n",
      "====> Epoch: 800 Average training loss: 2.7429\n",
      "====> Epoch: 900 Average training loss: 2.5527\n",
      "====> Epoch: 1000 Average training loss: 2.3697\n",
      "====> Epoch: 1100 Average training loss: 2.2114\n",
      "====> Epoch: 1200 Average training loss: 2.0827\n",
      "====> Epoch: 1300 Average training loss: 1.9620\n",
      "====> Epoch: 1400 Average training loss: 1.8528\n",
      "====> Epoch: 1500 Average training loss: 1.7661\n",
      "====> Epoch: 1600 Average training loss: 1.6885\n",
      "====> Epoch: 1700 Average training loss: 1.6040\n",
      "====> Epoch: 1800 Average training loss: 1.5451\n",
      "====> Epoch: 100 Average training loss: 6.5518\n",
      "====> Epoch: 200 Average training loss: 5.3564\n",
      "====> Epoch: 300 Average training loss: 4.5727\n",
      "====> Epoch: 400 Average training loss: 4.0243\n",
      "====> Epoch: 500 Average training loss: 3.5968\n",
      "====> Epoch: 600 Average training loss: 3.2529\n",
      "====> Epoch: 700 Average training loss: 2.9681\n",
      "====> Epoch: 800 Average training loss: 2.7397\n",
      "====> Epoch: 900 Average training loss: 2.5348\n",
      "====> Epoch: 1000 Average training loss: 2.3711\n",
      "====> Epoch: 1100 Average training loss: 2.2121\n",
      "====> Epoch: 1200 Average training loss: 2.0784\n",
      "====> Epoch: 1300 Average training loss: 1.9658\n",
      "====> Epoch: 1400 Average training loss: 1.8729\n",
      "====> Epoch: 1500 Average training loss: 1.7621\n",
      "====> Epoch: 1600 Average training loss: 1.6900\n",
      "====> Epoch: 1700 Average training loss: 1.6073\n",
      "====> Epoch: 1800 Average training loss: 1.5402\n",
      "====> Epoch: 100 Average training loss: 6.6388\n",
      "====> Epoch: 200 Average training loss: 5.4292\n",
      "====> Epoch: 300 Average training loss: 4.6391\n",
      "====> Epoch: 400 Average training loss: 4.0747\n",
      "====> Epoch: 500 Average training loss: 3.6446\n",
      "====> Epoch: 600 Average training loss: 3.3188\n",
      "====> Epoch: 700 Average training loss: 3.0190\n",
      "====> Epoch: 800 Average training loss: 2.7818\n",
      "====> Epoch: 900 Average training loss: 2.5660\n",
      "====> Epoch: 1000 Average training loss: 2.3955\n",
      "====> Epoch: 1100 Average training loss: 2.2403\n",
      "====> Epoch: 1200 Average training loss: 2.0989\n",
      "====> Epoch: 1300 Average training loss: 1.9869\n",
      "====> Epoch: 1400 Average training loss: 1.8844\n",
      "====> Epoch: 1500 Average training loss: 1.7793\n",
      "====> Epoch: 1600 Average training loss: 1.6864\n",
      "====> Epoch: 1700 Average training loss: 1.6224\n",
      "====> Epoch: 1800 Average training loss: 1.5523\n",
      "====> Epoch: 100 Average training loss: 6.5002\n",
      "====> Epoch: 200 Average training loss: 5.3338\n",
      "====> Epoch: 300 Average training loss: 4.5785\n",
      "====> Epoch: 400 Average training loss: 4.0219\n",
      "====> Epoch: 500 Average training loss: 3.5882\n",
      "====> Epoch: 600 Average training loss: 3.2627\n",
      "====> Epoch: 700 Average training loss: 2.9652\n",
      "====> Epoch: 800 Average training loss: 2.7474\n",
      "====> Epoch: 900 Average training loss: 2.4933\n",
      "====> Epoch: 1000 Average training loss: 2.3466\n",
      "====> Epoch: 1100 Average training loss: 2.2142\n",
      "====> Epoch: 1200 Average training loss: 2.0852\n",
      "====> Epoch: 1300 Average training loss: 1.9464\n",
      "====> Epoch: 1400 Average training loss: 1.8075\n",
      "====> Epoch: 1500 Average training loss: 1.7347\n",
      "====> Epoch: 1600 Average training loss: 1.6574\n",
      "====> Epoch: 1700 Average training loss: 1.5969\n",
      "====> Epoch: 1800 Average training loss: 1.4989\n",
      "====> Epoch: 100 Average training loss: 6.6770\n",
      "====> Epoch: 200 Average training loss: 5.4815\n",
      "====> Epoch: 300 Average training loss: 4.6751\n",
      "====> Epoch: 400 Average training loss: 4.1049\n",
      "====> Epoch: 500 Average training loss: 3.6747\n",
      "====> Epoch: 600 Average training loss: 3.3197\n",
      "====> Epoch: 700 Average training loss: 3.0330\n",
      "====> Epoch: 800 Average training loss: 2.7893\n",
      "====> Epoch: 900 Average training loss: 2.5605\n",
      "====> Epoch: 1000 Average training loss: 2.3916\n",
      "====> Epoch: 1100 Average training loss: 2.2335\n",
      "====> Epoch: 1200 Average training loss: 2.0875\n",
      "====> Epoch: 1300 Average training loss: 1.9891\n",
      "====> Epoch: 1400 Average training loss: 1.8751\n",
      "====> Epoch: 1500 Average training loss: 1.7528\n",
      "====> Epoch: 1600 Average training loss: 1.6878\n",
      "====> Epoch: 1700 Average training loss: 1.6210\n",
      "====> Epoch: 1800 Average training loss: 1.5323\n",
      "====> Epoch: 100 Average training loss: 6.6678\n",
      "====> Epoch: 200 Average training loss: 5.3851\n",
      "====> Epoch: 300 Average training loss: 4.6155\n",
      "====> Epoch: 400 Average training loss: 4.0646\n",
      "====> Epoch: 500 Average training loss: 3.6315\n",
      "====> Epoch: 600 Average training loss: 3.2852\n",
      "====> Epoch: 700 Average training loss: 3.0031\n",
      "====> Epoch: 800 Average training loss: 2.7588\n",
      "====> Epoch: 900 Average training loss: 2.5551\n",
      "====> Epoch: 1000 Average training loss: 2.3714\n",
      "====> Epoch: 1100 Average training loss: 2.2201\n",
      "====> Epoch: 1200 Average training loss: 2.0850\n",
      "====> Epoch: 1300 Average training loss: 1.9680\n",
      "====> Epoch: 1400 Average training loss: 1.8684\n",
      "====> Epoch: 1500 Average training loss: 1.7615\n",
      "====> Epoch: 1600 Average training loss: 1.6790\n",
      "====> Epoch: 1700 Average training loss: 1.6209\n",
      "====> Epoch: 1800 Average training loss: 1.5395\n",
      "====> Epoch: 100 Average training loss: 6.8253\n",
      "====> Epoch: 200 Average training loss: 5.5524\n",
      "====> Epoch: 300 Average training loss: 4.7390\n",
      "====> Epoch: 400 Average training loss: 4.1633\n",
      "====> Epoch: 500 Average training loss: 3.7368\n",
      "====> Epoch: 600 Average training loss: 3.3787\n",
      "====> Epoch: 700 Average training loss: 3.0794\n",
      "====> Epoch: 800 Average training loss: 2.8309\n",
      "====> Epoch: 900 Average training loss: 2.6080\n",
      "====> Epoch: 1000 Average training loss: 2.4197\n",
      "====> Epoch: 1100 Average training loss: 2.2426\n",
      "====> Epoch: 1200 Average training loss: 2.1219\n",
      "====> Epoch: 1300 Average training loss: 1.9921\n",
      "====> Epoch: 1400 Average training loss: 1.8872\n",
      "====> Epoch: 1500 Average training loss: 1.7813\n",
      "====> Epoch: 1600 Average training loss: 1.7050\n",
      "====> Epoch: 1700 Average training loss: 1.6098\n",
      "====> Epoch: 1800 Average training loss: 1.5477\n",
      "====> Epoch: 100 Average training loss: 6.5351\n",
      "====> Epoch: 200 Average training loss: 5.3683\n",
      "====> Epoch: 300 Average training loss: 4.6131\n",
      "====> Epoch: 400 Average training loss: 4.0556\n",
      "====> Epoch: 500 Average training loss: 3.6152\n",
      "====> Epoch: 600 Average training loss: 3.2160\n",
      "====> Epoch: 700 Average training loss: 3.0502\n",
      "====> Epoch: 800 Average training loss: 2.7416\n",
      "====> Epoch: 900 Average training loss: 2.5519\n",
      "====> Epoch: 1000 Average training loss: 2.2203\n",
      "====> Epoch: 1100 Average training loss: 2.1942\n",
      "====> Epoch: 1200 Average training loss: 2.0345\n",
      "====> Epoch: 1300 Average training loss: 1.9004\n",
      "====> Epoch: 1400 Average training loss: 1.7613\n",
      "====> Epoch: 1500 Average training loss: 1.6914\n",
      "====> Epoch: 1600 Average training loss: 1.6009\n",
      "====> Epoch: 1700 Average training loss: 1.5263\n",
      "====> Epoch: 1800 Average training loss: 1.4591\n",
      "====> Epoch: 100 Average training loss: 6.6216\n",
      "====> Epoch: 200 Average training loss: 5.3705\n",
      "====> Epoch: 300 Average training loss: 4.5794\n",
      "====> Epoch: 400 Average training loss: 4.0330\n",
      "====> Epoch: 500 Average training loss: 3.6110\n",
      "====> Epoch: 600 Average training loss: 3.2756\n",
      "====> Epoch: 700 Average training loss: 2.9857\n",
      "====> Epoch: 800 Average training loss: 2.7589\n",
      "====> Epoch: 900 Average training loss: 2.5402\n",
      "====> Epoch: 1000 Average training loss: 2.3752\n",
      "====> Epoch: 1100 Average training loss: 2.2178\n",
      "====> Epoch: 1200 Average training loss: 2.0880\n",
      "====> Epoch: 1300 Average training loss: 1.9715\n",
      "====> Epoch: 1400 Average training loss: 1.8705\n",
      "====> Epoch: 1500 Average training loss: 1.7803\n",
      "====> Epoch: 1600 Average training loss: 1.6906\n",
      "====> Epoch: 1700 Average training loss: 1.6134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1800 Average training loss: 1.5416\n",
      "====> Epoch: 100 Average training loss: 6.5664\n",
      "====> Epoch: 200 Average training loss: 5.3412\n",
      "====> Epoch: 300 Average training loss: 4.5796\n",
      "====> Epoch: 400 Average training loss: 4.0335\n",
      "====> Epoch: 500 Average training loss: 3.5945\n",
      "====> Epoch: 600 Average training loss: 3.2756\n",
      "====> Epoch: 700 Average training loss: 2.9932\n",
      "====> Epoch: 800 Average training loss: 2.7547\n",
      "====> Epoch: 900 Average training loss: 2.5597\n",
      "====> Epoch: 1000 Average training loss: 2.3859\n",
      "====> Epoch: 1100 Average training loss: 2.2235\n",
      "====> Epoch: 1200 Average training loss: 2.0856\n",
      "====> Epoch: 1300 Average training loss: 1.9702\n",
      "====> Epoch: 1400 Average training loss: 1.8702\n",
      "====> Epoch: 1500 Average training loss: 1.7700\n",
      "====> Epoch: 1600 Average training loss: 1.6903\n",
      "====> Epoch: 1700 Average training loss: 1.6094\n",
      "====> Epoch: 1800 Average training loss: 1.5508\n",
      "====> Epoch: 100 Average training loss: 6.5276\n",
      "====> Epoch: 200 Average training loss: 5.3485\n",
      "====> Epoch: 300 Average training loss: 4.5950\n",
      "====> Epoch: 400 Average training loss: 4.0463\n",
      "====> Epoch: 500 Average training loss: 3.6252\n",
      "====> Epoch: 600 Average training loss: 3.2713\n",
      "====> Epoch: 700 Average training loss: 2.9871\n",
      "====> Epoch: 800 Average training loss: 2.7631\n",
      "====> Epoch: 900 Average training loss: 2.5529\n",
      "====> Epoch: 1000 Average training loss: 2.3702\n",
      "====> Epoch: 1100 Average training loss: 2.2191\n",
      "====> Epoch: 1200 Average training loss: 2.0871\n",
      "====> Epoch: 1300 Average training loss: 1.9695\n",
      "====> Epoch: 1400 Average training loss: 1.8764\n",
      "====> Epoch: 1500 Average training loss: 1.7791\n",
      "====> Epoch: 1600 Average training loss: 1.6796\n",
      "====> Epoch: 1700 Average training loss: 1.6079\n",
      "====> Epoch: 1800 Average training loss: 1.5461\n",
      "====> Epoch: 100 Average training loss: 6.8607\n",
      "====> Epoch: 200 Average training loss: 5.5877\n",
      "====> Epoch: 300 Average training loss: 4.7916\n",
      "====> Epoch: 400 Average training loss: 4.1951\n",
      "====> Epoch: 500 Average training loss: 3.7330\n",
      "====> Epoch: 600 Average training loss: 3.3639\n",
      "====> Epoch: 700 Average training loss: 3.0865\n",
      "====> Epoch: 800 Average training loss: 2.8209\n",
      "====> Epoch: 900 Average training loss: 2.6058\n",
      "====> Epoch: 1000 Average training loss: 2.4138\n",
      "====> Epoch: 1100 Average training loss: 2.2417\n",
      "====> Epoch: 1200 Average training loss: 2.1051\n",
      "====> Epoch: 1300 Average training loss: 1.9793\n",
      "====> Epoch: 1400 Average training loss: 1.8645\n",
      "====> Epoch: 1500 Average training loss: 1.7701\n",
      "====> Epoch: 1600 Average training loss: 1.6840\n",
      "====> Epoch: 1700 Average training loss: 1.6128\n",
      "====> Epoch: 1800 Average training loss: 1.5402\n",
      "====> Epoch: 100 Average training loss: 6.6350\n",
      "====> Epoch: 200 Average training loss: 5.4065\n",
      "====> Epoch: 300 Average training loss: 4.6296\n",
      "====> Epoch: 400 Average training loss: 4.0772\n",
      "====> Epoch: 500 Average training loss: 3.6425\n",
      "====> Epoch: 600 Average training loss: 3.3019\n",
      "====> Epoch: 700 Average training loss: 3.0226\n",
      "====> Epoch: 800 Average training loss: 2.7627\n",
      "====> Epoch: 900 Average training loss: 2.5578\n",
      "====> Epoch: 1000 Average training loss: 2.3978\n",
      "====> Epoch: 1100 Average training loss: 2.2352\n",
      "====> Epoch: 1200 Average training loss: 2.1152\n",
      "====> Epoch: 1300 Average training loss: 1.9788\n",
      "====> Epoch: 1400 Average training loss: 1.8751\n",
      "====> Epoch: 1500 Average training loss: 1.7789\n",
      "====> Epoch: 1600 Average training loss: 1.6931\n",
      "====> Epoch: 1700 Average training loss: 1.6116\n",
      "====> Epoch: 1800 Average training loss: 1.5532\n",
      "====> Epoch: 100 Average training loss: 6.7359\n",
      "====> Epoch: 200 Average training loss: 5.5061\n",
      "====> Epoch: 300 Average training loss: 4.6944\n",
      "====> Epoch: 400 Average training loss: 4.1028\n",
      "====> Epoch: 500 Average training loss: 3.6827\n",
      "====> Epoch: 600 Average training loss: 3.3086\n",
      "====> Epoch: 700 Average training loss: 3.0134\n",
      "====> Epoch: 800 Average training loss: 2.7591\n",
      "====> Epoch: 900 Average training loss: 2.5546\n",
      "====> Epoch: 1000 Average training loss: 2.3644\n",
      "====> Epoch: 1100 Average training loss: 2.2307\n",
      "====> Epoch: 1200 Average training loss: 2.0908\n",
      "====> Epoch: 1300 Average training loss: 1.9632\n",
      "====> Epoch: 1400 Average training loss: 1.8563\n",
      "====> Epoch: 1500 Average training loss: 1.7730\n",
      "====> Epoch: 1600 Average training loss: 1.6751\n",
      "====> Epoch: 1700 Average training loss: 1.6095\n",
      "====> Epoch: 1800 Average training loss: 1.5461\n",
      "====> Epoch: 100 Average training loss: 6.5999\n",
      "====> Epoch: 200 Average training loss: 5.4112\n",
      "====> Epoch: 300 Average training loss: 4.6438\n",
      "====> Epoch: 400 Average training loss: 4.0746\n",
      "====> Epoch: 500 Average training loss: 3.6405\n",
      "====> Epoch: 600 Average training loss: 3.3002\n",
      "====> Epoch: 700 Average training loss: 3.0007\n",
      "====> Epoch: 800 Average training loss: 2.7569\n",
      "====> Epoch: 900 Average training loss: 2.5537\n",
      "====> Epoch: 1000 Average training loss: 2.3847\n",
      "====> Epoch: 1100 Average training loss: 2.2303\n",
      "====> Epoch: 1200 Average training loss: 2.0978\n",
      "====> Epoch: 1300 Average training loss: 1.9704\n",
      "====> Epoch: 1400 Average training loss: 1.8633\n",
      "====> Epoch: 1500 Average training loss: 1.7708\n",
      "====> Epoch: 1600 Average training loss: 1.6824\n",
      "====> Epoch: 1700 Average training loss: 1.6246\n",
      "====> Epoch: 1800 Average training loss: 1.5435\n",
      "====> Epoch: 100 Average training loss: 6.7111\n",
      "====> Epoch: 200 Average training loss: 5.3963\n",
      "====> Epoch: 300 Average training loss: 4.5677\n",
      "====> Epoch: 400 Average training loss: 4.0235\n",
      "====> Epoch: 500 Average training loss: 3.5891\n",
      "====> Epoch: 600 Average training loss: 3.2618\n",
      "====> Epoch: 700 Average training loss: 2.9815\n",
      "====> Epoch: 800 Average training loss: 2.7219\n",
      "====> Epoch: 900 Average training loss: 2.5474\n",
      "====> Epoch: 1000 Average training loss: 2.3604\n",
      "====> Epoch: 1100 Average training loss: 2.2381\n",
      "====> Epoch: 1200 Average training loss: 2.0863\n",
      "====> Epoch: 1300 Average training loss: 1.9724\n",
      "====> Epoch: 1400 Average training loss: 1.8842\n",
      "====> Epoch: 1500 Average training loss: 1.7838\n",
      "====> Epoch: 1600 Average training loss: 1.6956\n",
      "====> Epoch: 1700 Average training loss: 1.6124\n",
      "====> Epoch: 1800 Average training loss: 1.5569\n",
      "====> Epoch: 100 Average training loss: 6.4785\n",
      "====> Epoch: 200 Average training loss: 5.3151\n",
      "====> Epoch: 300 Average training loss: 4.5701\n",
      "====> Epoch: 400 Average training loss: 4.0161\n",
      "====> Epoch: 500 Average training loss: 3.5971\n",
      "====> Epoch: 600 Average training loss: 3.2548\n",
      "====> Epoch: 700 Average training loss: 2.9695\n",
      "====> Epoch: 800 Average training loss: 2.7468\n",
      "====> Epoch: 900 Average training loss: 2.5246\n",
      "====> Epoch: 1000 Average training loss: 2.3574\n",
      "====> Epoch: 1100 Average training loss: 2.2197\n",
      "====> Epoch: 1200 Average training loss: 2.0637\n",
      "====> Epoch: 1300 Average training loss: 1.9564\n",
      "====> Epoch: 1400 Average training loss: 1.8609\n",
      "====> Epoch: 1500 Average training loss: 1.7767\n",
      "====> Epoch: 1600 Average training loss: 1.6892\n",
      "====> Epoch: 1700 Average training loss: 1.6089\n",
      "====> Epoch: 1800 Average training loss: 1.5482\n",
      "====> Epoch: 100 Average training loss: 6.5192\n",
      "====> Epoch: 200 Average training loss: 5.3374\n",
      "====> Epoch: 300 Average training loss: 4.5854\n",
      "====> Epoch: 400 Average training loss: 4.0137\n",
      "====> Epoch: 500 Average training loss: 3.5988\n",
      "====> Epoch: 600 Average training loss: 3.2756\n",
      "====> Epoch: 700 Average training loss: 2.9955\n",
      "====> Epoch: 800 Average training loss: 2.7502\n",
      "====> Epoch: 900 Average training loss: 2.5299\n",
      "====> Epoch: 1000 Average training loss: 2.3649\n",
      "====> Epoch: 1100 Average training loss: 2.2153\n",
      "====> Epoch: 1200 Average training loss: 2.0873\n",
      "====> Epoch: 1300 Average training loss: 1.9468\n",
      "====> Epoch: 1400 Average training loss: 1.8650\n",
      "====> Epoch: 1500 Average training loss: 1.7819\n",
      "====> Epoch: 1600 Average training loss: 1.6847\n",
      "====> Epoch: 1700 Average training loss: 1.5999\n",
      "====> Epoch: 1800 Average training loss: 1.5436\n",
      "====> Epoch: 100 Average training loss: 6.5947\n",
      "====> Epoch: 200 Average training loss: 5.3810\n",
      "====> Epoch: 300 Average training loss: 4.6206\n",
      "====> Epoch: 400 Average training loss: 4.0505\n",
      "====> Epoch: 500 Average training loss: 3.6136\n",
      "====> Epoch: 600 Average training loss: 3.2705\n",
      "====> Epoch: 700 Average training loss: 2.9848\n",
      "====> Epoch: 800 Average training loss: 2.7475\n",
      "====> Epoch: 900 Average training loss: 2.5433\n",
      "====> Epoch: 1000 Average training loss: 2.3666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1100 Average training loss: 2.2247\n",
      "====> Epoch: 1200 Average training loss: 2.0842\n",
      "====> Epoch: 1300 Average training loss: 1.9843\n",
      "====> Epoch: 1400 Average training loss: 1.8604\n",
      "====> Epoch: 1500 Average training loss: 1.7785\n",
      "====> Epoch: 1600 Average training loss: 1.6882\n",
      "====> Epoch: 1700 Average training loss: 1.6136\n",
      "====> Epoch: 1800 Average training loss: 1.5442\n",
      "====> Epoch: 100 Average training loss: 6.6367\n",
      "====> Epoch: 200 Average training loss: 5.4364\n",
      "====> Epoch: 300 Average training loss: 4.6306\n",
      "====> Epoch: 400 Average training loss: 4.0695\n",
      "====> Epoch: 500 Average training loss: 3.6331\n",
      "====> Epoch: 600 Average training loss: 3.2742\n",
      "====> Epoch: 700 Average training loss: 2.9946\n",
      "====> Epoch: 800 Average training loss: 2.7519\n",
      "====> Epoch: 900 Average training loss: 2.5427\n",
      "====> Epoch: 1000 Average training loss: 2.3672\n",
      "====> Epoch: 1100 Average training loss: 2.2199\n",
      "====> Epoch: 1200 Average training loss: 2.0848\n",
      "====> Epoch: 1300 Average training loss: 1.9684\n",
      "====> Epoch: 1400 Average training loss: 1.8672\n",
      "====> Epoch: 1500 Average training loss: 1.7753\n",
      "====> Epoch: 1600 Average training loss: 1.6848\n",
      "====> Epoch: 1700 Average training loss: 1.6104\n",
      "====> Epoch: 1800 Average training loss: 1.5315\n",
      "====> Epoch: 100 Average training loss: 6.6210\n",
      "====> Epoch: 200 Average training loss: 5.4159\n",
      "====> Epoch: 300 Average training loss: 4.6410\n",
      "====> Epoch: 400 Average training loss: 4.0642\n",
      "====> Epoch: 500 Average training loss: 3.6359\n",
      "====> Epoch: 600 Average training loss: 3.2972\n",
      "====> Epoch: 700 Average training loss: 2.9963\n",
      "====> Epoch: 800 Average training loss: 2.7665\n",
      "====> Epoch: 900 Average training loss: 2.5611\n",
      "====> Epoch: 1000 Average training loss: 2.3719\n",
      "====> Epoch: 1100 Average training loss: 2.2362\n",
      "====> Epoch: 1200 Average training loss: 2.0795\n",
      "====> Epoch: 1300 Average training loss: 1.8758\n",
      "====> Epoch: 1400 Average training loss: 1.8594\n",
      "====> Epoch: 1500 Average training loss: 1.7678\n",
      "====> Epoch: 1600 Average training loss: 1.6745\n",
      "====> Epoch: 1700 Average training loss: 1.5992\n",
      "====> Epoch: 1800 Average training loss: 1.5290\n",
      "====> Epoch: 100 Average training loss: 6.6943\n",
      "====> Epoch: 200 Average training loss: 5.4214\n",
      "====> Epoch: 300 Average training loss: 4.6547\n",
      "====> Epoch: 400 Average training loss: 4.0903\n",
      "====> Epoch: 500 Average training loss: 3.5126\n",
      "====> Epoch: 600 Average training loss: 3.3085\n",
      "====> Epoch: 700 Average training loss: 2.8329\n",
      "====> Epoch: 800 Average training loss: 2.7209\n",
      "====> Epoch: 900 Average training loss: 2.4837\n",
      "====> Epoch: 1000 Average training loss: 2.2947\n",
      "====> Epoch: 1100 Average training loss: 2.1321\n",
      "====> Epoch: 1200 Average training loss: 1.9989\n",
      "====> Epoch: 1300 Average training loss: 1.8817\n",
      "====> Epoch: 1400 Average training loss: 1.7879\n",
      "====> Epoch: 1500 Average training loss: 1.6867\n",
      "====> Epoch: 1600 Average training loss: 1.6108\n",
      "====> Epoch: 1700 Average training loss: 1.5425\n",
      "====> Epoch: 1800 Average training loss: 1.4756\n",
      "====> Epoch: 100 Average training loss: 6.5152\n",
      "====> Epoch: 200 Average training loss: 5.3434\n",
      "====> Epoch: 300 Average training loss: 4.5906\n",
      "====> Epoch: 400 Average training loss: 4.0112\n",
      "====> Epoch: 500 Average training loss: 3.6003\n",
      "====> Epoch: 600 Average training loss: 3.2610\n",
      "====> Epoch: 700 Average training loss: 2.9716\n",
      "====> Epoch: 800 Average training loss: 2.7451\n",
      "====> Epoch: 900 Average training loss: 2.5462\n",
      "====> Epoch: 1000 Average training loss: 2.3653\n",
      "====> Epoch: 1100 Average training loss: 2.2156\n",
      "====> Epoch: 1200 Average training loss: 2.0707\n",
      "====> Epoch: 1300 Average training loss: 1.9598\n",
      "====> Epoch: 1400 Average training loss: 1.8666\n",
      "====> Epoch: 1500 Average training loss: 1.7644\n",
      "====> Epoch: 1600 Average training loss: 1.6708\n",
      "====> Epoch: 1700 Average training loss: 1.6023\n",
      "====> Epoch: 1800 Average training loss: 1.5368\n",
      "====> Epoch: 100 Average training loss: 6.6539\n",
      "====> Epoch: 200 Average training loss: 5.4365\n",
      "====> Epoch: 300 Average training loss: 4.6429\n",
      "====> Epoch: 400 Average training loss: 4.0675\n",
      "====> Epoch: 500 Average training loss: 3.6548\n",
      "====> Epoch: 600 Average training loss: 3.2983\n",
      "====> Epoch: 700 Average training loss: 3.0107\n",
      "====> Epoch: 800 Average training loss: 2.7679\n",
      "====> Epoch: 900 Average training loss: 2.5715\n",
      "====> Epoch: 1000 Average training loss: 2.3867\n",
      "====> Epoch: 1100 Average training loss: 2.2296\n",
      "====> Epoch: 1200 Average training loss: 2.0967\n",
      "====> Epoch: 1300 Average training loss: 1.9645\n",
      "====> Epoch: 1400 Average training loss: 1.8588\n",
      "====> Epoch: 1500 Average training loss: 1.7699\n",
      "====> Epoch: 1600 Average training loss: 1.6898\n",
      "====> Epoch: 1700 Average training loss: 1.6019\n",
      "====> Epoch: 1800 Average training loss: 1.5310\n",
      "====> Epoch: 100 Average training loss: 6.5858\n",
      "====> Epoch: 200 Average training loss: 5.3719\n",
      "====> Epoch: 300 Average training loss: 4.6049\n",
      "====> Epoch: 400 Average training loss: 4.0539\n",
      "====> Epoch: 500 Average training loss: 3.6225\n",
      "====> Epoch: 600 Average training loss: 3.2861\n",
      "====> Epoch: 700 Average training loss: 3.0013\n",
      "====> Epoch: 800 Average training loss: 2.7666\n",
      "====> Epoch: 900 Average training loss: 2.5742\n",
      "====> Epoch: 1000 Average training loss: 2.3819\n",
      "====> Epoch: 1100 Average training loss: 2.2276\n",
      "====> Epoch: 1200 Average training loss: 2.0923\n",
      "====> Epoch: 1300 Average training loss: 1.9659\n",
      "====> Epoch: 1400 Average training loss: 1.8674\n",
      "====> Epoch: 1500 Average training loss: 1.7690\n",
      "====> Epoch: 1600 Average training loss: 1.6906\n",
      "====> Epoch: 1700 Average training loss: 1.6018\n",
      "====> Epoch: 1800 Average training loss: 1.5464\n",
      "====> Epoch: 100 Average training loss: 6.8115\n",
      "====> Epoch: 200 Average training loss: 5.5731\n",
      "====> Epoch: 300 Average training loss: 4.7260\n",
      "====> Epoch: 400 Average training loss: 4.1635\n",
      "====> Epoch: 500 Average training loss: 3.7126\n",
      "====> Epoch: 600 Average training loss: 3.3547\n",
      "====> Epoch: 700 Average training loss: 3.0610\n",
      "====> Epoch: 800 Average training loss: 2.7934\n",
      "====> Epoch: 900 Average training loss: 2.5907\n",
      "====> Epoch: 1000 Average training loss: 2.3871\n",
      "====> Epoch: 1100 Average training loss: 2.2540\n",
      "====> Epoch: 1200 Average training loss: 2.1015\n",
      "====> Epoch: 1300 Average training loss: 1.9746\n",
      "====> Epoch: 1400 Average training loss: 1.8704\n",
      "====> Epoch: 1500 Average training loss: 1.7757\n",
      "====> Epoch: 1600 Average training loss: 1.7052\n",
      "====> Epoch: 1700 Average training loss: 1.6132\n",
      "====> Epoch: 1800 Average training loss: 1.5262\n",
      "====> Epoch: 100 Average training loss: 6.8663\n",
      "====> Epoch: 200 Average training loss: 5.5304\n",
      "====> Epoch: 300 Average training loss: 4.6929\n",
      "====> Epoch: 400 Average training loss: 4.0986\n",
      "====> Epoch: 500 Average training loss: 3.6649\n",
      "====> Epoch: 600 Average training loss: 3.2980\n",
      "====> Epoch: 700 Average training loss: 3.0069\n",
      "====> Epoch: 800 Average training loss: 2.7666\n",
      "====> Epoch: 900 Average training loss: 2.5626\n",
      "====> Epoch: 1000 Average training loss: 2.3913\n",
      "====> Epoch: 1100 Average training loss: 2.2260\n",
      "====> Epoch: 1200 Average training loss: 2.0816\n",
      "====> Epoch: 1300 Average training loss: 1.9509\n",
      "====> Epoch: 1400 Average training loss: 1.8607\n",
      "====> Epoch: 1500 Average training loss: 1.7587\n",
      "====> Epoch: 1600 Average training loss: 1.6877\n",
      "====> Epoch: 1700 Average training loss: 1.6169\n",
      "====> Epoch: 1800 Average training loss: 1.5484\n",
      "====> Epoch: 100 Average training loss: 6.4365\n",
      "====> Epoch: 200 Average training loss: 5.2541\n",
      "====> Epoch: 300 Average training loss: 4.5292\n",
      "====> Epoch: 400 Average training loss: 3.9812\n",
      "====> Epoch: 500 Average training loss: 3.5757\n",
      "====> Epoch: 600 Average training loss: 3.2395\n",
      "====> Epoch: 700 Average training loss: 2.9587\n",
      "====> Epoch: 800 Average training loss: 2.7361\n",
      "====> Epoch: 900 Average training loss: 2.5195\n",
      "====> Epoch: 1000 Average training loss: 2.3461\n",
      "====> Epoch: 1100 Average training loss: 2.2024\n",
      "====> Epoch: 1200 Average training loss: 2.0768\n",
      "====> Epoch: 1300 Average training loss: 1.9617\n",
      "====> Epoch: 1400 Average training loss: 1.8456\n",
      "====> Epoch: 1500 Average training loss: 1.7459\n",
      "====> Epoch: 1600 Average training loss: 1.6860\n",
      "====> Epoch: 1700 Average training loss: 1.6079\n",
      "====> Epoch: 1800 Average training loss: 1.5281\n",
      "====> Epoch: 100 Average training loss: 6.6191\n",
      "====> Epoch: 200 Average training loss: 5.3912\n",
      "====> Epoch: 300 Average training loss: 4.6202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 400 Average training loss: 4.0462\n",
      "====> Epoch: 500 Average training loss: 3.6043\n",
      "====> Epoch: 600 Average training loss: 3.2675\n",
      "====> Epoch: 700 Average training loss: 2.9781\n",
      "====> Epoch: 800 Average training loss: 2.7436\n",
      "====> Epoch: 900 Average training loss: 2.5481\n",
      "====> Epoch: 1000 Average training loss: 2.3724\n",
      "====> Epoch: 1100 Average training loss: 2.2263\n",
      "====> Epoch: 1200 Average training loss: 2.0786\n",
      "====> Epoch: 1300 Average training loss: 1.9691\n",
      "====> Epoch: 1400 Average training loss: 1.8663\n",
      "====> Epoch: 1500 Average training loss: 1.7690\n",
      "====> Epoch: 1600 Average training loss: 1.6896\n",
      "====> Epoch: 1700 Average training loss: 1.6177\n",
      "====> Epoch: 1800 Average training loss: 1.5347\n",
      "====> Epoch: 100 Average training loss: 6.5096\n",
      "====> Epoch: 200 Average training loss: 5.3429\n",
      "====> Epoch: 300 Average training loss: 4.5936\n",
      "====> Epoch: 400 Average training loss: 4.0547\n",
      "====> Epoch: 500 Average training loss: 3.6164\n",
      "====> Epoch: 600 Average training loss: 3.2792\n",
      "====> Epoch: 700 Average training loss: 3.0001\n",
      "====> Epoch: 800 Average training loss: 2.7478\n",
      "====> Epoch: 900 Average training loss: 2.5431\n",
      "====> Epoch: 1000 Average training loss: 2.3723\n",
      "====> Epoch: 1100 Average training loss: 2.2291\n",
      "====> Epoch: 1200 Average training loss: 2.0921\n",
      "====> Epoch: 1300 Average training loss: 1.9696\n",
      "====> Epoch: 1400 Average training loss: 1.8622\n",
      "====> Epoch: 1500 Average training loss: 1.7682\n",
      "====> Epoch: 1600 Average training loss: 1.6829\n",
      "====> Epoch: 1700 Average training loss: 1.6004\n",
      "====> Epoch: 1800 Average training loss: 1.5397\n",
      "====> Epoch: 100 Average training loss: 6.7345\n",
      "====> Epoch: 200 Average training loss: 5.5080\n",
      "====> Epoch: 300 Average training loss: 4.7105\n",
      "====> Epoch: 400 Average training loss: 4.1353\n",
      "====> Epoch: 500 Average training loss: 3.6893\n",
      "====> Epoch: 600 Average training loss: 3.3286\n",
      "====> Epoch: 700 Average training loss: 3.0381\n",
      "====> Epoch: 800 Average training loss: 2.7843\n",
      "====> Epoch: 900 Average training loss: 2.5633\n",
      "====> Epoch: 1000 Average training loss: 2.3806\n",
      "====> Epoch: 1100 Average training loss: 2.2381\n",
      "====> Epoch: 1200 Average training loss: 2.0956\n",
      "====> Epoch: 1300 Average training loss: 1.9739\n",
      "====> Epoch: 1400 Average training loss: 1.8681\n",
      "====> Epoch: 1500 Average training loss: 1.7692\n",
      "====> Epoch: 1600 Average training loss: 1.6856\n",
      "====> Epoch: 1700 Average training loss: 1.6219\n",
      "====> Epoch: 1800 Average training loss: 1.5462\n",
      "====> Epoch: 100 Average training loss: 6.5232\n",
      "====> Epoch: 200 Average training loss: 5.3615\n",
      "====> Epoch: 300 Average training loss: 4.5872\n",
      "====> Epoch: 400 Average training loss: 4.0454\n",
      "====> Epoch: 500 Average training loss: 3.6158\n",
      "====> Epoch: 600 Average training loss: 3.2743\n",
      "====> Epoch: 700 Average training loss: 2.9906\n",
      "====> Epoch: 800 Average training loss: 2.7461\n",
      "====> Epoch: 900 Average training loss: 2.5429\n",
      "====> Epoch: 1000 Average training loss: 2.3654\n",
      "====> Epoch: 1100 Average training loss: 2.2165\n",
      "====> Epoch: 1200 Average training loss: 2.0848\n",
      "====> Epoch: 1300 Average training loss: 1.9557\n",
      "====> Epoch: 1400 Average training loss: 1.8717\n",
      "====> Epoch: 1500 Average training loss: 1.7657\n",
      "====> Epoch: 1600 Average training loss: 1.6637\n",
      "====> Epoch: 1700 Average training loss: 1.6012\n",
      "====> Epoch: 1800 Average training loss: 1.5327\n",
      "====> Epoch: 100 Average training loss: 6.7725\n",
      "====> Epoch: 200 Average training loss: 5.5562\n",
      "====> Epoch: 300 Average training loss: 4.7499\n",
      "====> Epoch: 400 Average training loss: 4.1781\n",
      "====> Epoch: 500 Average training loss: 3.7250\n",
      "====> Epoch: 600 Average training loss: 3.3495\n",
      "====> Epoch: 700 Average training loss: 3.0521\n",
      "====> Epoch: 800 Average training loss: 2.7992\n",
      "====> Epoch: 900 Average training loss: 2.5931\n",
      "====> Epoch: 1000 Average training loss: 2.3962\n",
      "====> Epoch: 1100 Average training loss: 2.2353\n",
      "====> Epoch: 1200 Average training loss: 2.1146\n",
      "====> Epoch: 1300 Average training loss: 1.9783\n",
      "====> Epoch: 1400 Average training loss: 1.8672\n",
      "====> Epoch: 1500 Average training loss: 1.7722\n",
      "====> Epoch: 1600 Average training loss: 1.6827\n",
      "====> Epoch: 1700 Average training loss: 1.6065\n",
      "====> Epoch: 1800 Average training loss: 1.5240\n",
      "====> Epoch: 100 Average training loss: 6.4647\n",
      "====> Epoch: 200 Average training loss: 5.3077\n",
      "====> Epoch: 300 Average training loss: 4.5631\n",
      "====> Epoch: 400 Average training loss: 4.0189\n",
      "====> Epoch: 500 Average training loss: 3.5984\n",
      "====> Epoch: 600 Average training loss: 3.2620\n",
      "====> Epoch: 700 Average training loss: 2.9882\n",
      "====> Epoch: 800 Average training loss: 2.7412\n",
      "====> Epoch: 900 Average training loss: 2.5314\n",
      "====> Epoch: 1000 Average training loss: 2.3594\n",
      "====> Epoch: 1100 Average training loss: 2.2209\n",
      "====> Epoch: 1200 Average training loss: 2.0847\n",
      "====> Epoch: 1300 Average training loss: 1.9697\n",
      "====> Epoch: 1400 Average training loss: 1.8587\n",
      "====> Epoch: 1500 Average training loss: 1.7626\n",
      "====> Epoch: 1600 Average training loss: 1.6765\n",
      "====> Epoch: 1700 Average training loss: 1.6048\n",
      "====> Epoch: 1800 Average training loss: 1.5267\n",
      "====> Epoch: 100 Average training loss: 6.4674\n",
      "====> Epoch: 200 Average training loss: 5.2868\n",
      "====> Epoch: 300 Average training loss: 4.5623\n",
      "====> Epoch: 400 Average training loss: 4.0194\n",
      "====> Epoch: 500 Average training loss: 3.6028\n",
      "====> Epoch: 600 Average training loss: 3.2675\n",
      "====> Epoch: 700 Average training loss: 2.9771\n",
      "====> Epoch: 800 Average training loss: 2.7450\n",
      "====> Epoch: 900 Average training loss: 2.5481\n",
      "====> Epoch: 1000 Average training loss: 2.3773\n",
      "====> Epoch: 1100 Average training loss: 2.2125\n",
      "====> Epoch: 1200 Average training loss: 2.0855\n",
      "====> Epoch: 1300 Average training loss: 1.9692\n",
      "====> Epoch: 1400 Average training loss: 1.8664\n",
      "====> Epoch: 1500 Average training loss: 1.7726\n",
      "====> Epoch: 1600 Average training loss: 1.6818\n",
      "====> Epoch: 1700 Average training loss: 1.6062\n",
      "====> Epoch: 1800 Average training loss: 1.5387\n"
     ]
    }
   ],
   "source": [
    "epochs=[1800]\n",
    "hl=[2,3,4]\n",
    "lr=[0.0001,0.01,0.001]\n",
    "mm=[0.001,0.01]\n",
    "act=['relu','tanh']\n",
    "opt=['adam','adagrad','sgd']\n",
    "ldm=[2,3,4]\n",
    "\n",
    "min_loss=10000\n",
    "MODEL=None\n",
    "BESTCOMB=None\n",
    "\n",
    "for e in epochs:\n",
    "    for h in hl:\n",
    "        for l in lr:\n",
    "            for m in mm:\n",
    "                for a in act:\n",
    "                    for o in opt:\n",
    "                        for ld in ldm:\n",
    "                            \n",
    "                            D_in = trainloader.dataset.x.shape[1]\n",
    "                            \n",
    "                            if hl==2:\n",
    "                                model = VAE2(D_in,ld,a).to(device)\n",
    "                            if hl==3:\n",
    "                                model = VAE3(D_in,ld,a).to(device)\n",
    "                            if hl==4:\n",
    "                                model = VAE4(D_in,ld,a).to(device)\n",
    "                            \n",
    "                            if opt=='adam':\n",
    "                                optimizer = optim.Adam(model.parameters(), lr=l)\n",
    "                            if opt=='sgd':\n",
    "                                optimizer = optim.SGD(model.parameters(), lr=l,momentum=m)\n",
    "                            if opt=='adagrad':\n",
    "                                optimizer = torch.optim.Adagrad(model.parameters(), lr = l)\n",
    "                            \n",
    "                            start = time.time()\n",
    "                            for epoch in range(1, e+1):\n",
    "                                train(epoch)\n",
    "                            #     test(epoch)\n",
    "                            elapsed_time = time.time()-start\n",
    "                            #print(\"total_time taken is :\",elapsed_time)\n",
    "\n",
    "                            cur_loss=train_losses[len(train_losses)-1]\n",
    "                            if cur_loss < min_loss:\n",
    "                                min_loss=cur_loss\n",
    "                                MODEL=model\n",
    "                                BESTCOMB=[e,h,l,m,a,o,ld]\n",
    "                            \n",
    "                            \n",
    "                            ## junk --ignore\n",
    "                            model = VAE2(D_in,2,'relu').to(device)\n",
    "                            optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "5yodKYq4Z97c"
   },
   "outputs": [],
   "source": [
    "BESTCOMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "wzRN_rxaZ97d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE2(\n",
       "  (linear1): Linear(in_features=8, out_features=10, bias=True)\n",
       "  (lin_bn1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear2): Linear(in_features=10, out_features=15, bias=True)\n",
       "  (lin_bn2): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=15, out_features=2, bias=True)\n",
       "  (bn1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc21): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc22): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc3): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc_bn3): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=2, out_features=15, bias=True)\n",
       "  (fc_bn4): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear4): Linear(in_features=15, out_features=10, bias=True)\n",
       "  (lin_bn4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear5): Linear(in_features=10, out_features=8, bias=True)\n",
       "  (lin_bn5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (Tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "WlECkpI4Z97d"
   },
   "outputs": [],
   "source": [
    "x_hat = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = MODEL(data)\n",
    "        x_hat.append(recon_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhfGnqZ8Z97d",
    "outputId": "7975c36b-9438-4180-f0f7-080e4d18e90e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.6823,  0.1817,  0.1601,  ...,  0.9453,  0.1416,  0.5184],\n",
       "         [ 0.6967,  0.7846,  0.3372,  ...,  0.8046,  0.2936, -0.0058],\n",
       "         [ 0.3732,  0.1750,  0.8032,  ...,  0.2196,  0.8473,  0.5171],\n",
       "         ...,\n",
       "         [ 0.4364,  0.2931,  0.6242,  ...,  0.4735,  0.6443,  0.4036],\n",
       "         [ 0.4676,  0.3111,  0.5840,  ...,  0.5264,  0.6010,  0.4048],\n",
       "         [ 0.6528,  0.8518,  0.5190,  ...,  0.6587,  0.4759, -0.0767]])]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "okDzPTsGZ97e"
   },
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame(np.array(x_hat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-riYi8WwZ97e",
    "outputId": "9ec1cbe4-9f76-4243-ff50-5693636ed936",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682302</td>\n",
       "      <td>0.181664</td>\n",
       "      <td>0.160124</td>\n",
       "      <td>0.218293</td>\n",
       "      <td>0.087439</td>\n",
       "      <td>0.945278</td>\n",
       "      <td>0.141607</td>\n",
       "      <td>0.518402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.784630</td>\n",
       "      <td>0.337177</td>\n",
       "      <td>0.591466</td>\n",
       "      <td>-0.119760</td>\n",
       "      <td>0.804641</td>\n",
       "      <td>0.293623</td>\n",
       "      <td>-0.005806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.373250</td>\n",
       "      <td>0.174955</td>\n",
       "      <td>0.803203</td>\n",
       "      <td>0.405306</td>\n",
       "      <td>0.360827</td>\n",
       "      <td>0.219641</td>\n",
       "      <td>0.847347</td>\n",
       "      <td>0.517073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380489</td>\n",
       "      <td>-0.113510</td>\n",
       "      <td>0.660653</td>\n",
       "      <td>0.303539</td>\n",
       "      <td>0.453734</td>\n",
       "      <td>0.389440</td>\n",
       "      <td>0.711760</td>\n",
       "      <td>0.696993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.756398</td>\n",
       "      <td>-0.052024</td>\n",
       "      <td>-0.135941</td>\n",
       "      <td>-0.354321</td>\n",
       "      <td>0.075660</td>\n",
       "      <td>1.169491</td>\n",
       "      <td>-0.164971</td>\n",
       "      <td>1.026090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0.373250</td>\n",
       "      <td>0.174955</td>\n",
       "      <td>0.803203</td>\n",
       "      <td>0.405306</td>\n",
       "      <td>0.360827</td>\n",
       "      <td>0.219641</td>\n",
       "      <td>0.847347</td>\n",
       "      <td>0.517073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0.670697</td>\n",
       "      <td>0.306268</td>\n",
       "      <td>0.235417</td>\n",
       "      <td>0.361252</td>\n",
       "      <td>0.061206</td>\n",
       "      <td>0.887190</td>\n",
       "      <td>0.214945</td>\n",
       "      <td>0.362840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0.436424</td>\n",
       "      <td>0.293129</td>\n",
       "      <td>0.624173</td>\n",
       "      <td>0.445553</td>\n",
       "      <td>0.270823</td>\n",
       "      <td>0.473534</td>\n",
       "      <td>0.644261</td>\n",
       "      <td>0.403554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>0.467602</td>\n",
       "      <td>0.311101</td>\n",
       "      <td>0.584015</td>\n",
       "      <td>0.435035</td>\n",
       "      <td>0.233166</td>\n",
       "      <td>0.526447</td>\n",
       "      <td>0.601048</td>\n",
       "      <td>0.404837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0.652772</td>\n",
       "      <td>0.851770</td>\n",
       "      <td>0.518973</td>\n",
       "      <td>0.627753</td>\n",
       "      <td>-0.029545</td>\n",
       "      <td>0.658689</td>\n",
       "      <td>0.475865</td>\n",
       "      <td>-0.076679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.682302  0.181664  0.160124  0.218293  0.087439  0.945278  0.141607   \n",
       "1     0.696721  0.784630  0.337177  0.591466 -0.119760  0.804641  0.293623   \n",
       "2     0.373250  0.174955  0.803203  0.405306  0.360827  0.219641  0.847347   \n",
       "3     0.380489 -0.113510  0.660653  0.303539  0.453734  0.389440  0.711760   \n",
       "4     0.756398 -0.052024 -0.135941 -0.354321  0.075660  1.169491 -0.164971   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6995  0.373250  0.174955  0.803203  0.405306  0.360827  0.219641  0.847347   \n",
       "6996  0.670697  0.306268  0.235417  0.361252  0.061206  0.887190  0.214945   \n",
       "6997  0.436424  0.293129  0.624173  0.445553  0.270823  0.473534  0.644261   \n",
       "6998  0.467602  0.311101  0.584015  0.435035  0.233166  0.526447  0.601048   \n",
       "6999  0.652772  0.851770  0.518973  0.627753 -0.029545  0.658689  0.475865   \n",
       "\n",
       "             7  \n",
       "0     0.518402  \n",
       "1    -0.005806  \n",
       "2     0.517073  \n",
       "3     0.696993  \n",
       "4     1.026090  \n",
       "...        ...  \n",
       "6995  0.517073  \n",
       "6996  0.362840  \n",
       "6997  0.403554  \n",
       "6998  0.404837  \n",
       "6999 -0.076679  \n",
       "\n",
       "[7000 rows x 8 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "E7gXHb5KZ97e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "N6WOcdB8Z97e"
   },
   "outputs": [],
   "source": [
    "org =pd.DataFrame(np.array(trainloader.dataset.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "_b8xFx6SZ97e"
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(np.array(testloader.dataset.x)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Equq_25Z97f",
    "outputId": "8f5299ee-b7d6-498c-e8cf-4087daa3dcd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.192962\n",
       "1    0.141110\n",
       "2    0.287587\n",
       "3    0.248447\n",
       "4    0.192987\n",
       "5    0.456147\n",
       "6    0.499946\n",
       "7    0.286641\n",
       "dtype: float32"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "6JdbQjxCZ97f"
   },
   "outputs": [],
   "source": [
    "syn_test = pd.concat([d1],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rlx9mkpWZ97f",
    "outputId": "85bb0514-f443-41b2-b2bb-eb4ce01e5ad5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 8)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugokdDbAZ97g",
    "outputId": "610b63e0-6c51-4644-c1c7-f12331f3cd57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.164533\n",
       "1    0.321246\n",
       "2    0.331171\n",
       "3    0.299163\n",
       "4    0.194953\n",
       "5    0.348831\n",
       "6    0.359857\n",
       "7    0.323809\n",
       "dtype: float32"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "Xwp1ghAhZ97g"
   },
   "outputs": [],
   "source": [
    "# d1.to_csv('vae-wnn-yes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evasion Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(testloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = MODEL(data)\n",
    "        x_hat.append(recon_batch)\n",
    "\n",
    "d1 = pd.DataFrame(np.array(x_hat[0]))\n",
    "eva_test = pd.concat([d1],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "2389 0 611 0\n",
      "0.0\n",
      "1.0\n",
      "0.5\n",
      "Decision Tree\n",
      "2143 246 550 61\n",
      "0.09983633387888707\n",
      "0.8970280452071997\n",
      "0.49843218954304336\n",
      "LGBM Classifier\n",
      "2389 0 611 0\n",
      "0.0\n",
      "1.0\n",
      "0.5\n",
      "XGB Classifier\n",
      "2375 14 609 2\n",
      "0.0032733224222585926\n",
      "0.9941398074508162\n",
      "0.4987065649365374\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../../datasets/Churn_Modelling.csv\"\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "df_base = pd.read_csv(DATA_PATH, sep=',')\n",
    "df_base.head()\n",
    "\n",
    "cols = df_base.columns\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=',')\n",
    "# replace nan with -99\n",
    "y = df['Exited']\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname','Geography',\n",
    "   'Gender','Exited'],axis=1,inplace=True)\n",
    "#df = df.fillna(-99)\n",
    "#df = df.fillna(-99)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data=scaler.fit_transform(df)\n",
    "df1=pd.DataFrame(data)\n",
    "# randomly split\n",
    "X_train, X_test,Y_train,Y_test = train_test_split(df1, y,test_size=0.3, stratify=y, random_state=4)\n",
    "\n",
    "\n",
    "Y_train.reset_index(drop = True);Y_test.reset_index(drop = True)\n",
    "\n",
    "## Models\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "print(\"LOGISTIC REGRESSION\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "preds = lr.predict(eva_test)\n",
    "\n",
    "#roc_auc_score(Y_test,ypred_lr)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "\n",
    "logi = DecisionTreeClassifier()\n",
    "logi.fit(X_train,Y_train)\n",
    "\n",
    "preds =logi.predict(eva_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "\n",
    "print(\"LGBM Classifier\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# parameters = {'n_estimators': [25,50,100,150,175,200]}\n",
    "# parameters = {'criterion' : [\"gini\", \"entropy\"],\n",
    "#               'n_estimators': [25,50,100,150,175,200]}\n",
    "# best_model=None\n",
    "# best_score=0.0\n",
    "\n",
    "# for ne in parameters['n_estimators']:\n",
    "#     gb = LGBMClassifier(n_estimators=ne)\n",
    "#     gb.fit(X_train,Y_train)\n",
    "#     y_predg=gb.predict(X_test)\n",
    "\n",
    "#     accuracy=accuracy_score(Y_test,y_predg)\n",
    "#     auc=roc_auc_score(Y_test,y_predg)\n",
    "#     # print('Combination',c,ne)\n",
    "#     #print('AUC',auc)\n",
    "\n",
    "#     if auc > best_score:\n",
    "#         best_model=gb\n",
    "#        best_score=auc\n",
    "        \n",
    "gb = LGBMClassifier(n_estimators=150)\n",
    "gb.fit(X_train,Y_train)\n",
    "preds=gb.predict(eva_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "\n",
    "\n",
    "print(\"XGB Classifier\")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_model = xgb.fit(X_train,Y_train)\n",
    "preds = xgb_model.predict(eva_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poison Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = MODEL(data)\n",
    "        x_hat.append(recon_batch)\n",
    "\n",
    "d1 = pd.DataFrame(np.array(x_hat[0]))\n",
    "eva_train = pd.concat([d1],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "1528 888 374 210\n",
      "0.3595890410958904\n",
      "0.6324503311258278\n",
      "0.4960196861108591\n",
      "Decision Tree\n",
      "776 1640 234 350\n",
      "0.5993150684931506\n",
      "0.3211920529801324\n",
      "0.46025356073664153\n",
      "LGBM Classifier\n",
      "2263 153 531 53\n",
      "0.09075342465753425\n",
      "0.9366721854304636\n",
      "0.513712805043999\n",
      "XGB Classifier\n",
      "1595 821 374 210\n",
      "0.3595890410958904\n",
      "0.660182119205298\n",
      "0.5098855801505942\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../../datasets/Churn_Modelling.csv\"\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "df_base = pd.read_csv(DATA_PATH, sep=',')\n",
    "df_base.head()\n",
    "\n",
    "cols = df_base.columns\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=',')\n",
    "# replace nan with -99\n",
    "y = df['Exited']\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname','Geography',\n",
    "   'Gender','Exited'],axis=1,inplace=True)\n",
    "#df = df.fillna(-99)\n",
    "#df = df.fillna(-99)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data=scaler.fit_transform(df)\n",
    "df1=pd.DataFrame(data)\n",
    "# randomly split\n",
    "X_train, X_test,Y_train,Y_test = train_test_split(df1, y,test_size=0.3, random_state=4)\n",
    "\n",
    "\n",
    "Y_train.reset_index(drop = True);Y_test.reset_index(drop = True)\n",
    "\n",
    "## Models\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "print(\"LOGISTIC REGRESSION\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(eva_train,Y_train)\n",
    "\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "#roc_auc_score(Y_test,ypred_lr)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "\n",
    "logi = DecisionTreeClassifier()\n",
    "logi.fit(eva_train,Y_train)\n",
    "\n",
    "preds =logi.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "\n",
    "print(\"LGBM Classifier\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# parameters = {'n_estimators': [25,50,100,150,175,200]}\n",
    "# parameters = {'criterion' : [\"gini\", \"entropy\"],\n",
    "#               'n_estimators': [25,50,100,150,175,200]}\n",
    "# best_model=None\n",
    "# best_score=0.0\n",
    "\n",
    "# for ne in parameters['n_estimators']:\n",
    "#     gb = LGBMClassifier(n_estimators=ne)\n",
    "#     gb.fit(X_train,Y_train)\n",
    "#     y_predg=gb.predict(X_test)\n",
    "\n",
    "#     accuracy=accuracy_score(Y_test,y_predg)\n",
    "#     auc=roc_auc_score(Y_test,y_predg)\n",
    "#     # print('Combination',c,ne)\n",
    "#     #print('AUC',auc)\n",
    "\n",
    "#     if auc > best_score:\n",
    "#         best_model=gb\n",
    "#         best_score=auc\n",
    "        \n",
    "gb = LGBMClassifier(n_estimators=150)\n",
    "gb.fit(eva_train,Y_train)\n",
    "preds=gb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "\n",
    "\n",
    "print(\"XGB Classifier\")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_model = xgb.fit(eva_train,Y_train)\n",
    "preds = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9aAzVVbZ97v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbiTHpgpZ97w"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
