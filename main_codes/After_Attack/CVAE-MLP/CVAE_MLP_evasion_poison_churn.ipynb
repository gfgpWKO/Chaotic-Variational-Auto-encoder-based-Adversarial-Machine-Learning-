{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2jDnKenRZ97Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kfy-M5brZ97S"
   },
   "outputs": [],
   "source": [
    "# # data = pd.read_csv(\"D:/Udler downloads/train.csv\")\n",
    "data = pd.read_csv(\"../../../datasets/Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7nnkha-OZ97T",
    "outputId": "850b9ddb-5edb-49c2-88dd-e373380ff525"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB5KTaxPZ97T",
    "outputId": "4a0c859b-3d11-447d-c847-2880f1062e39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          10000\n",
       "CustomerId         10000\n",
       "Surname             2932\n",
       "CreditScore          460\n",
       "Geography              3\n",
       "Gender                 2\n",
       "Age                   70\n",
       "Tenure                11\n",
       "Balance             6382\n",
       "NumOfProducts          4\n",
       "HasCrCard              2\n",
       "IsActiveMember         2\n",
       "EstimatedSalary     9999\n",
       "Exited                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfI0iU4IZ97T",
    "outputId": "4ad4472c-c075-4672-acda-7049475d2c57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "dApTDn4HZ97U"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../../datasets/Churn_Modelling.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FzHCy5z-Z97U"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7-xjb_JrZ97U"
   },
   "outputs": [],
   "source": [
    "def load_and_standardize_data(path):\n",
    "    # read in from csv\n",
    "    df = pd.read_csv(path, sep=',')\n",
    "    # replace nan with -99\n",
    "    # df = df.fillna(-99)\n",
    "    y = df['Exited']\n",
    "    df.drop(['RowNumber', 'CustomerId', 'Surname','Geography',\n",
    "       'Gender','Exited'],axis=1,inplace=True)\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(df,y,stratify = y,test_size = 0.3,random_state = 4)\n",
    "    # df = df.values.reshape(-1, df.shape[1]).astype('float32')\n",
    "    # randomly split\n",
    "\n",
    "    # standardize values\n",
    "#     scaler = preprocessing.StandardScaler()\n",
    "    scaler=preprocessing.MinMaxScaler()\n",
    "    xtrain = scaler.fit_transform(xtrain)\n",
    "    xtest= scaler.transform(xtest)\n",
    "    return xtrain,xtest,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "WYLJY0GHZ97V"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class DataBuilder(Dataset):\n",
    "    def __init__(self, path, train=True):\n",
    "        self.X_train, self.X_test, self.standardizer = load_and_standardize_data(DATA_PATH)\n",
    "        if train:\n",
    "            # self.x = torch.from_numpy(self.X_train)\n",
    "            self.x = torch.FloatTensor(self.X_train)\n",
    "            self.len=self.x.shape[0]\n",
    "        else:\n",
    "            # self.x = torch.from_numpy(self.X_test)\n",
    "            self.x = torch.FloatTensor(self.X_test)\n",
    "            self.len=self.x.shape[0]\n",
    "        del self.X_train\n",
    "        del self.X_test\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XBmJCKNTZ97V"
   },
   "outputs": [],
   "source": [
    "traindata_set=DataBuilder(DATA_PATH, train=True)\n",
    "testdata_set=DataBuilder(DATA_PATH, train=False)\n",
    "\n",
    "trainloader=DataLoader(dataset=traindata_set,batch_size=20000)\n",
    "testloader=DataLoader(dataset=testdata_set,batch_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5N7SNklZ97W",
    "outputId": "c3bb24d7-427e-440f-f5bd-02a9f191c99b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainloader.dataset.x), type(testloader.dataset.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWS4-fodZ97W",
    "outputId": "00af49bc-5cc2-4deb-8423-661e91be3029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7000, 8]), torch.Size([3000, 8]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset.x.shape, testloader.dataset.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seJZe9tOZ97W",
    "outputId": "4dc10e95-e381-43eb-8b8b-3528bcbffefe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8700, 0.2162, 0.9000,  ..., 1.0000, 1.0000, 0.3430],\n",
       "        [0.8600, 0.2568, 1.0000,  ..., 1.0000, 0.0000, 0.6317],\n",
       "        [0.6340, 0.2432, 0.3000,  ..., 1.0000, 1.0000, 0.9344],\n",
       "        ...,\n",
       "        [0.3860, 0.2568, 0.3000,  ..., 1.0000, 1.0000, 0.3946],\n",
       "        [0.4180, 0.3243, 0.7000,  ..., 1.0000, 1.0000, 0.9504],\n",
       "        [0.7880, 0.3378, 1.0000,  ..., 0.0000, 1.0000, 0.1211]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RFxhTMpZ97X",
    "outputId": "100d4db8-2a7a-42c8-f33d-04f8c5a2c019"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7860, 0.2973, 0.8000,  ..., 1.0000, 0.0000, 0.4745],\n",
       "        [0.2760, 0.0541, 0.6000,  ..., 1.0000, 1.0000, 0.3320],\n",
       "        [0.5320, 0.3378, 0.3000,  ..., 1.0000, 0.0000, 0.0938],\n",
       "        ...,\n",
       "        [0.5060, 0.1757, 0.8000,  ..., 1.0000, 1.0000, 0.8498],\n",
       "        [0.5540, 0.3514, 0.6000,  ..., 0.0000, 0.0000, 0.1765],\n",
       "        [0.5280, 0.2432, 0.1000,  ..., 1.0000, 0.0000, 0.7308]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader.dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "aUqz2jxkZ97X"
   },
   "outputs": [],
   "source": [
    "latent_dims = 2\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE2(nn.Module):\n",
    "    def __init__(self,D_in,latent_dim,fn,H=10,H2=15):\n",
    "\n",
    "        #Encoder\n",
    "        super(VAE2,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2=nn.Linear(H,H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "\n",
    "#         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H2, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "#         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "\n",
    "#         # Decoder\n",
    "        self.linear4=nn.Linear(H2,H)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear5=nn.Linear(H,D_in)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=D_in)\n",
    "        self.prev_seed =random.uniform(0,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        \n",
    "        self.fn=fn\n",
    "\n",
    "    def encode(self, x):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            lin1 = self.Tanh(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.Tanh(self.lin_bn2(self.linear2(lin1)))\n",
    "            \n",
    "        if self.fn=='relu':\n",
    "            lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "            \n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin2)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "\n",
    "        return r1, r2\n",
    "\n",
    "    def decode(self, z):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            fc3 = self.Tanh(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.Tanh(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin4 =self.Tanh(self.lin_bn4(self.linear4(fc4)))\n",
    "            #lin5 = self.Tanh(self.lin_bn5(self.linear5(lin4)))\n",
    "        if self.fn=='relu':\n",
    "            fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin4 =self.relu(self.lin_bn4(self.linear4(fc4)))\n",
    "            #lin5 = self.Tanh(self.lin_bn5(self.linear5(lin4)))\n",
    "        \n",
    "        return self.lin_bn5(self.linear5(lin4))\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        mu,sigma = self.encode(x)\n",
    "        prev_seed = self.prev_seed\n",
    "#         print('vae prev_seed',prev_seed)\n",
    "        z,self.prev_seed = reparameterize(mu,sigma,prev_seed)\n",
    "#         print(\"z\",z.shape)\n",
    "#         znew = sampling_vector(z,H)\n",
    "        return self.decode(z),mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE3(nn.Module):\n",
    "    def __init__(self,D_in,latent_dim,fn,H=10,H2=15):\n",
    "\n",
    "        #Encoder\n",
    "        super(VAE3,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2=nn.Linear(H,H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3=nn.Linear(H2,H2)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n",
    "\n",
    "#         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H2, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "#         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "\n",
    "#         # Decoder\n",
    "        self.linear4=nn.Linear(H2,H2)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear5=nn.Linear(H2,H)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear6=nn.Linear(H,D_in)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
    "        self.prev_seed =random.uniform(0,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        \n",
    "        self.fn=fn\n",
    "\n",
    "    def encode(self, x):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            lin1 = self.Tanh(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.Tanh(self.lin_bn2(self.linear2(lin1)))\n",
    "            lin3 = self.Tanh(self.lin_bn3(self.linear3(lin2)))\n",
    "        if self.fn=='relu':\n",
    "            lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "            lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin3)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "\n",
    "        return r1, r2\n",
    "\n",
    "    def decode(self, z):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            fc3 = self.Tanh(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.Tanh(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin4 =self.Tanh(self.lin_bn4(self.linear4(fc4)))\n",
    "            lin5 = self.Tanh(self.lin_bn5(self.linear5(lin4)))\n",
    "        if self.fn=='relu':\n",
    "            fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin4 =self.relu(self.lin_bn4(self.linear4(fc4)))\n",
    "            lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))\n",
    "        \n",
    "        return self.lin_bn6(self.linear6(lin5))\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        mu,sigma = self.encode(x)\n",
    "        prev_seed = self.prev_seed\n",
    "#         print('vae prev_seed',prev_seed)\n",
    "        z,self.prev_seed = reparameterize(mu,sigma,prev_seed)\n",
    "#         print(\"z\",z.shape)\n",
    "#         znew = sampling_vector(z,H)\n",
    "        return self.decode(z),mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE4(nn.Module):\n",
    "    def __init__(self,D_in,latent_dim,fn,H=10,H2=15,H3=20):\n",
    "\n",
    "        #Encoder\n",
    "        super(VAE4,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2=nn.Linear(H,H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3=nn.Linear(H2,H3)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H3)\n",
    "        self.linear4=nn.Linear(H3,H3)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H3)\n",
    "        \n",
    "\n",
    "#         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H3, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "#         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H3)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H3)\n",
    "\n",
    "#         # Decoder\n",
    "        self.linear5=nn.Linear(H3,H3)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H3)\n",
    "        self.linear6=nn.Linear(H3,H2)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear7=nn.Linear(H2,H)\n",
    "        self.lin_bn7 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear8=nn.Linear(H,D_in)\n",
    "        self.lin_bn8 = nn.BatchNorm1d(num_features=D_in)\n",
    "        self.prev_seed =random.uniform(0,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Tanh = nn.Tanh()\n",
    "        \n",
    "        self.fn=fn\n",
    "\n",
    "    def encode(self, x):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            lin1 = self.Tanh(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.Tanh(self.lin_bn2(self.linear2(lin1)))\n",
    "            lin3 = self.Tanh(self.lin_bn3(self.linear3(lin2)))\n",
    "            lin4 = self.Tanh(self.lin_bn4(self.linear4(lin3)))\n",
    "        if self.fn=='relu':\n",
    "            lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "            lin2 =self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "            lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "            lin4 = self.relu(self.lin_bn4(self.linear4(lin3)))\n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin4)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "\n",
    "        return r1, r2\n",
    "\n",
    "    def decode(self, z):\n",
    "        \n",
    "        if self.fn=='tanh':\n",
    "            fc3 = self.Tanh(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.Tanh(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin5 =self.Tanh(self.lin_bn5(self.linear5(fc4)))\n",
    "            lin6 = self.Tanh(self.lin_bn6(self.linear6(lin5)))\n",
    "            lin7 = self.Tanh(self.lin_bn7(self.linear7(lin6)))\n",
    "        if self.fn=='relu':\n",
    "            fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "            fc4 =self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "            lin5 =self.relu(self.lin_bn5(self.linear5(fc4)))\n",
    "            lin6 = self.relu(self.lin_bn6(self.linear6(lin5)))\n",
    "            lin7 = self.relu(self.lin_bn7(self.linear7(lin6)))\n",
    "        \n",
    "        return self.lin_bn8(self.linear8(lin7))\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        mu,sigma = self.encode(x)\n",
    "        prev_seed = self.prev_seed\n",
    "#         print('vae prev_seed',prev_seed)\n",
    "        z,self.prev_seed = reparameterize(mu,sigma,prev_seed)\n",
    "#         print(\"z\",z.shape)\n",
    "#         znew = sampling_vector(z,H)\n",
    "        return self.decode(z),mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_chaotic_distribution(latent_dims,previous_seed):\n",
    "      # Logistic Map\n",
    "#         print(\"latent_dims_cha\",latent_dims[1])\n",
    "        noise=[]\n",
    "        x0=previous_seed\n",
    "#         print(\"prev_seed\",x0)\n",
    "      #print(\"chaotic on cards \")\n",
    "      #print(latent_dims,type(latent_dims))\n",
    "      #print(previous_seed)\n",
    "\n",
    "        for i in range(latent_dims[1]):\n",
    "            x1=(4.0*x0*(1-x0))\n",
    "            x0=x1\n",
    "#             print('x1',x1)\n",
    "        #print(x0,x1)\n",
    "            noise.append(x1)\n",
    "\n",
    "\n",
    "        t_noise=torch.FloatTensor(noise)\n",
    "#         print(\"t_noise\",t_noise)\n",
    "        return t_noise,x0\n",
    "\n",
    "def reparameterize(mu,sigma,prev_seed):\n",
    "        random_seed = 1\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "        std = sigma.mul(0.5).exp_()\n",
    "        eps = Variable(std.data.new(std.size())).normal_()\n",
    "        eps_row = eps.shape[0]\n",
    "        eps_col = eps.shape[1]\n",
    "#         print('eps_row',eps_row,'eps_col',eps_col)\n",
    "        eps = eps.reshape(1,-1)\n",
    "#         print(\"eps shape\",eps.shape)\n",
    "        chaot,prev_seed = get_chaotic_distribution(eps.shape,prev_seed)\n",
    "#         print(\"chaot_shape\",chaot.shape)\n",
    "        chaot = chaot.reshape(eps_row,eps_col)\n",
    "#         print(\"chaot_reshaped\",chaot.shape)\n",
    "#         print(\"reparameter\",eps.mul(std).add_(mu))\n",
    "        return chaot.mul(std).add_(mu),prev_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "vyL5PM2VZ97b"
   },
   "outputs": [],
   "source": [
    "class sampling_vector(nn.Module):\n",
    "    def __init__(self, z,H2):\n",
    "        super().__init__()\n",
    "        self.z = z\n",
    "        self.fc3 = nn.Linear(self.z,H2)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(H2)\n",
    "#         self.fc4 = nn.Linear(latent_dims, H2)\n",
    "#         self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,z):\n",
    "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "        return fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "9CugFxDXZ97c"
   },
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, x_recon, x, mu, logvar):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return loss_MSE + loss_KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print('====> Epoch: {} Average training loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))\n",
    "        \n",
    "def test(epoch):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch_idx, data in enumerate(testloader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch = model(data)\n",
    "            loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "            if epoch % 100 == 0:\n",
    "                print('====> Epoch: {} Average test loss: {:.4f}'.format(\n",
    "                    epoch, test_loss / len(testloader.dataset)))\n",
    "            test_losses.append(test_loss / len(testloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Gdse-DhdZ97c"
   },
   "outputs": [],
   "source": [
    "loss_mse = customLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = trainloader.dataset.x.shape[1]\n",
    "\n",
    "model = VAE2(D_in,2,'relu').to(device)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 100 Average training loss: 6.1700\n",
      "====> Epoch: 200 Average training loss: 4.8804\n",
      "====> Epoch: 300 Average training loss: 4.0591\n",
      "total_time taken is : 54.6328341960907\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "epochs=300\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "#     test(epoch)\n",
    "elapsed_time = time.time()-start\n",
    "print(\"total_time taken is :\",elapsed_time)\n",
    "#     test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.059070870535714\n"
     ]
    }
   ],
   "source": [
    "print(train_losses[len(train_losses)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "global model\n",
    "global optimizer\n",
    "\n",
    "model = VAE2(D_in,2,'relu').to(device)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 100 Average training loss: 5.9166\n",
      "====> Epoch: 200 Average training loss: 4.7501\n",
      "====> Epoch: 300 Average training loss: 3.9874\n",
      "====> Epoch: 400 Average training loss: 3.4448\n",
      "====> Epoch: 500 Average training loss: 3.0195\n",
      "====> Epoch: 600 Average training loss: 2.6879\n",
      "====> Epoch: 700 Average training loss: 2.4348\n",
      "====> Epoch: 800 Average training loss: 2.1997\n",
      "====> Epoch: 900 Average training loss: 2.0237\n",
      "====> Epoch: 1000 Average training loss: 1.8572\n",
      "====> Epoch: 1100 Average training loss: 1.7204\n",
      "====> Epoch: 1200 Average training loss: 1.6014\n",
      "====> Epoch: 1300 Average training loss: 1.5029\n",
      "====> Epoch: 1400 Average training loss: 1.4031\n",
      "====> Epoch: 1500 Average training loss: 1.3280\n",
      "====> Epoch: 1600 Average training loss: 1.2667\n",
      "====> Epoch: 1700 Average training loss: 1.1965\n",
      "====> Epoch: 1800 Average training loss: 1.1325\n",
      "====> Epoch: 100 Average training loss: 5.9155\n",
      "====> Epoch: 200 Average training loss: 4.7100\n",
      "====> Epoch: 300 Average training loss: 3.9408\n",
      "====> Epoch: 400 Average training loss: 3.4176\n",
      "====> Epoch: 500 Average training loss: 3.0075\n",
      "====> Epoch: 600 Average training loss: 2.6851\n",
      "====> Epoch: 700 Average training loss: 2.4203\n",
      "====> Epoch: 800 Average training loss: 2.1941\n",
      "====> Epoch: 900 Average training loss: 2.0249\n",
      "====> Epoch: 1000 Average training loss: 1.8535\n",
      "====> Epoch: 1100 Average training loss: 1.7241\n",
      "====> Epoch: 1200 Average training loss: 1.5996\n",
      "====> Epoch: 1300 Average training loss: 1.4990\n",
      "====> Epoch: 1400 Average training loss: 1.4111\n",
      "====> Epoch: 1500 Average training loss: 1.3285\n",
      "====> Epoch: 1600 Average training loss: 1.2640\n",
      "====> Epoch: 1700 Average training loss: 1.2009\n",
      "====> Epoch: 1800 Average training loss: 1.1459\n",
      "====> Epoch: 100 Average training loss: 5.9116\n",
      "====> Epoch: 200 Average training loss: 4.7394\n",
      "====> Epoch: 300 Average training loss: 3.9555\n",
      "====> Epoch: 400 Average training loss: 3.4276\n",
      "====> Epoch: 500 Average training loss: 3.0229\n",
      "====> Epoch: 600 Average training loss: 2.6920\n",
      "====> Epoch: 700 Average training loss: 2.4301\n",
      "====> Epoch: 800 Average training loss: 2.1934\n",
      "====> Epoch: 900 Average training loss: 2.0106\n",
      "====> Epoch: 1000 Average training loss: 1.8419\n",
      "====> Epoch: 1100 Average training loss: 1.7129\n",
      "====> Epoch: 1200 Average training loss: 1.5977\n",
      "====> Epoch: 1300 Average training loss: 1.4995\n",
      "====> Epoch: 1400 Average training loss: 1.4001\n",
      "====> Epoch: 1500 Average training loss: 1.3200\n",
      "====> Epoch: 1600 Average training loss: 1.2522\n",
      "====> Epoch: 1700 Average training loss: 1.1853\n",
      "====> Epoch: 1800 Average training loss: 1.1203\n",
      "====> Epoch: 100 Average training loss: 5.9220\n",
      "====> Epoch: 200 Average training loss: 4.7540\n",
      "====> Epoch: 300 Average training loss: 4.0021\n",
      "====> Epoch: 400 Average training loss: 3.4645\n",
      "====> Epoch: 500 Average training loss: 3.0264\n",
      "====> Epoch: 600 Average training loss: 2.6884\n",
      "====> Epoch: 700 Average training loss: 2.4172\n",
      "====> Epoch: 800 Average training loss: 2.1682\n",
      "====> Epoch: 900 Average training loss: 1.9404\n",
      "====> Epoch: 1000 Average training loss: 1.6333\n",
      "====> Epoch: 1100 Average training loss: 1.5239\n",
      "====> Epoch: 1200 Average training loss: 1.3330\n",
      "====> Epoch: 1300 Average training loss: 1.2612\n",
      "====> Epoch: 1400 Average training loss: 1.0993\n",
      "====> Epoch: 1500 Average training loss: 1.0697\n",
      "====> Epoch: 1600 Average training loss: 0.8932\n",
      "====> Epoch: 1700 Average training loss: 0.8741\n",
      "====> Epoch: 1800 Average training loss: 0.8412\n",
      "====> Epoch: 100 Average training loss: 5.9353\n",
      "====> Epoch: 200 Average training loss: 4.7362\n",
      "====> Epoch: 300 Average training loss: 3.9674\n",
      "====> Epoch: 400 Average training loss: 3.4324\n",
      "====> Epoch: 500 Average training loss: 3.0437\n",
      "====> Epoch: 600 Average training loss: 2.7029\n",
      "====> Epoch: 700 Average training loss: 2.4264\n",
      "====> Epoch: 800 Average training loss: 2.2080\n",
      "====> Epoch: 900 Average training loss: 2.0185\n",
      "====> Epoch: 1000 Average training loss: 1.8726\n",
      "====> Epoch: 1100 Average training loss: 1.7339\n",
      "====> Epoch: 1200 Average training loss: 1.6128\n",
      "====> Epoch: 1300 Average training loss: 1.2818\n",
      "====> Epoch: 1400 Average training loss: 1.0607\n",
      "====> Epoch: 1500 Average training loss: 0.9048\n",
      "====> Epoch: 1600 Average training loss: 0.8106\n",
      "====> Epoch: 1700 Average training loss: 0.7531\n",
      "====> Epoch: 1800 Average training loss: 0.7060\n",
      "====> Epoch: 100 Average training loss: 5.9365\n",
      "====> Epoch: 200 Average training loss: 4.7494\n",
      "====> Epoch: 300 Average training loss: 4.0246\n",
      "====> Epoch: 400 Average training loss: 3.4959\n",
      "====> Epoch: 500 Average training loss: 3.0643\n",
      "====> Epoch: 600 Average training loss: 2.7302\n",
      "====> Epoch: 700 Average training loss: 2.4634\n",
      "====> Epoch: 800 Average training loss: 2.2440\n",
      "====> Epoch: 900 Average training loss: 2.0490\n",
      "====> Epoch: 1000 Average training loss: 1.8973\n",
      "====> Epoch: 1100 Average training loss: 1.7444\n",
      "====> Epoch: 1200 Average training loss: 1.6220\n",
      "====> Epoch: 1300 Average training loss: 1.5301\n",
      "====> Epoch: 1400 Average training loss: 1.4261\n",
      "====> Epoch: 1500 Average training loss: 1.3427\n",
      "====> Epoch: 1600 Average training loss: 1.2635\n",
      "====> Epoch: 1700 Average training loss: 1.2020\n",
      "====> Epoch: 1800 Average training loss: 1.1169\n",
      "====> Epoch: 100 Average training loss: 5.9267\n",
      "====> Epoch: 200 Average training loss: 4.7457\n",
      "====> Epoch: 300 Average training loss: 3.9609\n",
      "====> Epoch: 400 Average training loss: 3.4306\n",
      "====> Epoch: 500 Average training loss: 3.0252\n",
      "====> Epoch: 600 Average training loss: 2.6782\n",
      "====> Epoch: 700 Average training loss: 2.4336\n",
      "====> Epoch: 800 Average training loss: 2.2116\n",
      "====> Epoch: 900 Average training loss: 2.0161\n",
      "====> Epoch: 1000 Average training loss: 1.8523\n",
      "====> Epoch: 1100 Average training loss: 1.7176\n",
      "====> Epoch: 1200 Average training loss: 1.5953\n",
      "====> Epoch: 1300 Average training loss: 1.4731\n",
      "====> Epoch: 1400 Average training loss: 1.3885\n",
      "====> Epoch: 1500 Average training loss: 1.3011\n",
      "====> Epoch: 1600 Average training loss: 1.2289\n",
      "====> Epoch: 1700 Average training loss: 1.1554\n",
      "====> Epoch: 1800 Average training loss: 1.0894\n",
      "====> Epoch: 100 Average training loss: 5.9309\n",
      "====> Epoch: 200 Average training loss: 4.7652\n",
      "====> Epoch: 300 Average training loss: 3.9972\n",
      "====> Epoch: 400 Average training loss: 3.4654\n",
      "====> Epoch: 500 Average training loss: 3.0671\n",
      "====> Epoch: 600 Average training loss: 2.7110\n",
      "====> Epoch: 700 Average training loss: 2.4610\n",
      "====> Epoch: 800 Average training loss: 2.2352\n",
      "====> Epoch: 900 Average training loss: 2.0288\n",
      "====> Epoch: 1000 Average training loss: 1.8710\n",
      "====> Epoch: 1100 Average training loss: 1.7356\n",
      "====> Epoch: 1200 Average training loss: 1.6153\n",
      "====> Epoch: 1300 Average training loss: 1.5077\n",
      "====> Epoch: 1400 Average training loss: 1.4275\n",
      "====> Epoch: 1500 Average training loss: 1.3244\n",
      "====> Epoch: 1600 Average training loss: 1.2620\n",
      "====> Epoch: 1700 Average training loss: 1.1923\n",
      "====> Epoch: 1800 Average training loss: 1.1386\n",
      "====> Epoch: 100 Average training loss: 5.9462\n",
      "====> Epoch: 200 Average training loss: 4.7527\n",
      "====> Epoch: 300 Average training loss: 3.9984\n",
      "====> Epoch: 400 Average training loss: 3.4477\n",
      "====> Epoch: 500 Average training loss: 3.0416\n",
      "====> Epoch: 600 Average training loss: 2.6949\n",
      "====> Epoch: 700 Average training loss: 2.4283\n",
      "====> Epoch: 800 Average training loss: 2.2078\n",
      "====> Epoch: 900 Average training loss: 2.0162\n",
      "====> Epoch: 1000 Average training loss: 1.8593\n",
      "====> Epoch: 1100 Average training loss: 1.7338\n",
      "====> Epoch: 1200 Average training loss: 1.5993\n",
      "====> Epoch: 1300 Average training loss: 1.5100\n",
      "====> Epoch: 1400 Average training loss: 1.4075\n",
      "====> Epoch: 1500 Average training loss: 1.3380\n",
      "====> Epoch: 1600 Average training loss: 1.2604\n",
      "====> Epoch: 1700 Average training loss: 1.1948\n",
      "====> Epoch: 1800 Average training loss: 1.1401\n",
      "====> Epoch: 100 Average training loss: 5.9146\n",
      "====> Epoch: 200 Average training loss: 4.7555\n",
      "====> Epoch: 300 Average training loss: 4.0028\n",
      "====> Epoch: 400 Average training loss: 3.4740\n",
      "====> Epoch: 500 Average training loss: 3.0546\n",
      "====> Epoch: 600 Average training loss: 2.7267\n",
      "====> Epoch: 700 Average training loss: 2.4763\n",
      "====> Epoch: 800 Average training loss: 2.2605\n",
      "====> Epoch: 900 Average training loss: 2.0567\n",
      "====> Epoch: 1000 Average training loss: 1.8833\n",
      "====> Epoch: 1100 Average training loss: 1.7502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1200 Average training loss: 1.6481\n",
      "====> Epoch: 1300 Average training loss: 1.5296\n",
      "====> Epoch: 1400 Average training loss: 1.4436\n",
      "====> Epoch: 1500 Average training loss: 1.3563\n",
      "====> Epoch: 1600 Average training loss: 1.2694\n",
      "====> Epoch: 1700 Average training loss: 1.1954\n",
      "====> Epoch: 1800 Average training loss: 1.1294\n",
      "====> Epoch: 100 Average training loss: 5.9266\n",
      "====> Epoch: 200 Average training loss: 4.7527\n",
      "====> Epoch: 300 Average training loss: 4.0012\n",
      "====> Epoch: 400 Average training loss: 3.4519\n",
      "====> Epoch: 500 Average training loss: 3.0326\n",
      "====> Epoch: 600 Average training loss: 2.6929\n",
      "====> Epoch: 700 Average training loss: 2.4339\n",
      "====> Epoch: 800 Average training loss: 2.2021\n",
      "====> Epoch: 900 Average training loss: 2.0291\n",
      "====> Epoch: 1000 Average training loss: 1.8663\n",
      "====> Epoch: 1100 Average training loss: 1.7162\n",
      "====> Epoch: 1200 Average training loss: 1.6012\n",
      "====> Epoch: 1300 Average training loss: 1.4897\n",
      "====> Epoch: 1400 Average training loss: 1.4143\n",
      "====> Epoch: 1500 Average training loss: 1.3204\n",
      "====> Epoch: 1600 Average training loss: 1.2641\n",
      "====> Epoch: 1700 Average training loss: 1.1831\n",
      "====> Epoch: 1800 Average training loss: 1.1412\n",
      "====> Epoch: 100 Average training loss: 5.9336\n",
      "====> Epoch: 200 Average training loss: 4.7418\n",
      "====> Epoch: 300 Average training loss: 3.9905\n",
      "====> Epoch: 400 Average training loss: 3.4449\n",
      "====> Epoch: 500 Average training loss: 3.0137\n",
      "====> Epoch: 600 Average training loss: 2.6845\n",
      "====> Epoch: 700 Average training loss: 2.4250\n",
      "====> Epoch: 800 Average training loss: 2.1970\n",
      "====> Epoch: 900 Average training loss: 2.0151\n",
      "====> Epoch: 1000 Average training loss: 1.8508\n",
      "====> Epoch: 1100 Average training loss: 1.7129\n",
      "====> Epoch: 1200 Average training loss: 1.5919\n",
      "====> Epoch: 1300 Average training loss: 1.4870\n",
      "====> Epoch: 1400 Average training loss: 1.3868\n",
      "====> Epoch: 1500 Average training loss: 1.2994\n",
      "====> Epoch: 1600 Average training loss: 1.2398\n",
      "====> Epoch: 1700 Average training loss: 1.1778\n",
      "====> Epoch: 1800 Average training loss: 1.1192\n",
      "====> Epoch: 100 Average training loss: 5.8998\n",
      "====> Epoch: 200 Average training loss: 4.7355\n",
      "====> Epoch: 300 Average training loss: 3.9843\n",
      "====> Epoch: 400 Average training loss: 3.4337\n",
      "====> Epoch: 500 Average training loss: 3.0246\n",
      "====> Epoch: 600 Average training loss: 2.6984\n",
      "====> Epoch: 700 Average training loss: 2.4272\n",
      "====> Epoch: 800 Average training loss: 2.2021\n",
      "====> Epoch: 900 Average training loss: 2.0231\n",
      "====> Epoch: 1000 Average training loss: 1.8573\n",
      "====> Epoch: 1100 Average training loss: 1.7283\n",
      "====> Epoch: 1200 Average training loss: 1.6148\n",
      "====> Epoch: 1300 Average training loss: 1.4890\n",
      "====> Epoch: 1400 Average training loss: 1.4009\n",
      "====> Epoch: 1500 Average training loss: 1.3139\n",
      "====> Epoch: 1600 Average training loss: 1.2460\n",
      "====> Epoch: 1700 Average training loss: 1.1777\n",
      "====> Epoch: 1800 Average training loss: 1.1162\n",
      "====> Epoch: 100 Average training loss: 5.9205\n",
      "====> Epoch: 200 Average training loss: 4.7384\n",
      "====> Epoch: 300 Average training loss: 3.9922\n",
      "====> Epoch: 400 Average training loss: 3.4480\n",
      "====> Epoch: 500 Average training loss: 3.0358\n",
      "====> Epoch: 600 Average training loss: 2.7304\n",
      "====> Epoch: 700 Average training loss: 2.4441\n",
      "====> Epoch: 800 Average training loss: 2.2199\n",
      "====> Epoch: 900 Average training loss: 2.0306\n",
      "====> Epoch: 1000 Average training loss: 1.8830\n",
      "====> Epoch: 1100 Average training loss: 1.7384\n",
      "====> Epoch: 1200 Average training loss: 1.6033\n",
      "====> Epoch: 1300 Average training loss: 1.5114\n",
      "====> Epoch: 1400 Average training loss: 1.4146\n",
      "====> Epoch: 1500 Average training loss: 1.3425\n",
      "====> Epoch: 1600 Average training loss: 1.2687\n",
      "====> Epoch: 1700 Average training loss: 1.2219\n",
      "====> Epoch: 1800 Average training loss: 1.1592\n",
      "====> Epoch: 100 Average training loss: 5.9420\n",
      "====> Epoch: 200 Average training loss: 4.7387\n",
      "====> Epoch: 300 Average training loss: 3.9936\n",
      "====> Epoch: 400 Average training loss: 3.4477\n",
      "====> Epoch: 500 Average training loss: 3.0336\n",
      "====> Epoch: 600 Average training loss: 2.7137\n",
      "====> Epoch: 700 Average training loss: 2.4246\n",
      "====> Epoch: 800 Average training loss: 2.2094\n",
      "====> Epoch: 900 Average training loss: 2.0263\n",
      "====> Epoch: 1000 Average training loss: 1.8589\n",
      "====> Epoch: 1100 Average training loss: 1.7251\n",
      "====> Epoch: 1200 Average training loss: 1.6111\n",
      "====> Epoch: 1300 Average training loss: 1.4970\n",
      "====> Epoch: 1400 Average training loss: 1.4097\n",
      "====> Epoch: 1500 Average training loss: 1.3139\n",
      "====> Epoch: 1600 Average training loss: 1.2426\n",
      "====> Epoch: 1700 Average training loss: 1.1605\n",
      "====> Epoch: 1800 Average training loss: 1.1030\n",
      "====> Epoch: 100 Average training loss: 5.9406\n",
      "====> Epoch: 200 Average training loss: 4.7524\n",
      "====> Epoch: 300 Average training loss: 4.0132\n",
      "====> Epoch: 400 Average training loss: 3.4709\n",
      "====> Epoch: 500 Average training loss: 3.0691\n",
      "====> Epoch: 600 Average training loss: 2.7381\n",
      "====> Epoch: 700 Average training loss: 2.4667\n",
      "====> Epoch: 800 Average training loss: 2.2314\n",
      "====> Epoch: 900 Average training loss: 2.0531\n",
      "====> Epoch: 1000 Average training loss: 1.8812\n",
      "====> Epoch: 1100 Average training loss: 1.7476\n",
      "====> Epoch: 1200 Average training loss: 1.6201\n",
      "====> Epoch: 1300 Average training loss: 1.5126\n",
      "====> Epoch: 1400 Average training loss: 1.4325\n",
      "====> Epoch: 1500 Average training loss: 1.3312\n",
      "====> Epoch: 1600 Average training loss: 1.2712\n",
      "====> Epoch: 1700 Average training loss: 1.2042\n",
      "====> Epoch: 1800 Average training loss: 1.1484\n",
      "====> Epoch: 100 Average training loss: 5.9158\n",
      "====> Epoch: 200 Average training loss: 4.7358\n",
      "====> Epoch: 300 Average training loss: 3.9646\n",
      "====> Epoch: 400 Average training loss: 3.4441\n",
      "====> Epoch: 500 Average training loss: 3.0216\n",
      "====> Epoch: 600 Average training loss: 2.7022\n",
      "====> Epoch: 700 Average training loss: 2.4298\n",
      "====> Epoch: 800 Average training loss: 2.1939\n",
      "====> Epoch: 900 Average training loss: 2.0200\n",
      "====> Epoch: 1000 Average training loss: 1.8502\n",
      "====> Epoch: 1100 Average training loss: 1.7144\n",
      "====> Epoch: 1200 Average training loss: 1.5980\n",
      "====> Epoch: 1300 Average training loss: 1.5098\n",
      "====> Epoch: 1400 Average training loss: 1.3948\n",
      "====> Epoch: 1500 Average training loss: 1.3043\n",
      "====> Epoch: 1600 Average training loss: 1.2374\n",
      "====> Epoch: 1700 Average training loss: 1.1665\n",
      "====> Epoch: 1800 Average training loss: 1.1220\n",
      "====> Epoch: 100 Average training loss: 5.9199\n",
      "====> Epoch: 200 Average training loss: 4.7401\n",
      "====> Epoch: 300 Average training loss: 3.9751\n",
      "====> Epoch: 400 Average training loss: 3.4289\n",
      "====> Epoch: 500 Average training loss: 3.0195\n",
      "====> Epoch: 600 Average training loss: 2.6898\n",
      "====> Epoch: 700 Average training loss: 2.4187\n",
      "====> Epoch: 800 Average training loss: 2.0594\n",
      "====> Epoch: 900 Average training loss: 1.6736\n",
      "====> Epoch: 1000 Average training loss: 1.4564\n",
      "====> Epoch: 1100 Average training loss: 1.2694\n",
      "====> Epoch: 1200 Average training loss: 1.1224\n",
      "====> Epoch: 1300 Average training loss: 0.9637\n",
      "====> Epoch: 1400 Average training loss: 0.8838\n",
      "====> Epoch: 1500 Average training loss: 0.8141\n",
      "====> Epoch: 1600 Average training loss: 0.7594\n",
      "====> Epoch: 1700 Average training loss: 0.7110\n",
      "====> Epoch: 1800 Average training loss: 0.6674\n",
      "====> Epoch: 100 Average training loss: 5.9171\n",
      "====> Epoch: 200 Average training loss: 4.7358\n",
      "====> Epoch: 300 Average training loss: 3.9854\n",
      "====> Epoch: 400 Average training loss: 3.4611\n",
      "====> Epoch: 500 Average training loss: 3.0437\n",
      "====> Epoch: 600 Average training loss: 2.7093\n",
      "====> Epoch: 700 Average training loss: 2.4415\n",
      "====> Epoch: 800 Average training loss: 2.2263\n",
      "====> Epoch: 900 Average training loss: 2.0383\n",
      "====> Epoch: 1000 Average training loss: 1.8941\n",
      "====> Epoch: 1100 Average training loss: 1.7451\n",
      "====> Epoch: 1200 Average training loss: 1.6349\n",
      "====> Epoch: 1300 Average training loss: 1.5329\n",
      "====> Epoch: 1400 Average training loss: 1.4364\n",
      "====> Epoch: 1500 Average training loss: 1.3548\n",
      "====> Epoch: 1600 Average training loss: 1.2872\n",
      "====> Epoch: 1700 Average training loss: 1.2255\n",
      "====> Epoch: 1800 Average training loss: 1.1666\n",
      "====> Epoch: 100 Average training loss: 5.9170\n",
      "====> Epoch: 200 Average training loss: 4.7340\n",
      "====> Epoch: 300 Average training loss: 3.9629\n",
      "====> Epoch: 400 Average training loss: 3.4192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 500 Average training loss: 3.0219\n",
      "====> Epoch: 600 Average training loss: 2.6949\n",
      "====> Epoch: 700 Average training loss: 2.4322\n",
      "====> Epoch: 800 Average training loss: 2.1958\n",
      "====> Epoch: 900 Average training loss: 1.9960\n",
      "====> Epoch: 1000 Average training loss: 1.8475\n",
      "====> Epoch: 1100 Average training loss: 1.6872\n",
      "====> Epoch: 1200 Average training loss: 1.5855\n",
      "====> Epoch: 1300 Average training loss: 1.4511\n",
      "====> Epoch: 1400 Average training loss: 1.3860\n",
      "====> Epoch: 1500 Average training loss: 1.3101\n",
      "====> Epoch: 1600 Average training loss: 1.2797\n",
      "====> Epoch: 1700 Average training loss: 1.1790\n",
      "====> Epoch: 1800 Average training loss: 1.1378\n",
      "====> Epoch: 100 Average training loss: 5.9274\n",
      "====> Epoch: 200 Average training loss: 4.7452\n",
      "====> Epoch: 300 Average training loss: 4.0150\n",
      "====> Epoch: 400 Average training loss: 3.4592\n",
      "====> Epoch: 500 Average training loss: 3.0639\n",
      "====> Epoch: 600 Average training loss: 2.7290\n",
      "====> Epoch: 700 Average training loss: 2.4712\n",
      "====> Epoch: 800 Average training loss: 2.2580\n",
      "====> Epoch: 900 Average training loss: 2.0530\n",
      "====> Epoch: 1000 Average training loss: 1.8948\n",
      "====> Epoch: 1100 Average training loss: 1.7538\n",
      "====> Epoch: 1200 Average training loss: 1.6247\n",
      "====> Epoch: 1300 Average training loss: 1.5083\n",
      "====> Epoch: 1400 Average training loss: 1.4094\n",
      "====> Epoch: 1500 Average training loss: 1.3258\n",
      "====> Epoch: 1600 Average training loss: 1.2548\n",
      "====> Epoch: 1700 Average training loss: 1.1862\n",
      "====> Epoch: 1800 Average training loss: 1.1258\n",
      "====> Epoch: 100 Average training loss: 5.9103\n",
      "====> Epoch: 200 Average training loss: 4.7233\n",
      "====> Epoch: 300 Average training loss: 3.9478\n",
      "====> Epoch: 400 Average training loss: 3.4179\n",
      "====> Epoch: 500 Average training loss: 3.0082\n",
      "====> Epoch: 600 Average training loss: 2.6667\n",
      "====> Epoch: 700 Average training loss: 2.4082\n",
      "====> Epoch: 800 Average training loss: 2.1785\n",
      "====> Epoch: 900 Average training loss: 1.9916\n",
      "====> Epoch: 1000 Average training loss: 1.8271\n",
      "====> Epoch: 1100 Average training loss: 1.6960\n",
      "====> Epoch: 1200 Average training loss: 1.5701\n",
      "====> Epoch: 1300 Average training loss: 1.4643\n",
      "====> Epoch: 1400 Average training loss: 1.3788\n",
      "====> Epoch: 1500 Average training loss: 1.3053\n",
      "====> Epoch: 1600 Average training loss: 1.2300\n",
      "====> Epoch: 1700 Average training loss: 1.1585\n",
      "====> Epoch: 1800 Average training loss: 1.1096\n",
      "====> Epoch: 100 Average training loss: 5.9305\n",
      "====> Epoch: 200 Average training loss: 4.7227\n",
      "====> Epoch: 300 Average training loss: 3.9721\n",
      "====> Epoch: 400 Average training loss: 3.4080\n",
      "====> Epoch: 500 Average training loss: 3.0007\n",
      "====> Epoch: 600 Average training loss: 2.6793\n",
      "====> Epoch: 700 Average training loss: 2.4075\n",
      "====> Epoch: 800 Average training loss: 2.1808\n",
      "====> Epoch: 900 Average training loss: 1.9914\n",
      "====> Epoch: 1000 Average training loss: 1.8418\n",
      "====> Epoch: 1100 Average training loss: 1.7005\n",
      "====> Epoch: 1200 Average training loss: 1.5868\n",
      "====> Epoch: 1300 Average training loss: 1.4833\n",
      "====> Epoch: 1400 Average training loss: 1.3885\n",
      "====> Epoch: 1500 Average training loss: 1.3112\n",
      "====> Epoch: 1600 Average training loss: 1.2366\n",
      "====> Epoch: 1700 Average training loss: 1.1749\n",
      "====> Epoch: 1800 Average training loss: 1.1136\n",
      "====> Epoch: 100 Average training loss: 5.9327\n",
      "====> Epoch: 200 Average training loss: 4.7611\n",
      "====> Epoch: 300 Average training loss: 3.9958\n",
      "====> Epoch: 400 Average training loss: 3.4537\n",
      "====> Epoch: 500 Average training loss: 3.0278\n",
      "====> Epoch: 600 Average training loss: 2.7028\n",
      "====> Epoch: 700 Average training loss: 2.4452\n",
      "====> Epoch: 800 Average training loss: 2.2312\n",
      "====> Epoch: 900 Average training loss: 2.0380\n",
      "====> Epoch: 1000 Average training loss: 1.8804\n",
      "====> Epoch: 1100 Average training loss: 1.7403\n",
      "====> Epoch: 1200 Average training loss: 1.6175\n",
      "====> Epoch: 1300 Average training loss: 1.5146\n",
      "====> Epoch: 1400 Average training loss: 1.4325\n",
      "====> Epoch: 1500 Average training loss: 1.3377\n",
      "====> Epoch: 1600 Average training loss: 1.2625\n",
      "====> Epoch: 1700 Average training loss: 1.2117\n",
      "====> Epoch: 1800 Average training loss: 1.1473\n",
      "====> Epoch: 100 Average training loss: 5.9158\n",
      "====> Epoch: 200 Average training loss: 4.7311\n",
      "====> Epoch: 300 Average training loss: 3.9541\n",
      "====> Epoch: 400 Average training loss: 3.4050\n",
      "====> Epoch: 500 Average training loss: 3.0106\n",
      "====> Epoch: 600 Average training loss: 2.6967\n",
      "====> Epoch: 700 Average training loss: 2.4386\n",
      "====> Epoch: 800 Average training loss: 2.2209\n",
      "====> Epoch: 900 Average training loss: 2.0376\n",
      "====> Epoch: 1000 Average training loss: 1.8708\n",
      "====> Epoch: 1100 Average training loss: 1.7351\n",
      "====> Epoch: 1200 Average training loss: 1.6171\n",
      "====> Epoch: 1300 Average training loss: 1.5149\n",
      "====> Epoch: 1400 Average training loss: 1.4178\n",
      "====> Epoch: 1500 Average training loss: 1.3447\n",
      "====> Epoch: 1600 Average training loss: 1.2579\n",
      "====> Epoch: 1700 Average training loss: 1.2056\n",
      "====> Epoch: 1800 Average training loss: 1.1474\n",
      "====> Epoch: 100 Average training loss: 5.9064\n",
      "====> Epoch: 200 Average training loss: 4.7394\n",
      "====> Epoch: 300 Average training loss: 3.9859\n",
      "====> Epoch: 400 Average training loss: 3.4523\n",
      "====> Epoch: 500 Average training loss: 3.0208\n",
      "====> Epoch: 600 Average training loss: 2.7006\n",
      "====> Epoch: 700 Average training loss: 2.4388\n",
      "====> Epoch: 800 Average training loss: 2.2141\n",
      "====> Epoch: 900 Average training loss: 2.0323\n",
      "====> Epoch: 1000 Average training loss: 1.8689\n",
      "====> Epoch: 1100 Average training loss: 1.7347\n",
      "====> Epoch: 1200 Average training loss: 1.6141\n",
      "====> Epoch: 1300 Average training loss: 1.5176\n",
      "====> Epoch: 1400 Average training loss: 1.4214\n",
      "====> Epoch: 1500 Average training loss: 1.3565\n",
      "====> Epoch: 1600 Average training loss: 1.2664\n",
      "====> Epoch: 1700 Average training loss: 1.2021\n",
      "====> Epoch: 1800 Average training loss: 1.1536\n",
      "====> Epoch: 100 Average training loss: 5.9233\n",
      "====> Epoch: 200 Average training loss: 4.7287\n",
      "====> Epoch: 300 Average training loss: 3.9832\n",
      "====> Epoch: 400 Average training loss: 3.4603\n",
      "====> Epoch: 500 Average training loss: 3.0380\n",
      "====> Epoch: 600 Average training loss: 2.7221\n",
      "====> Epoch: 700 Average training loss: 2.4473\n",
      "====> Epoch: 800 Average training loss: 2.2262\n",
      "====> Epoch: 900 Average training loss: 2.0341\n",
      "====> Epoch: 1000 Average training loss: 1.8806\n",
      "====> Epoch: 1100 Average training loss: 1.7279\n",
      "====> Epoch: 1200 Average training loss: 1.6219\n",
      "====> Epoch: 1300 Average training loss: 1.5166\n",
      "====> Epoch: 1400 Average training loss: 1.4227\n",
      "====> Epoch: 1500 Average training loss: 1.3435\n",
      "====> Epoch: 1600 Average training loss: 1.2716\n",
      "====> Epoch: 1700 Average training loss: 1.2080\n",
      "====> Epoch: 1800 Average training loss: 1.1507\n",
      "====> Epoch: 100 Average training loss: 5.9092\n",
      "====> Epoch: 200 Average training loss: 4.7432\n",
      "====> Epoch: 300 Average training loss: 3.9776\n",
      "====> Epoch: 400 Average training loss: 3.4367\n",
      "====> Epoch: 500 Average training loss: 2.9988\n",
      "====> Epoch: 600 Average training loss: 2.6656\n",
      "====> Epoch: 700 Average training loss: 2.3908\n",
      "====> Epoch: 800 Average training loss: 2.1792\n",
      "====> Epoch: 900 Average training loss: 1.9963\n",
      "====> Epoch: 1000 Average training loss: 1.8277\n",
      "====> Epoch: 1100 Average training loss: 1.7008\n",
      "====> Epoch: 1200 Average training loss: 1.5777\n",
      "====> Epoch: 1300 Average training loss: 1.4748\n",
      "====> Epoch: 1400 Average training loss: 1.3825\n",
      "====> Epoch: 1500 Average training loss: 1.3047\n",
      "====> Epoch: 1600 Average training loss: 1.2390\n",
      "====> Epoch: 1700 Average training loss: 1.1782\n",
      "====> Epoch: 1800 Average training loss: 1.1088\n",
      "====> Epoch: 100 Average training loss: 5.9366\n",
      "====> Epoch: 200 Average training loss: 4.7715\n",
      "====> Epoch: 300 Average training loss: 3.9816\n",
      "====> Epoch: 400 Average training loss: 3.4598\n",
      "====> Epoch: 500 Average training loss: 3.0571\n",
      "====> Epoch: 600 Average training loss: 2.7154\n",
      "====> Epoch: 700 Average training loss: 2.4573\n",
      "====> Epoch: 800 Average training loss: 2.2420\n",
      "====> Epoch: 900 Average training loss: 2.0336\n",
      "====> Epoch: 1000 Average training loss: 1.8717\n",
      "====> Epoch: 1100 Average training loss: 1.7300\n",
      "====> Epoch: 1200 Average training loss: 1.6159\n",
      "====> Epoch: 1300 Average training loss: 1.4999\n",
      "====> Epoch: 1400 Average training loss: 1.3946\n",
      "====> Epoch: 1500 Average training loss: 1.3231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1600 Average training loss: 1.2478\n",
      "====> Epoch: 1700 Average training loss: 1.1846\n",
      "====> Epoch: 1800 Average training loss: 1.1269\n",
      "====> Epoch: 100 Average training loss: 5.9197\n",
      "====> Epoch: 200 Average training loss: 4.7473\n",
      "====> Epoch: 300 Average training loss: 3.9889\n",
      "====> Epoch: 400 Average training loss: 3.4243\n",
      "====> Epoch: 500 Average training loss: 3.0121\n",
      "====> Epoch: 600 Average training loss: 2.6861\n",
      "====> Epoch: 700 Average training loss: 2.4304\n",
      "====> Epoch: 800 Average training loss: 2.2011\n",
      "====> Epoch: 900 Average training loss: 2.0126\n",
      "====> Epoch: 1000 Average training loss: 1.8666\n",
      "====> Epoch: 1100 Average training loss: 1.7060\n",
      "====> Epoch: 1200 Average training loss: 1.5955\n",
      "====> Epoch: 1300 Average training loss: 1.4976\n",
      "====> Epoch: 1400 Average training loss: 1.3981\n",
      "====> Epoch: 1500 Average training loss: 1.3310\n",
      "====> Epoch: 1600 Average training loss: 1.2542\n",
      "====> Epoch: 1700 Average training loss: 1.1873\n",
      "====> Epoch: 1800 Average training loss: 1.1424\n",
      "====> Epoch: 100 Average training loss: 5.9231\n",
      "====> Epoch: 200 Average training loss: 4.7421\n",
      "====> Epoch: 300 Average training loss: 3.9825\n",
      "====> Epoch: 400 Average training loss: 3.4424\n",
      "====> Epoch: 500 Average training loss: 3.0206\n",
      "====> Epoch: 600 Average training loss: 2.6846\n",
      "====> Epoch: 700 Average training loss: 2.4382\n",
      "====> Epoch: 800 Average training loss: 2.2042\n",
      "====> Epoch: 900 Average training loss: 2.0263\n",
      "====> Epoch: 1000 Average training loss: 1.8622\n",
      "====> Epoch: 1100 Average training loss: 1.7325\n",
      "====> Epoch: 1200 Average training loss: 1.5930\n",
      "====> Epoch: 1300 Average training loss: 1.4878\n",
      "====> Epoch: 1400 Average training loss: 1.4100\n",
      "====> Epoch: 1500 Average training loss: 1.3263\n",
      "====> Epoch: 1600 Average training loss: 1.2478\n",
      "====> Epoch: 1700 Average training loss: 1.1851\n",
      "====> Epoch: 1800 Average training loss: 1.1337\n",
      "====> Epoch: 100 Average training loss: 5.9440\n",
      "====> Epoch: 200 Average training loss: 4.7183\n",
      "====> Epoch: 300 Average training loss: 3.9548\n",
      "====> Epoch: 400 Average training loss: 3.4236\n",
      "====> Epoch: 500 Average training loss: 3.0346\n",
      "====> Epoch: 600 Average training loss: 2.6906\n",
      "====> Epoch: 700 Average training loss: 2.4317\n",
      "====> Epoch: 800 Average training loss: 2.2139\n",
      "====> Epoch: 900 Average training loss: 2.0201\n",
      "====> Epoch: 1000 Average training loss: 1.8535\n",
      "====> Epoch: 1100 Average training loss: 1.7273\n",
      "====> Epoch: 1200 Average training loss: 1.6074\n",
      "====> Epoch: 1300 Average training loss: 1.5070\n",
      "====> Epoch: 1400 Average training loss: 1.4123\n",
      "====> Epoch: 1500 Average training loss: 1.3368\n",
      "====> Epoch: 1600 Average training loss: 1.2629\n",
      "====> Epoch: 1700 Average training loss: 1.1923\n",
      "====> Epoch: 1800 Average training loss: 1.1535\n",
      "====> Epoch: 100 Average training loss: 5.9422\n",
      "====> Epoch: 200 Average training loss: 4.7315\n",
      "====> Epoch: 300 Average training loss: 3.9693\n",
      "====> Epoch: 400 Average training loss: 3.4107\n",
      "====> Epoch: 500 Average training loss: 3.0077\n",
      "====> Epoch: 600 Average training loss: 2.6891\n",
      "====> Epoch: 700 Average training loss: 2.4152\n",
      "====> Epoch: 800 Average training loss: 2.1911\n",
      "====> Epoch: 900 Average training loss: 2.0062\n",
      "====> Epoch: 1000 Average training loss: 1.8455\n",
      "====> Epoch: 1100 Average training loss: 1.7164\n",
      "====> Epoch: 1200 Average training loss: 1.5906\n",
      "====> Epoch: 1300 Average training loss: 1.4954\n",
      "====> Epoch: 1400 Average training loss: 1.3965\n",
      "====> Epoch: 1500 Average training loss: 1.3251\n",
      "====> Epoch: 1600 Average training loss: 1.2458\n",
      "====> Epoch: 1700 Average training loss: 1.1919\n",
      "====> Epoch: 1800 Average training loss: 1.1268\n",
      "====> Epoch: 100 Average training loss: 5.9181\n",
      "====> Epoch: 200 Average training loss: 4.7434\n",
      "====> Epoch: 300 Average training loss: 3.9881\n",
      "====> Epoch: 400 Average training loss: 3.4506\n",
      "====> Epoch: 500 Average training loss: 3.0376\n",
      "====> Epoch: 600 Average training loss: 2.7062\n",
      "====> Epoch: 700 Average training loss: 2.4478\n",
      "====> Epoch: 800 Average training loss: 2.2228\n",
      "====> Epoch: 900 Average training loss: 2.0265\n",
      "====> Epoch: 1000 Average training loss: 1.8578\n",
      "====> Epoch: 1100 Average training loss: 1.7232\n",
      "====> Epoch: 1200 Average training loss: 1.6076\n",
      "====> Epoch: 1300 Average training loss: 1.5029\n",
      "====> Epoch: 1400 Average training loss: 1.4074\n",
      "====> Epoch: 1500 Average training loss: 1.3255\n",
      "====> Epoch: 1600 Average training loss: 1.2521\n",
      "====> Epoch: 1700 Average training loss: 1.1970\n",
      "====> Epoch: 1800 Average training loss: 1.1353\n",
      "====> Epoch: 100 Average training loss: 5.9391\n",
      "====> Epoch: 200 Average training loss: 4.7275\n",
      "====> Epoch: 300 Average training loss: 3.9691\n",
      "====> Epoch: 400 Average training loss: 3.4196\n",
      "====> Epoch: 500 Average training loss: 3.0068\n",
      "====> Epoch: 600 Average training loss: 2.6685\n",
      "====> Epoch: 700 Average training loss: 2.4016\n",
      "====> Epoch: 800 Average training loss: 2.1790\n",
      "====> Epoch: 900 Average training loss: 1.9954\n",
      "====> Epoch: 1000 Average training loss: 1.8304\n",
      "====> Epoch: 1100 Average training loss: 1.6923\n",
      "====> Epoch: 1200 Average training loss: 1.5770\n",
      "====> Epoch: 1300 Average training loss: 1.4711\n",
      "====> Epoch: 1400 Average training loss: 1.3779\n",
      "====> Epoch: 1500 Average training loss: 1.3009\n",
      "====> Epoch: 1600 Average training loss: 1.2291\n",
      "====> Epoch: 1700 Average training loss: 1.1694\n",
      "====> Epoch: 1800 Average training loss: 1.1054\n",
      "====> Epoch: 100 Average training loss: 5.9218\n",
      "====> Epoch: 200 Average training loss: 4.7733\n",
      "====> Epoch: 300 Average training loss: 4.0152\n",
      "====> Epoch: 400 Average training loss: 3.4504\n",
      "====> Epoch: 500 Average training loss: 3.0340\n",
      "====> Epoch: 600 Average training loss: 2.7121\n",
      "====> Epoch: 700 Average training loss: 2.4538\n",
      "====> Epoch: 800 Average training loss: 2.2279\n",
      "====> Epoch: 900 Average training loss: 2.0494\n",
      "====> Epoch: 1000 Average training loss: 1.8614\n",
      "====> Epoch: 1100 Average training loss: 1.7235\n",
      "====> Epoch: 1200 Average training loss: 1.6155\n",
      "====> Epoch: 1300 Average training loss: 1.5007\n",
      "====> Epoch: 1400 Average training loss: 1.4099\n",
      "====> Epoch: 1500 Average training loss: 1.3292\n",
      "====> Epoch: 1600 Average training loss: 1.2645\n",
      "====> Epoch: 1700 Average training loss: 1.2049\n",
      "====> Epoch: 1800 Average training loss: 1.1394\n",
      "====> Epoch: 100 Average training loss: 5.9232\n",
      "====> Epoch: 200 Average training loss: 4.7396\n",
      "====> Epoch: 300 Average training loss: 3.9701\n",
      "====> Epoch: 400 Average training loss: 3.4366\n",
      "====> Epoch: 500 Average training loss: 3.0114\n",
      "====> Epoch: 600 Average training loss: 2.6770\n",
      "====> Epoch: 700 Average training loss: 2.4162\n",
      "====> Epoch: 800 Average training loss: 2.1821\n",
      "====> Epoch: 900 Average training loss: 1.9989\n",
      "====> Epoch: 1000 Average training loss: 1.8367\n",
      "====> Epoch: 1100 Average training loss: 1.7098\n",
      "====> Epoch: 1200 Average training loss: 1.5881\n",
      "====> Epoch: 1300 Average training loss: 1.4797\n",
      "====> Epoch: 1400 Average training loss: 1.3440\n",
      "====> Epoch: 1500 Average training loss: 1.0971\n",
      "====> Epoch: 1600 Average training loss: 0.9355\n",
      "====> Epoch: 1700 Average training loss: 0.7840\n",
      "====> Epoch: 1800 Average training loss: 0.6953\n",
      "====> Epoch: 100 Average training loss: 5.9241\n",
      "====> Epoch: 200 Average training loss: 4.7391\n",
      "====> Epoch: 300 Average training loss: 3.9874\n",
      "====> Epoch: 400 Average training loss: 3.4653\n",
      "====> Epoch: 500 Average training loss: 3.0482\n",
      "====> Epoch: 600 Average training loss: 2.7184\n",
      "====> Epoch: 700 Average training loss: 2.4444\n",
      "====> Epoch: 800 Average training loss: 2.2198\n",
      "====> Epoch: 900 Average training loss: 2.0337\n",
      "====> Epoch: 1000 Average training loss: 1.8805\n",
      "====> Epoch: 1100 Average training loss: 1.7416\n",
      "====> Epoch: 1200 Average training loss: 1.6269\n",
      "====> Epoch: 1300 Average training loss: 1.5122\n",
      "====> Epoch: 1400 Average training loss: 1.4193\n",
      "====> Epoch: 1500 Average training loss: 1.3370\n",
      "====> Epoch: 1600 Average training loss: 1.2710\n",
      "====> Epoch: 1700 Average training loss: 1.1923\n",
      "====> Epoch: 1800 Average training loss: 1.1528\n",
      "====> Epoch: 100 Average training loss: 5.9182\n",
      "====> Epoch: 200 Average training loss: 4.7396\n",
      "====> Epoch: 300 Average training loss: 3.9762\n",
      "====> Epoch: 400 Average training loss: 3.4296\n",
      "====> Epoch: 500 Average training loss: 3.0207\n",
      "====> Epoch: 600 Average training loss: 2.6904\n",
      "====> Epoch: 700 Average training loss: 2.4112\n",
      "====> Epoch: 800 Average training loss: 2.1932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 900 Average training loss: 1.9946\n",
      "====> Epoch: 1000 Average training loss: 1.8344\n",
      "====> Epoch: 1100 Average training loss: 1.7095\n",
      "====> Epoch: 1200 Average training loss: 1.5832\n",
      "====> Epoch: 1300 Average training loss: 1.4841\n",
      "====> Epoch: 1400 Average training loss: 1.3844\n",
      "====> Epoch: 1500 Average training loss: 1.3157\n",
      "====> Epoch: 1600 Average training loss: 1.2385\n",
      "====> Epoch: 1700 Average training loss: 1.1729\n",
      "====> Epoch: 1800 Average training loss: 1.1226\n",
      "====> Epoch: 100 Average training loss: 5.9251\n",
      "====> Epoch: 200 Average training loss: 4.7444\n",
      "====> Epoch: 300 Average training loss: 4.0104\n",
      "====> Epoch: 400 Average training loss: 3.4604\n",
      "====> Epoch: 500 Average training loss: 3.0487\n",
      "====> Epoch: 600 Average training loss: 2.7098\n",
      "====> Epoch: 700 Average training loss: 2.4503\n",
      "====> Epoch: 800 Average training loss: 2.2211\n",
      "====> Epoch: 900 Average training loss: 2.0337\n",
      "====> Epoch: 1000 Average training loss: 1.8690\n",
      "====> Epoch: 1100 Average training loss: 1.7346\n",
      "====> Epoch: 1200 Average training loss: 1.6177\n",
      "====> Epoch: 1300 Average training loss: 1.5054\n",
      "====> Epoch: 1400 Average training loss: 1.4077\n",
      "====> Epoch: 1500 Average training loss: 1.3246\n",
      "====> Epoch: 1600 Average training loss: 1.2457\n",
      "====> Epoch: 1700 Average training loss: 1.1843\n",
      "====> Epoch: 1800 Average training loss: 1.1228\n",
      "====> Epoch: 100 Average training loss: 5.9266\n",
      "====> Epoch: 200 Average training loss: 4.7432\n",
      "====> Epoch: 300 Average training loss: 3.9923\n",
      "====> Epoch: 400 Average training loss: 3.4419\n",
      "====> Epoch: 500 Average training loss: 3.0387\n",
      "====> Epoch: 600 Average training loss: 2.7065\n",
      "====> Epoch: 700 Average training loss: 2.4396\n",
      "====> Epoch: 800 Average training loss: 2.2347\n",
      "====> Epoch: 900 Average training loss: 2.0240\n",
      "====> Epoch: 1000 Average training loss: 1.8697\n",
      "====> Epoch: 1100 Average training loss: 1.7298\n",
      "====> Epoch: 1200 Average training loss: 1.6302\n",
      "====> Epoch: 1300 Average training loss: 1.5064\n",
      "====> Epoch: 1400 Average training loss: 1.4099\n",
      "====> Epoch: 1500 Average training loss: 1.3358\n",
      "====> Epoch: 1600 Average training loss: 1.2559\n",
      "====> Epoch: 1700 Average training loss: 1.1481\n",
      "====> Epoch: 1800 Average training loss: 1.1100\n",
      "====> Epoch: 100 Average training loss: 5.9228\n",
      "====> Epoch: 200 Average training loss: 4.7333\n",
      "====> Epoch: 300 Average training loss: 3.9579\n",
      "====> Epoch: 400 Average training loss: 3.4196\n",
      "====> Epoch: 500 Average training loss: 3.0199\n",
      "====> Epoch: 600 Average training loss: 2.7040\n",
      "====> Epoch: 700 Average training loss: 2.4254\n",
      "====> Epoch: 800 Average training loss: 2.2201\n",
      "====> Epoch: 900 Average training loss: 2.0150\n",
      "====> Epoch: 1000 Average training loss: 1.8630\n",
      "====> Epoch: 1100 Average training loss: 1.7234\n",
      "====> Epoch: 1200 Average training loss: 1.6052\n",
      "====> Epoch: 1300 Average training loss: 1.5113\n",
      "====> Epoch: 1400 Average training loss: 1.4065\n",
      "====> Epoch: 1500 Average training loss: 1.3416\n",
      "====> Epoch: 1600 Average training loss: 1.2619\n",
      "====> Epoch: 1700 Average training loss: 1.2020\n",
      "====> Epoch: 1800 Average training loss: 1.1381\n",
      "====> Epoch: 100 Average training loss: 5.9347\n",
      "====> Epoch: 200 Average training loss: 4.7328\n",
      "====> Epoch: 300 Average training loss: 3.9689\n",
      "====> Epoch: 400 Average training loss: 3.4359\n",
      "====> Epoch: 500 Average training loss: 3.0224\n",
      "====> Epoch: 600 Average training loss: 2.6933\n",
      "====> Epoch: 700 Average training loss: 2.4310\n",
      "====> Epoch: 800 Average training loss: 2.2026\n",
      "====> Epoch: 900 Average training loss: 2.0064\n",
      "====> Epoch: 1000 Average training loss: 1.8463\n",
      "====> Epoch: 1100 Average training loss: 1.7061\n",
      "====> Epoch: 1200 Average training loss: 1.5891\n",
      "====> Epoch: 1300 Average training loss: 1.4782\n",
      "====> Epoch: 1400 Average training loss: 1.3849\n",
      "====> Epoch: 1500 Average training loss: 1.3065\n",
      "====> Epoch: 1600 Average training loss: 1.2411\n",
      "====> Epoch: 1700 Average training loss: 1.1718\n",
      "====> Epoch: 1800 Average training loss: 1.1135\n",
      "====> Epoch: 100 Average training loss: 5.9419\n",
      "====> Epoch: 200 Average training loss: 4.7447\n",
      "====> Epoch: 300 Average training loss: 3.9575\n",
      "====> Epoch: 400 Average training loss: 3.4370\n",
      "====> Epoch: 500 Average training loss: 3.0238\n",
      "====> Epoch: 600 Average training loss: 2.7014\n",
      "====> Epoch: 700 Average training loss: 2.4394\n",
      "====> Epoch: 800 Average training loss: 2.2045\n",
      "====> Epoch: 900 Average training loss: 2.0205\n",
      "====> Epoch: 1000 Average training loss: 1.8523\n",
      "====> Epoch: 1100 Average training loss: 1.7198\n",
      "====> Epoch: 1200 Average training loss: 1.5932\n",
      "====> Epoch: 1300 Average training loss: 1.4897\n",
      "====> Epoch: 1400 Average training loss: 1.3982\n",
      "====> Epoch: 1500 Average training loss: 1.3139\n",
      "====> Epoch: 1600 Average training loss: 1.2435\n",
      "====> Epoch: 1700 Average training loss: 1.1806\n",
      "====> Epoch: 1800 Average training loss: 1.1301\n",
      "====> Epoch: 100 Average training loss: 5.9312\n",
      "====> Epoch: 200 Average training loss: 4.7549\n",
      "====> Epoch: 300 Average training loss: 3.9881\n",
      "====> Epoch: 400 Average training loss: 3.4379\n",
      "====> Epoch: 500 Average training loss: 3.0130\n",
      "====> Epoch: 600 Average training loss: 2.6952\n",
      "====> Epoch: 700 Average training loss: 2.4241\n",
      "====> Epoch: 800 Average training loss: 2.2141\n",
      "====> Epoch: 900 Average training loss: 2.0301\n",
      "====> Epoch: 1000 Average training loss: 1.8674\n",
      "====> Epoch: 1100 Average training loss: 1.7390\n",
      "====> Epoch: 1200 Average training loss: 1.6103\n",
      "====> Epoch: 1300 Average training loss: 1.5110\n",
      "====> Epoch: 1400 Average training loss: 1.4160\n",
      "====> Epoch: 1500 Average training loss: 1.3283\n",
      "====> Epoch: 1600 Average training loss: 1.2630\n",
      "====> Epoch: 1700 Average training loss: 1.2065\n",
      "====> Epoch: 1800 Average training loss: 1.1522\n",
      "====> Epoch: 100 Average training loss: 5.9304\n",
      "====> Epoch: 200 Average training loss: 4.7359\n",
      "====> Epoch: 300 Average training loss: 3.9648\n",
      "====> Epoch: 400 Average training loss: 3.4335\n",
      "====> Epoch: 500 Average training loss: 3.0151\n",
      "====> Epoch: 600 Average training loss: 2.6843\n",
      "====> Epoch: 700 Average training loss: 2.4214\n",
      "====> Epoch: 800 Average training loss: 2.2064\n",
      "====> Epoch: 900 Average training loss: 1.7532\n",
      "====> Epoch: 1000 Average training loss: 1.4792\n",
      "====> Epoch: 1100 Average training loss: 1.1968\n",
      "====> Epoch: 1200 Average training loss: 1.0867\n",
      "====> Epoch: 1300 Average training loss: 1.0032\n",
      "====> Epoch: 1400 Average training loss: 0.9027\n",
      "====> Epoch: 1500 Average training loss: 0.8511\n",
      "====> Epoch: 1600 Average training loss: 0.7862\n",
      "====> Epoch: 1700 Average training loss: 0.7172\n",
      "====> Epoch: 1800 Average training loss: 0.6140\n",
      "====> Epoch: 100 Average training loss: 5.9300\n",
      "====> Epoch: 200 Average training loss: 4.7484\n",
      "====> Epoch: 300 Average training loss: 3.9825\n",
      "====> Epoch: 400 Average training loss: 3.4276\n",
      "====> Epoch: 500 Average training loss: 3.0180\n",
      "====> Epoch: 600 Average training loss: 2.7106\n",
      "====> Epoch: 700 Average training loss: 2.4457\n",
      "====> Epoch: 800 Average training loss: 2.2047\n",
      "====> Epoch: 900 Average training loss: 2.0254\n",
      "====> Epoch: 1000 Average training loss: 1.8696\n",
      "====> Epoch: 1100 Average training loss: 1.7372\n",
      "====> Epoch: 1200 Average training loss: 1.6127\n",
      "====> Epoch: 1300 Average training loss: 1.5156\n",
      "====> Epoch: 1400 Average training loss: 1.4251\n",
      "====> Epoch: 1500 Average training loss: 1.3328\n",
      "====> Epoch: 1600 Average training loss: 1.2622\n",
      "====> Epoch: 1700 Average training loss: 1.1983\n",
      "====> Epoch: 1800 Average training loss: 1.1555\n",
      "====> Epoch: 100 Average training loss: 5.9250\n",
      "====> Epoch: 200 Average training loss: 4.7510\n",
      "====> Epoch: 300 Average training loss: 3.9749\n",
      "====> Epoch: 400 Average training loss: 3.4337\n",
      "====> Epoch: 500 Average training loss: 3.0137\n",
      "====> Epoch: 600 Average training loss: 2.6872\n",
      "====> Epoch: 700 Average training loss: 2.4194\n",
      "====> Epoch: 800 Average training loss: 2.2162\n",
      "====> Epoch: 900 Average training loss: 2.0105\n",
      "====> Epoch: 1000 Average training loss: 1.8503\n",
      "====> Epoch: 1100 Average training loss: 1.7165\n",
      "====> Epoch: 1200 Average training loss: 1.6018\n",
      "====> Epoch: 1300 Average training loss: 1.4973\n",
      "====> Epoch: 1400 Average training loss: 1.4056\n",
      "====> Epoch: 1500 Average training loss: 1.3284\n",
      "====> Epoch: 1600 Average training loss: 1.2610\n",
      "====> Epoch: 1700 Average training loss: 1.1891\n",
      "====> Epoch: 1800 Average training loss: 1.1353\n",
      "====> Epoch: 100 Average training loss: 5.9138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 200 Average training loss: 4.7227\n",
      "====> Epoch: 300 Average training loss: 3.9837\n",
      "====> Epoch: 400 Average training loss: 3.4389\n",
      "====> Epoch: 500 Average training loss: 3.0207\n",
      "====> Epoch: 600 Average training loss: 2.6974\n",
      "====> Epoch: 700 Average training loss: 2.4314\n",
      "====> Epoch: 800 Average training loss: 2.2156\n",
      "====> Epoch: 900 Average training loss: 2.0184\n",
      "====> Epoch: 1000 Average training loss: 1.8704\n",
      "====> Epoch: 1100 Average training loss: 1.7241\n",
      "====> Epoch: 1200 Average training loss: 1.3707\n",
      "====> Epoch: 1300 Average training loss: 1.1682\n",
      "====> Epoch: 1400 Average training loss: 1.0345\n",
      "====> Epoch: 1500 Average training loss: 0.9305\n",
      "====> Epoch: 1600 Average training loss: 0.8635\n",
      "====> Epoch: 1700 Average training loss: 0.8251\n",
      "====> Epoch: 1800 Average training loss: 0.6378\n",
      "====> Epoch: 100 Average training loss: 5.9227\n",
      "====> Epoch: 200 Average training loss: 4.7514\n",
      "====> Epoch: 300 Average training loss: 4.0097\n",
      "====> Epoch: 400 Average training loss: 3.4561\n",
      "====> Epoch: 500 Average training loss: 3.0532\n",
      "====> Epoch: 600 Average training loss: 2.7176\n",
      "====> Epoch: 700 Average training loss: 2.4507\n",
      "====> Epoch: 800 Average training loss: 2.2215\n",
      "====> Epoch: 900 Average training loss: 2.0252\n",
      "====> Epoch: 1000 Average training loss: 1.8782\n",
      "====> Epoch: 1100 Average training loss: 1.7267\n",
      "====> Epoch: 1200 Average training loss: 1.6256\n",
      "====> Epoch: 1300 Average training loss: 1.4996\n",
      "====> Epoch: 1400 Average training loss: 1.4163\n",
      "====> Epoch: 1500 Average training loss: 1.3325\n",
      "====> Epoch: 1600 Average training loss: 1.2554\n",
      "====> Epoch: 1700 Average training loss: 1.1852\n",
      "====> Epoch: 1800 Average training loss: 1.1262\n",
      "====> Epoch: 100 Average training loss: 5.9228\n",
      "====> Epoch: 200 Average training loss: 4.7406\n",
      "====> Epoch: 300 Average training loss: 3.9806\n",
      "====> Epoch: 400 Average training loss: 3.4358\n",
      "====> Epoch: 500 Average training loss: 3.0215\n",
      "====> Epoch: 600 Average training loss: 2.1024\n",
      "====> Epoch: 700 Average training loss: 1.7169\n",
      "====> Epoch: 800 Average training loss: 1.5163\n",
      "====> Epoch: 900 Average training loss: 1.3640\n",
      "====> Epoch: 1000 Average training loss: 1.2321\n",
      "====> Epoch: 1100 Average training loss: 1.1206\n",
      "====> Epoch: 1200 Average training loss: 1.0267\n",
      "====> Epoch: 1300 Average training loss: 0.9464\n",
      "====> Epoch: 1400 Average training loss: 0.8730\n",
      "====> Epoch: 1500 Average training loss: 0.8101\n",
      "====> Epoch: 1600 Average training loss: 0.7572\n",
      "====> Epoch: 1700 Average training loss: 0.7087\n",
      "====> Epoch: 1800 Average training loss: 0.6643\n",
      "====> Epoch: 100 Average training loss: 5.9290\n",
      "====> Epoch: 200 Average training loss: 4.7587\n",
      "====> Epoch: 300 Average training loss: 3.9813\n",
      "====> Epoch: 400 Average training loss: 3.4341\n",
      "====> Epoch: 500 Average training loss: 3.0155\n",
      "====> Epoch: 600 Average training loss: 2.6907\n",
      "====> Epoch: 700 Average training loss: 2.4227\n",
      "====> Epoch: 800 Average training loss: 2.2181\n",
      "====> Epoch: 900 Average training loss: 2.0234\n",
      "====> Epoch: 1000 Average training loss: 1.8670\n",
      "====> Epoch: 1100 Average training loss: 1.7218\n",
      "====> Epoch: 1200 Average training loss: 1.6117\n",
      "====> Epoch: 1300 Average training loss: 1.5073\n",
      "====> Epoch: 1400 Average training loss: 1.4256\n",
      "====> Epoch: 1500 Average training loss: 1.3478\n",
      "====> Epoch: 1600 Average training loss: 1.2600\n",
      "====> Epoch: 1700 Average training loss: 1.1957\n",
      "====> Epoch: 1800 Average training loss: 1.1597\n",
      "====> Epoch: 100 Average training loss: 5.9347\n",
      "====> Epoch: 200 Average training loss: 4.7633\n",
      "====> Epoch: 300 Average training loss: 3.9941\n",
      "====> Epoch: 400 Average training loss: 3.4443\n",
      "====> Epoch: 500 Average training loss: 3.0092\n",
      "====> Epoch: 600 Average training loss: 2.6679\n",
      "====> Epoch: 700 Average training loss: 2.4132\n",
      "====> Epoch: 800 Average training loss: 2.1819\n",
      "====> Epoch: 900 Average training loss: 1.9846\n",
      "====> Epoch: 1000 Average training loss: 1.8030\n",
      "====> Epoch: 1100 Average training loss: 1.6680\n",
      "====> Epoch: 1200 Average training loss: 1.5486\n",
      "====> Epoch: 1300 Average training loss: 1.4370\n",
      "====> Epoch: 1400 Average training loss: 1.3537\n",
      "====> Epoch: 1500 Average training loss: 1.2600\n",
      "====> Epoch: 1600 Average training loss: 1.1841\n",
      "====> Epoch: 1700 Average training loss: 1.1276\n",
      "====> Epoch: 1800 Average training loss: 1.0611\n",
      "====> Epoch: 100 Average training loss: 5.9186\n",
      "====> Epoch: 200 Average training loss: 4.7500\n",
      "====> Epoch: 300 Average training loss: 3.9839\n",
      "====> Epoch: 400 Average training loss: 3.4408\n",
      "====> Epoch: 500 Average training loss: 2.3082\n",
      "====> Epoch: 600 Average training loss: 1.9281\n",
      "====> Epoch: 700 Average training loss: 1.6965\n",
      "====> Epoch: 800 Average training loss: 1.5138\n",
      "====> Epoch: 900 Average training loss: 1.3692\n",
      "====> Epoch: 1000 Average training loss: 1.2394\n",
      "====> Epoch: 1100 Average training loss: 1.1313\n",
      "====> Epoch: 1200 Average training loss: 1.0367\n",
      "====> Epoch: 1300 Average training loss: 0.9554\n",
      "====> Epoch: 1400 Average training loss: 0.8850\n",
      "====> Epoch: 1500 Average training loss: 0.8244\n",
      "====> Epoch: 1600 Average training loss: 0.7676\n",
      "====> Epoch: 1700 Average training loss: 0.7179\n",
      "====> Epoch: 1800 Average training loss: 0.6749\n",
      "====> Epoch: 100 Average training loss: 5.9455\n",
      "====> Epoch: 200 Average training loss: 4.7548\n",
      "====> Epoch: 300 Average training loss: 3.9912\n",
      "====> Epoch: 400 Average training loss: 3.4314\n",
      "====> Epoch: 500 Average training loss: 3.0251\n",
      "====> Epoch: 600 Average training loss: 2.7121\n",
      "====> Epoch: 700 Average training loss: 2.4397\n",
      "====> Epoch: 800 Average training loss: 2.2114\n",
      "====> Epoch: 900 Average training loss: 2.0336\n",
      "====> Epoch: 1000 Average training loss: 1.8978\n",
      "====> Epoch: 1100 Average training loss: 1.7255\n",
      "====> Epoch: 1200 Average training loss: 1.6032\n",
      "====> Epoch: 1300 Average training loss: 1.5133\n",
      "====> Epoch: 1400 Average training loss: 1.3470\n",
      "====> Epoch: 1500 Average training loss: 1.2532\n",
      "====> Epoch: 1600 Average training loss: 1.2368\n",
      "====> Epoch: 1700 Average training loss: 1.1764\n",
      "====> Epoch: 1800 Average training loss: 1.1020\n",
      "====> Epoch: 100 Average training loss: 5.9240\n",
      "====> Epoch: 200 Average training loss: 4.7378\n",
      "====> Epoch: 300 Average training loss: 3.9725\n",
      "====> Epoch: 400 Average training loss: 3.4262\n",
      "====> Epoch: 500 Average training loss: 3.0190\n",
      "====> Epoch: 600 Average training loss: 2.6894\n",
      "====> Epoch: 700 Average training loss: 2.4235\n",
      "====> Epoch: 800 Average training loss: 2.2073\n",
      "====> Epoch: 900 Average training loss: 2.0284\n",
      "====> Epoch: 1000 Average training loss: 1.8672\n",
      "====> Epoch: 1100 Average training loss: 1.7329\n",
      "====> Epoch: 1200 Average training loss: 1.6074\n",
      "====> Epoch: 1300 Average training loss: 1.5048\n",
      "====> Epoch: 1400 Average training loss: 1.4005\n",
      "====> Epoch: 1500 Average training loss: 1.3280\n",
      "====> Epoch: 1600 Average training loss: 1.2651\n",
      "====> Epoch: 1700 Average training loss: 1.2063\n",
      "====> Epoch: 1800 Average training loss: 1.1357\n",
      "====> Epoch: 100 Average training loss: 5.9002\n",
      "====> Epoch: 200 Average training loss: 4.7034\n",
      "====> Epoch: 300 Average training loss: 3.9461\n",
      "====> Epoch: 400 Average training loss: 3.4167\n",
      "====> Epoch: 500 Average training loss: 2.9971\n",
      "====> Epoch: 600 Average training loss: 2.6734\n",
      "====> Epoch: 700 Average training loss: 2.4105\n",
      "====> Epoch: 800 Average training loss: 2.1943\n",
      "====> Epoch: 900 Average training loss: 2.0110\n",
      "====> Epoch: 1000 Average training loss: 1.8381\n",
      "====> Epoch: 1100 Average training loss: 1.7100\n",
      "====> Epoch: 1200 Average training loss: 1.5906\n",
      "====> Epoch: 1300 Average training loss: 1.4856\n",
      "====> Epoch: 1400 Average training loss: 1.3987\n",
      "====> Epoch: 1500 Average training loss: 1.3189\n",
      "====> Epoch: 1600 Average training loss: 1.2419\n",
      "====> Epoch: 1700 Average training loss: 1.1858\n",
      "====> Epoch: 1800 Average training loss: 1.1300\n",
      "====> Epoch: 100 Average training loss: 5.9090\n",
      "====> Epoch: 200 Average training loss: 4.7452\n",
      "====> Epoch: 300 Average training loss: 3.9967\n",
      "====> Epoch: 400 Average training loss: 3.4669\n",
      "====> Epoch: 500 Average training loss: 3.0609\n",
      "====> Epoch: 600 Average training loss: 2.7133\n",
      "====> Epoch: 700 Average training loss: 2.4521\n",
      "====> Epoch: 800 Average training loss: 2.2324\n",
      "====> Epoch: 900 Average training loss: 2.0490\n",
      "====> Epoch: 1000 Average training loss: 1.8736\n",
      "====> Epoch: 1100 Average training loss: 1.7463\n",
      "====> Epoch: 1200 Average training loss: 1.6044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1300 Average training loss: 1.5096\n",
      "====> Epoch: 1400 Average training loss: 1.4225\n",
      "====> Epoch: 1500 Average training loss: 1.3430\n",
      "====> Epoch: 1600 Average training loss: 1.2638\n",
      "====> Epoch: 1700 Average training loss: 1.1968\n",
      "====> Epoch: 1800 Average training loss: 1.1472\n",
      "====> Epoch: 100 Average training loss: 5.9187\n",
      "====> Epoch: 200 Average training loss: 4.7417\n",
      "====> Epoch: 300 Average training loss: 3.9734\n",
      "====> Epoch: 400 Average training loss: 3.4241\n",
      "====> Epoch: 500 Average training loss: 3.0037\n",
      "====> Epoch: 600 Average training loss: 2.6763\n",
      "====> Epoch: 700 Average training loss: 2.3989\n",
      "====> Epoch: 800 Average training loss: 2.1845\n",
      "====> Epoch: 900 Average training loss: 1.9897\n",
      "====> Epoch: 1000 Average training loss: 1.8445\n",
      "====> Epoch: 1100 Average training loss: 1.7070\n",
      "====> Epoch: 1200 Average training loss: 1.5861\n",
      "====> Epoch: 1300 Average training loss: 1.4883\n",
      "====> Epoch: 1400 Average training loss: 1.3972\n",
      "====> Epoch: 1500 Average training loss: 1.3045\n",
      "====> Epoch: 1600 Average training loss: 1.2376\n",
      "====> Epoch: 1700 Average training loss: 1.1779\n",
      "====> Epoch: 1800 Average training loss: 1.1189\n",
      "====> Epoch: 100 Average training loss: 5.8831\n",
      "====> Epoch: 200 Average training loss: 4.7151\n",
      "====> Epoch: 300 Average training loss: 3.9854\n",
      "====> Epoch: 400 Average training loss: 3.4316\n",
      "====> Epoch: 500 Average training loss: 3.0210\n",
      "====> Epoch: 600 Average training loss: 2.6992\n",
      "====> Epoch: 700 Average training loss: 2.4253\n",
      "====> Epoch: 800 Average training loss: 2.1233\n",
      "====> Epoch: 900 Average training loss: 1.7863\n",
      "====> Epoch: 1000 Average training loss: 1.5448\n",
      "====> Epoch: 1100 Average training loss: 1.3540\n",
      "====> Epoch: 1200 Average training loss: 1.1679\n",
      "====> Epoch: 1300 Average training loss: 1.0481\n",
      "====> Epoch: 1400 Average training loss: 0.8440\n",
      "====> Epoch: 1500 Average training loss: 0.9083\n",
      "====> Epoch: 1600 Average training loss: 0.7136\n",
      "====> Epoch: 1700 Average training loss: 0.6250\n",
      "====> Epoch: 1800 Average training loss: 0.6459\n",
      "====> Epoch: 100 Average training loss: 5.9339\n",
      "====> Epoch: 200 Average training loss: 4.7585\n",
      "====> Epoch: 300 Average training loss: 4.0060\n",
      "====> Epoch: 400 Average training loss: 3.4593\n",
      "====> Epoch: 500 Average training loss: 3.0328\n",
      "====> Epoch: 600 Average training loss: 2.7058\n",
      "====> Epoch: 700 Average training loss: 2.4304\n",
      "====> Epoch: 800 Average training loss: 2.2172\n",
      "====> Epoch: 900 Average training loss: 2.0165\n",
      "====> Epoch: 1000 Average training loss: 1.8546\n",
      "====> Epoch: 1100 Average training loss: 1.7232\n",
      "====> Epoch: 1200 Average training loss: 1.5992\n",
      "====> Epoch: 1300 Average training loss: 1.4941\n",
      "====> Epoch: 1400 Average training loss: 1.4023\n",
      "====> Epoch: 1500 Average training loss: 1.3257\n",
      "====> Epoch: 1600 Average training loss: 1.2549\n",
      "====> Epoch: 1700 Average training loss: 1.1939\n",
      "====> Epoch: 1800 Average training loss: 1.1362\n",
      "====> Epoch: 100 Average training loss: 5.9301\n",
      "====> Epoch: 200 Average training loss: 4.7434\n",
      "====> Epoch: 300 Average training loss: 3.9824\n",
      "====> Epoch: 400 Average training loss: 3.4502\n",
      "====> Epoch: 500 Average training loss: 3.0437\n",
      "====> Epoch: 600 Average training loss: 2.7135\n",
      "====> Epoch: 700 Average training loss: 2.4379\n",
      "====> Epoch: 800 Average training loss: 2.2154\n",
      "====> Epoch: 900 Average training loss: 2.0179\n",
      "====> Epoch: 1000 Average training loss: 1.8817\n",
      "====> Epoch: 1100 Average training loss: 1.7371\n",
      "====> Epoch: 1200 Average training loss: 1.6136\n",
      "====> Epoch: 1300 Average training loss: 1.5006\n",
      "====> Epoch: 1400 Average training loss: 1.4081\n",
      "====> Epoch: 1500 Average training loss: 1.3193\n",
      "====> Epoch: 1600 Average training loss: 1.2547\n",
      "====> Epoch: 1700 Average training loss: 1.1953\n",
      "====> Epoch: 1800 Average training loss: 1.1310\n",
      "====> Epoch: 100 Average training loss: 5.9141\n",
      "====> Epoch: 200 Average training loss: 4.7198\n",
      "====> Epoch: 300 Average training loss: 3.9647\n",
      "====> Epoch: 400 Average training loss: 3.4155\n",
      "====> Epoch: 500 Average training loss: 3.0104\n",
      "====> Epoch: 600 Average training loss: 2.6701\n",
      "====> Epoch: 700 Average training loss: 2.4088\n",
      "====> Epoch: 800 Average training loss: 2.1784\n",
      "====> Epoch: 900 Average training loss: 2.0015\n",
      "====> Epoch: 1000 Average training loss: 1.8371\n",
      "====> Epoch: 1100 Average training loss: 1.7046\n",
      "====> Epoch: 1200 Average training loss: 1.5750\n",
      "====> Epoch: 1300 Average training loss: 1.4774\n",
      "====> Epoch: 1400 Average training loss: 1.3834\n",
      "====> Epoch: 1500 Average training loss: 1.3003\n",
      "====> Epoch: 1600 Average training loss: 1.2406\n",
      "====> Epoch: 1700 Average training loss: 1.1669\n",
      "====> Epoch: 1800 Average training loss: 1.1083\n",
      "====> Epoch: 100 Average training loss: 5.9224\n",
      "====> Epoch: 200 Average training loss: 4.7298\n",
      "====> Epoch: 300 Average training loss: 3.9793\n",
      "====> Epoch: 400 Average training loss: 3.4440\n",
      "====> Epoch: 500 Average training loss: 3.0195\n",
      "====> Epoch: 600 Average training loss: 2.6988\n",
      "====> Epoch: 700 Average training loss: 2.4262\n",
      "====> Epoch: 800 Average training loss: 2.2024\n",
      "====> Epoch: 900 Average training loss: 2.0149\n",
      "====> Epoch: 1000 Average training loss: 1.8509\n",
      "====> Epoch: 1100 Average training loss: 1.7124\n",
      "====> Epoch: 1200 Average training loss: 1.6017\n",
      "====> Epoch: 1300 Average training loss: 1.4911\n",
      "====> Epoch: 1400 Average training loss: 1.4058\n",
      "====> Epoch: 1500 Average training loss: 1.3145\n",
      "====> Epoch: 1600 Average training loss: 1.2457\n",
      "====> Epoch: 1700 Average training loss: 1.1768\n",
      "====> Epoch: 1800 Average training loss: 1.1244\n",
      "====> Epoch: 100 Average training loss: 5.9273\n",
      "====> Epoch: 200 Average training loss: 4.7466\n",
      "====> Epoch: 300 Average training loss: 3.9901\n",
      "====> Epoch: 400 Average training loss: 3.4531\n",
      "====> Epoch: 500 Average training loss: 3.0281\n",
      "====> Epoch: 600 Average training loss: 2.3233\n",
      "====> Epoch: 700 Average training loss: 1.9217\n",
      "====> Epoch: 800 Average training loss: 1.7371\n",
      "====> Epoch: 900 Average training loss: 1.5124\n",
      "====> Epoch: 1000 Average training loss: 1.1891\n",
      "====> Epoch: 1100 Average training loss: 1.0995\n",
      "====> Epoch: 1200 Average training loss: 0.9646\n",
      "====> Epoch: 1300 Average training loss: 0.9631\n",
      "====> Epoch: 1400 Average training loss: 0.8771\n",
      "====> Epoch: 1500 Average training loss: 0.7927\n",
      "====> Epoch: 1600 Average training loss: 0.6682\n",
      "====> Epoch: 1700 Average training loss: 0.6972\n",
      "====> Epoch: 1800 Average training loss: 0.5931\n",
      "====> Epoch: 100 Average training loss: 5.9176\n",
      "====> Epoch: 200 Average training loss: 4.7526\n",
      "====> Epoch: 300 Average training loss: 3.9815\n",
      "====> Epoch: 400 Average training loss: 3.4453\n",
      "====> Epoch: 500 Average training loss: 3.0298\n",
      "====> Epoch: 600 Average training loss: 2.7024\n",
      "====> Epoch: 700 Average training loss: 2.4299\n",
      "====> Epoch: 800 Average training loss: 2.2075\n",
      "====> Epoch: 900 Average training loss: 2.0086\n",
      "====> Epoch: 1000 Average training loss: 1.8527\n",
      "====> Epoch: 1100 Average training loss: 1.7237\n",
      "====> Epoch: 1200 Average training loss: 1.6004\n",
      "====> Epoch: 1300 Average training loss: 1.4834\n",
      "====> Epoch: 1400 Average training loss: 1.4027\n",
      "====> Epoch: 1500 Average training loss: 1.3512\n",
      "====> Epoch: 1600 Average training loss: 1.2722\n",
      "====> Epoch: 1700 Average training loss: 1.2108\n",
      "====> Epoch: 1800 Average training loss: 1.1102\n",
      "====> Epoch: 100 Average training loss: 5.9170\n",
      "====> Epoch: 200 Average training loss: 4.7616\n",
      "====> Epoch: 300 Average training loss: 3.9773\n",
      "====> Epoch: 400 Average training loss: 3.4313\n",
      "====> Epoch: 500 Average training loss: 3.0273\n",
      "====> Epoch: 600 Average training loss: 2.6814\n",
      "====> Epoch: 700 Average training loss: 2.4180\n",
      "====> Epoch: 800 Average training loss: 2.1968\n",
      "====> Epoch: 900 Average training loss: 1.9985\n",
      "====> Epoch: 1000 Average training loss: 1.8521\n",
      "====> Epoch: 1100 Average training loss: 1.7093\n",
      "====> Epoch: 1200 Average training loss: 1.5993\n",
      "====> Epoch: 1300 Average training loss: 1.4856\n",
      "====> Epoch: 1400 Average training loss: 1.4080\n",
      "====> Epoch: 1500 Average training loss: 1.3111\n",
      "====> Epoch: 1600 Average training loss: 1.2408\n",
      "====> Epoch: 1700 Average training loss: 1.1746\n",
      "====> Epoch: 1800 Average training loss: 1.1309\n",
      "====> Epoch: 100 Average training loss: 5.9093\n",
      "====> Epoch: 200 Average training loss: 4.7232\n",
      "====> Epoch: 300 Average training loss: 3.9770\n",
      "====> Epoch: 400 Average training loss: 3.4364\n",
      "====> Epoch: 500 Average training loss: 3.0295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 600 Average training loss: 2.6962\n",
      "====> Epoch: 700 Average training loss: 2.4344\n",
      "====> Epoch: 800 Average training loss: 2.2190\n",
      "====> Epoch: 900 Average training loss: 2.0279\n",
      "====> Epoch: 1000 Average training loss: 1.8565\n",
      "====> Epoch: 1100 Average training loss: 1.7260\n",
      "====> Epoch: 1200 Average training loss: 1.5996\n",
      "====> Epoch: 1300 Average training loss: 1.4944\n",
      "====> Epoch: 1400 Average training loss: 1.3844\n",
      "====> Epoch: 1500 Average training loss: 1.2987\n",
      "====> Epoch: 1600 Average training loss: 1.2142\n",
      "====> Epoch: 1700 Average training loss: 1.1531\n",
      "====> Epoch: 1800 Average training loss: 1.0887\n",
      "====> Epoch: 100 Average training loss: 5.9032\n",
      "====> Epoch: 200 Average training loss: 4.7156\n",
      "====> Epoch: 300 Average training loss: 3.9810\n",
      "====> Epoch: 400 Average training loss: 3.4372\n",
      "====> Epoch: 500 Average training loss: 2.8410\n",
      "====> Epoch: 600 Average training loss: 2.4049\n",
      "====> Epoch: 700 Average training loss: 2.1378\n",
      "====> Epoch: 800 Average training loss: 1.8792\n",
      "====> Epoch: 900 Average training loss: 1.7201\n",
      "====> Epoch: 1000 Average training loss: 1.4316\n",
      "====> Epoch: 1100 Average training loss: 1.3918\n",
      "====> Epoch: 1200 Average training loss: 1.1854\n",
      "====> Epoch: 1300 Average training loss: 1.1506\n",
      "====> Epoch: 1400 Average training loss: 1.0588\n",
      "====> Epoch: 1500 Average training loss: 0.9803\n",
      "====> Epoch: 1600 Average training loss: 0.9267\n",
      "====> Epoch: 1700 Average training loss: 0.8729\n",
      "====> Epoch: 1800 Average training loss: 0.8328\n",
      "====> Epoch: 100 Average training loss: 5.9287\n",
      "====> Epoch: 200 Average training loss: 4.7270\n",
      "====> Epoch: 300 Average training loss: 3.9458\n",
      "====> Epoch: 400 Average training loss: 3.4250\n",
      "====> Epoch: 500 Average training loss: 3.0025\n",
      "====> Epoch: 600 Average training loss: 2.6842\n",
      "====> Epoch: 700 Average training loss: 2.4127\n",
      "====> Epoch: 800 Average training loss: 2.2112\n",
      "====> Epoch: 900 Average training loss: 2.0195\n",
      "====> Epoch: 1000 Average training loss: 1.8717\n",
      "====> Epoch: 1100 Average training loss: 1.7168\n",
      "====> Epoch: 1200 Average training loss: 1.6091\n",
      "====> Epoch: 1300 Average training loss: 1.5070\n",
      "====> Epoch: 1400 Average training loss: 1.4050\n",
      "====> Epoch: 1500 Average training loss: 1.3285\n",
      "====> Epoch: 1600 Average training loss: 1.2519\n",
      "====> Epoch: 1700 Average training loss: 1.2049\n",
      "====> Epoch: 1800 Average training loss: 1.1404\n",
      "====> Epoch: 100 Average training loss: 5.9116\n",
      "====> Epoch: 200 Average training loss: 4.7326\n",
      "====> Epoch: 300 Average training loss: 3.9764\n",
      "====> Epoch: 400 Average training loss: 3.4502\n",
      "====> Epoch: 500 Average training loss: 3.0329\n",
      "====> Epoch: 600 Average training loss: 2.7062\n",
      "====> Epoch: 700 Average training loss: 2.4366\n",
      "====> Epoch: 800 Average training loss: 2.2153\n",
      "====> Epoch: 900 Average training loss: 2.0323\n",
      "====> Epoch: 1000 Average training loss: 1.8551\n",
      "====> Epoch: 1100 Average training loss: 1.6990\n",
      "====> Epoch: 1200 Average training loss: 1.6360\n",
      "====> Epoch: 1300 Average training loss: 1.4892\n",
      "====> Epoch: 1400 Average training loss: 1.3937\n",
      "====> Epoch: 1500 Average training loss: 1.2790\n",
      "====> Epoch: 1600 Average training loss: 1.2116\n",
      "====> Epoch: 1700 Average training loss: 1.1659\n",
      "====> Epoch: 1800 Average training loss: 1.1029\n",
      "====> Epoch: 100 Average training loss: 5.9230\n",
      "====> Epoch: 200 Average training loss: 4.7483\n",
      "====> Epoch: 300 Average training loss: 4.0081\n",
      "====> Epoch: 400 Average training loss: 3.4836\n",
      "====> Epoch: 500 Average training loss: 3.0499\n",
      "====> Epoch: 600 Average training loss: 2.7309\n",
      "====> Epoch: 700 Average training loss: 2.4476\n",
      "====> Epoch: 800 Average training loss: 2.2400\n",
      "====> Epoch: 900 Average training loss: 2.0431\n",
      "====> Epoch: 1000 Average training loss: 1.8784\n",
      "====> Epoch: 1100 Average training loss: 1.7475\n",
      "====> Epoch: 1200 Average training loss: 1.6290\n",
      "====> Epoch: 1300 Average training loss: 1.5153\n",
      "====> Epoch: 1400 Average training loss: 1.4239\n",
      "====> Epoch: 1500 Average training loss: 1.3511\n",
      "====> Epoch: 1600 Average training loss: 1.2771\n",
      "====> Epoch: 1700 Average training loss: 1.2142\n",
      "====> Epoch: 1800 Average training loss: 1.1555\n",
      "====> Epoch: 100 Average training loss: 5.9412\n",
      "====> Epoch: 200 Average training loss: 4.7324\n",
      "====> Epoch: 300 Average training loss: 3.9834\n",
      "====> Epoch: 400 Average training loss: 3.4243\n",
      "====> Epoch: 500 Average training loss: 3.0151\n",
      "====> Epoch: 600 Average training loss: 2.6971\n",
      "====> Epoch: 700 Average training loss: 2.4226\n",
      "====> Epoch: 800 Average training loss: 2.2040\n",
      "====> Epoch: 900 Average training loss: 2.0185\n",
      "====> Epoch: 1000 Average training loss: 1.8562\n",
      "====> Epoch: 1100 Average training loss: 1.4252\n",
      "====> Epoch: 1200 Average training loss: 1.1371\n",
      "====> Epoch: 1300 Average training loss: 1.0246\n",
      "====> Epoch: 1400 Average training loss: 0.9392\n",
      "====> Epoch: 1500 Average training loss: 0.8646\n",
      "====> Epoch: 1600 Average training loss: 0.7983\n",
      "====> Epoch: 1700 Average training loss: 0.7439\n",
      "====> Epoch: 1800 Average training loss: 0.6870\n",
      "====> Epoch: 100 Average training loss: 5.9173\n",
      "====> Epoch: 200 Average training loss: 4.7269\n",
      "====> Epoch: 300 Average training loss: 4.0045\n",
      "====> Epoch: 400 Average training loss: 3.4336\n",
      "====> Epoch: 500 Average training loss: 3.0155\n",
      "====> Epoch: 600 Average training loss: 2.6871\n",
      "====> Epoch: 700 Average training loss: 2.4280\n",
      "====> Epoch: 800 Average training loss: 2.2085\n",
      "====> Epoch: 900 Average training loss: 2.0035\n",
      "====> Epoch: 1000 Average training loss: 1.8530\n",
      "====> Epoch: 1100 Average training loss: 1.7142\n",
      "====> Epoch: 1200 Average training loss: 1.5948\n",
      "====> Epoch: 1300 Average training loss: 1.4956\n",
      "====> Epoch: 1400 Average training loss: 1.3952\n",
      "====> Epoch: 1500 Average training loss: 1.3238\n",
      "====> Epoch: 1600 Average training loss: 1.2427\n",
      "====> Epoch: 1700 Average training loss: 1.1768\n",
      "====> Epoch: 1800 Average training loss: 1.1067\n",
      "====> Epoch: 100 Average training loss: 5.9085\n",
      "====> Epoch: 200 Average training loss: 4.7263\n",
      "====> Epoch: 300 Average training loss: 3.9850\n",
      "====> Epoch: 400 Average training loss: 3.4457\n",
      "====> Epoch: 500 Average training loss: 3.0334\n",
      "====> Epoch: 600 Average training loss: 2.7028\n",
      "====> Epoch: 700 Average training loss: 2.4286\n",
      "====> Epoch: 800 Average training loss: 2.2245\n",
      "====> Epoch: 900 Average training loss: 2.0284\n",
      "====> Epoch: 1000 Average training loss: 1.8667\n",
      "====> Epoch: 1100 Average training loss: 1.7351\n",
      "====> Epoch: 1200 Average training loss: 1.6251\n",
      "====> Epoch: 1300 Average training loss: 1.5189\n",
      "====> Epoch: 1400 Average training loss: 1.4215\n",
      "====> Epoch: 1500 Average training loss: 1.3339\n",
      "====> Epoch: 1600 Average training loss: 1.2757\n",
      "====> Epoch: 1700 Average training loss: 1.2043\n",
      "====> Epoch: 1800 Average training loss: 1.1389\n",
      "====> Epoch: 100 Average training loss: 5.9182\n",
      "====> Epoch: 200 Average training loss: 4.7430\n",
      "====> Epoch: 300 Average training loss: 3.9794\n",
      "====> Epoch: 400 Average training loss: 3.4442\n",
      "====> Epoch: 500 Average training loss: 3.0325\n",
      "====> Epoch: 600 Average training loss: 2.6990\n",
      "====> Epoch: 700 Average training loss: 2.4187\n",
      "====> Epoch: 800 Average training loss: 2.1939\n",
      "====> Epoch: 900 Average training loss: 2.0043\n",
      "====> Epoch: 1000 Average training loss: 1.8499\n",
      "====> Epoch: 1100 Average training loss: 1.6992\n",
      "====> Epoch: 1200 Average training loss: 1.5874\n",
      "====> Epoch: 1300 Average training loss: 1.4786\n",
      "====> Epoch: 1400 Average training loss: 1.3799\n",
      "====> Epoch: 1500 Average training loss: 1.3040\n",
      "====> Epoch: 1600 Average training loss: 1.2332\n",
      "====> Epoch: 1700 Average training loss: 1.1660\n",
      "====> Epoch: 1800 Average training loss: 1.1144\n",
      "====> Epoch: 100 Average training loss: 5.9186\n",
      "====> Epoch: 200 Average training loss: 4.7393\n",
      "====> Epoch: 300 Average training loss: 3.9831\n",
      "====> Epoch: 400 Average training loss: 3.4563\n",
      "====> Epoch: 500 Average training loss: 3.0285\n",
      "====> Epoch: 600 Average training loss: 2.6932\n",
      "====> Epoch: 700 Average training loss: 2.4391\n",
      "====> Epoch: 800 Average training loss: 2.2058\n",
      "====> Epoch: 900 Average training loss: 2.0108\n",
      "====> Epoch: 1000 Average training loss: 1.8563\n",
      "====> Epoch: 1100 Average training loss: 1.7015\n",
      "====> Epoch: 1200 Average training loss: 1.5986\n",
      "====> Epoch: 1300 Average training loss: 1.4734\n",
      "====> Epoch: 1400 Average training loss: 1.3891\n",
      "====> Epoch: 1500 Average training loss: 1.3100\n",
      "====> Epoch: 1600 Average training loss: 1.2429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1700 Average training loss: 1.1666\n",
      "====> Epoch: 1800 Average training loss: 1.1059\n",
      "====> Epoch: 100 Average training loss: 5.9008\n",
      "====> Epoch: 200 Average training loss: 4.7289\n",
      "====> Epoch: 300 Average training loss: 3.9619\n",
      "====> Epoch: 400 Average training loss: 3.4425\n",
      "====> Epoch: 500 Average training loss: 3.0229\n",
      "====> Epoch: 600 Average training loss: 2.7029\n",
      "====> Epoch: 700 Average training loss: 2.4319\n",
      "====> Epoch: 800 Average training loss: 2.1987\n",
      "====> Epoch: 900 Average training loss: 2.0114\n",
      "====> Epoch: 1000 Average training loss: 1.8408\n",
      "====> Epoch: 1100 Average training loss: 1.7018\n",
      "====> Epoch: 1200 Average training loss: 1.5798\n",
      "====> Epoch: 1300 Average training loss: 1.4762\n",
      "====> Epoch: 1400 Average training loss: 1.3794\n",
      "====> Epoch: 1500 Average training loss: 1.2955\n",
      "====> Epoch: 1600 Average training loss: 1.2285\n",
      "====> Epoch: 1700 Average training loss: 1.1673\n",
      "====> Epoch: 1800 Average training loss: 1.1080\n",
      "====> Epoch: 100 Average training loss: 5.9239\n",
      "====> Epoch: 200 Average training loss: 4.7451\n",
      "====> Epoch: 300 Average training loss: 3.9889\n",
      "====> Epoch: 400 Average training loss: 3.4412\n",
      "====> Epoch: 500 Average training loss: 3.0378\n",
      "====> Epoch: 600 Average training loss: 2.6953\n",
      "====> Epoch: 700 Average training loss: 2.4472\n",
      "====> Epoch: 800 Average training loss: 2.2122\n",
      "====> Epoch: 900 Average training loss: 2.0276\n",
      "====> Epoch: 1000 Average training loss: 1.8816\n",
      "====> Epoch: 1100 Average training loss: 1.7284\n",
      "====> Epoch: 1200 Average training loss: 1.6199\n",
      "====> Epoch: 1300 Average training loss: 1.4988\n",
      "====> Epoch: 1400 Average training loss: 1.4229\n",
      "====> Epoch: 1500 Average training loss: 1.3160\n",
      "====> Epoch: 1600 Average training loss: 1.2761\n",
      "====> Epoch: 1700 Average training loss: 1.1812\n",
      "====> Epoch: 1800 Average training loss: 1.1530\n",
      "====> Epoch: 100 Average training loss: 5.9289\n",
      "====> Epoch: 200 Average training loss: 4.7617\n",
      "====> Epoch: 300 Average training loss: 3.9879\n",
      "====> Epoch: 400 Average training loss: 3.4445\n",
      "====> Epoch: 500 Average training loss: 3.0271\n",
      "====> Epoch: 600 Average training loss: 2.7103\n",
      "====> Epoch: 700 Average training loss: 2.4417\n",
      "====> Epoch: 800 Average training loss: 2.2167\n",
      "====> Epoch: 900 Average training loss: 2.0230\n",
      "====> Epoch: 1000 Average training loss: 1.8652\n",
      "====> Epoch: 1100 Average training loss: 1.7363\n",
      "====> Epoch: 1200 Average training loss: 1.6066\n",
      "====> Epoch: 1300 Average training loss: 1.5058\n",
      "====> Epoch: 1400 Average training loss: 1.4125\n",
      "====> Epoch: 1500 Average training loss: 1.3253\n",
      "====> Epoch: 1600 Average training loss: 1.2560\n",
      "====> Epoch: 1700 Average training loss: 1.1876\n",
      "====> Epoch: 1800 Average training loss: 1.1371\n",
      "====> Epoch: 100 Average training loss: 5.9195\n",
      "====> Epoch: 200 Average training loss: 4.7262\n",
      "====> Epoch: 300 Average training loss: 3.9534\n",
      "====> Epoch: 400 Average training loss: 3.4270\n",
      "====> Epoch: 500 Average training loss: 2.3004\n",
      "====> Epoch: 600 Average training loss: 1.9277\n",
      "====> Epoch: 700 Average training loss: 1.6895\n",
      "====> Epoch: 800 Average training loss: 1.5044\n",
      "====> Epoch: 900 Average training loss: 1.3568\n",
      "====> Epoch: 1000 Average training loss: 1.2210\n",
      "====> Epoch: 1100 Average training loss: 1.1122\n",
      "====> Epoch: 1200 Average training loss: 1.0195\n",
      "====> Epoch: 1300 Average training loss: 0.9497\n",
      "====> Epoch: 1400 Average training loss: 0.8708\n",
      "====> Epoch: 1500 Average training loss: 0.8085\n",
      "====> Epoch: 1600 Average training loss: 0.7543\n",
      "====> Epoch: 1700 Average training loss: 0.7052\n",
      "====> Epoch: 1800 Average training loss: 0.6623\n",
      "====> Epoch: 100 Average training loss: 5.9059\n",
      "====> Epoch: 200 Average training loss: 4.7416\n",
      "====> Epoch: 300 Average training loss: 3.9811\n",
      "====> Epoch: 400 Average training loss: 3.4287\n",
      "====> Epoch: 500 Average training loss: 3.0197\n",
      "====> Epoch: 600 Average training loss: 2.6881\n",
      "====> Epoch: 700 Average training loss: 2.4087\n",
      "====> Epoch: 800 Average training loss: 2.1904\n",
      "====> Epoch: 900 Average training loss: 2.0102\n",
      "====> Epoch: 1000 Average training loss: 1.8612\n",
      "====> Epoch: 1100 Average training loss: 1.7251\n",
      "====> Epoch: 1200 Average training loss: 1.6003\n",
      "====> Epoch: 1300 Average training loss: 1.4891\n",
      "====> Epoch: 1400 Average training loss: 1.4131\n",
      "====> Epoch: 1500 Average training loss: 1.3258\n",
      "====> Epoch: 1600 Average training loss: 1.2589\n",
      "====> Epoch: 1700 Average training loss: 1.1997\n",
      "====> Epoch: 1800 Average training loss: 1.1410\n",
      "====> Epoch: 100 Average training loss: 5.8985\n",
      "====> Epoch: 200 Average training loss: 4.7285\n",
      "====> Epoch: 300 Average training loss: 3.9957\n",
      "====> Epoch: 400 Average training loss: 3.4622\n",
      "====> Epoch: 500 Average training loss: 3.0559\n",
      "====> Epoch: 600 Average training loss: 2.7285\n",
      "====> Epoch: 700 Average training loss: 2.4478\n",
      "====> Epoch: 800 Average training loss: 2.2326\n",
      "====> Epoch: 900 Average training loss: 2.0479\n",
      "====> Epoch: 1000 Average training loss: 1.8879\n",
      "====> Epoch: 1100 Average training loss: 1.7526\n",
      "====> Epoch: 1200 Average training loss: 1.6341\n",
      "====> Epoch: 1300 Average training loss: 1.5200\n",
      "====> Epoch: 1400 Average training loss: 1.4285\n",
      "====> Epoch: 1500 Average training loss: 1.3538\n",
      "====> Epoch: 1600 Average training loss: 1.2720\n",
      "====> Epoch: 1700 Average training loss: 1.2034\n",
      "====> Epoch: 1800 Average training loss: 1.1588\n",
      "====> Epoch: 100 Average training loss: 5.9136\n",
      "====> Epoch: 200 Average training loss: 4.7391\n",
      "====> Epoch: 300 Average training loss: 3.9735\n",
      "====> Epoch: 400 Average training loss: 3.4253\n",
      "====> Epoch: 500 Average training loss: 3.0123\n",
      "====> Epoch: 600 Average training loss: 2.6890\n",
      "====> Epoch: 700 Average training loss: 2.4068\n",
      "====> Epoch: 800 Average training loss: 2.1898\n",
      "====> Epoch: 900 Average training loss: 2.0072\n",
      "====> Epoch: 1000 Average training loss: 1.8524\n",
      "====> Epoch: 1100 Average training loss: 1.7136\n",
      "====> Epoch: 1200 Average training loss: 1.5911\n",
      "====> Epoch: 1300 Average training loss: 1.4921\n",
      "====> Epoch: 1400 Average training loss: 1.3991\n",
      "====> Epoch: 1500 Average training loss: 1.3188\n",
      "====> Epoch: 1600 Average training loss: 1.2504\n",
      "====> Epoch: 1700 Average training loss: 1.1875\n",
      "====> Epoch: 1800 Average training loss: 1.1289\n",
      "====> Epoch: 100 Average training loss: 5.9041\n",
      "====> Epoch: 200 Average training loss: 4.7229\n",
      "====> Epoch: 300 Average training loss: 3.9705\n",
      "====> Epoch: 400 Average training loss: 3.4325\n",
      "====> Epoch: 500 Average training loss: 3.0221\n",
      "====> Epoch: 600 Average training loss: 2.6954\n",
      "====> Epoch: 700 Average training loss: 2.4356\n",
      "====> Epoch: 800 Average training loss: 2.2155\n",
      "====> Epoch: 900 Average training loss: 2.0418\n",
      "====> Epoch: 1000 Average training loss: 1.8671\n",
      "====> Epoch: 1100 Average training loss: 1.7357\n",
      "====> Epoch: 1200 Average training loss: 1.6101\n",
      "====> Epoch: 1300 Average training loss: 1.5282\n",
      "====> Epoch: 1400 Average training loss: 1.3625\n",
      "====> Epoch: 1500 Average training loss: 1.3185\n",
      "====> Epoch: 1600 Average training loss: 1.2632\n",
      "====> Epoch: 1700 Average training loss: 1.1387\n",
      "====> Epoch: 1800 Average training loss: 1.1094\n",
      "====> Epoch: 100 Average training loss: 5.9203\n",
      "====> Epoch: 200 Average training loss: 4.7283\n",
      "====> Epoch: 300 Average training loss: 3.9877\n",
      "====> Epoch: 400 Average training loss: 3.4376\n",
      "====> Epoch: 500 Average training loss: 3.0401\n",
      "====> Epoch: 600 Average training loss: 2.7016\n",
      "====> Epoch: 700 Average training loss: 2.4365\n",
      "====> Epoch: 800 Average training loss: 2.2073\n",
      "====> Epoch: 900 Average training loss: 2.0024\n",
      "====> Epoch: 1000 Average training loss: 1.8582\n",
      "====> Epoch: 1100 Average training loss: 1.7242\n",
      "====> Epoch: 1200 Average training loss: 1.5886\n",
      "====> Epoch: 1300 Average training loss: 1.4561\n",
      "====> Epoch: 1400 Average training loss: 1.3375\n",
      "====> Epoch: 1500 Average training loss: 1.2324\n",
      "====> Epoch: 1600 Average training loss: 1.1888\n",
      "====> Epoch: 1700 Average training loss: 1.0995\n",
      "====> Epoch: 1800 Average training loss: 1.0396\n",
      "====> Epoch: 100 Average training loss: 5.9083\n",
      "====> Epoch: 200 Average training loss: 4.7304\n",
      "====> Epoch: 300 Average training loss: 3.9391\n",
      "====> Epoch: 400 Average training loss: 3.3903\n",
      "====> Epoch: 500 Average training loss: 2.9827\n",
      "====> Epoch: 600 Average training loss: 2.6513\n",
      "====> Epoch: 700 Average training loss: 2.3624\n",
      "====> Epoch: 800 Average training loss: 2.1543\n",
      "====> Epoch: 900 Average training loss: 1.9649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average training loss: 1.8040\n",
      "====> Epoch: 1100 Average training loss: 1.6648\n",
      "====> Epoch: 1200 Average training loss: 1.5458\n",
      "====> Epoch: 1300 Average training loss: 1.4463\n",
      "====> Epoch: 1400 Average training loss: 1.3556\n",
      "====> Epoch: 1500 Average training loss: 1.2781\n",
      "====> Epoch: 1600 Average training loss: 1.2028\n",
      "====> Epoch: 1700 Average training loss: 1.1437\n",
      "====> Epoch: 1800 Average training loss: 1.0960\n",
      "====> Epoch: 100 Average training loss: 5.9381\n",
      "====> Epoch: 200 Average training loss: 4.7562\n",
      "====> Epoch: 300 Average training loss: 4.0044\n",
      "====> Epoch: 400 Average training loss: 3.4411\n",
      "====> Epoch: 500 Average training loss: 3.0337\n",
      "====> Epoch: 600 Average training loss: 2.7026\n",
      "====> Epoch: 700 Average training loss: 2.4176\n",
      "====> Epoch: 800 Average training loss: 2.0757\n",
      "====> Epoch: 900 Average training loss: 1.6385\n",
      "====> Epoch: 1000 Average training loss: 1.2680\n",
      "====> Epoch: 1100 Average training loss: 1.1344\n",
      "====> Epoch: 1200 Average training loss: 1.0286\n",
      "====> Epoch: 1300 Average training loss: 0.9409\n",
      "====> Epoch: 1400 Average training loss: 0.8689\n",
      "====> Epoch: 1500 Average training loss: 0.8060\n",
      "====> Epoch: 1600 Average training loss: 0.7526\n",
      "====> Epoch: 1700 Average training loss: 0.7035\n",
      "====> Epoch: 1800 Average training loss: 0.6592\n",
      "====> Epoch: 100 Average training loss: 5.9279\n",
      "====> Epoch: 200 Average training loss: 4.7395\n",
      "====> Epoch: 300 Average training loss: 4.0102\n",
      "====> Epoch: 400 Average training loss: 3.4752\n",
      "====> Epoch: 500 Average training loss: 3.0788\n",
      "====> Epoch: 600 Average training loss: 2.7505\n",
      "====> Epoch: 700 Average training loss: 2.4730\n",
      "====> Epoch: 800 Average training loss: 2.2496\n",
      "====> Epoch: 900 Average training loss: 2.0680\n",
      "====> Epoch: 1000 Average training loss: 1.8846\n",
      "====> Epoch: 1100 Average training loss: 1.7420\n",
      "====> Epoch: 1200 Average training loss: 1.6164\n",
      "====> Epoch: 1300 Average training loss: 1.5039\n",
      "====> Epoch: 1400 Average training loss: 1.4198\n",
      "====> Epoch: 1500 Average training loss: 1.3300\n",
      "====> Epoch: 1600 Average training loss: 1.2438\n",
      "====> Epoch: 1700 Average training loss: 1.1749\n",
      "====> Epoch: 1800 Average training loss: 1.1153\n",
      "====> Epoch: 100 Average training loss: 5.9369\n",
      "====> Epoch: 200 Average training loss: 4.7337\n",
      "====> Epoch: 300 Average training loss: 3.4711\n",
      "====> Epoch: 400 Average training loss: 2.5473\n",
      "====> Epoch: 500 Average training loss: 2.1810\n",
      "====> Epoch: 600 Average training loss: 1.9072\n",
      "====> Epoch: 700 Average training loss: 1.6890\n",
      "====> Epoch: 800 Average training loss: 1.5086\n",
      "====> Epoch: 900 Average training loss: 1.3566\n",
      "====> Epoch: 1000 Average training loss: 1.2270\n",
      "====> Epoch: 1100 Average training loss: 1.1152\n",
      "====> Epoch: 1200 Average training loss: 1.0201\n",
      "====> Epoch: 1300 Average training loss: 0.9377\n",
      "====> Epoch: 1400 Average training loss: 0.8655\n",
      "====> Epoch: 1500 Average training loss: 0.8020\n",
      "====> Epoch: 1600 Average training loss: 0.7465\n",
      "====> Epoch: 1700 Average training loss: 0.6973\n",
      "====> Epoch: 1800 Average training loss: 0.6541\n",
      "====> Epoch: 100 Average training loss: 5.8919\n",
      "====> Epoch: 200 Average training loss: 4.7273\n",
      "====> Epoch: 300 Average training loss: 3.9926\n",
      "====> Epoch: 400 Average training loss: 3.4314\n",
      "====> Epoch: 500 Average training loss: 3.0183\n",
      "====> Epoch: 600 Average training loss: 2.6980\n",
      "====> Epoch: 700 Average training loss: 2.4292\n",
      "====> Epoch: 800 Average training loss: 2.2000\n",
      "====> Epoch: 900 Average training loss: 2.0109\n",
      "====> Epoch: 1000 Average training loss: 1.8332\n",
      "====> Epoch: 1100 Average training loss: 1.7076\n",
      "====> Epoch: 1200 Average training loss: 1.5598\n",
      "====> Epoch: 1300 Average training loss: 1.4612\n",
      "====> Epoch: 1400 Average training loss: 1.3456\n",
      "====> Epoch: 1500 Average training loss: 1.2870\n",
      "====> Epoch: 1600 Average training loss: 1.1744\n",
      "====> Epoch: 1700 Average training loss: 1.0921\n",
      "====> Epoch: 1800 Average training loss: 1.0198\n",
      "====> Epoch: 100 Average training loss: 5.9161\n",
      "====> Epoch: 200 Average training loss: 4.7478\n",
      "====> Epoch: 300 Average training loss: 3.9924\n",
      "====> Epoch: 400 Average training loss: 3.4609\n",
      "====> Epoch: 500 Average training loss: 3.0301\n",
      "====> Epoch: 600 Average training loss: 2.6988\n",
      "====> Epoch: 700 Average training loss: 2.4358\n",
      "====> Epoch: 800 Average training loss: 2.2115\n",
      "====> Epoch: 900 Average training loss: 2.0167\n",
      "====> Epoch: 1000 Average training loss: 1.8774\n",
      "====> Epoch: 1100 Average training loss: 1.4048\n",
      "====> Epoch: 1200 Average training loss: 1.3755\n",
      "====> Epoch: 1300 Average training loss: 1.1923\n",
      "====> Epoch: 1400 Average training loss: 1.0367\n",
      "====> Epoch: 1500 Average training loss: 0.8947\n",
      "====> Epoch: 1600 Average training loss: 0.9667\n",
      "====> Epoch: 1700 Average training loss: 0.8501\n",
      "====> Epoch: 1800 Average training loss: 0.8084\n",
      "====> Epoch: 100 Average training loss: 5.9358\n",
      "====> Epoch: 200 Average training loss: 4.7420\n",
      "====> Epoch: 300 Average training loss: 4.0000\n",
      "====> Epoch: 400 Average training loss: 3.4696\n",
      "====> Epoch: 500 Average training loss: 3.0440\n",
      "====> Epoch: 600 Average training loss: 2.7106\n",
      "====> Epoch: 700 Average training loss: 2.4461\n",
      "====> Epoch: 800 Average training loss: 2.2317\n",
      "====> Epoch: 900 Average training loss: 2.0391\n",
      "====> Epoch: 1000 Average training loss: 1.8762\n",
      "====> Epoch: 1100 Average training loss: 1.7340\n",
      "====> Epoch: 1200 Average training loss: 1.6184\n",
      "====> Epoch: 1300 Average training loss: 1.5228\n",
      "====> Epoch: 1400 Average training loss: 1.4244\n",
      "====> Epoch: 1500 Average training loss: 1.3438\n",
      "====> Epoch: 1600 Average training loss: 1.2721\n",
      "====> Epoch: 1700 Average training loss: 1.2009\n",
      "====> Epoch: 1800 Average training loss: 1.1444\n",
      "====> Epoch: 100 Average training loss: 5.9271\n",
      "====> Epoch: 200 Average training loss: 4.7129\n",
      "====> Epoch: 300 Average training loss: 3.9621\n",
      "====> Epoch: 400 Average training loss: 3.4243\n",
      "====> Epoch: 500 Average training loss: 3.0322\n",
      "====> Epoch: 600 Average training loss: 2.6898\n",
      "====> Epoch: 700 Average training loss: 2.4317\n",
      "====> Epoch: 800 Average training loss: 2.1963\n",
      "====> Epoch: 900 Average training loss: 2.0207\n",
      "====> Epoch: 1000 Average training loss: 1.8466\n",
      "====> Epoch: 1100 Average training loss: 1.7032\n",
      "====> Epoch: 1200 Average training loss: 1.5787\n",
      "====> Epoch: 1300 Average training loss: 1.4792\n",
      "====> Epoch: 1400 Average training loss: 1.3865\n",
      "====> Epoch: 1500 Average training loss: 1.3033\n",
      "====> Epoch: 1600 Average training loss: 1.2420\n",
      "====> Epoch: 1700 Average training loss: 1.1787\n",
      "====> Epoch: 1800 Average training loss: 1.1074\n",
      "====> Epoch: 100 Average training loss: 5.9369\n",
      "====> Epoch: 200 Average training loss: 4.7522\n",
      "====> Epoch: 300 Average training loss: 3.9789\n",
      "====> Epoch: 400 Average training loss: 3.4302\n",
      "====> Epoch: 500 Average training loss: 3.0172\n",
      "====> Epoch: 600 Average training loss: 2.6904\n",
      "====> Epoch: 700 Average training loss: 2.4154\n",
      "====> Epoch: 800 Average training loss: 2.1883\n",
      "====> Epoch: 900 Average training loss: 2.0096\n",
      "====> Epoch: 1000 Average training loss: 1.8497\n",
      "====> Epoch: 1100 Average training loss: 1.7123\n",
      "====> Epoch: 1200 Average training loss: 1.5868\n",
      "====> Epoch: 1300 Average training loss: 1.4835\n",
      "====> Epoch: 1400 Average training loss: 1.4003\n",
      "====> Epoch: 1500 Average training loss: 1.3210\n",
      "====> Epoch: 1600 Average training loss: 1.2486\n",
      "====> Epoch: 1700 Average training loss: 1.1977\n",
      "====> Epoch: 1800 Average training loss: 1.1259\n",
      "====> Epoch: 100 Average training loss: 5.9289\n",
      "====> Epoch: 200 Average training loss: 4.7445\n",
      "====> Epoch: 300 Average training loss: 3.9858\n",
      "====> Epoch: 400 Average training loss: 3.4329\n",
      "====> Epoch: 500 Average training loss: 3.0082\n",
      "====> Epoch: 600 Average training loss: 2.6763\n",
      "====> Epoch: 700 Average training loss: 2.4184\n",
      "====> Epoch: 800 Average training loss: 2.1874\n",
      "====> Epoch: 900 Average training loss: 2.0090\n",
      "====> Epoch: 1000 Average training loss: 1.8417\n",
      "====> Epoch: 1100 Average training loss: 1.7111\n",
      "====> Epoch: 1200 Average training loss: 1.5894\n",
      "====> Epoch: 1300 Average training loss: 1.4897\n",
      "====> Epoch: 1400 Average training loss: 1.4067\n",
      "====> Epoch: 1500 Average training loss: 1.3149\n",
      "====> Epoch: 1600 Average training loss: 1.2468\n",
      "====> Epoch: 1700 Average training loss: 1.1909\n",
      "====> Epoch: 1800 Average training loss: 1.1398\n",
      "====> Epoch: 100 Average training loss: 5.9283\n",
      "====> Epoch: 200 Average training loss: 4.7373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average training loss: 3.9837\n",
      "====> Epoch: 400 Average training loss: 3.4418\n",
      "====> Epoch: 500 Average training loss: 3.0119\n",
      "====> Epoch: 600 Average training loss: 2.6822\n",
      "====> Epoch: 700 Average training loss: 2.4092\n",
      "====> Epoch: 800 Average training loss: 2.1823\n",
      "====> Epoch: 900 Average training loss: 1.9943\n",
      "====> Epoch: 1000 Average training loss: 1.8394\n",
      "====> Epoch: 1100 Average training loss: 1.7046\n",
      "====> Epoch: 1200 Average training loss: 1.5934\n",
      "====> Epoch: 1300 Average training loss: 1.4829\n",
      "====> Epoch: 1400 Average training loss: 1.3993\n",
      "====> Epoch: 1500 Average training loss: 1.3138\n",
      "====> Epoch: 1600 Average training loss: 1.2411\n",
      "====> Epoch: 1700 Average training loss: 1.1741\n",
      "====> Epoch: 1800 Average training loss: 1.1361\n",
      "====> Epoch: 100 Average training loss: 5.9158\n",
      "====> Epoch: 200 Average training loss: 4.7298\n",
      "====> Epoch: 300 Average training loss: 3.9824\n",
      "====> Epoch: 400 Average training loss: 3.4201\n",
      "====> Epoch: 500 Average training loss: 3.0193\n",
      "====> Epoch: 600 Average training loss: 2.6938\n",
      "====> Epoch: 700 Average training loss: 2.4306\n",
      "====> Epoch: 800 Average training loss: 2.2208\n",
      "====> Epoch: 900 Average training loss: 2.0227\n",
      "====> Epoch: 1000 Average training loss: 1.8632\n",
      "====> Epoch: 1100 Average training loss: 1.7301\n",
      "====> Epoch: 1200 Average training loss: 1.6101\n",
      "====> Epoch: 1300 Average training loss: 1.5040\n",
      "====> Epoch: 1400 Average training loss: 1.4120\n",
      "====> Epoch: 1500 Average training loss: 1.3625\n",
      "====> Epoch: 1600 Average training loss: 1.2436\n",
      "====> Epoch: 1700 Average training loss: 1.1881\n",
      "====> Epoch: 1800 Average training loss: 1.1530\n",
      "====> Epoch: 100 Average training loss: 5.9312\n",
      "====> Epoch: 200 Average training loss: 4.7275\n",
      "====> Epoch: 300 Average training loss: 3.9810\n",
      "====> Epoch: 400 Average training loss: 3.4614\n",
      "====> Epoch: 500 Average training loss: 3.0376\n",
      "====> Epoch: 600 Average training loss: 2.7004\n",
      "====> Epoch: 700 Average training loss: 2.4443\n",
      "====> Epoch: 800 Average training loss: 2.2168\n",
      "====> Epoch: 900 Average training loss: 2.0284\n",
      "====> Epoch: 1000 Average training loss: 1.8780\n",
      "====> Epoch: 1100 Average training loss: 1.7343\n",
      "====> Epoch: 1200 Average training loss: 1.6217\n",
      "====> Epoch: 1300 Average training loss: 1.5103\n",
      "====> Epoch: 1400 Average training loss: 1.4158\n",
      "====> Epoch: 1500 Average training loss: 1.3391\n",
      "====> Epoch: 1600 Average training loss: 1.2595\n",
      "====> Epoch: 1700 Average training loss: 1.2016\n",
      "====> Epoch: 1800 Average training loss: 1.1498\n",
      "====> Epoch: 100 Average training loss: 5.9073\n",
      "====> Epoch: 200 Average training loss: 4.7208\n",
      "====> Epoch: 300 Average training loss: 3.9490\n",
      "====> Epoch: 400 Average training loss: 3.4167\n",
      "====> Epoch: 500 Average training loss: 3.0104\n",
      "====> Epoch: 600 Average training loss: 2.6774\n",
      "====> Epoch: 700 Average training loss: 2.4296\n",
      "====> Epoch: 800 Average training loss: 2.2168\n",
      "====> Epoch: 900 Average training loss: 2.0201\n",
      "====> Epoch: 1000 Average training loss: 1.8513\n",
      "====> Epoch: 1100 Average training loss: 1.7246\n",
      "====> Epoch: 1200 Average training loss: 1.6072\n",
      "====> Epoch: 1300 Average training loss: 1.5110\n",
      "====> Epoch: 1400 Average training loss: 1.4065\n",
      "====> Epoch: 1500 Average training loss: 1.3352\n",
      "====> Epoch: 1600 Average training loss: 1.2722\n",
      "====> Epoch: 1700 Average training loss: 1.2049\n",
      "====> Epoch: 1800 Average training loss: 1.1483\n",
      "====> Epoch: 100 Average training loss: 5.9387\n",
      "====> Epoch: 200 Average training loss: 4.7327\n",
      "====> Epoch: 300 Average training loss: 3.9850\n",
      "====> Epoch: 400 Average training loss: 3.4458\n",
      "====> Epoch: 500 Average training loss: 3.0109\n",
      "====> Epoch: 600 Average training loss: 2.6795\n",
      "====> Epoch: 700 Average training loss: 2.2569\n",
      "====> Epoch: 800 Average training loss: 1.7659\n",
      "====> Epoch: 900 Average training loss: 1.4328\n",
      "====> Epoch: 1000 Average training loss: 1.2209\n",
      "====> Epoch: 1100 Average training loss: 1.0924\n",
      "====> Epoch: 1200 Average training loss: 0.9930\n",
      "====> Epoch: 1300 Average training loss: 0.9075\n",
      "====> Epoch: 1400 Average training loss: 0.8336\n",
      "====> Epoch: 1500 Average training loss: 0.7686\n",
      "====> Epoch: 1600 Average training loss: 0.7158\n",
      "====> Epoch: 1700 Average training loss: 0.6584\n",
      "====> Epoch: 1800 Average training loss: 0.6171\n",
      "====> Epoch: 100 Average training loss: 5.9156\n",
      "====> Epoch: 200 Average training loss: 4.7359\n",
      "====> Epoch: 300 Average training loss: 3.9710\n",
      "====> Epoch: 400 Average training loss: 3.4328\n",
      "====> Epoch: 500 Average training loss: 3.0238\n",
      "====> Epoch: 600 Average training loss: 2.6945\n",
      "====> Epoch: 700 Average training loss: 2.4325\n",
      "====> Epoch: 800 Average training loss: 2.1995\n",
      "====> Epoch: 900 Average training loss: 2.0282\n",
      "====> Epoch: 1000 Average training loss: 1.8743\n",
      "====> Epoch: 1100 Average training loss: 1.7235\n",
      "====> Epoch: 1200 Average training loss: 1.6144\n",
      "====> Epoch: 1300 Average training loss: 1.5102\n",
      "====> Epoch: 1400 Average training loss: 1.4056\n",
      "====> Epoch: 1500 Average training loss: 1.3397\n",
      "====> Epoch: 1600 Average training loss: 1.2601\n",
      "====> Epoch: 1700 Average training loss: 1.1913\n",
      "====> Epoch: 1800 Average training loss: 1.1234\n",
      "====> Epoch: 100 Average training loss: 5.9239\n",
      "====> Epoch: 200 Average training loss: 4.7279\n",
      "====> Epoch: 300 Average training loss: 3.9893\n",
      "====> Epoch: 400 Average training loss: 3.4452\n",
      "====> Epoch: 500 Average training loss: 3.0184\n",
      "====> Epoch: 600 Average training loss: 2.6991\n",
      "====> Epoch: 700 Average training loss: 2.4423\n",
      "====> Epoch: 800 Average training loss: 2.2140\n",
      "====> Epoch: 900 Average training loss: 2.0325\n",
      "====> Epoch: 1000 Average training loss: 1.8740\n",
      "====> Epoch: 1100 Average training loss: 1.7303\n",
      "====> Epoch: 1200 Average training loss: 1.6210\n",
      "====> Epoch: 1300 Average training loss: 1.5066\n",
      "====> Epoch: 1400 Average training loss: 1.4263\n",
      "====> Epoch: 1500 Average training loss: 1.3480\n",
      "====> Epoch: 1600 Average training loss: 1.2699\n",
      "====> Epoch: 1700 Average training loss: 1.2071\n",
      "====> Epoch: 1800 Average training loss: 1.1412\n",
      "====> Epoch: 100 Average training loss: 5.9073\n",
      "====> Epoch: 200 Average training loss: 4.7231\n",
      "====> Epoch: 300 Average training loss: 3.9784\n",
      "====> Epoch: 400 Average training loss: 3.4558\n",
      "====> Epoch: 500 Average training loss: 2.9805\n",
      "====> Epoch: 600 Average training loss: 2.3761\n",
      "====> Epoch: 700 Average training loss: 2.0294\n",
      "====> Epoch: 800 Average training loss: 1.9040\n",
      "====> Epoch: 900 Average training loss: 1.6905\n",
      "====> Epoch: 1000 Average training loss: 1.3590\n",
      "====> Epoch: 1100 Average training loss: 1.3262\n",
      "====> Epoch: 1200 Average training loss: 1.0520\n",
      "====> Epoch: 1300 Average training loss: 1.0010\n",
      "====> Epoch: 1400 Average training loss: 0.8722\n",
      "====> Epoch: 1500 Average training loss: 0.8243\n",
      "====> Epoch: 1600 Average training loss: 0.6622\n",
      "====> Epoch: 1700 Average training loss: 0.6643\n",
      "====> Epoch: 1800 Average training loss: 0.6193\n",
      "====> Epoch: 100 Average training loss: 5.9262\n",
      "====> Epoch: 200 Average training loss: 4.7273\n",
      "====> Epoch: 300 Average training loss: 3.9853\n",
      "====> Epoch: 400 Average training loss: 3.1399\n",
      "====> Epoch: 500 Average training loss: 2.2249\n",
      "====> Epoch: 600 Average training loss: 1.9216\n",
      "====> Epoch: 700 Average training loss: 1.6889\n",
      "====> Epoch: 800 Average training loss: 1.5040\n",
      "====> Epoch: 900 Average training loss: 1.3528\n",
      "====> Epoch: 1000 Average training loss: 1.2265\n",
      "====> Epoch: 1100 Average training loss: 1.1186\n",
      "====> Epoch: 1200 Average training loss: 1.0266\n",
      "====> Epoch: 1300 Average training loss: 0.9466\n",
      "====> Epoch: 1400 Average training loss: 0.8747\n",
      "====> Epoch: 1500 Average training loss: 0.8132\n",
      "====> Epoch: 1600 Average training loss: 0.7588\n",
      "====> Epoch: 1700 Average training loss: 0.7110\n",
      "====> Epoch: 1800 Average training loss: 0.6674\n",
      "====> Epoch: 100 Average training loss: 5.9110\n",
      "====> Epoch: 200 Average training loss: 4.7168\n",
      "====> Epoch: 300 Average training loss: 3.9558\n",
      "====> Epoch: 400 Average training loss: 3.4245\n",
      "====> Epoch: 500 Average training loss: 3.0117\n",
      "====> Epoch: 600 Average training loss: 2.6827\n",
      "====> Epoch: 700 Average training loss: 2.4283\n",
      "====> Epoch: 800 Average training loss: 2.1992\n",
      "====> Epoch: 900 Average training loss: 2.0096\n",
      "====> Epoch: 1000 Average training loss: 1.8527\n",
      "====> Epoch: 1100 Average training loss: 1.7260\n",
      "====> Epoch: 1200 Average training loss: 1.6015\n",
      "====> Epoch: 1300 Average training loss: 1.4927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1400 Average training loss: 1.4134\n",
      "====> Epoch: 1500 Average training loss: 1.3316\n",
      "====> Epoch: 1600 Average training loss: 1.2629\n",
      "====> Epoch: 1700 Average training loss: 1.2007\n",
      "====> Epoch: 1800 Average training loss: 1.1344\n",
      "====> Epoch: 100 Average training loss: 5.9129\n",
      "====> Epoch: 200 Average training loss: 4.7249\n",
      "====> Epoch: 300 Average training loss: 3.9780\n",
      "====> Epoch: 400 Average training loss: 3.4309\n",
      "====> Epoch: 500 Average training loss: 3.0098\n",
      "====> Epoch: 600 Average training loss: 2.6820\n",
      "====> Epoch: 700 Average training loss: 2.4368\n",
      "====> Epoch: 800 Average training loss: 2.2004\n",
      "====> Epoch: 900 Average training loss: 2.0166\n",
      "====> Epoch: 1000 Average training loss: 1.8520\n",
      "====> Epoch: 1100 Average training loss: 1.4610\n",
      "====> Epoch: 1200 Average training loss: 1.2944\n",
      "====> Epoch: 1300 Average training loss: 1.1597\n",
      "====> Epoch: 1400 Average training loss: 1.0354\n",
      "====> Epoch: 1500 Average training loss: 0.9424\n",
      "====> Epoch: 1600 Average training loss: 0.8799\n",
      "====> Epoch: 1700 Average training loss: 0.8254\n",
      "====> Epoch: 1800 Average training loss: 0.7783\n",
      "====> Epoch: 100 Average training loss: 5.9224\n",
      "====> Epoch: 200 Average training loss: 4.7329\n",
      "====> Epoch: 300 Average training loss: 3.9821\n",
      "====> Epoch: 400 Average training loss: 3.4573\n",
      "====> Epoch: 500 Average training loss: 3.0445\n",
      "====> Epoch: 600 Average training loss: 2.7094\n",
      "====> Epoch: 700 Average training loss: 2.4507\n",
      "====> Epoch: 800 Average training loss: 2.2257\n",
      "====> Epoch: 900 Average training loss: 2.0378\n",
      "====> Epoch: 1000 Average training loss: 1.8703\n",
      "====> Epoch: 1100 Average training loss: 1.7326\n",
      "====> Epoch: 1200 Average training loss: 1.6106\n",
      "====> Epoch: 1300 Average training loss: 1.5175\n",
      "====> Epoch: 1400 Average training loss: 1.4212\n",
      "====> Epoch: 1500 Average training loss: 1.3579\n",
      "====> Epoch: 1600 Average training loss: 1.2674\n",
      "====> Epoch: 1700 Average training loss: 1.2000\n",
      "====> Epoch: 1800 Average training loss: 1.1440\n",
      "====> Epoch: 100 Average training loss: 5.9236\n",
      "====> Epoch: 200 Average training loss: 4.7438\n",
      "====> Epoch: 300 Average training loss: 3.9982\n",
      "====> Epoch: 400 Average training loss: 3.4319\n",
      "====> Epoch: 500 Average training loss: 3.0289\n",
      "====> Epoch: 600 Average training loss: 2.6933\n",
      "====> Epoch: 700 Average training loss: 2.4293\n",
      "====> Epoch: 800 Average training loss: 2.1987\n",
      "====> Epoch: 900 Average training loss: 2.0189\n",
      "====> Epoch: 1000 Average training loss: 1.8585\n",
      "====> Epoch: 1100 Average training loss: 1.7699\n",
      "====> Epoch: 1200 Average training loss: 1.2411\n",
      "====> Epoch: 1300 Average training loss: 1.0091\n",
      "====> Epoch: 1400 Average training loss: 0.8773\n",
      "====> Epoch: 1500 Average training loss: 0.8052\n",
      "====> Epoch: 1600 Average training loss: 0.7455\n",
      "====> Epoch: 1700 Average training loss: 0.6987\n",
      "====> Epoch: 1800 Average training loss: 0.6564\n",
      "====> Epoch: 100 Average training loss: 5.9377\n",
      "====> Epoch: 200 Average training loss: 4.7387\n",
      "====> Epoch: 300 Average training loss: 3.9956\n",
      "====> Epoch: 400 Average training loss: 3.4422\n",
      "====> Epoch: 500 Average training loss: 3.0336\n",
      "====> Epoch: 600 Average training loss: 2.6969\n",
      "====> Epoch: 700 Average training loss: 2.4305\n",
      "====> Epoch: 800 Average training loss: 2.2089\n",
      "====> Epoch: 900 Average training loss: 2.0076\n",
      "====> Epoch: 1000 Average training loss: 1.8350\n",
      "====> Epoch: 1100 Average training loss: 1.6901\n",
      "====> Epoch: 1200 Average training loss: 1.5515\n",
      "====> Epoch: 1300 Average training loss: 1.4436\n",
      "====> Epoch: 1400 Average training loss: 1.3572\n",
      "====> Epoch: 1500 Average training loss: 1.2702\n",
      "====> Epoch: 1600 Average training loss: 1.1989\n",
      "====> Epoch: 1700 Average training loss: 1.1350\n",
      "====> Epoch: 1800 Average training loss: 1.0973\n",
      "====> Epoch: 100 Average training loss: 5.9251\n",
      "====> Epoch: 200 Average training loss: 4.7422\n",
      "====> Epoch: 300 Average training loss: 3.9931\n",
      "====> Epoch: 400 Average training loss: 3.4568\n",
      "====> Epoch: 500 Average training loss: 3.0370\n",
      "====> Epoch: 600 Average training loss: 2.7125\n",
      "====> Epoch: 700 Average training loss: 2.4246\n",
      "====> Epoch: 800 Average training loss: 2.1895\n",
      "====> Epoch: 900 Average training loss: 1.9953\n",
      "====> Epoch: 1000 Average training loss: 1.8373\n",
      "====> Epoch: 1100 Average training loss: 1.6951\n",
      "====> Epoch: 1200 Average training loss: 1.5680\n",
      "====> Epoch: 1300 Average training loss: 1.4704\n",
      "====> Epoch: 1400 Average training loss: 1.3861\n",
      "====> Epoch: 1500 Average training loss: 1.3038\n",
      "====> Epoch: 1600 Average training loss: 1.2158\n",
      "====> Epoch: 1700 Average training loss: 1.1542\n",
      "====> Epoch: 1800 Average training loss: 1.1058\n",
      "====> Epoch: 100 Average training loss: 5.9205\n",
      "====> Epoch: 200 Average training loss: 4.7348\n",
      "====> Epoch: 300 Average training loss: 3.9591\n",
      "====> Epoch: 400 Average training loss: 3.4125\n",
      "====> Epoch: 500 Average training loss: 3.0095\n",
      "====> Epoch: 600 Average training loss: 2.6911\n",
      "====> Epoch: 700 Average training loss: 2.4155\n",
      "====> Epoch: 800 Average training loss: 2.1845\n",
      "====> Epoch: 900 Average training loss: 2.0061\n",
      "====> Epoch: 1000 Average training loss: 1.8429\n",
      "====> Epoch: 1100 Average training loss: 1.7123\n",
      "====> Epoch: 1200 Average training loss: 1.5878\n",
      "====> Epoch: 1300 Average training loss: 1.4855\n",
      "====> Epoch: 1400 Average training loss: 1.4016\n",
      "====> Epoch: 1500 Average training loss: 1.3248\n",
      "====> Epoch: 1600 Average training loss: 1.2398\n",
      "====> Epoch: 1700 Average training loss: 1.1776\n",
      "====> Epoch: 1800 Average training loss: 1.1156\n",
      "====> Epoch: 100 Average training loss: 5.9198\n",
      "====> Epoch: 200 Average training loss: 4.7492\n",
      "====> Epoch: 300 Average training loss: 3.9862\n",
      "====> Epoch: 400 Average training loss: 3.4367\n",
      "====> Epoch: 500 Average training loss: 3.0230\n",
      "====> Epoch: 600 Average training loss: 2.6919\n",
      "====> Epoch: 700 Average training loss: 2.4180\n",
      "====> Epoch: 800 Average training loss: 2.1850\n",
      "====> Epoch: 900 Average training loss: 2.0045\n",
      "====> Epoch: 1000 Average training loss: 1.8592\n",
      "====> Epoch: 1100 Average training loss: 1.7108\n",
      "====> Epoch: 1200 Average training loss: 1.5824\n",
      "====> Epoch: 1300 Average training loss: 1.4805\n",
      "====> Epoch: 1400 Average training loss: 1.3866\n",
      "====> Epoch: 1500 Average training loss: 1.3083\n",
      "====> Epoch: 1600 Average training loss: 1.2366\n",
      "====> Epoch: 1700 Average training loss: 1.1847\n",
      "====> Epoch: 1800 Average training loss: 1.1203\n",
      "====> Epoch: 100 Average training loss: 5.9291\n",
      "====> Epoch: 200 Average training loss: 4.7287\n",
      "====> Epoch: 300 Average training loss: 3.9656\n",
      "====> Epoch: 400 Average training loss: 3.4152\n",
      "====> Epoch: 500 Average training loss: 3.0129\n",
      "====> Epoch: 600 Average training loss: 2.6866\n",
      "====> Epoch: 700 Average training loss: 2.4109\n",
      "====> Epoch: 800 Average training loss: 2.1902\n",
      "====> Epoch: 900 Average training loss: 2.0023\n",
      "====> Epoch: 1000 Average training loss: 1.8411\n",
      "====> Epoch: 1100 Average training loss: 1.7160\n",
      "====> Epoch: 1200 Average training loss: 1.5988\n",
      "====> Epoch: 1300 Average training loss: 1.4861\n",
      "====> Epoch: 1400 Average training loss: 1.3930\n",
      "====> Epoch: 1500 Average training loss: 1.3152\n",
      "====> Epoch: 1600 Average training loss: 1.2447\n",
      "====> Epoch: 1700 Average training loss: 1.1876\n",
      "====> Epoch: 1800 Average training loss: 1.1278\n",
      "====> Epoch: 100 Average training loss: 5.9185\n",
      "====> Epoch: 200 Average training loss: 4.7362\n",
      "====> Epoch: 300 Average training loss: 3.9774\n",
      "====> Epoch: 400 Average training loss: 3.4294\n",
      "====> Epoch: 500 Average training loss: 3.0432\n",
      "====> Epoch: 600 Average training loss: 2.7011\n",
      "====> Epoch: 700 Average training loss: 2.4374\n",
      "====> Epoch: 800 Average training loss: 2.2158\n",
      "====> Epoch: 900 Average training loss: 2.0278\n",
      "====> Epoch: 1000 Average training loss: 1.8729\n",
      "====> Epoch: 1100 Average training loss: 1.7333\n",
      "====> Epoch: 1200 Average training loss: 1.6110\n",
      "====> Epoch: 1300 Average training loss: 1.5077\n",
      "====> Epoch: 1400 Average training loss: 1.4288\n",
      "====> Epoch: 1500 Average training loss: 1.3409\n",
      "====> Epoch: 1600 Average training loss: 1.2053\n",
      "====> Epoch: 1700 Average training loss: 1.1964\n",
      "====> Epoch: 1800 Average training loss: 1.1121\n",
      "====> Epoch: 100 Average training loss: 5.9225\n",
      "====> Epoch: 200 Average training loss: 4.7388\n",
      "====> Epoch: 300 Average training loss: 3.9696\n",
      "====> Epoch: 400 Average training loss: 3.4433\n",
      "====> Epoch: 500 Average training loss: 3.0163\n",
      "====> Epoch: 600 Average training loss: 2.6889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 700 Average training loss: 2.4182\n",
      "====> Epoch: 800 Average training loss: 2.1844\n",
      "====> Epoch: 900 Average training loss: 1.9928\n",
      "====> Epoch: 1000 Average training loss: 1.8433\n",
      "====> Epoch: 1100 Average training loss: 1.7225\n",
      "====> Epoch: 1200 Average training loss: 1.5929\n",
      "====> Epoch: 1300 Average training loss: 1.4876\n",
      "====> Epoch: 1400 Average training loss: 1.3912\n",
      "====> Epoch: 1500 Average training loss: 1.3055\n",
      "====> Epoch: 1600 Average training loss: 1.2292\n",
      "====> Epoch: 1700 Average training loss: 1.1683\n",
      "====> Epoch: 1800 Average training loss: 1.1187\n",
      "====> Epoch: 100 Average training loss: 5.9245\n",
      "====> Epoch: 200 Average training loss: 4.7374\n",
      "====> Epoch: 300 Average training loss: 3.9867\n",
      "====> Epoch: 400 Average training loss: 3.4256\n",
      "====> Epoch: 500 Average training loss: 3.0145\n",
      "====> Epoch: 600 Average training loss: 2.6932\n",
      "====> Epoch: 700 Average training loss: 2.4464\n",
      "====> Epoch: 800 Average training loss: 2.2037\n",
      "====> Epoch: 900 Average training loss: 2.0234\n",
      "====> Epoch: 1000 Average training loss: 1.8546\n",
      "====> Epoch: 1100 Average training loss: 1.7222\n",
      "====> Epoch: 1200 Average training loss: 1.6035\n",
      "====> Epoch: 1300 Average training loss: 1.4894\n",
      "====> Epoch: 1400 Average training loss: 1.3951\n",
      "====> Epoch: 1500 Average training loss: 1.3241\n",
      "====> Epoch: 1600 Average training loss: 1.2590\n",
      "====> Epoch: 1700 Average training loss: 1.2043\n",
      "====> Epoch: 1800 Average training loss: 1.1411\n",
      "====> Epoch: 100 Average training loss: 5.9296\n",
      "====> Epoch: 200 Average training loss: 4.7717\n",
      "====> Epoch: 300 Average training loss: 4.0010\n",
      "====> Epoch: 400 Average training loss: 3.4535\n",
      "====> Epoch: 500 Average training loss: 3.0321\n",
      "====> Epoch: 600 Average training loss: 2.6996\n",
      "====> Epoch: 700 Average training loss: 2.4470\n",
      "====> Epoch: 800 Average training loss: 2.2159\n",
      "====> Epoch: 900 Average training loss: 2.0372\n",
      "====> Epoch: 1000 Average training loss: 1.8712\n",
      "====> Epoch: 1100 Average training loss: 1.7374\n",
      "====> Epoch: 1200 Average training loss: 1.6136\n",
      "====> Epoch: 1300 Average training loss: 1.4998\n",
      "====> Epoch: 1400 Average training loss: 1.4180\n",
      "====> Epoch: 1500 Average training loss: 1.3389\n",
      "====> Epoch: 1600 Average training loss: 1.2656\n",
      "====> Epoch: 1700 Average training loss: 1.2026\n",
      "====> Epoch: 1800 Average training loss: 1.1516\n",
      "====> Epoch: 100 Average training loss: 5.9156\n",
      "====> Epoch: 200 Average training loss: 4.7188\n",
      "====> Epoch: 300 Average training loss: 3.1643\n",
      "====> Epoch: 400 Average training loss: 2.5620\n",
      "====> Epoch: 500 Average training loss: 2.1959\n",
      "====> Epoch: 600 Average training loss: 1.9273\n",
      "====> Epoch: 700 Average training loss: 1.7089\n",
      "====> Epoch: 800 Average training loss: 1.5288\n",
      "====> Epoch: 900 Average training loss: 1.3789\n",
      "====> Epoch: 1000 Average training loss: 1.2497\n",
      "====> Epoch: 1100 Average training loss: 1.1384\n",
      "====> Epoch: 1200 Average training loss: 1.0436\n",
      "====> Epoch: 1300 Average training loss: 0.9597\n",
      "====> Epoch: 1400 Average training loss: 0.8878\n",
      "====> Epoch: 1500 Average training loss: 0.8262\n",
      "====> Epoch: 1600 Average training loss: 0.7672\n",
      "====> Epoch: 1700 Average training loss: 0.7195\n",
      "====> Epoch: 1800 Average training loss: 0.6743\n",
      "====> Epoch: 100 Average training loss: 5.9174\n",
      "====> Epoch: 200 Average training loss: 4.7117\n",
      "====> Epoch: 300 Average training loss: 3.9674\n",
      "====> Epoch: 400 Average training loss: 3.4277\n",
      "====> Epoch: 500 Average training loss: 3.0155\n",
      "====> Epoch: 600 Average training loss: 2.6927\n",
      "====> Epoch: 700 Average training loss: 2.4191\n",
      "====> Epoch: 800 Average training loss: 2.2074\n",
      "====> Epoch: 900 Average training loss: 2.0406\n",
      "====> Epoch: 1000 Average training loss: 1.8596\n",
      "====> Epoch: 1100 Average training loss: 1.6815\n",
      "====> Epoch: 1200 Average training loss: 1.5495\n",
      "====> Epoch: 1300 Average training loss: 1.4957\n",
      "====> Epoch: 1400 Average training loss: 1.4139\n",
      "====> Epoch: 1500 Average training loss: 1.3143\n",
      "====> Epoch: 1600 Average training loss: 1.2298\n",
      "====> Epoch: 1700 Average training loss: 1.1619\n",
      "====> Epoch: 1800 Average training loss: 1.1132\n",
      "====> Epoch: 100 Average training loss: 5.9207\n",
      "====> Epoch: 200 Average training loss: 4.7499\n",
      "====> Epoch: 300 Average training loss: 3.9963\n",
      "====> Epoch: 400 Average training loss: 3.4426\n",
      "====> Epoch: 500 Average training loss: 3.0412\n",
      "====> Epoch: 600 Average training loss: 2.7199\n",
      "====> Epoch: 700 Average training loss: 2.4463\n",
      "====> Epoch: 800 Average training loss: 2.2008\n",
      "====> Epoch: 900 Average training loss: 2.0251\n",
      "====> Epoch: 1000 Average training loss: 1.8640\n",
      "====> Epoch: 1100 Average training loss: 1.7252\n",
      "====> Epoch: 1200 Average training loss: 1.6107\n",
      "====> Epoch: 1300 Average training loss: 1.5102\n",
      "====> Epoch: 1400 Average training loss: 1.4129\n",
      "====> Epoch: 1500 Average training loss: 1.3294\n",
      "====> Epoch: 1600 Average training loss: 1.2622\n",
      "====> Epoch: 1700 Average training loss: 1.1998\n",
      "====> Epoch: 1800 Average training loss: 1.1420\n",
      "====> Epoch: 100 Average training loss: 5.9165\n",
      "====> Epoch: 200 Average training loss: 4.7143\n",
      "====> Epoch: 300 Average training loss: 3.9721\n",
      "====> Epoch: 400 Average training loss: 3.4256\n",
      "====> Epoch: 500 Average training loss: 3.0064\n",
      "====> Epoch: 600 Average training loss: 2.6739\n",
      "====> Epoch: 700 Average training loss: 2.4050\n",
      "====> Epoch: 800 Average training loss: 2.1937\n",
      "====> Epoch: 900 Average training loss: 2.0001\n",
      "====> Epoch: 1000 Average training loss: 1.8388\n",
      "====> Epoch: 1100 Average training loss: 1.7159\n",
      "====> Epoch: 1200 Average training loss: 1.5867\n",
      "====> Epoch: 1300 Average training loss: 1.4947\n",
      "====> Epoch: 1400 Average training loss: 1.3886\n",
      "====> Epoch: 1500 Average training loss: 1.3098\n",
      "====> Epoch: 1600 Average training loss: 1.2401\n",
      "====> Epoch: 1700 Average training loss: 1.1783\n",
      "====> Epoch: 1800 Average training loss: 1.1367\n",
      "====> Epoch: 100 Average training loss: 5.9242\n",
      "====> Epoch: 200 Average training loss: 4.7306\n",
      "====> Epoch: 300 Average training loss: 3.9628\n",
      "====> Epoch: 400 Average training loss: 3.4343\n",
      "====> Epoch: 500 Average training loss: 3.0172\n",
      "====> Epoch: 600 Average training loss: 2.6846\n",
      "====> Epoch: 700 Average training loss: 2.4326\n",
      "====> Epoch: 800 Average training loss: 2.2085\n",
      "====> Epoch: 900 Average training loss: 2.0145\n",
      "====> Epoch: 1000 Average training loss: 1.8551\n",
      "====> Epoch: 1100 Average training loss: 1.7199\n",
      "====> Epoch: 1200 Average training loss: 1.6126\n",
      "====> Epoch: 1300 Average training loss: 1.5087\n",
      "====> Epoch: 1400 Average training loss: 1.4098\n",
      "====> Epoch: 1500 Average training loss: 1.3211\n",
      "====> Epoch: 1600 Average training loss: 1.2609\n",
      "====> Epoch: 1700 Average training loss: 1.1861\n",
      "====> Epoch: 1800 Average training loss: 1.1319\n",
      "====> Epoch: 100 Average training loss: 5.9185\n",
      "====> Epoch: 200 Average training loss: 4.7294\n",
      "====> Epoch: 300 Average training loss: 3.9812\n",
      "====> Epoch: 400 Average training loss: 3.4396\n",
      "====> Epoch: 500 Average training loss: 3.0271\n",
      "====> Epoch: 600 Average training loss: 2.7028\n",
      "====> Epoch: 700 Average training loss: 2.4281\n",
      "====> Epoch: 800 Average training loss: 2.2022\n",
      "====> Epoch: 900 Average training loss: 2.0296\n",
      "====> Epoch: 1000 Average training loss: 1.8544\n",
      "====> Epoch: 1100 Average training loss: 1.7213\n",
      "====> Epoch: 1200 Average training loss: 1.6087\n",
      "====> Epoch: 1300 Average training loss: 1.5068\n",
      "====> Epoch: 1400 Average training loss: 1.4076\n",
      "====> Epoch: 1500 Average training loss: 0.9559\n",
      "====> Epoch: 1600 Average training loss: 0.8035\n",
      "====> Epoch: 1700 Average training loss: 0.7244\n",
      "====> Epoch: 1800 Average training loss: 0.6664\n",
      "====> Epoch: 100 Average training loss: 5.9295\n",
      "====> Epoch: 200 Average training loss: 4.7610\n",
      "====> Epoch: 300 Average training loss: 3.9617\n",
      "====> Epoch: 400 Average training loss: 3.4397\n",
      "====> Epoch: 500 Average training loss: 3.0137\n",
      "====> Epoch: 600 Average training loss: 2.6918\n",
      "====> Epoch: 700 Average training loss: 2.4289\n",
      "====> Epoch: 800 Average training loss: 2.1895\n",
      "====> Epoch: 900 Average training loss: 2.0061\n",
      "====> Epoch: 1000 Average training loss: 1.8430\n",
      "====> Epoch: 1100 Average training loss: 1.7160\n",
      "====> Epoch: 1200 Average training loss: 1.5974\n",
      "====> Epoch: 1300 Average training loss: 1.4859\n",
      "====> Epoch: 1400 Average training loss: 1.3939\n",
      "====> Epoch: 1500 Average training loss: 1.3120\n",
      "====> Epoch: 1600 Average training loss: 1.2380\n",
      "====> Epoch: 1700 Average training loss: 1.1766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1800 Average training loss: 1.1211\n",
      "====> Epoch: 100 Average training loss: 5.9026\n",
      "====> Epoch: 200 Average training loss: 4.7195\n",
      "====> Epoch: 300 Average training loss: 3.9713\n",
      "====> Epoch: 400 Average training loss: 3.4108\n",
      "====> Epoch: 500 Average training loss: 3.0085\n",
      "====> Epoch: 600 Average training loss: 2.6818\n",
      "====> Epoch: 700 Average training loss: 2.4224\n",
      "====> Epoch: 800 Average training loss: 2.2073\n",
      "====> Epoch: 900 Average training loss: 2.0251\n",
      "====> Epoch: 1000 Average training loss: 1.8696\n",
      "====> Epoch: 1100 Average training loss: 1.7398\n",
      "====> Epoch: 1200 Average training loss: 1.6227\n",
      "====> Epoch: 1300 Average training loss: 1.4992\n",
      "====> Epoch: 1400 Average training loss: 1.4087\n",
      "====> Epoch: 1500 Average training loss: 1.3365\n",
      "====> Epoch: 1600 Average training loss: 1.2642\n",
      "====> Epoch: 1700 Average training loss: 1.1923\n",
      "====> Epoch: 1800 Average training loss: 1.1425\n",
      "====> Epoch: 100 Average training loss: 5.9291\n",
      "====> Epoch: 200 Average training loss: 4.7644\n",
      "====> Epoch: 300 Average training loss: 4.0110\n",
      "====> Epoch: 400 Average training loss: 3.4697\n",
      "====> Epoch: 500 Average training loss: 3.0661\n",
      "====> Epoch: 600 Average training loss: 2.7324\n",
      "====> Epoch: 700 Average training loss: 2.4673\n",
      "====> Epoch: 800 Average training loss: 2.2459\n",
      "====> Epoch: 900 Average training loss: 2.0651\n",
      "====> Epoch: 1000 Average training loss: 1.8948\n",
      "====> Epoch: 1100 Average training loss: 1.7383\n",
      "====> Epoch: 1200 Average training loss: 1.6008\n",
      "====> Epoch: 1300 Average training loss: 1.5213\n",
      "====> Epoch: 1400 Average training loss: 1.4410\n",
      "====> Epoch: 1500 Average training loss: 1.3433\n",
      "====> Epoch: 1600 Average training loss: 1.2633\n",
      "====> Epoch: 1700 Average training loss: 1.2011\n",
      "====> Epoch: 1800 Average training loss: 1.1601\n",
      "====> Epoch: 100 Average training loss: 5.8903\n",
      "====> Epoch: 200 Average training loss: 4.7412\n",
      "====> Epoch: 300 Average training loss: 3.9844\n",
      "====> Epoch: 400 Average training loss: 3.4181\n",
      "====> Epoch: 500 Average training loss: 3.0004\n",
      "====> Epoch: 600 Average training loss: 2.6682\n",
      "====> Epoch: 700 Average training loss: 2.4112\n",
      "====> Epoch: 800 Average training loss: 2.1742\n",
      "====> Epoch: 900 Average training loss: 1.9892\n",
      "====> Epoch: 1000 Average training loss: 1.8480\n",
      "====> Epoch: 1100 Average training loss: 1.6960\n",
      "====> Epoch: 1200 Average training loss: 1.5729\n",
      "====> Epoch: 1300 Average training loss: 1.4762\n",
      "====> Epoch: 1400 Average training loss: 1.3674\n",
      "====> Epoch: 1500 Average training loss: 1.2982\n",
      "====> Epoch: 1600 Average training loss: 1.2321\n",
      "====> Epoch: 1700 Average training loss: 1.1594\n",
      "====> Epoch: 1800 Average training loss: 1.1067\n",
      "====> Epoch: 100 Average training loss: 5.9269\n",
      "====> Epoch: 200 Average training loss: 4.7371\n",
      "====> Epoch: 300 Average training loss: 3.9865\n",
      "====> Epoch: 400 Average training loss: 3.4512\n",
      "====> Epoch: 500 Average training loss: 3.0442\n",
      "====> Epoch: 600 Average training loss: 2.7192\n",
      "====> Epoch: 700 Average training loss: 2.4490\n",
      "====> Epoch: 800 Average training loss: 2.2196\n",
      "====> Epoch: 900 Average training loss: 2.0473\n",
      "====> Epoch: 1000 Average training loss: 1.8728\n",
      "====> Epoch: 1100 Average training loss: 1.7442\n",
      "====> Epoch: 1200 Average training loss: 1.6263\n",
      "====> Epoch: 1300 Average training loss: 1.5177\n",
      "====> Epoch: 1400 Average training loss: 1.4271\n",
      "====> Epoch: 1500 Average training loss: 1.3451\n",
      "====> Epoch: 1600 Average training loss: 1.2844\n",
      "====> Epoch: 1700 Average training loss: 1.2031\n",
      "====> Epoch: 1800 Average training loss: 1.1484\n",
      "====> Epoch: 100 Average training loss: 5.9108\n",
      "====> Epoch: 200 Average training loss: 4.7150\n",
      "====> Epoch: 300 Average training loss: 3.9761\n",
      "====> Epoch: 400 Average training loss: 3.4292\n",
      "====> Epoch: 500 Average training loss: 3.0370\n",
      "====> Epoch: 600 Average training loss: 2.6830\n",
      "====> Epoch: 700 Average training loss: 1.9584\n",
      "====> Epoch: 800 Average training loss: 1.6256\n",
      "====> Epoch: 900 Average training loss: 1.3715\n",
      "====> Epoch: 1000 Average training loss: 1.2362\n",
      "====> Epoch: 1100 Average training loss: 1.1253\n",
      "====> Epoch: 1200 Average training loss: 1.0314\n",
      "====> Epoch: 1300 Average training loss: 0.9520\n",
      "====> Epoch: 1400 Average training loss: 0.8823\n",
      "====> Epoch: 1500 Average training loss: 0.8245\n",
      "====> Epoch: 1600 Average training loss: 0.7676\n",
      "====> Epoch: 1700 Average training loss: 0.7190\n",
      "====> Epoch: 1800 Average training loss: 0.6773\n",
      "====> Epoch: 100 Average training loss: 5.9103\n",
      "====> Epoch: 200 Average training loss: 4.7637\n",
      "====> Epoch: 300 Average training loss: 3.9896\n",
      "====> Epoch: 400 Average training loss: 3.4520\n",
      "====> Epoch: 500 Average training loss: 3.0344\n",
      "====> Epoch: 600 Average training loss: 2.7141\n",
      "====> Epoch: 700 Average training loss: 2.4408\n",
      "====> Epoch: 800 Average training loss: 2.2126\n",
      "====> Epoch: 900 Average training loss: 2.0174\n",
      "====> Epoch: 1000 Average training loss: 1.8706\n",
      "====> Epoch: 1100 Average training loss: 1.7173\n",
      "====> Epoch: 1200 Average training loss: 1.6056\n",
      "====> Epoch: 1300 Average training loss: 1.4976\n",
      "====> Epoch: 1400 Average training loss: 1.4022\n",
      "====> Epoch: 1500 Average training loss: 1.3248\n",
      "====> Epoch: 1600 Average training loss: 1.2543\n",
      "====> Epoch: 1700 Average training loss: 1.1883\n",
      "====> Epoch: 1800 Average training loss: 1.1268\n",
      "====> Epoch: 100 Average training loss: 5.9279\n",
      "====> Epoch: 200 Average training loss: 4.7098\n",
      "====> Epoch: 300 Average training loss: 3.9595\n",
      "====> Epoch: 400 Average training loss: 3.4171\n",
      "====> Epoch: 500 Average training loss: 3.0257\n",
      "====> Epoch: 600 Average training loss: 2.6986\n",
      "====> Epoch: 700 Average training loss: 2.4281\n",
      "====> Epoch: 800 Average training loss: 2.2122\n",
      "====> Epoch: 900 Average training loss: 2.0251\n",
      "====> Epoch: 1000 Average training loss: 1.8841\n",
      "====> Epoch: 1100 Average training loss: 1.7396\n",
      "====> Epoch: 1200 Average training loss: 1.6085\n",
      "====> Epoch: 1300 Average training loss: 1.5080\n",
      "====> Epoch: 1400 Average training loss: 1.4168\n",
      "====> Epoch: 1500 Average training loss: 1.3353\n",
      "====> Epoch: 1600 Average training loss: 1.2580\n",
      "====> Epoch: 1700 Average training loss: 1.2057\n",
      "====> Epoch: 1800 Average training loss: 1.1536\n",
      "====> Epoch: 100 Average training loss: 5.9242\n",
      "====> Epoch: 200 Average training loss: 4.7415\n",
      "====> Epoch: 300 Average training loss: 3.9906\n",
      "====> Epoch: 400 Average training loss: 3.4450\n",
      "====> Epoch: 500 Average training loss: 3.0371\n",
      "====> Epoch: 600 Average training loss: 2.7144\n",
      "====> Epoch: 700 Average training loss: 2.4651\n",
      "====> Epoch: 800 Average training loss: 2.2294\n",
      "====> Epoch: 900 Average training loss: 2.0551\n",
      "====> Epoch: 1000 Average training loss: 1.8792\n",
      "====> Epoch: 1100 Average training loss: 1.7425\n",
      "====> Epoch: 1200 Average training loss: 1.6213\n",
      "====> Epoch: 1300 Average training loss: 1.5226\n",
      "====> Epoch: 1400 Average training loss: 1.4156\n",
      "====> Epoch: 1500 Average training loss: 1.3500\n",
      "====> Epoch: 1600 Average training loss: 1.2815\n",
      "====> Epoch: 1700 Average training loss: 1.2069\n",
      "====> Epoch: 1800 Average training loss: 1.1510\n",
      "====> Epoch: 100 Average training loss: 5.9283\n",
      "====> Epoch: 200 Average training loss: 4.7363\n",
      "====> Epoch: 300 Average training loss: 3.9765\n",
      "====> Epoch: 400 Average training loss: 3.4249\n",
      "====> Epoch: 500 Average training loss: 3.0022\n",
      "====> Epoch: 600 Average training loss: 2.6836\n",
      "====> Epoch: 700 Average training loss: 2.4066\n",
      "====> Epoch: 800 Average training loss: 2.1944\n",
      "====> Epoch: 900 Average training loss: 1.9984\n",
      "====> Epoch: 1000 Average training loss: 1.8424\n",
      "====> Epoch: 1100 Average training loss: 1.7055\n",
      "====> Epoch: 1200 Average training loss: 1.5851\n",
      "====> Epoch: 1300 Average training loss: 1.4813\n",
      "====> Epoch: 1400 Average training loss: 1.3861\n",
      "====> Epoch: 1500 Average training loss: 1.3071\n",
      "====> Epoch: 1600 Average training loss: 1.2460\n",
      "====> Epoch: 1700 Average training loss: 1.1756\n",
      "====> Epoch: 1800 Average training loss: 1.1094\n",
      "====> Epoch: 100 Average training loss: 5.9267\n",
      "====> Epoch: 200 Average training loss: 4.6974\n",
      "====> Epoch: 300 Average training loss: 3.9611\n",
      "====> Epoch: 400 Average training loss: 3.4360\n",
      "====> Epoch: 500 Average training loss: 3.0150\n",
      "====> Epoch: 600 Average training loss: 2.6924\n",
      "====> Epoch: 700 Average training loss: 2.4186\n",
      "====> Epoch: 800 Average training loss: 2.2013\n",
      "====> Epoch: 900 Average training loss: 2.0197\n",
      "====> Epoch: 1000 Average training loss: 1.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1100 Average training loss: 1.7235\n",
      "====> Epoch: 1200 Average training loss: 1.6109\n",
      "====> Epoch: 1300 Average training loss: 1.5061\n",
      "====> Epoch: 1400 Average training loss: 1.4174\n",
      "====> Epoch: 1500 Average training loss: 1.3384\n",
      "====> Epoch: 1600 Average training loss: 1.2617\n",
      "====> Epoch: 1700 Average training loss: 1.2016\n",
      "====> Epoch: 1800 Average training loss: 1.1583\n",
      "====> Epoch: 100 Average training loss: 5.9248\n",
      "====> Epoch: 200 Average training loss: 4.7477\n",
      "====> Epoch: 300 Average training loss: 3.9989\n",
      "====> Epoch: 400 Average training loss: 3.4449\n",
      "====> Epoch: 500 Average training loss: 3.0633\n",
      "====> Epoch: 600 Average training loss: 2.7299\n",
      "====> Epoch: 700 Average training loss: 2.4699\n",
      "====> Epoch: 800 Average training loss: 2.2343\n",
      "====> Epoch: 900 Average training loss: 2.0436\n",
      "====> Epoch: 1000 Average training loss: 1.8858\n",
      "====> Epoch: 1100 Average training loss: 1.7525\n",
      "====> Epoch: 1200 Average training loss: 1.6258\n",
      "====> Epoch: 1300 Average training loss: 1.5282\n",
      "====> Epoch: 1400 Average training loss: 1.4351\n",
      "====> Epoch: 1500 Average training loss: 1.3429\n",
      "====> Epoch: 1600 Average training loss: 1.2696\n",
      "====> Epoch: 1700 Average training loss: 1.2082\n",
      "====> Epoch: 1800 Average training loss: 1.1482\n",
      "====> Epoch: 100 Average training loss: 5.9163\n",
      "====> Epoch: 200 Average training loss: 4.7415\n",
      "====> Epoch: 300 Average training loss: 3.9819\n",
      "====> Epoch: 400 Average training loss: 3.4548\n",
      "====> Epoch: 500 Average training loss: 3.0390\n",
      "====> Epoch: 600 Average training loss: 2.7154\n",
      "====> Epoch: 700 Average training loss: 2.4385\n",
      "====> Epoch: 800 Average training loss: 2.2171\n",
      "====> Epoch: 900 Average training loss: 2.0303\n",
      "====> Epoch: 1000 Average training loss: 1.8704\n",
      "====> Epoch: 1100 Average training loss: 1.7398\n",
      "====> Epoch: 1200 Average training loss: 1.6098\n",
      "====> Epoch: 1300 Average training loss: 1.5035\n",
      "====> Epoch: 1400 Average training loss: 1.4053\n",
      "====> Epoch: 1500 Average training loss: 1.3198\n",
      "====> Epoch: 1600 Average training loss: 1.2446\n",
      "====> Epoch: 1700 Average training loss: 1.1705\n",
      "====> Epoch: 1800 Average training loss: 1.0966\n",
      "====> Epoch: 100 Average training loss: 5.9404\n",
      "====> Epoch: 200 Average training loss: 4.7467\n",
      "====> Epoch: 300 Average training loss: 3.9831\n",
      "====> Epoch: 400 Average training loss: 3.4333\n",
      "====> Epoch: 500 Average training loss: 3.0263\n",
      "====> Epoch: 600 Average training loss: 2.6973\n",
      "====> Epoch: 700 Average training loss: 2.4268\n",
      "====> Epoch: 800 Average training loss: 2.1916\n",
      "====> Epoch: 900 Average training loss: 2.0164\n",
      "====> Epoch: 1000 Average training loss: 1.8502\n",
      "====> Epoch: 1100 Average training loss: 1.7206\n",
      "====> Epoch: 1200 Average training loss: 1.5914\n",
      "====> Epoch: 1300 Average training loss: 1.4974\n",
      "====> Epoch: 1400 Average training loss: 1.3957\n",
      "====> Epoch: 1500 Average training loss: 1.3138\n",
      "====> Epoch: 1600 Average training loss: 1.2383\n",
      "====> Epoch: 1700 Average training loss: 1.1857\n",
      "====> Epoch: 1800 Average training loss: 1.1151\n",
      "====> Epoch: 100 Average training loss: 5.9195\n",
      "====> Epoch: 200 Average training loss: 4.7177\n",
      "====> Epoch: 300 Average training loss: 3.9650\n",
      "====> Epoch: 400 Average training loss: 3.4271\n",
      "====> Epoch: 500 Average training loss: 3.0171\n",
      "====> Epoch: 600 Average training loss: 2.6830\n",
      "====> Epoch: 700 Average training loss: 2.4218\n",
      "====> Epoch: 800 Average training loss: 2.2023\n",
      "====> Epoch: 900 Average training loss: 2.0113\n",
      "====> Epoch: 1000 Average training loss: 1.8452\n",
      "====> Epoch: 1100 Average training loss: 1.7142\n",
      "====> Epoch: 1200 Average training loss: 1.5982\n",
      "====> Epoch: 1300 Average training loss: 1.4956\n",
      "====> Epoch: 1400 Average training loss: 1.4010\n",
      "====> Epoch: 1500 Average training loss: 1.3182\n",
      "====> Epoch: 1600 Average training loss: 1.2527\n",
      "====> Epoch: 1700 Average training loss: 1.1980\n",
      "====> Epoch: 1800 Average training loss: 1.1305\n",
      "====> Epoch: 100 Average training loss: 5.9305\n",
      "====> Epoch: 200 Average training loss: 4.7351\n",
      "====> Epoch: 300 Average training loss: 3.9781\n",
      "====> Epoch: 400 Average training loss: 3.4268\n",
      "====> Epoch: 500 Average training loss: 3.0010\n",
      "====> Epoch: 600 Average training loss: 2.6844\n",
      "====> Epoch: 700 Average training loss: 2.4204\n",
      "====> Epoch: 800 Average training loss: 2.1901\n",
      "====> Epoch: 900 Average training loss: 2.0139\n",
      "====> Epoch: 1000 Average training loss: 1.8675\n",
      "====> Epoch: 1100 Average training loss: 1.7199\n",
      "====> Epoch: 1200 Average training loss: 1.6041\n",
      "====> Epoch: 1300 Average training loss: 1.4949\n",
      "====> Epoch: 1400 Average training loss: 1.4127\n",
      "====> Epoch: 1500 Average training loss: 1.3358\n",
      "====> Epoch: 1600 Average training loss: 1.2591\n",
      "====> Epoch: 1700 Average training loss: 1.2038\n",
      "====> Epoch: 1800 Average training loss: 1.1386\n",
      "====> Epoch: 100 Average training loss: 5.9042\n",
      "====> Epoch: 200 Average training loss: 4.7111\n",
      "====> Epoch: 300 Average training loss: 3.9667\n",
      "====> Epoch: 400 Average training loss: 3.4148\n",
      "====> Epoch: 500 Average training loss: 2.9892\n",
      "====> Epoch: 600 Average training loss: 2.6601\n",
      "====> Epoch: 700 Average training loss: 2.3870\n",
      "====> Epoch: 800 Average training loss: 2.1666\n",
      "====> Epoch: 900 Average training loss: 1.9738\n",
      "====> Epoch: 1000 Average training loss: 1.8245\n",
      "====> Epoch: 1100 Average training loss: 1.6839\n",
      "====> Epoch: 1200 Average training loss: 1.5635\n",
      "====> Epoch: 1300 Average training loss: 1.4523\n",
      "====> Epoch: 1400 Average training loss: 1.3619\n",
      "====> Epoch: 1500 Average training loss: 1.2868\n",
      "====> Epoch: 1600 Average training loss: 1.2122\n",
      "====> Epoch: 1700 Average training loss: 1.1513\n",
      "====> Epoch: 1800 Average training loss: 1.0918\n",
      "====> Epoch: 100 Average training loss: 5.9007\n",
      "====> Epoch: 200 Average training loss: 4.7279\n",
      "====> Epoch: 300 Average training loss: 3.9683\n",
      "====> Epoch: 400 Average training loss: 3.4279\n",
      "====> Epoch: 500 Average training loss: 3.0120\n",
      "====> Epoch: 600 Average training loss: 2.6887\n",
      "====> Epoch: 700 Average training loss: 2.4050\n",
      "====> Epoch: 800 Average training loss: 2.1880\n",
      "====> Epoch: 900 Average training loss: 1.9983\n",
      "====> Epoch: 1000 Average training loss: 1.8429\n",
      "====> Epoch: 1100 Average training loss: 1.7004\n",
      "====> Epoch: 1200 Average training loss: 1.5807\n",
      "====> Epoch: 1300 Average training loss: 1.4868\n",
      "====> Epoch: 1400 Average training loss: 1.3911\n",
      "====> Epoch: 1500 Average training loss: 1.3079\n",
      "====> Epoch: 1600 Average training loss: 1.2350\n",
      "====> Epoch: 1700 Average training loss: 1.1716\n",
      "====> Epoch: 1800 Average training loss: 1.1195\n",
      "====> Epoch: 100 Average training loss: 5.9188\n",
      "====> Epoch: 200 Average training loss: 4.7293\n",
      "====> Epoch: 300 Average training loss: 3.9825\n",
      "====> Epoch: 400 Average training loss: 3.4487\n",
      "====> Epoch: 500 Average training loss: 3.0400\n",
      "====> Epoch: 600 Average training loss: 2.7165\n",
      "====> Epoch: 700 Average training loss: 2.4476\n",
      "====> Epoch: 800 Average training loss: 2.2318\n",
      "====> Epoch: 900 Average training loss: 2.0450\n",
      "====> Epoch: 1000 Average training loss: 1.8863\n",
      "====> Epoch: 1100 Average training loss: 1.7477\n",
      "====> Epoch: 1200 Average training loss: 1.6156\n",
      "====> Epoch: 1300 Average training loss: 1.5104\n",
      "====> Epoch: 1400 Average training loss: 1.4149\n",
      "====> Epoch: 1500 Average training loss: 1.3425\n",
      "====> Epoch: 1600 Average training loss: 1.2686\n",
      "====> Epoch: 1700 Average training loss: 1.2034\n",
      "====> Epoch: 1800 Average training loss: 1.1435\n",
      "====> Epoch: 100 Average training loss: 5.8921\n",
      "====> Epoch: 200 Average training loss: 4.7315\n",
      "====> Epoch: 300 Average training loss: 3.9739\n",
      "====> Epoch: 400 Average training loss: 3.4468\n",
      "====> Epoch: 500 Average training loss: 3.0426\n",
      "====> Epoch: 600 Average training loss: 2.7166\n",
      "====> Epoch: 700 Average training loss: 2.4445\n",
      "====> Epoch: 800 Average training loss: 2.2267\n",
      "====> Epoch: 900 Average training loss: 2.0367\n",
      "====> Epoch: 1000 Average training loss: 1.8762\n",
      "====> Epoch: 1100 Average training loss: 1.7393\n",
      "====> Epoch: 1200 Average training loss: 1.6248\n",
      "====> Epoch: 1300 Average training loss: 1.5158\n",
      "====> Epoch: 1400 Average training loss: 1.4273\n",
      "====> Epoch: 1500 Average training loss: 1.3476\n",
      "====> Epoch: 1600 Average training loss: 1.2788\n",
      "====> Epoch: 1700 Average training loss: 1.2070\n",
      "====> Epoch: 1800 Average training loss: 1.1561\n",
      "====> Epoch: 100 Average training loss: 5.9055\n",
      "====> Epoch: 200 Average training loss: 4.7485\n",
      "====> Epoch: 300 Average training loss: 3.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 400 Average training loss: 3.4480\n",
      "====> Epoch: 500 Average training loss: 3.0299\n",
      "====> Epoch: 600 Average training loss: 2.6873\n",
      "====> Epoch: 700 Average training loss: 2.4200\n",
      "====> Epoch: 800 Average training loss: 2.1999\n",
      "====> Epoch: 900 Average training loss: 2.0167\n",
      "====> Epoch: 1000 Average training loss: 1.8575\n",
      "====> Epoch: 1100 Average training loss: 1.7178\n",
      "====> Epoch: 1200 Average training loss: 1.5727\n",
      "====> Epoch: 1300 Average training loss: 1.4652\n",
      "====> Epoch: 1400 Average training loss: 1.3646\n",
      "====> Epoch: 1500 Average training loss: 1.2622\n",
      "====> Epoch: 1600 Average training loss: 1.2109\n",
      "====> Epoch: 1700 Average training loss: 1.1365\n",
      "====> Epoch: 1800 Average training loss: 1.0851\n",
      "====> Epoch: 100 Average training loss: 5.9257\n",
      "====> Epoch: 200 Average training loss: 4.7178\n",
      "====> Epoch: 300 Average training loss: 3.9691\n",
      "====> Epoch: 400 Average training loss: 3.4187\n",
      "====> Epoch: 500 Average training loss: 3.0133\n",
      "====> Epoch: 600 Average training loss: 2.7023\n",
      "====> Epoch: 700 Average training loss: 2.4174\n",
      "====> Epoch: 800 Average training loss: 2.2103\n",
      "====> Epoch: 900 Average training loss: 2.0151\n",
      "====> Epoch: 1000 Average training loss: 1.8755\n",
      "====> Epoch: 1100 Average training loss: 1.7261\n",
      "====> Epoch: 1200 Average training loss: 1.6090\n",
      "====> Epoch: 1300 Average training loss: 1.5077\n",
      "====> Epoch: 1400 Average training loss: 1.4142\n",
      "====> Epoch: 1500 Average training loss: 1.3382\n",
      "====> Epoch: 1600 Average training loss: 1.2570\n",
      "====> Epoch: 1700 Average training loss: 1.1958\n",
      "====> Epoch: 1800 Average training loss: 1.1452\n",
      "====> Epoch: 100 Average training loss: 5.9026\n",
      "====> Epoch: 200 Average training loss: 4.7452\n",
      "====> Epoch: 300 Average training loss: 3.9986\n",
      "====> Epoch: 400 Average training loss: 3.4229\n",
      "====> Epoch: 500 Average training loss: 3.0218\n",
      "====> Epoch: 600 Average training loss: 2.6939\n",
      "====> Epoch: 700 Average training loss: 2.4208\n",
      "====> Epoch: 800 Average training loss: 2.2096\n",
      "====> Epoch: 900 Average training loss: 2.0276\n",
      "====> Epoch: 1000 Average training loss: 1.8690\n",
      "====> Epoch: 1100 Average training loss: 1.7284\n",
      "====> Epoch: 1200 Average training loss: 1.6112\n",
      "====> Epoch: 1300 Average training loss: 1.5094\n",
      "====> Epoch: 1400 Average training loss: 1.4164\n",
      "====> Epoch: 1500 Average training loss: 1.3411\n",
      "====> Epoch: 1600 Average training loss: 1.2712\n",
      "====> Epoch: 1700 Average training loss: 1.2014\n",
      "====> Epoch: 1800 Average training loss: 1.1522\n",
      "====> Epoch: 100 Average training loss: 5.9263\n",
      "====> Epoch: 200 Average training loss: 4.7525\n",
      "====> Epoch: 300 Average training loss: 3.9728\n",
      "====> Epoch: 400 Average training loss: 3.4459\n",
      "====> Epoch: 500 Average training loss: 3.0279\n",
      "====> Epoch: 600 Average training loss: 2.5216\n",
      "====> Epoch: 700 Average training loss: 1.7196\n",
      "====> Epoch: 800 Average training loss: 1.5013\n",
      "====> Epoch: 900 Average training loss: 1.3486\n",
      "====> Epoch: 1000 Average training loss: 1.2208\n",
      "====> Epoch: 1100 Average training loss: 1.1152\n",
      "====> Epoch: 1200 Average training loss: 1.0270\n",
      "====> Epoch: 1300 Average training loss: 0.9519\n",
      "====> Epoch: 1400 Average training loss: 0.8535\n",
      "====> Epoch: 1500 Average training loss: 0.8623\n",
      "====> Epoch: 1600 Average training loss: 0.7194\n",
      "====> Epoch: 1700 Average training loss: 0.6810\n",
      "====> Epoch: 1800 Average training loss: 0.6107\n",
      "====> Epoch: 100 Average training loss: 5.9213\n",
      "====> Epoch: 200 Average training loss: 4.7441\n",
      "====> Epoch: 300 Average training loss: 4.0096\n",
      "====> Epoch: 400 Average training loss: 3.4704\n",
      "====> Epoch: 500 Average training loss: 3.0505\n",
      "====> Epoch: 600 Average training loss: 2.7082\n",
      "====> Epoch: 700 Average training loss: 2.4427\n",
      "====> Epoch: 800 Average training loss: 2.2085\n",
      "====> Epoch: 900 Average training loss: 2.0244\n",
      "====> Epoch: 1000 Average training loss: 1.8408\n",
      "====> Epoch: 1100 Average training loss: 1.6912\n",
      "====> Epoch: 1200 Average training loss: 1.5604\n",
      "====> Epoch: 1300 Average training loss: 1.4444\n",
      "====> Epoch: 1400 Average training loss: 1.3473\n",
      "====> Epoch: 1500 Average training loss: 1.2804\n",
      "====> Epoch: 1600 Average training loss: 1.1921\n",
      "====> Epoch: 1700 Average training loss: 1.1204\n",
      "====> Epoch: 1800 Average training loss: 1.0570\n",
      "====> Epoch: 100 Average training loss: 5.9270\n",
      "====> Epoch: 200 Average training loss: 4.7354\n",
      "====> Epoch: 300 Average training loss: 3.9882\n",
      "====> Epoch: 400 Average training loss: 3.4646\n",
      "====> Epoch: 500 Average training loss: 3.0364\n",
      "====> Epoch: 600 Average training loss: 2.7149\n",
      "====> Epoch: 700 Average training loss: 2.4354\n",
      "====> Epoch: 800 Average training loss: 2.2177\n",
      "====> Epoch: 900 Average training loss: 2.0259\n",
      "====> Epoch: 1000 Average training loss: 1.8935\n",
      "====> Epoch: 1100 Average training loss: 1.7344\n",
      "====> Epoch: 1200 Average training loss: 1.6144\n",
      "====> Epoch: 1300 Average training loss: 1.5165\n",
      "====> Epoch: 1400 Average training loss: 1.4354\n",
      "====> Epoch: 1500 Average training loss: 1.3446\n",
      "====> Epoch: 1600 Average training loss: 1.2740\n",
      "====> Epoch: 1700 Average training loss: 1.2067\n",
      "====> Epoch: 1800 Average training loss: 1.1557\n",
      "====> Epoch: 100 Average training loss: 5.9324\n",
      "====> Epoch: 200 Average training loss: 4.7716\n",
      "====> Epoch: 300 Average training loss: 3.9991\n",
      "====> Epoch: 400 Average training loss: 3.4628\n",
      "====> Epoch: 500 Average training loss: 3.0530\n",
      "====> Epoch: 600 Average training loss: 2.7131\n",
      "====> Epoch: 700 Average training loss: 2.4646\n",
      "====> Epoch: 800 Average training loss: 2.2321\n",
      "====> Epoch: 900 Average training loss: 2.0510\n",
      "====> Epoch: 1000 Average training loss: 1.8970\n",
      "====> Epoch: 1100 Average training loss: 1.7542\n",
      "====> Epoch: 1200 Average training loss: 1.6409\n",
      "====> Epoch: 1300 Average training loss: 1.5260\n",
      "====> Epoch: 1400 Average training loss: 1.4319\n",
      "====> Epoch: 1500 Average training loss: 1.3560\n",
      "====> Epoch: 1600 Average training loss: 1.2821\n",
      "====> Epoch: 1700 Average training loss: 1.2157\n",
      "====> Epoch: 1800 Average training loss: 1.1591\n",
      "====> Epoch: 100 Average training loss: 5.9197\n",
      "====> Epoch: 200 Average training loss: 4.7457\n",
      "====> Epoch: 300 Average training loss: 3.9988\n",
      "====> Epoch: 400 Average training loss: 3.4314\n",
      "====> Epoch: 500 Average training loss: 3.0084\n",
      "====> Epoch: 600 Average training loss: 2.6868\n",
      "====> Epoch: 700 Average training loss: 2.4203\n",
      "====> Epoch: 800 Average training loss: 2.1845\n",
      "====> Epoch: 900 Average training loss: 2.0090\n",
      "====> Epoch: 1000 Average training loss: 1.8342\n",
      "====> Epoch: 1100 Average training loss: 1.7021\n",
      "====> Epoch: 1200 Average training loss: 1.5787\n",
      "====> Epoch: 1300 Average training loss: 1.4793\n",
      "====> Epoch: 1400 Average training loss: 1.3871\n",
      "====> Epoch: 1500 Average training loss: 1.3067\n",
      "====> Epoch: 1600 Average training loss: 1.2418\n",
      "====> Epoch: 1700 Average training loss: 1.1779\n",
      "====> Epoch: 1800 Average training loss: 1.1226\n",
      "====> Epoch: 100 Average training loss: 5.9376\n",
      "====> Epoch: 200 Average training loss: 4.7588\n",
      "====> Epoch: 300 Average training loss: 3.9931\n",
      "====> Epoch: 400 Average training loss: 3.4385\n",
      "====> Epoch: 500 Average training loss: 3.0238\n",
      "====> Epoch: 600 Average training loss: 2.7052\n",
      "====> Epoch: 700 Average training loss: 2.4339\n",
      "====> Epoch: 800 Average training loss: 2.2086\n",
      "====> Epoch: 900 Average training loss: 2.0146\n",
      "====> Epoch: 1000 Average training loss: 1.8519\n",
      "====> Epoch: 1100 Average training loss: 1.7164\n",
      "====> Epoch: 1200 Average training loss: 1.6005\n",
      "====> Epoch: 1300 Average training loss: 1.4878\n",
      "====> Epoch: 1400 Average training loss: 1.3780\n",
      "====> Epoch: 1500 Average training loss: 1.2938\n",
      "====> Epoch: 1600 Average training loss: 1.1943\n",
      "====> Epoch: 1700 Average training loss: 1.1251\n",
      "====> Epoch: 1800 Average training loss: 1.0862\n",
      "====> Epoch: 100 Average training loss: 5.9123\n",
      "====> Epoch: 200 Average training loss: 4.7515\n",
      "====> Epoch: 300 Average training loss: 4.0110\n",
      "====> Epoch: 400 Average training loss: 3.4704\n",
      "====> Epoch: 500 Average training loss: 3.0510\n",
      "====> Epoch: 600 Average training loss: 2.7228\n",
      "====> Epoch: 700 Average training loss: 2.4517\n",
      "====> Epoch: 800 Average training loss: 2.2321\n",
      "====> Epoch: 900 Average training loss: 2.0334\n",
      "====> Epoch: 1000 Average training loss: 1.8878\n",
      "====> Epoch: 1100 Average training loss: 1.7486\n",
      "====> Epoch: 1200 Average training loss: 1.6323\n",
      "====> Epoch: 1300 Average training loss: 1.5370\n",
      "====> Epoch: 1400 Average training loss: 1.4336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1500 Average training loss: 1.3646\n",
      "====> Epoch: 1600 Average training loss: 1.2837\n",
      "====> Epoch: 1700 Average training loss: 1.2302\n",
      "====> Epoch: 1800 Average training loss: 1.1608\n",
      "====> Epoch: 100 Average training loss: 5.9221\n",
      "====> Epoch: 200 Average training loss: 4.7365\n",
      "====> Epoch: 300 Average training loss: 3.9889\n",
      "====> Epoch: 400 Average training loss: 3.4478\n",
      "====> Epoch: 500 Average training loss: 3.0284\n",
      "====> Epoch: 600 Average training loss: 2.6905\n",
      "====> Epoch: 700 Average training loss: 2.4296\n",
      "====> Epoch: 800 Average training loss: 2.1998\n",
      "====> Epoch: 900 Average training loss: 2.0139\n",
      "====> Epoch: 1000 Average training loss: 1.8654\n",
      "====> Epoch: 1100 Average training loss: 1.7236\n",
      "====> Epoch: 1200 Average training loss: 1.5926\n",
      "====> Epoch: 1300 Average training loss: 1.4992\n",
      "====> Epoch: 1400 Average training loss: 1.3889\n",
      "====> Epoch: 1500 Average training loss: 1.3355\n",
      "====> Epoch: 1600 Average training loss: 1.2260\n",
      "====> Epoch: 1700 Average training loss: 1.1386\n",
      "====> Epoch: 1800 Average training loss: 1.1181\n",
      "====> Epoch: 100 Average training loss: 5.9243\n",
      "====> Epoch: 200 Average training loss: 4.7765\n",
      "====> Epoch: 300 Average training loss: 3.9732\n",
      "====> Epoch: 400 Average training loss: 3.4280\n",
      "====> Epoch: 500 Average training loss: 3.0326\n",
      "====> Epoch: 600 Average training loss: 2.7053\n",
      "====> Epoch: 700 Average training loss: 2.4376\n",
      "====> Epoch: 800 Average training loss: 2.2169\n",
      "====> Epoch: 900 Average training loss: 2.0372\n",
      "====> Epoch: 1000 Average training loss: 1.8658\n",
      "====> Epoch: 1100 Average training loss: 1.7415\n",
      "====> Epoch: 1200 Average training loss: 1.6288\n",
      "====> Epoch: 1300 Average training loss: 1.5179\n",
      "====> Epoch: 1400 Average training loss: 1.4297\n",
      "====> Epoch: 1500 Average training loss: 1.3459\n",
      "====> Epoch: 1600 Average training loss: 1.2719\n",
      "====> Epoch: 1700 Average training loss: 1.2089\n",
      "====> Epoch: 1800 Average training loss: 1.1602\n",
      "====> Epoch: 100 Average training loss: 5.9225\n",
      "====> Epoch: 200 Average training loss: 4.7123\n",
      "====> Epoch: 300 Average training loss: 3.9693\n",
      "====> Epoch: 400 Average training loss: 3.4245\n",
      "====> Epoch: 500 Average training loss: 3.0073\n",
      "====> Epoch: 600 Average training loss: 2.6753\n",
      "====> Epoch: 700 Average training loss: 1.9475\n",
      "====> Epoch: 800 Average training loss: 1.6196\n",
      "====> Epoch: 900 Average training loss: 1.3863\n",
      "====> Epoch: 1000 Average training loss: 1.2492\n",
      "====> Epoch: 1100 Average training loss: 1.1361\n",
      "====> Epoch: 1200 Average training loss: 1.0409\n",
      "====> Epoch: 1300 Average training loss: 0.9607\n",
      "====> Epoch: 1400 Average training loss: 0.8902\n",
      "====> Epoch: 1500 Average training loss: 0.8269\n",
      "====> Epoch: 1600 Average training loss: 0.7673\n",
      "====> Epoch: 1700 Average training loss: 0.7170\n",
      "====> Epoch: 1800 Average training loss: 0.6740\n",
      "====> Epoch: 100 Average training loss: 5.9312\n",
      "====> Epoch: 200 Average training loss: 4.7355\n",
      "====> Epoch: 300 Average training loss: 3.9641\n",
      "====> Epoch: 400 Average training loss: 3.4279\n",
      "====> Epoch: 500 Average training loss: 3.0175\n",
      "====> Epoch: 600 Average training loss: 2.6873\n",
      "====> Epoch: 700 Average training loss: 2.4114\n",
      "====> Epoch: 800 Average training loss: 2.2011\n",
      "====> Epoch: 900 Average training loss: 2.0140\n",
      "====> Epoch: 1000 Average training loss: 1.8769\n",
      "====> Epoch: 1100 Average training loss: 1.7122\n",
      "====> Epoch: 1200 Average training loss: 1.6012\n",
      "====> Epoch: 1300 Average training loss: 1.5030\n",
      "====> Epoch: 1400 Average training loss: 1.1867\n",
      "====> Epoch: 1500 Average training loss: 1.0331\n",
      "====> Epoch: 1600 Average training loss: 0.8902\n",
      "====> Epoch: 1700 Average training loss: 0.7782\n",
      "====> Epoch: 1800 Average training loss: 0.6977\n",
      "====> Epoch: 100 Average training loss: 5.9050\n",
      "====> Epoch: 200 Average training loss: 4.7162\n",
      "====> Epoch: 300 Average training loss: 3.9737\n",
      "====> Epoch: 400 Average training loss: 3.4239\n",
      "====> Epoch: 500 Average training loss: 3.0069\n",
      "====> Epoch: 600 Average training loss: 2.6766\n",
      "====> Epoch: 700 Average training loss: 2.4150\n",
      "====> Epoch: 800 Average training loss: 2.2101\n",
      "====> Epoch: 900 Average training loss: 2.0258\n",
      "====> Epoch: 1000 Average training loss: 1.8449\n",
      "====> Epoch: 1100 Average training loss: 1.7194\n",
      "====> Epoch: 1200 Average training loss: 1.6016\n",
      "====> Epoch: 1300 Average training loss: 1.4922\n",
      "====> Epoch: 1400 Average training loss: 1.4029\n",
      "====> Epoch: 1500 Average training loss: 1.3231\n",
      "====> Epoch: 1600 Average training loss: 1.2760\n",
      "====> Epoch: 1700 Average training loss: 1.2043\n",
      "====> Epoch: 1800 Average training loss: 1.1404\n",
      "====> Epoch: 100 Average training loss: 5.9091\n",
      "====> Epoch: 200 Average training loss: 4.7062\n",
      "====> Epoch: 300 Average training loss: 3.9720\n",
      "====> Epoch: 400 Average training loss: 3.4010\n",
      "====> Epoch: 500 Average training loss: 2.9986\n",
      "====> Epoch: 600 Average training loss: 2.6661\n",
      "====> Epoch: 700 Average training loss: 2.4081\n",
      "====> Epoch: 800 Average training loss: 2.1758\n",
      "====> Epoch: 900 Average training loss: 1.9928\n",
      "====> Epoch: 1000 Average training loss: 1.8259\n",
      "====> Epoch: 1100 Average training loss: 1.6970\n",
      "====> Epoch: 1200 Average training loss: 1.5681\n",
      "====> Epoch: 1300 Average training loss: 1.4678\n",
      "====> Epoch: 1400 Average training loss: 1.3737\n",
      "====> Epoch: 1500 Average training loss: 1.2913\n",
      "====> Epoch: 1600 Average training loss: 1.2242\n",
      "====> Epoch: 1700 Average training loss: 1.1627\n",
      "====> Epoch: 1800 Average training loss: 1.1016\n",
      "====> Epoch: 100 Average training loss: 5.9071\n",
      "====> Epoch: 200 Average training loss: 4.7495\n",
      "====> Epoch: 300 Average training loss: 4.0247\n",
      "====> Epoch: 400 Average training loss: 3.4578\n",
      "====> Epoch: 500 Average training loss: 3.0364\n",
      "====> Epoch: 600 Average training loss: 2.7301\n",
      "====> Epoch: 700 Average training loss: 2.4506\n",
      "====> Epoch: 800 Average training loss: 2.2280\n",
      "====> Epoch: 900 Average training loss: 2.0288\n",
      "====> Epoch: 1000 Average training loss: 1.8787\n",
      "====> Epoch: 1100 Average training loss: 1.7311\n",
      "====> Epoch: 1200 Average training loss: 1.6231\n",
      "====> Epoch: 1300 Average training loss: 1.5147\n",
      "====> Epoch: 1400 Average training loss: 1.4283\n",
      "====> Epoch: 1500 Average training loss: 1.3459\n",
      "====> Epoch: 1600 Average training loss: 1.2655\n",
      "====> Epoch: 1700 Average training loss: 1.2087\n",
      "====> Epoch: 1800 Average training loss: 1.1395\n",
      "====> Epoch: 100 Average training loss: 5.9160\n",
      "====> Epoch: 200 Average training loss: 4.7320\n",
      "====> Epoch: 300 Average training loss: 3.9868\n",
      "====> Epoch: 400 Average training loss: 3.4495\n",
      "====> Epoch: 500 Average training loss: 3.0478\n",
      "====> Epoch: 600 Average training loss: 2.7176\n",
      "====> Epoch: 700 Average training loss: 2.4475\n",
      "====> Epoch: 800 Average training loss: 2.2448\n",
      "====> Epoch: 900 Average training loss: 2.0407\n",
      "====> Epoch: 1000 Average training loss: 1.8831\n",
      "====> Epoch: 1100 Average training loss: 1.7408\n",
      "====> Epoch: 1200 Average training loss: 1.6303\n",
      "====> Epoch: 1300 Average training loss: 1.5270\n",
      "====> Epoch: 1400 Average training loss: 1.4244\n",
      "====> Epoch: 1500 Average training loss: 1.3434\n",
      "====> Epoch: 1600 Average training loss: 1.2730\n",
      "====> Epoch: 1700 Average training loss: 1.2106\n",
      "====> Epoch: 1800 Average training loss: 1.1488\n",
      "====> Epoch: 100 Average training loss: 5.9326\n",
      "====> Epoch: 200 Average training loss: 4.7535\n",
      "====> Epoch: 300 Average training loss: 3.9808\n",
      "====> Epoch: 400 Average training loss: 3.4476\n",
      "====> Epoch: 500 Average training loss: 3.0176\n",
      "====> Epoch: 600 Average training loss: 2.6776\n",
      "====> Epoch: 700 Average training loss: 2.4000\n",
      "====> Epoch: 800 Average training loss: 2.1686\n",
      "====> Epoch: 900 Average training loss: 1.9718\n",
      "====> Epoch: 1000 Average training loss: 1.8021\n",
      "====> Epoch: 1100 Average training loss: 1.6814\n",
      "====> Epoch: 1200 Average training loss: 1.5514\n",
      "====> Epoch: 1300 Average training loss: 1.4458\n",
      "====> Epoch: 1400 Average training loss: 1.3604\n",
      "====> Epoch: 1500 Average training loss: 1.2811\n",
      "====> Epoch: 1600 Average training loss: 1.2141\n",
      "====> Epoch: 1700 Average training loss: 1.1424\n",
      "====> Epoch: 1800 Average training loss: 1.1068\n",
      "====> Epoch: 100 Average training loss: 5.9173\n",
      "====> Epoch: 200 Average training loss: 4.7257\n",
      "====> Epoch: 300 Average training loss: 3.9875\n",
      "====> Epoch: 400 Average training loss: 3.4571\n",
      "====> Epoch: 500 Average training loss: 3.0104\n",
      "====> Epoch: 600 Average training loss: 2.6615\n",
      "====> Epoch: 700 Average training loss: 2.3791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 800 Average training loss: 2.1482\n",
      "====> Epoch: 900 Average training loss: 1.9529\n",
      "====> Epoch: 1000 Average training loss: 1.8040\n",
      "====> Epoch: 1100 Average training loss: 1.6569\n",
      "====> Epoch: 1200 Average training loss: 1.5569\n",
      "====> Epoch: 1300 Average training loss: 1.4350\n",
      "====> Epoch: 1400 Average training loss: 1.3407\n",
      "====> Epoch: 1500 Average training loss: 1.2819\n",
      "====> Epoch: 1600 Average training loss: 1.1949\n",
      "====> Epoch: 1700 Average training loss: 1.1424\n",
      "====> Epoch: 1800 Average training loss: 1.0868\n",
      "====> Epoch: 100 Average training loss: 5.9033\n",
      "====> Epoch: 200 Average training loss: 4.7252\n",
      "====> Epoch: 300 Average training loss: 3.9788\n",
      "====> Epoch: 400 Average training loss: 3.4240\n",
      "====> Epoch: 500 Average training loss: 3.0096\n",
      "====> Epoch: 600 Average training loss: 2.6647\n",
      "====> Epoch: 700 Average training loss: 2.4089\n",
      "====> Epoch: 800 Average training loss: 2.1829\n",
      "====> Epoch: 900 Average training loss: 1.9941\n",
      "====> Epoch: 1000 Average training loss: 1.8368\n",
      "====> Epoch: 1100 Average training loss: 1.7091\n",
      "====> Epoch: 1200 Average training loss: 1.5901\n",
      "====> Epoch: 1300 Average training loss: 1.4771\n",
      "====> Epoch: 1400 Average training loss: 1.3965\n",
      "====> Epoch: 1500 Average training loss: 1.3255\n",
      "====> Epoch: 1600 Average training loss: 1.2335\n",
      "====> Epoch: 1700 Average training loss: 1.1778\n",
      "====> Epoch: 1800 Average training loss: 1.1186\n",
      "====> Epoch: 100 Average training loss: 5.9064\n",
      "====> Epoch: 200 Average training loss: 4.7304\n",
      "====> Epoch: 300 Average training loss: 3.9892\n",
      "====> Epoch: 400 Average training loss: 3.4326\n",
      "====> Epoch: 500 Average training loss: 3.0405\n",
      "====> Epoch: 600 Average training loss: 2.7087\n",
      "====> Epoch: 700 Average training loss: 2.4404\n",
      "====> Epoch: 800 Average training loss: 2.2262\n",
      "====> Epoch: 900 Average training loss: 2.0258\n",
      "====> Epoch: 1000 Average training loss: 1.8740\n",
      "====> Epoch: 1100 Average training loss: 1.7314\n",
      "====> Epoch: 1200 Average training loss: 1.6167\n",
      "====> Epoch: 1300 Average training loss: 1.5140\n",
      "====> Epoch: 1400 Average training loss: 1.4159\n",
      "====> Epoch: 1500 Average training loss: 1.3409\n",
      "====> Epoch: 1600 Average training loss: 1.2671\n",
      "====> Epoch: 1700 Average training loss: 1.1970\n",
      "====> Epoch: 1800 Average training loss: 1.1380\n",
      "====> Epoch: 100 Average training loss: 5.9150\n",
      "====> Epoch: 200 Average training loss: 4.7589\n",
      "====> Epoch: 300 Average training loss: 4.0121\n",
      "====> Epoch: 400 Average training loss: 3.4396\n",
      "====> Epoch: 500 Average training loss: 3.0250\n",
      "====> Epoch: 600 Average training loss: 2.6968\n",
      "====> Epoch: 700 Average training loss: 2.4286\n",
      "====> Epoch: 800 Average training loss: 2.2160\n",
      "====> Epoch: 900 Average training loss: 2.0161\n",
      "====> Epoch: 1000 Average training loss: 1.8542\n",
      "====> Epoch: 1100 Average training loss: 1.7174\n",
      "====> Epoch: 1200 Average training loss: 1.5982\n",
      "====> Epoch: 1300 Average training loss: 1.4992\n",
      "====> Epoch: 1400 Average training loss: 1.4029\n",
      "====> Epoch: 1500 Average training loss: 1.3304\n",
      "====> Epoch: 1600 Average training loss: 1.2562\n",
      "====> Epoch: 1700 Average training loss: 1.1966\n",
      "====> Epoch: 1800 Average training loss: 1.1323\n",
      "====> Epoch: 100 Average training loss: 5.9150\n",
      "====> Epoch: 200 Average training loss: 4.7413\n",
      "====> Epoch: 300 Average training loss: 3.9830\n",
      "====> Epoch: 400 Average training loss: 3.4453\n",
      "====> Epoch: 500 Average training loss: 3.0453\n",
      "====> Epoch: 600 Average training loss: 2.6875\n",
      "====> Epoch: 700 Average training loss: 2.4338\n",
      "====> Epoch: 800 Average training loss: 2.2011\n",
      "====> Epoch: 900 Average training loss: 2.0176\n",
      "====> Epoch: 1000 Average training loss: 1.8564\n",
      "====> Epoch: 1100 Average training loss: 1.7201\n",
      "====> Epoch: 1200 Average training loss: 1.5938\n",
      "====> Epoch: 1300 Average training loss: 1.4936\n",
      "====> Epoch: 1400 Average training loss: 1.3960\n",
      "====> Epoch: 1500 Average training loss: 1.3192\n",
      "====> Epoch: 1600 Average training loss: 1.2421\n",
      "====> Epoch: 1700 Average training loss: 1.1778\n",
      "====> Epoch: 1800 Average training loss: 1.1296\n",
      "====> Epoch: 100 Average training loss: 5.9310\n",
      "====> Epoch: 200 Average training loss: 4.7498\n",
      "====> Epoch: 300 Average training loss: 3.9757\n",
      "====> Epoch: 400 Average training loss: 3.4511\n",
      "====> Epoch: 500 Average training loss: 3.0195\n",
      "====> Epoch: 600 Average training loss: 2.6914\n",
      "====> Epoch: 700 Average training loss: 2.4193\n",
      "====> Epoch: 800 Average training loss: 2.2074\n",
      "====> Epoch: 900 Average training loss: 1.7780\n",
      "====> Epoch: 1000 Average training loss: 1.5467\n",
      "====> Epoch: 1100 Average training loss: 1.3744\n",
      "====> Epoch: 1200 Average training loss: 1.1538\n",
      "====> Epoch: 1300 Average training loss: 1.0044\n",
      "====> Epoch: 1400 Average training loss: 0.9081\n",
      "====> Epoch: 1500 Average training loss: 0.8419\n",
      "====> Epoch: 1600 Average training loss: 0.7711\n",
      "====> Epoch: 1700 Average training loss: 0.7058\n",
      "====> Epoch: 1800 Average training loss: 0.6561\n",
      "====> Epoch: 100 Average training loss: 5.9273\n",
      "====> Epoch: 200 Average training loss: 4.7374\n",
      "====> Epoch: 300 Average training loss: 3.9884\n",
      "====> Epoch: 400 Average training loss: 3.4288\n",
      "====> Epoch: 500 Average training loss: 3.0262\n",
      "====> Epoch: 600 Average training loss: 2.6923\n",
      "====> Epoch: 700 Average training loss: 2.4283\n",
      "====> Epoch: 800 Average training loss: 2.2048\n",
      "====> Epoch: 900 Average training loss: 2.0178\n",
      "====> Epoch: 1000 Average training loss: 1.8730\n",
      "====> Epoch: 1100 Average training loss: 1.7332\n",
      "====> Epoch: 1200 Average training loss: 1.6067\n",
      "====> Epoch: 1300 Average training loss: 1.5039\n",
      "====> Epoch: 1400 Average training loss: 1.4094\n",
      "====> Epoch: 1500 Average training loss: 1.3352\n",
      "====> Epoch: 1600 Average training loss: 1.2766\n",
      "====> Epoch: 1700 Average training loss: 1.2001\n",
      "====> Epoch: 1800 Average training loss: 1.1437\n",
      "====> Epoch: 100 Average training loss: 5.9333\n",
      "====> Epoch: 200 Average training loss: 4.7461\n",
      "====> Epoch: 300 Average training loss: 3.9819\n",
      "====> Epoch: 400 Average training loss: 3.4404\n",
      "====> Epoch: 500 Average training loss: 3.0249\n",
      "====> Epoch: 600 Average training loss: 2.6985\n",
      "====> Epoch: 700 Average training loss: 2.4171\n",
      "====> Epoch: 800 Average training loss: 2.2017\n",
      "====> Epoch: 900 Average training loss: 2.0152\n",
      "====> Epoch: 1000 Average training loss: 1.8484\n",
      "====> Epoch: 1100 Average training loss: 1.7129\n",
      "====> Epoch: 1200 Average training loss: 1.5993\n",
      "====> Epoch: 1300 Average training loss: 1.5032\n",
      "====> Epoch: 1400 Average training loss: 1.4062\n",
      "====> Epoch: 1500 Average training loss: 1.3276\n",
      "====> Epoch: 1600 Average training loss: 1.2549\n",
      "====> Epoch: 1700 Average training loss: 1.2015\n",
      "====> Epoch: 1800 Average training loss: 1.1357\n",
      "====> Epoch: 100 Average training loss: 5.9518\n",
      "====> Epoch: 200 Average training loss: 4.7388\n",
      "====> Epoch: 300 Average training loss: 3.9768\n",
      "====> Epoch: 400 Average training loss: 3.4115\n",
      "====> Epoch: 500 Average training loss: 3.0009\n",
      "====> Epoch: 600 Average training loss: 2.6844\n",
      "====> Epoch: 700 Average training loss: 2.4058\n",
      "====> Epoch: 800 Average training loss: 2.1892\n",
      "====> Epoch: 900 Average training loss: 1.9990\n",
      "====> Epoch: 1000 Average training loss: 1.8456\n",
      "====> Epoch: 1100 Average training loss: 1.7043\n",
      "====> Epoch: 1200 Average training loss: 1.5818\n",
      "====> Epoch: 1300 Average training loss: 1.4848\n",
      "====> Epoch: 1400 Average training loss: 1.3870\n",
      "====> Epoch: 1500 Average training loss: 1.3098\n",
      "====> Epoch: 1600 Average training loss: 1.2388\n",
      "====> Epoch: 1700 Average training loss: 1.1745\n",
      "====> Epoch: 1800 Average training loss: 1.1242\n",
      "====> Epoch: 100 Average training loss: 5.9196\n",
      "====> Epoch: 200 Average training loss: 4.7299\n",
      "====> Epoch: 300 Average training loss: 3.9770\n",
      "====> Epoch: 400 Average training loss: 3.4212\n",
      "====> Epoch: 500 Average training loss: 3.0309\n",
      "====> Epoch: 600 Average training loss: 2.6835\n",
      "====> Epoch: 700 Average training loss: 2.4252\n",
      "====> Epoch: 800 Average training loss: 2.2008\n",
      "====> Epoch: 900 Average training loss: 2.0050\n",
      "====> Epoch: 1000 Average training loss: 1.8480\n",
      "====> Epoch: 1100 Average training loss: 1.7065\n",
      "====> Epoch: 1200 Average training loss: 1.5992\n",
      "====> Epoch: 1300 Average training loss: 1.4920\n",
      "====> Epoch: 1400 Average training loss: 1.3962\n",
      "====> Epoch: 1500 Average training loss: 1.3212\n",
      "====> Epoch: 1600 Average training loss: 1.2490\n",
      "====> Epoch: 1700 Average training loss: 1.1787\n",
      "====> Epoch: 1800 Average training loss: 1.1253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 100 Average training loss: 5.9057\n",
      "====> Epoch: 200 Average training loss: 4.7369\n",
      "====> Epoch: 300 Average training loss: 3.9790\n",
      "====> Epoch: 400 Average training loss: 3.4283\n",
      "====> Epoch: 500 Average training loss: 3.0211\n",
      "====> Epoch: 600 Average training loss: 2.7007\n",
      "====> Epoch: 700 Average training loss: 2.4393\n",
      "====> Epoch: 800 Average training loss: 2.1890\n",
      "====> Epoch: 900 Average training loss: 2.0168\n",
      "====> Epoch: 1000 Average training loss: 1.8556\n",
      "====> Epoch: 1100 Average training loss: 1.7123\n",
      "====> Epoch: 1200 Average training loss: 1.6053\n",
      "====> Epoch: 1300 Average training loss: 1.4864\n",
      "====> Epoch: 1400 Average training loss: 1.4059\n",
      "====> Epoch: 1500 Average training loss: 1.3210\n",
      "====> Epoch: 1600 Average training loss: 1.2445\n",
      "====> Epoch: 1700 Average training loss: 1.1813\n",
      "====> Epoch: 1800 Average training loss: 1.1342\n",
      "====> Epoch: 100 Average training loss: 5.9161\n",
      "====> Epoch: 200 Average training loss: 4.7592\n",
      "====> Epoch: 300 Average training loss: 3.9920\n",
      "====> Epoch: 400 Average training loss: 3.4459\n",
      "====> Epoch: 500 Average training loss: 3.0516\n",
      "====> Epoch: 600 Average training loss: 2.7123\n",
      "====> Epoch: 700 Average training loss: 2.4466\n",
      "====> Epoch: 800 Average training loss: 2.2318\n",
      "====> Epoch: 900 Average training loss: 2.0356\n",
      "====> Epoch: 1000 Average training loss: 1.8593\n",
      "====> Epoch: 1100 Average training loss: 1.7337\n",
      "====> Epoch: 1200 Average training loss: 1.6071\n",
      "====> Epoch: 1300 Average training loss: 1.5062\n",
      "====> Epoch: 1400 Average training loss: 1.4132\n",
      "====> Epoch: 1500 Average training loss: 1.3216\n",
      "====> Epoch: 1600 Average training loss: 1.2565\n",
      "====> Epoch: 1700 Average training loss: 1.1932\n",
      "====> Epoch: 1800 Average training loss: 1.1301\n",
      "====> Epoch: 100 Average training loss: 5.9244\n",
      "====> Epoch: 200 Average training loss: 4.7632\n",
      "====> Epoch: 300 Average training loss: 3.9666\n",
      "====> Epoch: 400 Average training loss: 3.4307\n",
      "====> Epoch: 500 Average training loss: 3.0234\n",
      "====> Epoch: 600 Average training loss: 2.6940\n",
      "====> Epoch: 700 Average training loss: 2.4177\n",
      "====> Epoch: 800 Average training loss: 2.1977\n",
      "====> Epoch: 900 Average training loss: 2.0184\n",
      "====> Epoch: 1000 Average training loss: 1.8548\n",
      "====> Epoch: 1100 Average training loss: 1.7168\n",
      "====> Epoch: 1200 Average training loss: 1.5937\n",
      "====> Epoch: 1300 Average training loss: 1.4964\n",
      "====> Epoch: 1400 Average training loss: 1.4033\n",
      "====> Epoch: 1500 Average training loss: 1.3295\n",
      "====> Epoch: 1600 Average training loss: 1.2520\n",
      "====> Epoch: 1700 Average training loss: 1.1880\n",
      "====> Epoch: 1800 Average training loss: 1.1268\n",
      "====> Epoch: 100 Average training loss: 5.9292\n",
      "====> Epoch: 200 Average training loss: 4.7541\n",
      "====> Epoch: 300 Average training loss: 3.1051\n",
      "====> Epoch: 400 Average training loss: 2.5726\n",
      "====> Epoch: 500 Average training loss: 2.2050\n",
      "====> Epoch: 600 Average training loss: 1.9291\n",
      "====> Epoch: 700 Average training loss: 1.7033\n",
      "====> Epoch: 800 Average training loss: 1.5139\n",
      "====> Epoch: 900 Average training loss: 1.3608\n",
      "====> Epoch: 1000 Average training loss: 1.2292\n",
      "====> Epoch: 1100 Average training loss: 1.1155\n",
      "====> Epoch: 1200 Average training loss: 1.0212\n",
      "====> Epoch: 1300 Average training loss: 0.9415\n",
      "====> Epoch: 1400 Average training loss: 0.8665\n",
      "====> Epoch: 1500 Average training loss: 0.8047\n",
      "====> Epoch: 1600 Average training loss: 0.7528\n",
      "====> Epoch: 1700 Average training loss: 0.7005\n",
      "====> Epoch: 1800 Average training loss: 0.6591\n",
      "====> Epoch: 100 Average training loss: 5.9168\n",
      "====> Epoch: 200 Average training loss: 4.7490\n",
      "====> Epoch: 300 Average training loss: 3.9948\n",
      "====> Epoch: 400 Average training loss: 3.4631\n",
      "====> Epoch: 500 Average training loss: 3.0420\n",
      "====> Epoch: 600 Average training loss: 2.7001\n",
      "====> Epoch: 700 Average training loss: 2.5165\n",
      "====> Epoch: 800 Average training loss: 2.2434\n",
      "====> Epoch: 900 Average training loss: 1.9866\n",
      "====> Epoch: 1000 Average training loss: 1.5857\n",
      "====> Epoch: 1100 Average training loss: 1.4415\n",
      "====> Epoch: 1200 Average training loss: 1.3040\n",
      "====> Epoch: 1300 Average training loss: 1.2764\n",
      "====> Epoch: 1400 Average training loss: 1.1376\n",
      "====> Epoch: 1500 Average training loss: 1.0297\n",
      "====> Epoch: 1600 Average training loss: 1.0222\n",
      "====> Epoch: 1700 Average training loss: 0.9411\n",
      "====> Epoch: 1800 Average training loss: 0.8803\n",
      "====> Epoch: 100 Average training loss: 5.9206\n",
      "====> Epoch: 200 Average training loss: 4.7341\n",
      "====> Epoch: 300 Average training loss: 4.0000\n",
      "====> Epoch: 400 Average training loss: 3.4463\n",
      "====> Epoch: 500 Average training loss: 3.0432\n",
      "====> Epoch: 600 Average training loss: 2.7152\n",
      "====> Epoch: 700 Average training loss: 2.4262\n",
      "====> Epoch: 800 Average training loss: 2.2152\n",
      "====> Epoch: 900 Average training loss: 2.0223\n",
      "====> Epoch: 1000 Average training loss: 1.8581\n",
      "====> Epoch: 1100 Average training loss: 1.7297\n",
      "====> Epoch: 1200 Average training loss: 1.6062\n",
      "====> Epoch: 1300 Average training loss: 1.4942\n",
      "====> Epoch: 1400 Average training loss: 1.4059\n",
      "====> Epoch: 1500 Average training loss: 1.3251\n",
      "====> Epoch: 1600 Average training loss: 1.2512\n",
      "====> Epoch: 1700 Average training loss: 1.1738\n",
      "====> Epoch: 1800 Average training loss: 1.1073\n",
      "====> Epoch: 100 Average training loss: 5.9031\n",
      "====> Epoch: 200 Average training loss: 4.7185\n",
      "====> Epoch: 300 Average training loss: 3.9639\n",
      "====> Epoch: 400 Average training loss: 3.4292\n",
      "====> Epoch: 500 Average training loss: 2.9968\n",
      "====> Epoch: 600 Average training loss: 2.6847\n",
      "====> Epoch: 700 Average training loss: 1.8010\n",
      "====> Epoch: 800 Average training loss: 1.5417\n",
      "====> Epoch: 900 Average training loss: 1.3610\n",
      "====> Epoch: 1000 Average training loss: 1.2202\n",
      "====> Epoch: 1100 Average training loss: 1.1038\n",
      "====> Epoch: 1200 Average training loss: 1.0018\n",
      "====> Epoch: 1300 Average training loss: 0.9193\n",
      "====> Epoch: 1400 Average training loss: 0.8460\n",
      "====> Epoch: 1500 Average training loss: 0.7804\n",
      "====> Epoch: 1600 Average training loss: 0.7242\n",
      "====> Epoch: 1700 Average training loss: 0.6725\n",
      "====> Epoch: 1800 Average training loss: 0.6290\n",
      "====> Epoch: 100 Average training loss: 5.9121\n",
      "====> Epoch: 200 Average training loss: 4.7312\n",
      "====> Epoch: 300 Average training loss: 3.9563\n",
      "====> Epoch: 400 Average training loss: 3.4168\n",
      "====> Epoch: 500 Average training loss: 3.0037\n",
      "====> Epoch: 600 Average training loss: 2.6968\n",
      "====> Epoch: 700 Average training loss: 2.4155\n",
      "====> Epoch: 800 Average training loss: 2.2057\n",
      "====> Epoch: 900 Average training loss: 2.0340\n",
      "====> Epoch: 1000 Average training loss: 1.8631\n",
      "====> Epoch: 1100 Average training loss: 1.7350\n",
      "====> Epoch: 1200 Average training loss: 1.5991\n",
      "====> Epoch: 1300 Average training loss: 1.5058\n",
      "====> Epoch: 1400 Average training loss: 1.4170\n",
      "====> Epoch: 1500 Average training loss: 1.3387\n",
      "====> Epoch: 1600 Average training loss: 1.2659\n",
      "====> Epoch: 1700 Average training loss: 1.2046\n",
      "====> Epoch: 1800 Average training loss: 1.1490\n",
      "====> Epoch: 100 Average training loss: 5.9141\n",
      "====> Epoch: 200 Average training loss: 4.7598\n",
      "====> Epoch: 300 Average training loss: 4.0116\n",
      "====> Epoch: 400 Average training loss: 3.4608\n",
      "====> Epoch: 500 Average training loss: 3.0464\n",
      "====> Epoch: 600 Average training loss: 2.7069\n",
      "====> Epoch: 700 Average training loss: 2.4425\n",
      "====> Epoch: 800 Average training loss: 1.9259\n",
      "====> Epoch: 900 Average training loss: 1.4339\n",
      "====> Epoch: 1000 Average training loss: 1.2521\n",
      "====> Epoch: 1100 Average training loss: 1.1226\n",
      "====> Epoch: 1200 Average training loss: 1.0217\n",
      "====> Epoch: 1300 Average training loss: 0.9384\n",
      "====> Epoch: 1400 Average training loss: 0.8673\n",
      "====> Epoch: 1500 Average training loss: 0.8071\n",
      "====> Epoch: 1600 Average training loss: 0.7534\n",
      "====> Epoch: 1700 Average training loss: 0.7061\n",
      "====> Epoch: 1800 Average training loss: 0.6643\n",
      "====> Epoch: 100 Average training loss: 5.9031\n",
      "====> Epoch: 200 Average training loss: 4.7381\n",
      "====> Epoch: 300 Average training loss: 3.9858\n",
      "====> Epoch: 400 Average training loss: 3.4361\n",
      "====> Epoch: 500 Average training loss: 3.0185\n",
      "====> Epoch: 600 Average training loss: 2.6994\n",
      "====> Epoch: 700 Average training loss: 2.4269\n",
      "====> Epoch: 800 Average training loss: 2.1932\n",
      "====> Epoch: 900 Average training loss: 2.0099\n",
      "====> Epoch: 1000 Average training loss: 1.8450\n",
      "====> Epoch: 1100 Average training loss: 1.7082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1200 Average training loss: 1.5791\n",
      "====> Epoch: 1300 Average training loss: 1.4789\n",
      "====> Epoch: 1400 Average training loss: 1.3975\n",
      "====> Epoch: 1500 Average training loss: 1.3026\n",
      "====> Epoch: 1600 Average training loss: 1.2264\n",
      "====> Epoch: 1700 Average training loss: 1.1511\n",
      "====> Epoch: 1800 Average training loss: 1.0825\n",
      "====> Epoch: 100 Average training loss: 5.9191\n",
      "====> Epoch: 200 Average training loss: 4.7447\n",
      "====> Epoch: 300 Average training loss: 3.9955\n",
      "====> Epoch: 400 Average training loss: 3.4501\n",
      "====> Epoch: 500 Average training loss: 3.0308\n",
      "====> Epoch: 600 Average training loss: 2.7143\n",
      "====> Epoch: 700 Average training loss: 2.4311\n",
      "====> Epoch: 800 Average training loss: 2.2029\n",
      "====> Epoch: 900 Average training loss: 1.9847\n",
      "====> Epoch: 1000 Average training loss: 1.8585\n",
      "====> Epoch: 1100 Average training loss: 1.7127\n",
      "====> Epoch: 1200 Average training loss: 1.6194\n",
      "====> Epoch: 1300 Average training loss: 1.4430\n",
      "====> Epoch: 1400 Average training loss: 1.3740\n",
      "====> Epoch: 1500 Average training loss: 1.2976\n",
      "====> Epoch: 1600 Average training loss: 1.2053\n",
      "====> Epoch: 1700 Average training loss: 1.0711\n",
      "====> Epoch: 1800 Average training loss: 1.0080\n",
      "====> Epoch: 100 Average training loss: 5.9170\n",
      "====> Epoch: 200 Average training loss: 4.7490\n",
      "====> Epoch: 300 Average training loss: 3.9840\n",
      "====> Epoch: 400 Average training loss: 3.4385\n",
      "====> Epoch: 500 Average training loss: 3.0237\n",
      "====> Epoch: 600 Average training loss: 2.6784\n",
      "====> Epoch: 700 Average training loss: 2.4419\n",
      "====> Epoch: 800 Average training loss: 2.2243\n",
      "====> Epoch: 900 Average training loss: 2.0317\n",
      "====> Epoch: 1000 Average training loss: 1.8801\n",
      "====> Epoch: 1100 Average training loss: 1.7352\n",
      "====> Epoch: 1200 Average training loss: 1.6162\n",
      "====> Epoch: 1300 Average training loss: 1.4983\n",
      "====> Epoch: 1400 Average training loss: 1.4080\n",
      "====> Epoch: 1500 Average training loss: 1.3262\n",
      "====> Epoch: 1600 Average training loss: 1.2329\n",
      "====> Epoch: 1700 Average training loss: 1.1626\n",
      "====> Epoch: 1800 Average training loss: 1.1073\n",
      "====> Epoch: 100 Average training loss: 5.9134\n",
      "====> Epoch: 200 Average training loss: 4.7567\n",
      "====> Epoch: 300 Average training loss: 3.9974\n",
      "====> Epoch: 400 Average training loss: 3.4706\n",
      "====> Epoch: 500 Average training loss: 3.0443\n",
      "====> Epoch: 600 Average training loss: 2.7010\n",
      "====> Epoch: 700 Average training loss: 2.4310\n",
      "====> Epoch: 800 Average training loss: 2.2051\n",
      "====> Epoch: 900 Average training loss: 2.0494\n",
      "====> Epoch: 1000 Average training loss: 1.8364\n",
      "====> Epoch: 1100 Average training loss: 1.7332\n",
      "====> Epoch: 1200 Average training loss: 1.5704\n",
      "====> Epoch: 1300 Average training loss: 1.5408\n",
      "====> Epoch: 1400 Average training loss: 1.4122\n",
      "====> Epoch: 1500 Average training loss: 1.3271\n",
      "====> Epoch: 1600 Average training loss: 1.2479\n",
      "====> Epoch: 1700 Average training loss: 1.1958\n",
      "====> Epoch: 1800 Average training loss: 1.1302\n",
      "====> Epoch: 100 Average training loss: 5.9102\n",
      "====> Epoch: 200 Average training loss: 4.7408\n",
      "====> Epoch: 300 Average training loss: 3.9912\n",
      "====> Epoch: 400 Average training loss: 3.4500\n",
      "====> Epoch: 500 Average training loss: 3.0501\n",
      "====> Epoch: 600 Average training loss: 2.7341\n",
      "====> Epoch: 700 Average training loss: 2.4432\n",
      "====> Epoch: 800 Average training loss: 2.2268\n",
      "====> Epoch: 900 Average training loss: 2.0439\n",
      "====> Epoch: 1000 Average training loss: 1.8744\n",
      "====> Epoch: 1100 Average training loss: 1.7250\n",
      "====> Epoch: 1200 Average training loss: 1.6080\n",
      "====> Epoch: 1300 Average training loss: 1.5040\n",
      "====> Epoch: 1400 Average training loss: 1.4130\n",
      "====> Epoch: 1500 Average training loss: 1.3384\n",
      "====> Epoch: 1600 Average training loss: 1.2631\n",
      "====> Epoch: 1700 Average training loss: 1.2083\n",
      "====> Epoch: 1800 Average training loss: 1.1540\n",
      "====> Epoch: 100 Average training loss: 5.9178\n",
      "====> Epoch: 200 Average training loss: 4.7320\n",
      "====> Epoch: 300 Average training loss: 3.9840\n",
      "====> Epoch: 400 Average training loss: 3.4405\n",
      "====> Epoch: 500 Average training loss: 3.0274\n",
      "====> Epoch: 600 Average training loss: 2.6949\n",
      "====> Epoch: 700 Average training loss: 2.4327\n",
      "====> Epoch: 800 Average training loss: 2.2180\n",
      "====> Epoch: 900 Average training loss: 2.0267\n",
      "====> Epoch: 1000 Average training loss: 1.8669\n",
      "====> Epoch: 1100 Average training loss: 1.7158\n",
      "====> Epoch: 1200 Average training loss: 1.6003\n",
      "====> Epoch: 1300 Average training loss: 1.4979\n",
      "====> Epoch: 1400 Average training loss: 1.4140\n",
      "====> Epoch: 1500 Average training loss: 1.3203\n",
      "====> Epoch: 1600 Average training loss: 1.2398\n",
      "====> Epoch: 1700 Average training loss: 1.1595\n",
      "====> Epoch: 1800 Average training loss: 1.0776\n",
      "====> Epoch: 100 Average training loss: 5.9168\n",
      "====> Epoch: 200 Average training loss: 4.7174\n",
      "====> Epoch: 300 Average training loss: 3.9497\n",
      "====> Epoch: 400 Average training loss: 3.4336\n",
      "====> Epoch: 500 Average training loss: 3.0119\n",
      "====> Epoch: 600 Average training loss: 2.7018\n",
      "====> Epoch: 700 Average training loss: 1.9205\n",
      "====> Epoch: 800 Average training loss: 1.5707\n",
      "====> Epoch: 900 Average training loss: 1.4008\n",
      "====> Epoch: 1000 Average training loss: 1.2652\n",
      "====> Epoch: 1100 Average training loss: 1.1462\n",
      "====> Epoch: 1200 Average training loss: 1.0412\n",
      "====> Epoch: 1300 Average training loss: 0.9536\n",
      "====> Epoch: 1400 Average training loss: 0.8778\n",
      "====> Epoch: 1500 Average training loss: 0.8131\n",
      "====> Epoch: 1600 Average training loss: 0.7568\n",
      "====> Epoch: 1700 Average training loss: 0.7054\n",
      "====> Epoch: 1800 Average training loss: 0.6607\n",
      "====> Epoch: 100 Average training loss: 5.9283\n",
      "====> Epoch: 200 Average training loss: 4.7369\n",
      "====> Epoch: 300 Average training loss: 3.9896\n",
      "====> Epoch: 400 Average training loss: 3.4354\n",
      "====> Epoch: 500 Average training loss: 3.0200\n",
      "====> Epoch: 600 Average training loss: 2.6987\n",
      "====> Epoch: 700 Average training loss: 2.2363\n",
      "====> Epoch: 800 Average training loss: 1.6295\n",
      "====> Epoch: 900 Average training loss: 1.3989\n",
      "====> Epoch: 1000 Average training loss: 1.2422\n",
      "====> Epoch: 1100 Average training loss: 1.1264\n",
      "====> Epoch: 1200 Average training loss: 1.0290\n",
      "====> Epoch: 1300 Average training loss: 0.9489\n",
      "====> Epoch: 1400 Average training loss: 0.8778\n",
      "====> Epoch: 1500 Average training loss: 0.8150\n",
      "====> Epoch: 1600 Average training loss: 0.7601\n",
      "====> Epoch: 1700 Average training loss: 0.7114\n",
      "====> Epoch: 1800 Average training loss: 0.6687\n",
      "====> Epoch: 100 Average training loss: 5.9114\n",
      "====> Epoch: 200 Average training loss: 4.7371\n",
      "====> Epoch: 300 Average training loss: 3.9835\n",
      "====> Epoch: 400 Average training loss: 3.1717\n",
      "====> Epoch: 500 Average training loss: 2.4656\n",
      "====> Epoch: 600 Average training loss: 1.9911\n",
      "====> Epoch: 700 Average training loss: 1.7378\n",
      "====> Epoch: 800 Average training loss: 1.5369\n",
      "====> Epoch: 900 Average training loss: 1.3862\n",
      "====> Epoch: 1000 Average training loss: 1.2413\n",
      "====> Epoch: 1100 Average training loss: 1.1317\n",
      "====> Epoch: 1200 Average training loss: 1.0360\n",
      "====> Epoch: 1300 Average training loss: 0.9493\n",
      "====> Epoch: 1400 Average training loss: 0.8754\n",
      "====> Epoch: 1500 Average training loss: 0.8104\n",
      "====> Epoch: 1600 Average training loss: 0.7540\n",
      "====> Epoch: 1700 Average training loss: 0.7013\n",
      "====> Epoch: 1800 Average training loss: 0.6591\n",
      "====> Epoch: 100 Average training loss: 5.9177\n",
      "====> Epoch: 200 Average training loss: 4.7192\n",
      "====> Epoch: 300 Average training loss: 3.9822\n",
      "====> Epoch: 400 Average training loss: 3.4590\n",
      "====> Epoch: 500 Average training loss: 3.0609\n",
      "====> Epoch: 600 Average training loss: 2.7365\n",
      "====> Epoch: 700 Average training loss: 2.4649\n",
      "====> Epoch: 800 Average training loss: 2.2467\n",
      "====> Epoch: 900 Average training loss: 2.0516\n",
      "====> Epoch: 1000 Average training loss: 1.8873\n",
      "====> Epoch: 1100 Average training loss: 1.7580\n",
      "====> Epoch: 1200 Average training loss: 1.6296\n",
      "====> Epoch: 1300 Average training loss: 1.3912\n",
      "====> Epoch: 1400 Average training loss: 1.2755\n",
      "====> Epoch: 1500 Average training loss: 1.1768\n",
      "====> Epoch: 1600 Average training loss: 1.1128\n",
      "====> Epoch: 1700 Average training loss: 1.0071\n",
      "====> Epoch: 1800 Average training loss: 0.9628\n",
      "====> Epoch: 100 Average training loss: 5.9271\n",
      "====> Epoch: 200 Average training loss: 4.7419\n",
      "====> Epoch: 300 Average training loss: 3.9834\n",
      "====> Epoch: 400 Average training loss: 3.4432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 500 Average training loss: 3.0319\n",
      "====> Epoch: 600 Average training loss: 2.7015\n",
      "====> Epoch: 700 Average training loss: 2.4363\n",
      "====> Epoch: 800 Average training loss: 2.2123\n",
      "====> Epoch: 900 Average training loss: 2.0248\n",
      "====> Epoch: 1000 Average training loss: 1.8626\n",
      "====> Epoch: 1100 Average training loss: 1.7358\n",
      "====> Epoch: 1200 Average training loss: 1.6025\n",
      "====> Epoch: 1300 Average training loss: 1.4977\n",
      "====> Epoch: 1400 Average training loss: 1.4083\n",
      "====> Epoch: 1500 Average training loss: 1.3322\n",
      "====> Epoch: 1600 Average training loss: 1.2591\n",
      "====> Epoch: 1700 Average training loss: 1.1901\n",
      "====> Epoch: 1800 Average training loss: 1.1400\n",
      "====> Epoch: 100 Average training loss: 5.9314\n",
      "====> Epoch: 200 Average training loss: 4.7597\n",
      "====> Epoch: 300 Average training loss: 3.9749\n",
      "====> Epoch: 400 Average training loss: 3.4371\n",
      "====> Epoch: 500 Average training loss: 3.0268\n",
      "====> Epoch: 600 Average training loss: 2.6840\n",
      "====> Epoch: 700 Average training loss: 2.4260\n",
      "====> Epoch: 800 Average training loss: 2.1908\n",
      "====> Epoch: 900 Average training loss: 2.0185\n",
      "====> Epoch: 1000 Average training loss: 1.8493\n",
      "====> Epoch: 1100 Average training loss: 1.7056\n",
      "====> Epoch: 1200 Average training loss: 1.5962\n",
      "====> Epoch: 1300 Average training loss: 1.4988\n",
      "====> Epoch: 1400 Average training loss: 1.4046\n",
      "====> Epoch: 1500 Average training loss: 1.3260\n",
      "====> Epoch: 1600 Average training loss: 1.2608\n",
      "====> Epoch: 1700 Average training loss: 1.1933\n",
      "====> Epoch: 1800 Average training loss: 1.1408\n",
      "====> Epoch: 100 Average training loss: 5.9113\n",
      "====> Epoch: 200 Average training loss: 4.6963\n",
      "====> Epoch: 300 Average training loss: 3.9574\n",
      "====> Epoch: 400 Average training loss: 3.4126\n",
      "====> Epoch: 500 Average training loss: 3.0265\n",
      "====> Epoch: 600 Average training loss: 2.6857\n",
      "====> Epoch: 700 Average training loss: 2.4265\n",
      "====> Epoch: 800 Average training loss: 2.2124\n",
      "====> Epoch: 900 Average training loss: 2.0175\n",
      "====> Epoch: 1000 Average training loss: 1.8627\n",
      "====> Epoch: 1100 Average training loss: 1.7165\n",
      "====> Epoch: 1200 Average training loss: 1.6104\n",
      "====> Epoch: 1300 Average training loss: 1.5099\n",
      "====> Epoch: 1400 Average training loss: 1.4053\n",
      "====> Epoch: 1500 Average training loss: 1.3479\n",
      "====> Epoch: 1600 Average training loss: 1.2771\n",
      "====> Epoch: 1700 Average training loss: 1.2053\n",
      "====> Epoch: 1800 Average training loss: 1.1482\n",
      "====> Epoch: 100 Average training loss: 5.9396\n",
      "====> Epoch: 200 Average training loss: 4.7380\n",
      "====> Epoch: 300 Average training loss: 3.9739\n",
      "====> Epoch: 400 Average training loss: 3.4507\n",
      "====> Epoch: 500 Average training loss: 3.0200\n",
      "====> Epoch: 600 Average training loss: 2.6953\n",
      "====> Epoch: 700 Average training loss: 2.4292\n",
      "====> Epoch: 800 Average training loss: 2.2142\n",
      "====> Epoch: 900 Average training loss: 2.0258\n",
      "====> Epoch: 1000 Average training loss: 1.8470\n",
      "====> Epoch: 1100 Average training loss: 1.7215\n",
      "====> Epoch: 1200 Average training loss: 1.5935\n",
      "====> Epoch: 1300 Average training loss: 1.5010\n",
      "====> Epoch: 1400 Average training loss: 1.4051\n",
      "====> Epoch: 1500 Average training loss: 1.3233\n",
      "====> Epoch: 1600 Average training loss: 1.2491\n",
      "====> Epoch: 1700 Average training loss: 1.1821\n",
      "====> Epoch: 1800 Average training loss: 1.1261\n",
      "====> Epoch: 100 Average training loss: 5.9187\n",
      "====> Epoch: 200 Average training loss: 4.7432\n",
      "====> Epoch: 300 Average training loss: 4.0021\n",
      "====> Epoch: 400 Average training loss: 3.4463\n",
      "====> Epoch: 500 Average training loss: 3.0256\n",
      "====> Epoch: 600 Average training loss: 2.7072\n",
      "====> Epoch: 700 Average training loss: 2.4371\n",
      "====> Epoch: 800 Average training loss: 2.2026\n",
      "====> Epoch: 900 Average training loss: 2.0143\n",
      "====> Epoch: 1000 Average training loss: 1.8656\n",
      "====> Epoch: 1100 Average training loss: 1.7223\n",
      "====> Epoch: 1200 Average training loss: 1.6085\n",
      "====> Epoch: 1300 Average training loss: 1.5079\n",
      "====> Epoch: 1400 Average training loss: 1.4068\n",
      "====> Epoch: 1500 Average training loss: 1.3281\n",
      "====> Epoch: 1600 Average training loss: 1.2536\n",
      "====> Epoch: 1700 Average training loss: 1.1826\n",
      "====> Epoch: 1800 Average training loss: 1.1229\n",
      "====> Epoch: 100 Average training loss: 5.9105\n",
      "====> Epoch: 200 Average training loss: 4.7370\n",
      "====> Epoch: 300 Average training loss: 3.9623\n",
      "====> Epoch: 400 Average training loss: 3.4154\n",
      "====> Epoch: 500 Average training loss: 2.9980\n",
      "====> Epoch: 600 Average training loss: 2.6832\n",
      "====> Epoch: 700 Average training loss: 2.4047\n",
      "====> Epoch: 800 Average training loss: 2.1871\n",
      "====> Epoch: 900 Average training loss: 1.9135\n",
      "====> Epoch: 1000 Average training loss: 1.5759\n",
      "====> Epoch: 1100 Average training loss: 1.3455\n",
      "====> Epoch: 1200 Average training loss: 1.1720\n",
      "====> Epoch: 1300 Average training loss: 0.9335\n",
      "====> Epoch: 1400 Average training loss: 0.8421\n",
      "====> Epoch: 1500 Average training loss: 0.7699\n",
      "====> Epoch: 1600 Average training loss: 0.7133\n",
      "====> Epoch: 1700 Average training loss: 0.6611\n",
      "====> Epoch: 1800 Average training loss: 0.6117\n",
      "====> Epoch: 100 Average training loss: 5.9061\n",
      "====> Epoch: 200 Average training loss: 4.7576\n",
      "====> Epoch: 300 Average training loss: 3.9855\n",
      "====> Epoch: 400 Average training loss: 3.4683\n",
      "====> Epoch: 500 Average training loss: 3.0503\n",
      "====> Epoch: 600 Average training loss: 2.7016\n",
      "====> Epoch: 700 Average training loss: 2.4439\n",
      "====> Epoch: 800 Average training loss: 2.2300\n",
      "====> Epoch: 900 Average training loss: 2.0338\n",
      "====> Epoch: 1000 Average training loss: 1.8757\n",
      "====> Epoch: 1100 Average training loss: 1.7233\n",
      "====> Epoch: 1200 Average training loss: 1.5926\n",
      "====> Epoch: 1300 Average training loss: 1.4864\n",
      "====> Epoch: 1400 Average training loss: 1.3929\n",
      "====> Epoch: 1500 Average training loss: 1.3104\n",
      "====> Epoch: 1600 Average training loss: 1.2378\n",
      "====> Epoch: 1700 Average training loss: 1.1791\n",
      "====> Epoch: 1800 Average training loss: 1.1187\n",
      "====> Epoch: 100 Average training loss: 5.9100\n",
      "====> Epoch: 200 Average training loss: 4.7611\n",
      "====> Epoch: 300 Average training loss: 3.9754\n",
      "====> Epoch: 400 Average training loss: 3.4110\n",
      "====> Epoch: 500 Average training loss: 3.0094\n",
      "====> Epoch: 600 Average training loss: 2.6820\n",
      "====> Epoch: 700 Average training loss: 2.4304\n",
      "====> Epoch: 800 Average training loss: 2.2078\n",
      "====> Epoch: 900 Average training loss: 2.0117\n",
      "====> Epoch: 1000 Average training loss: 1.8706\n",
      "====> Epoch: 1100 Average training loss: 1.7291\n",
      "====> Epoch: 1200 Average training loss: 1.6137\n",
      "====> Epoch: 1300 Average training loss: 1.5089\n",
      "====> Epoch: 1400 Average training loss: 1.4236\n",
      "====> Epoch: 1500 Average training loss: 1.3351\n",
      "====> Epoch: 1600 Average training loss: 1.2664\n",
      "====> Epoch: 1700 Average training loss: 1.2107\n",
      "====> Epoch: 1800 Average training loss: 1.1555\n",
      "====> Epoch: 100 Average training loss: 5.9213\n",
      "====> Epoch: 200 Average training loss: 4.7286\n",
      "====> Epoch: 300 Average training loss: 3.9703\n",
      "====> Epoch: 400 Average training loss: 3.4545\n",
      "====> Epoch: 500 Average training loss: 3.0377\n",
      "====> Epoch: 600 Average training loss: 2.7080\n",
      "====> Epoch: 700 Average training loss: 2.4391\n",
      "====> Epoch: 800 Average training loss: 2.2211\n",
      "====> Epoch: 900 Average training loss: 2.0277\n",
      "====> Epoch: 1000 Average training loss: 1.8650\n",
      "====> Epoch: 1100 Average training loss: 1.7201\n",
      "====> Epoch: 1200 Average training loss: 1.2450\n",
      "====> Epoch: 1300 Average training loss: 1.0495\n",
      "====> Epoch: 1400 Average training loss: 0.9445\n",
      "====> Epoch: 1500 Average training loss: 0.8593\n",
      "====> Epoch: 1600 Average training loss: 0.7929\n",
      "====> Epoch: 1700 Average training loss: 0.7365\n",
      "====> Epoch: 1800 Average training loss: 0.6889\n",
      "====> Epoch: 100 Average training loss: 5.9325\n",
      "====> Epoch: 200 Average training loss: 4.7284\n",
      "====> Epoch: 300 Average training loss: 3.9649\n",
      "====> Epoch: 400 Average training loss: 3.4266\n",
      "====> Epoch: 500 Average training loss: 2.9968\n",
      "====> Epoch: 600 Average training loss: 2.6680\n",
      "====> Epoch: 700 Average training loss: 2.4081\n",
      "====> Epoch: 800 Average training loss: 2.2012\n",
      "====> Epoch: 900 Average training loss: 1.9975\n",
      "====> Epoch: 1000 Average training loss: 1.8438\n",
      "====> Epoch: 1100 Average training loss: 1.7045\n",
      "====> Epoch: 1200 Average training loss: 1.5955\n",
      "====> Epoch: 1300 Average training loss: 1.4982\n",
      "====> Epoch: 1400 Average training loss: 1.4025\n",
      "====> Epoch: 1500 Average training loss: 1.3223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1600 Average training loss: 1.2588\n",
      "====> Epoch: 1700 Average training loss: 1.1976\n",
      "====> Epoch: 1800 Average training loss: 1.1379\n",
      "====> Epoch: 100 Average training loss: 5.9257\n",
      "====> Epoch: 200 Average training loss: 4.7419\n",
      "====> Epoch: 300 Average training loss: 3.9694\n",
      "====> Epoch: 400 Average training loss: 3.4395\n",
      "====> Epoch: 500 Average training loss: 3.0271\n",
      "====> Epoch: 600 Average training loss: 2.6943\n",
      "====> Epoch: 700 Average training loss: 2.4321\n",
      "====> Epoch: 800 Average training loss: 2.2060\n",
      "====> Epoch: 900 Average training loss: 2.0132\n",
      "====> Epoch: 1000 Average training loss: 1.8685\n",
      "====> Epoch: 1100 Average training loss: 1.7257\n",
      "====> Epoch: 1200 Average training loss: 1.6131\n",
      "====> Epoch: 1300 Average training loss: 1.4981\n",
      "====> Epoch: 1400 Average training loss: 1.4088\n",
      "====> Epoch: 1500 Average training loss: 1.3359\n",
      "====> Epoch: 1600 Average training loss: 1.2535\n",
      "====> Epoch: 1700 Average training loss: 1.1841\n",
      "====> Epoch: 1800 Average training loss: 1.1327\n",
      "====> Epoch: 100 Average training loss: 5.9249\n",
      "====> Epoch: 200 Average training loss: 4.7301\n",
      "====> Epoch: 300 Average training loss: 3.9794\n",
      "====> Epoch: 400 Average training loss: 3.4434\n",
      "====> Epoch: 500 Average training loss: 3.0346\n",
      "====> Epoch: 600 Average training loss: 2.7152\n",
      "====> Epoch: 700 Average training loss: 2.4611\n",
      "====> Epoch: 800 Average training loss: 2.2278\n",
      "====> Epoch: 900 Average training loss: 2.0352\n",
      "====> Epoch: 1000 Average training loss: 1.8698\n",
      "====> Epoch: 1100 Average training loss: 1.7416\n",
      "====> Epoch: 1200 Average training loss: 1.6215\n",
      "====> Epoch: 1300 Average training loss: 1.5096\n",
      "====> Epoch: 1400 Average training loss: 1.4234\n",
      "====> Epoch: 1500 Average training loss: 1.3426\n",
      "====> Epoch: 1600 Average training loss: 1.2598\n",
      "====> Epoch: 1700 Average training loss: 1.2054\n",
      "====> Epoch: 1800 Average training loss: 1.1423\n",
      "====> Epoch: 100 Average training loss: 5.9147\n",
      "====> Epoch: 200 Average training loss: 4.7257\n",
      "====> Epoch: 300 Average training loss: 3.9693\n",
      "====> Epoch: 400 Average training loss: 3.4131\n",
      "====> Epoch: 500 Average training loss: 3.0177\n",
      "====> Epoch: 600 Average training loss: 2.7031\n",
      "====> Epoch: 700 Average training loss: 2.4300\n",
      "====> Epoch: 800 Average training loss: 2.2168\n",
      "====> Epoch: 900 Average training loss: 2.0304\n",
      "====> Epoch: 1000 Average training loss: 1.8765\n",
      "====> Epoch: 1100 Average training loss: 1.7258\n",
      "====> Epoch: 1200 Average training loss: 1.6166\n",
      "====> Epoch: 1300 Average training loss: 1.5076\n",
      "====> Epoch: 1400 Average training loss: 1.4148\n",
      "====> Epoch: 1500 Average training loss: 1.3337\n",
      "====> Epoch: 1600 Average training loss: 1.2658\n",
      "====> Epoch: 1700 Average training loss: 1.1946\n",
      "====> Epoch: 1800 Average training loss: 1.1514\n",
      "====> Epoch: 100 Average training loss: 5.9046\n",
      "====> Epoch: 200 Average training loss: 4.7126\n",
      "====> Epoch: 300 Average training loss: 3.9713\n",
      "====> Epoch: 400 Average training loss: 3.4227\n",
      "====> Epoch: 500 Average training loss: 3.0074\n",
      "====> Epoch: 600 Average training loss: 2.6568\n",
      "====> Epoch: 700 Average training loss: 2.2350\n",
      "====> Epoch: 800 Average training loss: 1.6883\n",
      "====> Epoch: 900 Average training loss: 1.4113\n",
      "====> Epoch: 1000 Average training loss: 1.2515\n",
      "====> Epoch: 1100 Average training loss: 1.1310\n",
      "====> Epoch: 1200 Average training loss: 1.0308\n",
      "====> Epoch: 1300 Average training loss: 0.9463\n",
      "====> Epoch: 1400 Average training loss: 0.8689\n",
      "====> Epoch: 1500 Average training loss: 0.8057\n",
      "====> Epoch: 1600 Average training loss: 0.7486\n",
      "====> Epoch: 1700 Average training loss: 0.6989\n",
      "====> Epoch: 1800 Average training loss: 0.6541\n",
      "====> Epoch: 100 Average training loss: 5.9126\n",
      "====> Epoch: 200 Average training loss: 4.7353\n",
      "====> Epoch: 300 Average training loss: 3.9859\n",
      "====> Epoch: 400 Average training loss: 3.4380\n",
      "====> Epoch: 500 Average training loss: 3.0211\n",
      "====> Epoch: 600 Average training loss: 2.6829\n",
      "====> Epoch: 700 Average training loss: 2.4253\n",
      "====> Epoch: 800 Average training loss: 2.1957\n",
      "====> Epoch: 900 Average training loss: 2.0166\n",
      "====> Epoch: 1000 Average training loss: 1.8519\n",
      "====> Epoch: 1100 Average training loss: 1.7116\n",
      "====> Epoch: 1200 Average training loss: 1.5964\n",
      "====> Epoch: 1300 Average training loss: 1.4921\n",
      "====> Epoch: 1400 Average training loss: 1.3959\n",
      "====> Epoch: 1500 Average training loss: 1.3347\n",
      "====> Epoch: 1600 Average training loss: 1.2451\n",
      "====> Epoch: 1700 Average training loss: 1.1347\n",
      "====> Epoch: 1800 Average training loss: 1.0960\n",
      "====> Epoch: 100 Average training loss: 5.9424\n",
      "====> Epoch: 200 Average training loss: 4.7488\n",
      "====> Epoch: 300 Average training loss: 3.9847\n",
      "====> Epoch: 400 Average training loss: 3.4598\n",
      "====> Epoch: 500 Average training loss: 3.0114\n",
      "====> Epoch: 600 Average training loss: 2.6946\n",
      "====> Epoch: 700 Average training loss: 2.4285\n",
      "====> Epoch: 800 Average training loss: 2.2076\n",
      "====> Epoch: 900 Average training loss: 2.0131\n",
      "====> Epoch: 1000 Average training loss: 1.8730\n",
      "====> Epoch: 1100 Average training loss: 1.7267\n",
      "====> Epoch: 1200 Average training loss: 1.6193\n",
      "====> Epoch: 1300 Average training loss: 1.5109\n",
      "====> Epoch: 1400 Average training loss: 1.4185\n",
      "====> Epoch: 1500 Average training loss: 1.3452\n",
      "====> Epoch: 1600 Average training loss: 1.2641\n",
      "====> Epoch: 1700 Average training loss: 1.2070\n",
      "====> Epoch: 1800 Average training loss: 1.1523\n",
      "====> Epoch: 100 Average training loss: 5.9105\n",
      "====> Epoch: 200 Average training loss: 4.6954\n",
      "====> Epoch: 300 Average training loss: 3.9632\n",
      "====> Epoch: 400 Average training loss: 3.4191\n",
      "====> Epoch: 500 Average training loss: 2.9922\n",
      "====> Epoch: 600 Average training loss: 2.6834\n",
      "====> Epoch: 700 Average training loss: 2.4021\n",
      "====> Epoch: 800 Average training loss: 2.1905\n",
      "====> Epoch: 900 Average training loss: 2.0098\n",
      "====> Epoch: 1000 Average training loss: 1.8413\n",
      "====> Epoch: 1100 Average training loss: 1.7165\n",
      "====> Epoch: 1200 Average training loss: 1.5802\n",
      "====> Epoch: 1300 Average training loss: 1.4902\n",
      "====> Epoch: 1400 Average training loss: 1.3918\n",
      "====> Epoch: 1500 Average training loss: 1.3160\n",
      "====> Epoch: 1600 Average training loss: 1.2484\n",
      "====> Epoch: 1700 Average training loss: 1.1830\n",
      "====> Epoch: 1800 Average training loss: 1.1293\n",
      "====> Epoch: 100 Average training loss: 5.9081\n",
      "====> Epoch: 200 Average training loss: 4.7381\n",
      "====> Epoch: 300 Average training loss: 3.9905\n",
      "====> Epoch: 400 Average training loss: 3.4428\n",
      "====> Epoch: 500 Average training loss: 3.0116\n",
      "====> Epoch: 600 Average training loss: 2.7088\n",
      "====> Epoch: 700 Average training loss: 2.4286\n",
      "====> Epoch: 800 Average training loss: 2.2103\n",
      "====> Epoch: 900 Average training loss: 2.0195\n",
      "====> Epoch: 1000 Average training loss: 1.8613\n",
      "====> Epoch: 1100 Average training loss: 1.7289\n",
      "====> Epoch: 1200 Average training loss: 1.6123\n",
      "====> Epoch: 1300 Average training loss: 1.5173\n",
      "====> Epoch: 1400 Average training loss: 1.4291\n",
      "====> Epoch: 1500 Average training loss: 1.3420\n",
      "====> Epoch: 1600 Average training loss: 1.2639\n",
      "====> Epoch: 1700 Average training loss: 1.2037\n",
      "====> Epoch: 1800 Average training loss: 1.1571\n",
      "====> Epoch: 100 Average training loss: 5.9242\n",
      "====> Epoch: 200 Average training loss: 4.7411\n",
      "====> Epoch: 300 Average training loss: 4.0018\n",
      "====> Epoch: 400 Average training loss: 3.4441\n",
      "====> Epoch: 500 Average training loss: 3.0169\n",
      "====> Epoch: 600 Average training loss: 2.6993\n",
      "====> Epoch: 700 Average training loss: 2.4282\n",
      "====> Epoch: 800 Average training loss: 2.2022\n",
      "====> Epoch: 900 Average training loss: 2.0212\n",
      "====> Epoch: 1000 Average training loss: 1.8567\n",
      "====> Epoch: 1100 Average training loss: 1.7347\n",
      "====> Epoch: 1200 Average training loss: 1.5951\n",
      "====> Epoch: 1300 Average training loss: 1.4978\n",
      "====> Epoch: 1400 Average training loss: 1.4023\n",
      "====> Epoch: 1500 Average training loss: 1.3153\n",
      "====> Epoch: 1600 Average training loss: 1.2570\n",
      "====> Epoch: 1700 Average training loss: 1.1878\n",
      "====> Epoch: 1800 Average training loss: 1.1310\n",
      "====> Epoch: 100 Average training loss: 5.9151\n",
      "====> Epoch: 200 Average training loss: 4.7281\n",
      "====> Epoch: 300 Average training loss: 3.9741\n",
      "====> Epoch: 400 Average training loss: 3.4296\n",
      "====> Epoch: 500 Average training loss: 3.0125\n",
      "====> Epoch: 600 Average training loss: 2.6780\n",
      "====> Epoch: 700 Average training loss: 2.4171\n",
      "====> Epoch: 800 Average training loss: 2.2033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 900 Average training loss: 2.0174\n",
      "====> Epoch: 1000 Average training loss: 1.8654\n",
      "====> Epoch: 1100 Average training loss: 1.7275\n",
      "====> Epoch: 1200 Average training loss: 1.6027\n",
      "====> Epoch: 1300 Average training loss: 1.5086\n",
      "====> Epoch: 1400 Average training loss: 1.4191\n",
      "====> Epoch: 1500 Average training loss: 1.3330\n",
      "====> Epoch: 1600 Average training loss: 1.2588\n",
      "====> Epoch: 1700 Average training loss: 1.1916\n",
      "====> Epoch: 1800 Average training loss: 1.1367\n",
      "====> Epoch: 100 Average training loss: 5.9206\n",
      "====> Epoch: 200 Average training loss: 4.7323\n",
      "====> Epoch: 300 Average training loss: 3.9774\n",
      "====> Epoch: 400 Average training loss: 3.4263\n",
      "====> Epoch: 500 Average training loss: 3.0193\n",
      "====> Epoch: 600 Average training loss: 2.6989\n",
      "====> Epoch: 700 Average training loss: 2.4284\n",
      "====> Epoch: 800 Average training loss: 2.2121\n",
      "====> Epoch: 900 Average training loss: 2.0192\n",
      "====> Epoch: 1000 Average training loss: 1.8535\n",
      "====> Epoch: 1100 Average training loss: 1.7240\n",
      "====> Epoch: 1200 Average training loss: 1.5982\n",
      "====> Epoch: 1300 Average training loss: 1.4987\n",
      "====> Epoch: 1400 Average training loss: 1.3976\n",
      "====> Epoch: 1500 Average training loss: 1.3265\n",
      "====> Epoch: 1600 Average training loss: 1.2471\n",
      "====> Epoch: 1700 Average training loss: 1.1872\n",
      "====> Epoch: 1800 Average training loss: 1.1261\n",
      "====> Epoch: 100 Average training loss: 5.9205\n",
      "====> Epoch: 200 Average training loss: 4.7215\n",
      "====> Epoch: 300 Average training loss: 3.9782\n",
      "====> Epoch: 400 Average training loss: 3.4250\n",
      "====> Epoch: 500 Average training loss: 3.0170\n",
      "====> Epoch: 600 Average training loss: 2.6919\n",
      "====> Epoch: 700 Average training loss: 2.4096\n",
      "====> Epoch: 800 Average training loss: 2.1995\n",
      "====> Epoch: 900 Average training loss: 1.5071\n",
      "====> Epoch: 1000 Average training loss: 1.2649\n",
      "====> Epoch: 1100 Average training loss: 1.1334\n",
      "====> Epoch: 1200 Average training loss: 1.0257\n",
      "====> Epoch: 1300 Average training loss: 0.9346\n",
      "====> Epoch: 1400 Average training loss: 0.8623\n",
      "====> Epoch: 1500 Average training loss: 0.7981\n",
      "====> Epoch: 1600 Average training loss: 0.7408\n",
      "====> Epoch: 1700 Average training loss: 0.6922\n",
      "====> Epoch: 1800 Average training loss: 0.6472\n",
      "====> Epoch: 100 Average training loss: 5.9172\n",
      "====> Epoch: 200 Average training loss: 4.6962\n",
      "====> Epoch: 300 Average training loss: 3.0855\n",
      "====> Epoch: 400 Average training loss: 2.5572\n",
      "====> Epoch: 500 Average training loss: 2.2050\n",
      "====> Epoch: 600 Average training loss: 1.9336\n",
      "====> Epoch: 700 Average training loss: 1.7080\n",
      "====> Epoch: 800 Average training loss: 1.5240\n",
      "====> Epoch: 900 Average training loss: 1.3678\n",
      "====> Epoch: 1000 Average training loss: 1.2393\n",
      "====> Epoch: 1100 Average training loss: 1.1266\n",
      "====> Epoch: 1200 Average training loss: 1.0319\n",
      "====> Epoch: 1300 Average training loss: 0.9493\n",
      "====> Epoch: 1400 Average training loss: 0.8765\n",
      "====> Epoch: 1500 Average training loss: 0.8130\n",
      "====> Epoch: 1600 Average training loss: 0.7571\n",
      "====> Epoch: 1700 Average training loss: 0.7098\n",
      "====> Epoch: 1800 Average training loss: 0.6651\n",
      "====> Epoch: 100 Average training loss: 5.8944\n",
      "====> Epoch: 200 Average training loss: 4.7160\n",
      "====> Epoch: 300 Average training loss: 3.9501\n",
      "====> Epoch: 400 Average training loss: 3.4307\n",
      "====> Epoch: 500 Average training loss: 3.0020\n",
      "====> Epoch: 600 Average training loss: 2.6750\n",
      "====> Epoch: 700 Average training loss: 2.4022\n",
      "====> Epoch: 800 Average training loss: 2.1805\n",
      "====> Epoch: 900 Average training loss: 1.9960\n",
      "====> Epoch: 1000 Average training loss: 1.8419\n",
      "====> Epoch: 1100 Average training loss: 1.7131\n",
      "====> Epoch: 1200 Average training loss: 1.5864\n",
      "====> Epoch: 1300 Average training loss: 1.4823\n",
      "====> Epoch: 1400 Average training loss: 1.3903\n",
      "====> Epoch: 1500 Average training loss: 1.3232\n",
      "====> Epoch: 1600 Average training loss: 1.2427\n",
      "====> Epoch: 1700 Average training loss: 1.1773\n",
      "====> Epoch: 1800 Average training loss: 1.1256\n",
      "====> Epoch: 100 Average training loss: 5.9298\n",
      "====> Epoch: 200 Average training loss: 4.7446\n",
      "====> Epoch: 300 Average training loss: 4.0106\n",
      "====> Epoch: 400 Average training loss: 3.4640\n",
      "====> Epoch: 500 Average training loss: 3.0538\n",
      "====> Epoch: 600 Average training loss: 2.7076\n",
      "====> Epoch: 700 Average training loss: 2.4416\n",
      "====> Epoch: 800 Average training loss: 2.1984\n",
      "====> Epoch: 900 Average training loss: 2.0308\n",
      "====> Epoch: 1000 Average training loss: 1.8625\n",
      "====> Epoch: 1100 Average training loss: 1.7231\n",
      "====> Epoch: 1200 Average training loss: 1.6111\n",
      "====> Epoch: 1300 Average training loss: 1.5009\n",
      "====> Epoch: 1400 Average training loss: 1.4169\n",
      "====> Epoch: 1500 Average training loss: 1.3375\n",
      "====> Epoch: 1600 Average training loss: 1.2660\n",
      "====> Epoch: 1700 Average training loss: 1.1997\n",
      "====> Epoch: 1800 Average training loss: 1.1525\n",
      "====> Epoch: 100 Average training loss: 5.8952\n",
      "====> Epoch: 200 Average training loss: 4.7264\n",
      "====> Epoch: 300 Average training loss: 3.9667\n",
      "====> Epoch: 400 Average training loss: 3.4432\n",
      "====> Epoch: 500 Average training loss: 3.0173\n",
      "====> Epoch: 600 Average training loss: 2.6932\n",
      "====> Epoch: 700 Average training loss: 2.4388\n",
      "====> Epoch: 800 Average training loss: 2.2116\n",
      "====> Epoch: 900 Average training loss: 2.0376\n",
      "====> Epoch: 1000 Average training loss: 1.8620\n",
      "====> Epoch: 1100 Average training loss: 1.7308\n",
      "====> Epoch: 1200 Average training loss: 1.6139\n",
      "====> Epoch: 1300 Average training loss: 1.5090\n",
      "====> Epoch: 1400 Average training loss: 1.4203\n",
      "====> Epoch: 1500 Average training loss: 1.3388\n",
      "====> Epoch: 1600 Average training loss: 1.2680\n",
      "====> Epoch: 1700 Average training loss: 1.2079\n",
      "====> Epoch: 1800 Average training loss: 1.1461\n",
      "====> Epoch: 100 Average training loss: 5.9215\n",
      "====> Epoch: 200 Average training loss: 4.7338\n",
      "====> Epoch: 300 Average training loss: 3.9616\n",
      "====> Epoch: 400 Average training loss: 3.4228\n",
      "====> Epoch: 500 Average training loss: 3.0220\n",
      "====> Epoch: 600 Average training loss: 2.6986\n",
      "====> Epoch: 700 Average training loss: 2.4022\n",
      "====> Epoch: 800 Average training loss: 2.1940\n",
      "====> Epoch: 900 Average training loss: 2.0044\n",
      "====> Epoch: 1000 Average training loss: 1.8522\n",
      "====> Epoch: 1100 Average training loss: 1.7137\n",
      "====> Epoch: 1200 Average training loss: 1.5955\n",
      "====> Epoch: 1300 Average training loss: 1.4957\n",
      "====> Epoch: 1400 Average training loss: 1.4123\n",
      "====> Epoch: 1500 Average training loss: 1.3374\n",
      "====> Epoch: 1600 Average training loss: 1.2544\n",
      "====> Epoch: 1700 Average training loss: 1.1913\n",
      "====> Epoch: 1800 Average training loss: 1.1350\n",
      "====> Epoch: 100 Average training loss: 5.9248\n",
      "====> Epoch: 200 Average training loss: 4.7300\n",
      "====> Epoch: 300 Average training loss: 3.9943\n",
      "====> Epoch: 400 Average training loss: 3.4408\n",
      "====> Epoch: 500 Average training loss: 3.0268\n",
      "====> Epoch: 600 Average training loss: 2.7180\n",
      "====> Epoch: 700 Average training loss: 2.4340\n",
      "====> Epoch: 800 Average training loss: 2.2126\n",
      "====> Epoch: 900 Average training loss: 2.0377\n",
      "====> Epoch: 1000 Average training loss: 1.8665\n",
      "====> Epoch: 1100 Average training loss: 1.7282\n",
      "====> Epoch: 1200 Average training loss: 1.6085\n",
      "====> Epoch: 1300 Average training loss: 1.5082\n",
      "====> Epoch: 1400 Average training loss: 1.4159\n",
      "====> Epoch: 1500 Average training loss: 1.3213\n",
      "====> Epoch: 1600 Average training loss: 1.2600\n",
      "====> Epoch: 1700 Average training loss: 1.1893\n",
      "====> Epoch: 1800 Average training loss: 1.1690\n",
      "====> Epoch: 100 Average training loss: 5.9098\n",
      "====> Epoch: 200 Average training loss: 4.7315\n",
      "====> Epoch: 300 Average training loss: 3.9789\n",
      "====> Epoch: 400 Average training loss: 3.4223\n",
      "====> Epoch: 500 Average training loss: 3.0024\n",
      "====> Epoch: 600 Average training loss: 2.6925\n",
      "====> Epoch: 700 Average training loss: 2.4162\n",
      "====> Epoch: 800 Average training loss: 2.2009\n",
      "====> Epoch: 900 Average training loss: 2.0243\n",
      "====> Epoch: 1000 Average training loss: 1.8605\n",
      "====> Epoch: 1100 Average training loss: 1.7172\n",
      "====> Epoch: 1200 Average training loss: 1.6047\n",
      "====> Epoch: 1300 Average training loss: 1.4916\n",
      "====> Epoch: 1400 Average training loss: 1.4131\n",
      "====> Epoch: 1500 Average training loss: 1.3163\n",
      "====> Epoch: 1600 Average training loss: 1.2593\n",
      "====> Epoch: 1700 Average training loss: 1.1936\n",
      "====> Epoch: 1800 Average training loss: 1.1438\n",
      "====> Epoch: 100 Average training loss: 5.9126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 200 Average training loss: 4.7116\n",
      "====> Epoch: 300 Average training loss: 3.9696\n",
      "====> Epoch: 400 Average training loss: 3.4395\n",
      "====> Epoch: 500 Average training loss: 3.0106\n",
      "====> Epoch: 600 Average training loss: 2.6873\n",
      "====> Epoch: 700 Average training loss: 2.4237\n",
      "====> Epoch: 800 Average training loss: 2.1975\n",
      "====> Epoch: 900 Average training loss: 2.0121\n",
      "====> Epoch: 1000 Average training loss: 1.8458\n",
      "====> Epoch: 1100 Average training loss: 1.7187\n",
      "====> Epoch: 1200 Average training loss: 1.5967\n",
      "====> Epoch: 1300 Average training loss: 1.4882\n",
      "====> Epoch: 1400 Average training loss: 1.3834\n",
      "====> Epoch: 1500 Average training loss: 1.3202\n",
      "====> Epoch: 1600 Average training loss: 1.2465\n",
      "====> Epoch: 1700 Average training loss: 1.1810\n",
      "====> Epoch: 1800 Average training loss: 1.1125\n",
      "====> Epoch: 100 Average training loss: 5.9294\n",
      "====> Epoch: 200 Average training loss: 4.7379\n",
      "====> Epoch: 300 Average training loss: 4.0064\n",
      "====> Epoch: 400 Average training loss: 3.4667\n",
      "====> Epoch: 500 Average training loss: 3.0557\n",
      "====> Epoch: 600 Average training loss: 2.7274\n",
      "====> Epoch: 700 Average training loss: 2.4643\n",
      "====> Epoch: 800 Average training loss: 2.2537\n",
      "====> Epoch: 900 Average training loss: 2.0601\n",
      "====> Epoch: 1000 Average training loss: 1.9014\n",
      "====> Epoch: 1100 Average training loss: 1.7499\n",
      "====> Epoch: 1200 Average training loss: 1.6353\n",
      "====> Epoch: 1300 Average training loss: 1.5367\n",
      "====> Epoch: 1400 Average training loss: 1.4401\n",
      "====> Epoch: 1500 Average training loss: 1.3525\n",
      "====> Epoch: 1600 Average training loss: 1.2814\n",
      "====> Epoch: 1700 Average training loss: 1.2109\n",
      "====> Epoch: 1800 Average training loss: 1.1527\n",
      "====> Epoch: 100 Average training loss: 5.9232\n",
      "====> Epoch: 200 Average training loss: 4.7471\n",
      "====> Epoch: 300 Average training loss: 3.9804\n",
      "====> Epoch: 400 Average training loss: 3.4528\n",
      "====> Epoch: 500 Average training loss: 3.0513\n",
      "====> Epoch: 600 Average training loss: 2.7178\n",
      "====> Epoch: 700 Average training loss: 2.4412\n",
      "====> Epoch: 800 Average training loss: 2.2236\n",
      "====> Epoch: 900 Average training loss: 2.0294\n",
      "====> Epoch: 1000 Average training loss: 1.8724\n",
      "====> Epoch: 1100 Average training loss: 1.7351\n",
      "====> Epoch: 1200 Average training loss: 1.6212\n",
      "====> Epoch: 1300 Average training loss: 1.5091\n",
      "====> Epoch: 1400 Average training loss: 1.4143\n",
      "====> Epoch: 1500 Average training loss: 1.3305\n",
      "====> Epoch: 1600 Average training loss: 1.2673\n",
      "====> Epoch: 1700 Average training loss: 1.2043\n",
      "====> Epoch: 1800 Average training loss: 1.1396\n",
      "====> Epoch: 100 Average training loss: 5.9289\n",
      "====> Epoch: 200 Average training loss: 4.7410\n",
      "====> Epoch: 300 Average training loss: 4.0037\n",
      "====> Epoch: 400 Average training loss: 3.4501\n",
      "====> Epoch: 500 Average training loss: 3.0411\n",
      "====> Epoch: 600 Average training loss: 2.7134\n",
      "====> Epoch: 700 Average training loss: 2.4477\n",
      "====> Epoch: 800 Average training loss: 2.2214\n",
      "====> Epoch: 900 Average training loss: 2.0385\n",
      "====> Epoch: 1000 Average training loss: 1.8751\n",
      "====> Epoch: 1100 Average training loss: 1.7366\n",
      "====> Epoch: 1200 Average training loss: 1.6184\n",
      "====> Epoch: 1300 Average training loss: 1.5150\n",
      "====> Epoch: 1400 Average training loss: 1.4201\n",
      "====> Epoch: 1500 Average training loss: 1.3377\n",
      "====> Epoch: 1600 Average training loss: 1.2618\n",
      "====> Epoch: 1700 Average training loss: 1.1952\n",
      "====> Epoch: 1800 Average training loss: 1.1449\n",
      "====> Epoch: 100 Average training loss: 5.9194\n",
      "====> Epoch: 200 Average training loss: 4.7386\n",
      "====> Epoch: 300 Average training loss: 3.9849\n",
      "====> Epoch: 400 Average training loss: 3.4492\n",
      "====> Epoch: 500 Average training loss: 3.0244\n",
      "====> Epoch: 600 Average training loss: 2.6938\n",
      "====> Epoch: 700 Average training loss: 2.4209\n",
      "====> Epoch: 800 Average training loss: 2.1964\n",
      "====> Epoch: 900 Average training loss: 2.0271\n",
      "====> Epoch: 1000 Average training loss: 1.8543\n",
      "====> Epoch: 1100 Average training loss: 1.7238\n",
      "====> Epoch: 1200 Average training loss: 1.6073\n",
      "====> Epoch: 1300 Average training loss: 1.4888\n",
      "====> Epoch: 1400 Average training loss: 1.4160\n",
      "====> Epoch: 1500 Average training loss: 1.3546\n",
      "====> Epoch: 1600 Average training loss: 1.2674\n",
      "====> Epoch: 1700 Average training loss: 1.1875\n",
      "====> Epoch: 1800 Average training loss: 1.1187\n",
      "====> Epoch: 100 Average training loss: 5.9023\n",
      "====> Epoch: 200 Average training loss: 4.7327\n",
      "====> Epoch: 300 Average training loss: 3.9775\n",
      "====> Epoch: 400 Average training loss: 3.4517\n",
      "====> Epoch: 500 Average training loss: 3.0545\n",
      "====> Epoch: 600 Average training loss: 2.7156\n",
      "====> Epoch: 700 Average training loss: 2.4464\n",
      "====> Epoch: 800 Average training loss: 2.2338\n",
      "====> Epoch: 900 Average training loss: 2.0457\n",
      "====> Epoch: 1000 Average training loss: 1.8831\n",
      "====> Epoch: 1100 Average training loss: 1.7386\n",
      "====> Epoch: 1200 Average training loss: 1.6256\n",
      "====> Epoch: 1300 Average training loss: 1.5091\n",
      "====> Epoch: 1400 Average training loss: 1.4256\n",
      "====> Epoch: 1500 Average training loss: 1.3599\n",
      "====> Epoch: 1600 Average training loss: 1.2600\n",
      "====> Epoch: 1700 Average training loss: 1.1950\n",
      "====> Epoch: 1800 Average training loss: 1.1279\n",
      "====> Epoch: 100 Average training loss: 5.9259\n",
      "====> Epoch: 200 Average training loss: 4.7034\n",
      "====> Epoch: 300 Average training loss: 3.9532\n",
      "====> Epoch: 400 Average training loss: 3.4211\n",
      "====> Epoch: 500 Average training loss: 3.0131\n",
      "====> Epoch: 600 Average training loss: 2.6944\n",
      "====> Epoch: 700 Average training loss: 2.4223\n",
      "====> Epoch: 800 Average training loss: 2.2138\n",
      "====> Epoch: 900 Average training loss: 2.0163\n",
      "====> Epoch: 1000 Average training loss: 1.8628\n",
      "====> Epoch: 1100 Average training loss: 1.7303\n",
      "====> Epoch: 1200 Average training loss: 1.6124\n",
      "====> Epoch: 1300 Average training loss: 1.4928\n",
      "====> Epoch: 1400 Average training loss: 1.4022\n",
      "====> Epoch: 1500 Average training loss: 1.3260\n",
      "====> Epoch: 1600 Average training loss: 1.2331\n",
      "====> Epoch: 1700 Average training loss: 1.1482\n",
      "====> Epoch: 1800 Average training loss: 1.1465\n",
      "====> Epoch: 100 Average training loss: 5.9030\n",
      "====> Epoch: 200 Average training loss: 4.7316\n",
      "====> Epoch: 300 Average training loss: 3.9730\n",
      "====> Epoch: 400 Average training loss: 3.4415\n",
      "====> Epoch: 500 Average training loss: 3.0244\n",
      "====> Epoch: 600 Average training loss: 2.6934\n",
      "====> Epoch: 700 Average training loss: 2.4392\n",
      "====> Epoch: 800 Average training loss: 2.2044\n",
      "====> Epoch: 900 Average training loss: 2.0199\n",
      "====> Epoch: 1000 Average training loss: 1.8448\n",
      "====> Epoch: 1100 Average training loss: 1.6914\n",
      "====> Epoch: 1200 Average training loss: 1.5685\n",
      "====> Epoch: 1300 Average training loss: 1.4529\n",
      "====> Epoch: 1400 Average training loss: 1.3543\n",
      "====> Epoch: 1500 Average training loss: 1.2758\n",
      "====> Epoch: 1600 Average training loss: 1.1888\n",
      "====> Epoch: 1700 Average training loss: 1.1185\n",
      "====> Epoch: 1800 Average training loss: 1.0367\n",
      "====> Epoch: 100 Average training loss: 5.9303\n",
      "====> Epoch: 200 Average training loss: 4.7396\n",
      "====> Epoch: 300 Average training loss: 3.9983\n",
      "====> Epoch: 400 Average training loss: 3.4519\n",
      "====> Epoch: 500 Average training loss: 3.0214\n",
      "====> Epoch: 600 Average training loss: 2.7337\n",
      "====> Epoch: 700 Average training loss: 2.4402\n",
      "====> Epoch: 800 Average training loss: 2.2157\n",
      "====> Epoch: 900 Average training loss: 2.0159\n",
      "====> Epoch: 1000 Average training loss: 1.8533\n",
      "====> Epoch: 1100 Average training loss: 1.7078\n",
      "====> Epoch: 1200 Average training loss: 1.6043\n",
      "====> Epoch: 1300 Average training loss: 1.4888\n",
      "====> Epoch: 1400 Average training loss: 1.4022\n",
      "====> Epoch: 1500 Average training loss: 1.3176\n",
      "====> Epoch: 1600 Average training loss: 1.2417\n",
      "====> Epoch: 1700 Average training loss: 1.1919\n",
      "====> Epoch: 1800 Average training loss: 1.1331\n",
      "====> Epoch: 100 Average training loss: 5.9272\n",
      "====> Epoch: 200 Average training loss: 4.7625\n",
      "====> Epoch: 300 Average training loss: 3.9800\n",
      "====> Epoch: 400 Average training loss: 3.4474\n",
      "====> Epoch: 500 Average training loss: 3.0268\n",
      "====> Epoch: 600 Average training loss: 2.6871\n",
      "====> Epoch: 700 Average training loss: 2.4248\n",
      "====> Epoch: 800 Average training loss: 2.2016\n",
      "====> Epoch: 900 Average training loss: 2.0192\n",
      "====> Epoch: 1000 Average training loss: 1.8520\n",
      "====> Epoch: 1100 Average training loss: 1.7150\n",
      "====> Epoch: 1200 Average training loss: 1.6082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1300 Average training loss: 1.5002\n",
      "====> Epoch: 1400 Average training loss: 1.4088\n",
      "====> Epoch: 1500 Average training loss: 1.3258\n",
      "====> Epoch: 1600 Average training loss: 1.2646\n",
      "====> Epoch: 1700 Average training loss: 1.1840\n",
      "====> Epoch: 1800 Average training loss: 1.1467\n",
      "====> Epoch: 100 Average training loss: 5.9173\n",
      "====> Epoch: 200 Average training loss: 4.7401\n",
      "====> Epoch: 300 Average training loss: 3.9778\n",
      "====> Epoch: 400 Average training loss: 3.4420\n",
      "====> Epoch: 500 Average training loss: 3.0155\n",
      "====> Epoch: 600 Average training loss: 2.7038\n",
      "====> Epoch: 700 Average training loss: 2.4280\n",
      "====> Epoch: 800 Average training loss: 2.1921\n",
      "====> Epoch: 900 Average training loss: 2.0174\n",
      "====> Epoch: 1000 Average training loss: 1.8482\n",
      "====> Epoch: 1100 Average training loss: 1.7216\n",
      "====> Epoch: 1200 Average training loss: 1.6076\n",
      "====> Epoch: 1300 Average training loss: 1.5040\n",
      "====> Epoch: 1400 Average training loss: 1.4110\n",
      "====> Epoch: 1500 Average training loss: 1.3292\n",
      "====> Epoch: 1600 Average training loss: 1.2480\n",
      "====> Epoch: 1700 Average training loss: 1.1904\n",
      "====> Epoch: 1800 Average training loss: 1.1317\n",
      "====> Epoch: 100 Average training loss: 5.9070\n",
      "====> Epoch: 200 Average training loss: 4.7279\n",
      "====> Epoch: 300 Average training loss: 3.9756\n",
      "====> Epoch: 400 Average training loss: 3.4190\n",
      "====> Epoch: 500 Average training loss: 3.0245\n",
      "====> Epoch: 600 Average training loss: 2.7001\n",
      "====> Epoch: 700 Average training loss: 2.4336\n",
      "====> Epoch: 800 Average training loss: 2.2133\n",
      "====> Epoch: 900 Average training loss: 2.0288\n",
      "====> Epoch: 1000 Average training loss: 1.8649\n",
      "====> Epoch: 1100 Average training loss: 1.7274\n",
      "====> Epoch: 1200 Average training loss: 1.6086\n",
      "====> Epoch: 1300 Average training loss: 1.5027\n",
      "====> Epoch: 1400 Average training loss: 1.4230\n",
      "====> Epoch: 1500 Average training loss: 1.3432\n",
      "====> Epoch: 1600 Average training loss: 1.2724\n",
      "====> Epoch: 1700 Average training loss: 1.2137\n",
      "====> Epoch: 1800 Average training loss: 1.1475\n",
      "====> Epoch: 100 Average training loss: 5.9215\n",
      "====> Epoch: 200 Average training loss: 4.7364\n",
      "====> Epoch: 300 Average training loss: 3.9614\n",
      "====> Epoch: 400 Average training loss: 3.4441\n",
      "====> Epoch: 500 Average training loss: 3.0075\n",
      "====> Epoch: 600 Average training loss: 2.6739\n",
      "====> Epoch: 700 Average training loss: 2.4135\n",
      "====> Epoch: 800 Average training loss: 2.1874\n",
      "====> Epoch: 900 Average training loss: 2.0083\n",
      "====> Epoch: 1000 Average training loss: 1.8523\n",
      "====> Epoch: 1100 Average training loss: 1.7061\n",
      "====> Epoch: 1200 Average training loss: 1.5966\n",
      "====> Epoch: 1300 Average training loss: 1.4919\n",
      "====> Epoch: 1400 Average training loss: 1.4017\n",
      "====> Epoch: 1500 Average training loss: 1.3152\n",
      "====> Epoch: 1600 Average training loss: 1.2537\n",
      "====> Epoch: 1700 Average training loss: 1.1819\n",
      "====> Epoch: 1800 Average training loss: 1.1343\n",
      "====> Epoch: 100 Average training loss: 5.9293\n",
      "====> Epoch: 200 Average training loss: 4.7531\n",
      "====> Epoch: 300 Average training loss: 3.9836\n",
      "====> Epoch: 400 Average training loss: 3.4617\n",
      "====> Epoch: 500 Average training loss: 3.0421\n",
      "====> Epoch: 600 Average training loss: 2.7079\n",
      "====> Epoch: 700 Average training loss: 2.4401\n",
      "====> Epoch: 800 Average training loss: 2.2201\n",
      "====> Epoch: 900 Average training loss: 1.4995\n",
      "====> Epoch: 1000 Average training loss: 1.3118\n",
      "====> Epoch: 1100 Average training loss: 1.1746\n",
      "====> Epoch: 1200 Average training loss: 1.0647\n",
      "====> Epoch: 1300 Average training loss: 0.9796\n",
      "====> Epoch: 1400 Average training loss: 0.9024\n",
      "====> Epoch: 1500 Average training loss: 0.8350\n",
      "====> Epoch: 1600 Average training loss: 0.7753\n",
      "====> Epoch: 1700 Average training loss: 0.7175\n",
      "====> Epoch: 1800 Average training loss: 0.6659\n",
      "====> Epoch: 100 Average training loss: 5.9278\n",
      "====> Epoch: 200 Average training loss: 4.7544\n",
      "====> Epoch: 300 Average training loss: 3.9911\n",
      "====> Epoch: 400 Average training loss: 3.4605\n",
      "====> Epoch: 500 Average training loss: 3.0280\n",
      "====> Epoch: 600 Average training loss: 2.7092\n",
      "====> Epoch: 700 Average training loss: 2.4422\n",
      "====> Epoch: 800 Average training loss: 2.2182\n",
      "====> Epoch: 900 Average training loss: 2.0317\n",
      "====> Epoch: 1000 Average training loss: 1.8705\n",
      "====> Epoch: 1100 Average training loss: 1.7354\n",
      "====> Epoch: 1200 Average training loss: 1.6226\n",
      "====> Epoch: 1300 Average training loss: 1.5053\n",
      "====> Epoch: 1400 Average training loss: 1.4393\n",
      "====> Epoch: 1500 Average training loss: 1.3426\n",
      "====> Epoch: 1600 Average training loss: 1.2675\n",
      "====> Epoch: 1700 Average training loss: 1.2090\n",
      "====> Epoch: 1800 Average training loss: 1.1414\n",
      "====> Epoch: 100 Average training loss: 5.9143\n",
      "====> Epoch: 200 Average training loss: 4.7405\n",
      "====> Epoch: 300 Average training loss: 4.0212\n",
      "====> Epoch: 400 Average training loss: 3.4813\n",
      "====> Epoch: 500 Average training loss: 3.0625\n",
      "====> Epoch: 600 Average training loss: 2.7289\n",
      "====> Epoch: 700 Average training loss: 2.4460\n",
      "====> Epoch: 800 Average training loss: 2.2174\n",
      "====> Epoch: 900 Average training loss: 2.0488\n",
      "====> Epoch: 1000 Average training loss: 1.8789\n",
      "====> Epoch: 1100 Average training loss: 1.7389\n",
      "====> Epoch: 1200 Average training loss: 1.6276\n",
      "====> Epoch: 1300 Average training loss: 1.5212\n",
      "====> Epoch: 1400 Average training loss: 1.4204\n",
      "====> Epoch: 1500 Average training loss: 1.3604\n",
      "====> Epoch: 1600 Average training loss: 1.2909\n",
      "====> Epoch: 1700 Average training loss: 1.2024\n",
      "====> Epoch: 1800 Average training loss: 1.1264\n",
      "====> Epoch: 100 Average training loss: 5.9260\n",
      "====> Epoch: 200 Average training loss: 4.7487\n",
      "====> Epoch: 300 Average training loss: 3.9915\n",
      "====> Epoch: 400 Average training loss: 3.4394\n",
      "====> Epoch: 500 Average training loss: 3.0181\n",
      "====> Epoch: 600 Average training loss: 2.6869\n",
      "====> Epoch: 700 Average training loss: 2.4208\n",
      "====> Epoch: 800 Average training loss: 2.2225\n",
      "====> Epoch: 900 Average training loss: 2.0144\n",
      "====> Epoch: 1000 Average training loss: 1.8619\n",
      "====> Epoch: 1100 Average training loss: 1.7178\n",
      "====> Epoch: 1200 Average training loss: 1.6018\n",
      "====> Epoch: 1300 Average training loss: 1.4902\n",
      "====> Epoch: 1400 Average training loss: 1.4123\n",
      "====> Epoch: 1500 Average training loss: 1.3287\n",
      "====> Epoch: 1600 Average training loss: 1.2550\n",
      "====> Epoch: 1700 Average training loss: 1.1944\n",
      "====> Epoch: 1800 Average training loss: 1.1286\n",
      "====> Epoch: 100 Average training loss: 5.9246\n",
      "====> Epoch: 200 Average training loss: 4.7257\n",
      "====> Epoch: 300 Average training loss: 3.9895\n",
      "====> Epoch: 400 Average training loss: 3.4469\n",
      "====> Epoch: 500 Average training loss: 3.0478\n",
      "====> Epoch: 600 Average training loss: 2.7189\n",
      "====> Epoch: 700 Average training loss: 2.4426\n",
      "====> Epoch: 800 Average training loss: 2.2349\n",
      "====> Epoch: 900 Average training loss: 2.0452\n",
      "====> Epoch: 1000 Average training loss: 1.8818\n",
      "====> Epoch: 1100 Average training loss: 1.7467\n",
      "====> Epoch: 1200 Average training loss: 1.6098\n",
      "====> Epoch: 1300 Average training loss: 1.5068\n",
      "====> Epoch: 1400 Average training loss: 1.4183\n",
      "====> Epoch: 1500 Average training loss: 1.3244\n",
      "====> Epoch: 1600 Average training loss: 1.2538\n",
      "====> Epoch: 1700 Average training loss: 1.1990\n",
      "====> Epoch: 1800 Average training loss: 1.1134\n",
      "====> Epoch: 100 Average training loss: 5.9009\n",
      "====> Epoch: 200 Average training loss: 4.7275\n",
      "====> Epoch: 300 Average training loss: 3.9955\n",
      "====> Epoch: 400 Average training loss: 3.4490\n",
      "====> Epoch: 500 Average training loss: 3.0397\n",
      "====> Epoch: 600 Average training loss: 2.7093\n",
      "====> Epoch: 700 Average training loss: 2.4364\n",
      "====> Epoch: 800 Average training loss: 2.2214\n",
      "====> Epoch: 900 Average training loss: 2.0334\n",
      "====> Epoch: 1000 Average training loss: 1.8737\n",
      "====> Epoch: 1100 Average training loss: 1.7364\n",
      "====> Epoch: 1200 Average training loss: 1.6144\n",
      "====> Epoch: 1300 Average training loss: 1.5138\n",
      "====> Epoch: 1400 Average training loss: 1.4022\n",
      "====> Epoch: 1500 Average training loss: 1.3379\n",
      "====> Epoch: 1600 Average training loss: 1.2258\n",
      "====> Epoch: 1700 Average training loss: 1.1182\n",
      "====> Epoch: 1800 Average training loss: 1.0689\n",
      "====> Epoch: 100 Average training loss: 5.9296\n",
      "====> Epoch: 200 Average training loss: 4.7379\n",
      "====> Epoch: 300 Average training loss: 3.9711\n",
      "====> Epoch: 400 Average training loss: 3.4247\n",
      "====> Epoch: 500 Average training loss: 3.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 600 Average training loss: 2.6959\n",
      "====> Epoch: 700 Average training loss: 2.4168\n",
      "====> Epoch: 800 Average training loss: 2.1968\n",
      "====> Epoch: 900 Average training loss: 2.0216\n",
      "====> Epoch: 1000 Average training loss: 1.8580\n",
      "====> Epoch: 1100 Average training loss: 1.7030\n",
      "====> Epoch: 1200 Average training loss: 1.5909\n",
      "====> Epoch: 1300 Average training loss: 1.4924\n",
      "====> Epoch: 1400 Average training loss: 1.4026\n",
      "====> Epoch: 1500 Average training loss: 1.3186\n",
      "====> Epoch: 1600 Average training loss: 1.2558\n",
      "====> Epoch: 1700 Average training loss: 1.1847\n",
      "====> Epoch: 1800 Average training loss: 1.1315\n",
      "====> Epoch: 100 Average training loss: 5.9073\n",
      "====> Epoch: 200 Average training loss: 4.7493\n",
      "====> Epoch: 300 Average training loss: 4.0115\n",
      "====> Epoch: 400 Average training loss: 3.4618\n",
      "====> Epoch: 500 Average training loss: 3.0514\n",
      "====> Epoch: 600 Average training loss: 2.6945\n",
      "====> Epoch: 700 Average training loss: 2.4324\n",
      "====> Epoch: 800 Average training loss: 2.2175\n",
      "====> Epoch: 900 Average training loss: 2.0219\n",
      "====> Epoch: 1000 Average training loss: 1.8393\n",
      "====> Epoch: 1100 Average training loss: 1.6868\n",
      "====> Epoch: 1200 Average training loss: 1.5461\n",
      "====> Epoch: 1300 Average training loss: 1.4475\n",
      "====> Epoch: 1400 Average training loss: 1.3438\n",
      "====> Epoch: 1500 Average training loss: 1.2810\n",
      "====> Epoch: 1600 Average training loss: 1.2035\n",
      "====> Epoch: 1700 Average training loss: 1.1407\n",
      "====> Epoch: 1800 Average training loss: 1.0737\n",
      "====> Epoch: 100 Average training loss: 5.9147\n",
      "====> Epoch: 200 Average training loss: 4.7380\n",
      "====> Epoch: 300 Average training loss: 3.9732\n",
      "====> Epoch: 400 Average training loss: 3.4292\n",
      "====> Epoch: 500 Average training loss: 3.0086\n",
      "====> Epoch: 600 Average training loss: 2.6958\n",
      "====> Epoch: 700 Average training loss: 2.4110\n",
      "====> Epoch: 800 Average training loss: 2.1903\n",
      "====> Epoch: 900 Average training loss: 2.0044\n",
      "====> Epoch: 1000 Average training loss: 1.8512\n",
      "====> Epoch: 1100 Average training loss: 1.7069\n",
      "====> Epoch: 1200 Average training loss: 1.5867\n",
      "====> Epoch: 1300 Average training loss: 1.4836\n",
      "====> Epoch: 1400 Average training loss: 1.3840\n",
      "====> Epoch: 1500 Average training loss: 1.3153\n",
      "====> Epoch: 1600 Average training loss: 1.2381\n",
      "====> Epoch: 1700 Average training loss: 1.1707\n",
      "====> Epoch: 1800 Average training loss: 1.1224\n",
      "====> Epoch: 100 Average training loss: 5.9350\n",
      "====> Epoch: 200 Average training loss: 4.7417\n",
      "====> Epoch: 300 Average training loss: 3.9589\n",
      "====> Epoch: 400 Average training loss: 3.4115\n",
      "====> Epoch: 500 Average training loss: 3.0044\n",
      "====> Epoch: 600 Average training loss: 2.6667\n",
      "====> Epoch: 700 Average training loss: 2.4072\n",
      "====> Epoch: 800 Average training loss: 2.1797\n",
      "====> Epoch: 900 Average training loss: 1.9937\n",
      "====> Epoch: 1000 Average training loss: 1.8426\n",
      "====> Epoch: 1100 Average training loss: 1.6966\n",
      "====> Epoch: 1200 Average training loss: 1.5816\n",
      "====> Epoch: 1300 Average training loss: 1.4766\n",
      "====> Epoch: 1400 Average training loss: 1.3885\n",
      "====> Epoch: 1500 Average training loss: 1.3030\n",
      "====> Epoch: 1600 Average training loss: 1.2394\n",
      "====> Epoch: 1700 Average training loss: 1.1735\n",
      "====> Epoch: 1800 Average training loss: 1.1170\n",
      "====> Epoch: 100 Average training loss: 5.9020\n",
      "====> Epoch: 200 Average training loss: 4.7278\n",
      "====> Epoch: 300 Average training loss: 3.9858\n",
      "====> Epoch: 400 Average training loss: 3.4637\n",
      "====> Epoch: 500 Average training loss: 3.0250\n",
      "====> Epoch: 600 Average training loss: 2.0599\n",
      "====> Epoch: 700 Average training loss: 1.7599\n",
      "====> Epoch: 800 Average training loss: 1.5407\n",
      "====> Epoch: 900 Average training loss: 1.3767\n",
      "====> Epoch: 1000 Average training loss: 1.2417\n",
      "====> Epoch: 1100 Average training loss: 1.1296\n",
      "====> Epoch: 1200 Average training loss: 1.0315\n",
      "====> Epoch: 1300 Average training loss: 0.9467\n",
      "====> Epoch: 1400 Average training loss: 0.8719\n",
      "====> Epoch: 1500 Average training loss: 0.8074\n",
      "====> Epoch: 1600 Average training loss: 0.7506\n",
      "====> Epoch: 1700 Average training loss: 0.7009\n",
      "====> Epoch: 1800 Average training loss: 0.6563\n",
      "====> Epoch: 100 Average training loss: 5.9256\n",
      "====> Epoch: 200 Average training loss: 4.7437\n",
      "====> Epoch: 300 Average training loss: 3.9736\n",
      "====> Epoch: 400 Average training loss: 3.4283\n",
      "====> Epoch: 500 Average training loss: 3.0148\n",
      "====> Epoch: 600 Average training loss: 2.6808\n",
      "====> Epoch: 700 Average training loss: 2.4131\n",
      "====> Epoch: 800 Average training loss: 2.2012\n",
      "====> Epoch: 900 Average training loss: 2.0082\n",
      "====> Epoch: 1000 Average training loss: 1.8483\n",
      "====> Epoch: 1100 Average training loss: 1.7034\n",
      "====> Epoch: 1200 Average training loss: 1.5930\n",
      "====> Epoch: 1300 Average training loss: 1.4912\n",
      "====> Epoch: 1400 Average training loss: 1.3918\n",
      "====> Epoch: 1500 Average training loss: 1.3243\n",
      "====> Epoch: 1600 Average training loss: 1.2419\n",
      "====> Epoch: 1700 Average training loss: 1.1973\n",
      "====> Epoch: 1800 Average training loss: 1.1392\n",
      "====> Epoch: 100 Average training loss: 5.9384\n",
      "====> Epoch: 200 Average training loss: 4.7565\n",
      "====> Epoch: 300 Average training loss: 4.0001\n",
      "====> Epoch: 400 Average training loss: 3.4588\n",
      "====> Epoch: 500 Average training loss: 3.0389\n",
      "====> Epoch: 600 Average training loss: 2.7175\n",
      "====> Epoch: 700 Average training loss: 2.4531\n",
      "====> Epoch: 800 Average training loss: 2.2211\n",
      "====> Epoch: 900 Average training loss: 2.0424\n",
      "====> Epoch: 1000 Average training loss: 1.8808\n",
      "====> Epoch: 1100 Average training loss: 1.7419\n",
      "====> Epoch: 1200 Average training loss: 1.6204\n",
      "====> Epoch: 1300 Average training loss: 1.5170\n",
      "====> Epoch: 1400 Average training loss: 1.4212\n",
      "====> Epoch: 1500 Average training loss: 1.3423\n",
      "====> Epoch: 1600 Average training loss: 1.2418\n",
      "====> Epoch: 1700 Average training loss: 1.1547\n",
      "====> Epoch: 1800 Average training loss: 1.1488\n",
      "====> Epoch: 100 Average training loss: 5.9262\n",
      "====> Epoch: 200 Average training loss: 4.7191\n",
      "====> Epoch: 300 Average training loss: 3.9649\n",
      "====> Epoch: 400 Average training loss: 3.4272\n",
      "====> Epoch: 500 Average training loss: 3.0153\n",
      "====> Epoch: 600 Average training loss: 2.6785\n",
      "====> Epoch: 700 Average training loss: 2.4137\n",
      "====> Epoch: 800 Average training loss: 2.2035\n",
      "====> Epoch: 900 Average training loss: 2.0152\n",
      "====> Epoch: 1000 Average training loss: 1.8416\n",
      "====> Epoch: 1100 Average training loss: 1.1965\n",
      "====> Epoch: 1200 Average training loss: 1.0331\n",
      "====> Epoch: 1300 Average training loss: 0.9432\n",
      "====> Epoch: 1400 Average training loss: 0.8678\n",
      "====> Epoch: 1500 Average training loss: 0.8079\n",
      "====> Epoch: 1600 Average training loss: 0.7547\n",
      "====> Epoch: 1700 Average training loss: 0.7026\n",
      "====> Epoch: 1800 Average training loss: 0.6612\n",
      "====> Epoch: 100 Average training loss: 5.9350\n",
      "====> Epoch: 200 Average training loss: 4.7298\n",
      "====> Epoch: 300 Average training loss: 3.9749\n",
      "====> Epoch: 400 Average training loss: 3.4609\n",
      "====> Epoch: 500 Average training loss: 3.0393\n",
      "====> Epoch: 600 Average training loss: 2.7087\n",
      "====> Epoch: 700 Average training loss: 2.4237\n",
      "====> Epoch: 800 Average training loss: 2.1626\n",
      "====> Epoch: 900 Average training loss: 1.6394\n",
      "====> Epoch: 1000 Average training loss: 1.4599\n",
      "====> Epoch: 1100 Average training loss: 1.4371\n",
      "====> Epoch: 1200 Average training loss: 1.2312\n",
      "====> Epoch: 1300 Average training loss: 1.1701\n",
      "====> Epoch: 1400 Average training loss: 1.1747\n",
      "====> Epoch: 1500 Average training loss: 1.0739\n",
      "====> Epoch: 1600 Average training loss: 1.0168\n",
      "====> Epoch: 1700 Average training loss: 0.9798\n",
      "====> Epoch: 1800 Average training loss: 0.8993\n",
      "====> Epoch: 100 Average training loss: 4.7467\n",
      "====> Epoch: 200 Average training loss: 3.6087\n",
      "====> Epoch: 300 Average training loss: 2.9688\n",
      "====> Epoch: 400 Average training loss: 2.5161\n",
      "====> Epoch: 500 Average training loss: 2.2147\n",
      "====> Epoch: 600 Average training loss: 1.9148\n",
      "====> Epoch: 700 Average training loss: 1.6852\n",
      "====> Epoch: 800 Average training loss: 1.4717\n",
      "====> Epoch: 900 Average training loss: 1.2455\n",
      "====> Epoch: 1000 Average training loss: 1.2118\n",
      "====> Epoch: 1100 Average training loss: 1.0497\n",
      "====> Epoch: 1200 Average training loss: 0.9664\n",
      "====> Epoch: 1300 Average training loss: 0.8178\n",
      "====> Epoch: 1400 Average training loss: 0.7735\n",
      "====> Epoch: 1500 Average training loss: 0.7389\n",
      "====> Epoch: 1600 Average training loss: 0.6739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1700 Average training loss: 0.6331\n",
      "====> Epoch: 1800 Average training loss: 0.5852\n",
      "====> Epoch: 100 Average training loss: 5.9231\n",
      "====> Epoch: 200 Average training loss: 4.7416\n",
      "====> Epoch: 300 Average training loss: 3.9952\n",
      "====> Epoch: 400 Average training loss: 3.4267\n",
      "====> Epoch: 500 Average training loss: 3.0087\n",
      "====> Epoch: 600 Average training loss: 2.7266\n",
      "====> Epoch: 700 Average training loss: 2.4436\n",
      "====> Epoch: 800 Average training loss: 2.2068\n",
      "====> Epoch: 900 Average training loss: 2.0297\n",
      "====> Epoch: 1000 Average training loss: 1.8684\n",
      "====> Epoch: 1100 Average training loss: 1.7343\n",
      "====> Epoch: 1200 Average training loss: 1.6096\n",
      "====> Epoch: 1300 Average training loss: 1.5133\n",
      "====> Epoch: 1400 Average training loss: 1.4314\n",
      "====> Epoch: 1500 Average training loss: 1.3327\n",
      "====> Epoch: 1600 Average training loss: 1.2749\n",
      "====> Epoch: 1700 Average training loss: 1.2105\n",
      "====> Epoch: 1800 Average training loss: 1.1408\n",
      "====> Epoch: 100 Average training loss: 5.9048\n",
      "====> Epoch: 200 Average training loss: 4.7361\n",
      "====> Epoch: 300 Average training loss: 3.9859\n",
      "====> Epoch: 400 Average training loss: 3.4384\n",
      "====> Epoch: 500 Average training loss: 3.0149\n",
      "====> Epoch: 600 Average training loss: 2.6871\n",
      "====> Epoch: 700 Average training loss: 1.8564\n",
      "====> Epoch: 800 Average training loss: 1.6234\n",
      "====> Epoch: 900 Average training loss: 1.4394\n",
      "====> Epoch: 1000 Average training loss: 1.2957\n",
      "====> Epoch: 1100 Average training loss: 1.1800\n",
      "====> Epoch: 1200 Average training loss: 1.0424\n",
      "====> Epoch: 1300 Average training loss: 0.9491\n",
      "====> Epoch: 1400 Average training loss: 0.8793\n",
      "====> Epoch: 1500 Average training loss: 0.8138\n",
      "====> Epoch: 1600 Average training loss: 0.7602\n",
      "====> Epoch: 1700 Average training loss: 0.7100\n",
      "====> Epoch: 1800 Average training loss: 0.6673\n",
      "====> Epoch: 100 Average training loss: 5.9437\n",
      "====> Epoch: 200 Average training loss: 4.7622\n",
      "====> Epoch: 300 Average training loss: 4.0189\n",
      "====> Epoch: 400 Average training loss: 3.4825\n",
      "====> Epoch: 500 Average training loss: 3.0653\n",
      "====> Epoch: 600 Average training loss: 2.7393\n",
      "====> Epoch: 700 Average training loss: 2.4617\n",
      "====> Epoch: 800 Average training loss: 2.2272\n",
      "====> Epoch: 900 Average training loss: 2.0334\n",
      "====> Epoch: 1000 Average training loss: 1.8838\n",
      "====> Epoch: 1100 Average training loss: 1.7434\n",
      "====> Epoch: 1200 Average training loss: 1.6188\n",
      "====> Epoch: 1300 Average training loss: 1.5069\n",
      "====> Epoch: 1400 Average training loss: 1.4356\n",
      "====> Epoch: 1500 Average training loss: 1.3253\n",
      "====> Epoch: 1600 Average training loss: 1.2707\n",
      "====> Epoch: 1700 Average training loss: 1.1776\n",
      "====> Epoch: 1800 Average training loss: 1.1374\n",
      "====> Epoch: 100 Average training loss: 5.9165\n",
      "====> Epoch: 200 Average training loss: 4.7549\n",
      "====> Epoch: 300 Average training loss: 3.9921\n",
      "====> Epoch: 400 Average training loss: 3.4620\n",
      "====> Epoch: 500 Average training loss: 3.0475\n",
      "====> Epoch: 600 Average training loss: 2.6971\n",
      "====> Epoch: 700 Average training loss: 2.4464\n",
      "====> Epoch: 800 Average training loss: 2.2197\n",
      "====> Epoch: 900 Average training loss: 2.0206\n",
      "====> Epoch: 1000 Average training loss: 1.8551\n",
      "====> Epoch: 1100 Average training loss: 1.7165\n",
      "====> Epoch: 1200 Average training loss: 1.6077\n",
      "====> Epoch: 1300 Average training loss: 1.4984\n",
      "====> Epoch: 1400 Average training loss: 1.4063\n",
      "====> Epoch: 1500 Average training loss: 1.3174\n",
      "====> Epoch: 1600 Average training loss: 1.2572\n",
      "====> Epoch: 1700 Average training loss: 1.1888\n",
      "====> Epoch: 1800 Average training loss: 1.1395\n",
      "====> Epoch: 100 Average training loss: 5.9262\n",
      "====> Epoch: 200 Average training loss: 4.7413\n",
      "====> Epoch: 300 Average training loss: 3.9906\n",
      "====> Epoch: 400 Average training loss: 3.4406\n",
      "====> Epoch: 500 Average training loss: 3.0180\n",
      "====> Epoch: 600 Average training loss: 2.6937\n",
      "====> Epoch: 700 Average training loss: 2.4142\n",
      "====> Epoch: 800 Average training loss: 2.1908\n",
      "====> Epoch: 900 Average training loss: 2.0133\n",
      "====> Epoch: 1000 Average training loss: 1.8409\n",
      "====> Epoch: 1100 Average training loss: 1.7051\n",
      "====> Epoch: 1200 Average training loss: 1.5812\n",
      "====> Epoch: 1300 Average training loss: 1.4888\n",
      "====> Epoch: 1400 Average training loss: 1.3886\n",
      "====> Epoch: 1500 Average training loss: 1.3092\n",
      "====> Epoch: 1600 Average training loss: 1.2535\n",
      "====> Epoch: 1700 Average training loss: 1.1720\n",
      "====> Epoch: 1800 Average training loss: 1.1198\n",
      "====> Epoch: 100 Average training loss: 5.9107\n",
      "====> Epoch: 200 Average training loss: 4.0677\n",
      "====> Epoch: 300 Average training loss: 3.1018\n",
      "====> Epoch: 400 Average training loss: 2.6329\n",
      "====> Epoch: 500 Average training loss: 2.2802\n",
      "====> Epoch: 600 Average training loss: 1.9935\n",
      "====> Epoch: 700 Average training loss: 1.7674\n",
      "====> Epoch: 800 Average training loss: 1.5822\n",
      "====> Epoch: 900 Average training loss: 1.4175\n",
      "====> Epoch: 1000 Average training loss: 1.2812\n",
      "====> Epoch: 1100 Average training loss: 1.1666\n",
      "====> Epoch: 1200 Average training loss: 1.0670\n",
      "====> Epoch: 1300 Average training loss: 0.9829\n",
      "====> Epoch: 1400 Average training loss: 0.9073\n",
      "====> Epoch: 1500 Average training loss: 0.8417\n",
      "====> Epoch: 1600 Average training loss: 0.7849\n",
      "====> Epoch: 1700 Average training loss: 0.7338\n",
      "====> Epoch: 1800 Average training loss: 0.6889\n",
      "====> Epoch: 100 Average training loss: 5.9191\n",
      "====> Epoch: 200 Average training loss: 4.7481\n",
      "====> Epoch: 300 Average training loss: 3.9559\n",
      "====> Epoch: 400 Average training loss: 3.4144\n",
      "====> Epoch: 500 Average training loss: 3.0097\n",
      "====> Epoch: 600 Average training loss: 2.6934\n",
      "====> Epoch: 700 Average training loss: 2.4239\n",
      "====> Epoch: 800 Average training loss: 2.2100\n",
      "====> Epoch: 900 Average training loss: 2.0220\n",
      "====> Epoch: 1000 Average training loss: 1.8629\n",
      "====> Epoch: 1100 Average training loss: 1.7282\n",
      "====> Epoch: 1200 Average training loss: 1.6000\n",
      "====> Epoch: 1300 Average training loss: 1.5009\n",
      "====> Epoch: 1400 Average training loss: 1.4209\n",
      "====> Epoch: 1500 Average training loss: 1.3297\n",
      "====> Epoch: 1600 Average training loss: 1.2617\n",
      "====> Epoch: 1700 Average training loss: 1.1985\n",
      "====> Epoch: 1800 Average training loss: 1.1358\n",
      "====> Epoch: 100 Average training loss: 5.9287\n",
      "====> Epoch: 200 Average training loss: 4.7326\n",
      "====> Epoch: 300 Average training loss: 3.9716\n",
      "====> Epoch: 400 Average training loss: 3.4283\n",
      "====> Epoch: 500 Average training loss: 3.0183\n",
      "====> Epoch: 600 Average training loss: 2.6965\n",
      "====> Epoch: 700 Average training loss: 2.4264\n",
      "====> Epoch: 800 Average training loss: 2.2085\n",
      "====> Epoch: 900 Average training loss: 2.0160\n",
      "====> Epoch: 1000 Average training loss: 1.8694\n",
      "====> Epoch: 1100 Average training loss: 1.7194\n",
      "====> Epoch: 1200 Average training loss: 1.6011\n",
      "====> Epoch: 1300 Average training loss: 1.5013\n",
      "====> Epoch: 1400 Average training loss: 1.4089\n",
      "====> Epoch: 1500 Average training loss: 1.3344\n",
      "====> Epoch: 1600 Average training loss: 1.2540\n",
      "====> Epoch: 1700 Average training loss: 1.1911\n",
      "====> Epoch: 1800 Average training loss: 1.1509\n",
      "====> Epoch: 100 Average training loss: 5.9321\n",
      "====> Epoch: 200 Average training loss: 4.7306\n",
      "====> Epoch: 300 Average training loss: 3.9582\n",
      "====> Epoch: 400 Average training loss: 3.4409\n",
      "====> Epoch: 500 Average training loss: 3.0097\n",
      "====> Epoch: 600 Average training loss: 2.6833\n",
      "====> Epoch: 700 Average training loss: 2.4165\n",
      "====> Epoch: 800 Average training loss: 2.2081\n",
      "====> Epoch: 900 Average training loss: 2.0061\n",
      "====> Epoch: 1000 Average training loss: 1.8490\n",
      "====> Epoch: 1100 Average training loss: 1.7081\n",
      "====> Epoch: 1200 Average training loss: 1.5961\n",
      "====> Epoch: 1300 Average training loss: 1.4993\n",
      "====> Epoch: 1400 Average training loss: 1.4071\n",
      "====> Epoch: 1500 Average training loss: 1.3133\n",
      "====> Epoch: 1600 Average training loss: 1.2479\n",
      "====> Epoch: 1700 Average training loss: 1.1826\n",
      "====> Epoch: 1800 Average training loss: 1.1296\n",
      "====> Epoch: 100 Average training loss: 5.9196\n",
      "====> Epoch: 200 Average training loss: 4.7373\n",
      "====> Epoch: 300 Average training loss: 3.9822\n",
      "====> Epoch: 400 Average training loss: 3.4330\n",
      "====> Epoch: 500 Average training loss: 3.0410\n",
      "====> Epoch: 600 Average training loss: 2.6886\n",
      "====> Epoch: 700 Average training loss: 2.4208\n",
      "====> Epoch: 800 Average training loss: 2.1986\n",
      "====> Epoch: 900 Average training loss: 2.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1000 Average training loss: 1.8489\n",
      "====> Epoch: 1100 Average training loss: 1.7000\n",
      "====> Epoch: 1200 Average training loss: 1.6019\n",
      "====> Epoch: 1300 Average training loss: 1.4871\n",
      "====> Epoch: 1400 Average training loss: 1.3922\n",
      "====> Epoch: 1500 Average training loss: 1.3183\n",
      "====> Epoch: 1600 Average training loss: 1.2500\n",
      "====> Epoch: 1700 Average training loss: 1.1832\n",
      "====> Epoch: 1800 Average training loss: 1.1277\n",
      "====> Epoch: 100 Average training loss: 5.9321\n",
      "====> Epoch: 200 Average training loss: 4.7482\n",
      "====> Epoch: 300 Average training loss: 3.9946\n",
      "====> Epoch: 400 Average training loss: 3.4552\n",
      "====> Epoch: 500 Average training loss: 3.0461\n",
      "====> Epoch: 600 Average training loss: 2.7098\n",
      "====> Epoch: 700 Average training loss: 2.4457\n",
      "====> Epoch: 800 Average training loss: 2.2264\n",
      "====> Epoch: 900 Average training loss: 2.0320\n",
      "====> Epoch: 1000 Average training loss: 1.8663\n",
      "====> Epoch: 1100 Average training loss: 1.7301\n",
      "====> Epoch: 1200 Average training loss: 1.6065\n",
      "====> Epoch: 1300 Average training loss: 1.5050\n",
      "====> Epoch: 1400 Average training loss: 1.3964\n",
      "====> Epoch: 1500 Average training loss: 1.2775\n",
      "====> Epoch: 1600 Average training loss: 1.2196\n",
      "====> Epoch: 1700 Average training loss: 1.1610\n",
      "====> Epoch: 1800 Average training loss: 1.0828\n",
      "====> Epoch: 100 Average training loss: 5.8966\n",
      "====> Epoch: 200 Average training loss: 4.7349\n",
      "====> Epoch: 300 Average training loss: 3.9604\n",
      "====> Epoch: 400 Average training loss: 3.4305\n",
      "====> Epoch: 500 Average training loss: 3.0265\n",
      "====> Epoch: 600 Average training loss: 2.7130\n",
      "====> Epoch: 700 Average training loss: 2.4289\n",
      "====> Epoch: 800 Average training loss: 2.2168\n",
      "====> Epoch: 900 Average training loss: 2.0271\n",
      "====> Epoch: 1000 Average training loss: 1.8558\n",
      "====> Epoch: 1100 Average training loss: 1.7181\n",
      "====> Epoch: 1200 Average training loss: 1.6174\n",
      "====> Epoch: 1300 Average training loss: 1.5068\n",
      "====> Epoch: 1400 Average training loss: 1.4060\n",
      "====> Epoch: 1500 Average training loss: 1.3252\n",
      "====> Epoch: 1600 Average training loss: 1.2503\n",
      "====> Epoch: 1700 Average training loss: 1.2075\n",
      "====> Epoch: 1800 Average training loss: 1.1206\n",
      "====> Epoch: 100 Average training loss: 5.9310\n",
      "====> Epoch: 200 Average training loss: 4.7255\n",
      "====> Epoch: 300 Average training loss: 3.9760\n",
      "====> Epoch: 400 Average training loss: 3.4368\n",
      "====> Epoch: 500 Average training loss: 3.0323\n",
      "====> Epoch: 600 Average training loss: 2.6899\n",
      "====> Epoch: 700 Average training loss: 2.4328\n",
      "====> Epoch: 800 Average training loss: 2.2081\n",
      "====> Epoch: 900 Average training loss: 2.0174\n",
      "====> Epoch: 1000 Average training loss: 1.8596\n",
      "====> Epoch: 1100 Average training loss: 1.7386\n",
      "====> Epoch: 1200 Average training loss: 1.6006\n",
      "====> Epoch: 1300 Average training loss: 1.4954\n",
      "====> Epoch: 1400 Average training loss: 1.3967\n",
      "====> Epoch: 1500 Average training loss: 1.3233\n",
      "====> Epoch: 1600 Average training loss: 1.2479\n",
      "====> Epoch: 1700 Average training loss: 1.1815\n",
      "====> Epoch: 1800 Average training loss: 1.1259\n",
      "====> Epoch: 100 Average training loss: 5.9175\n",
      "====> Epoch: 200 Average training loss: 4.7019\n",
      "====> Epoch: 300 Average training loss: 3.9564\n",
      "====> Epoch: 400 Average training loss: 3.4213\n",
      "====> Epoch: 500 Average training loss: 3.0099\n",
      "====> Epoch: 600 Average training loss: 2.6913\n",
      "====> Epoch: 700 Average training loss: 2.4333\n",
      "====> Epoch: 800 Average training loss: 2.2188\n",
      "====> Epoch: 900 Average training loss: 1.5587\n",
      "====> Epoch: 1000 Average training loss: 1.2790\n",
      "====> Epoch: 1100 Average training loss: 1.1382\n",
      "====> Epoch: 1200 Average training loss: 1.0284\n",
      "====> Epoch: 1300 Average training loss: 0.9399\n",
      "====> Epoch: 1400 Average training loss: 0.8632\n",
      "====> Epoch: 1500 Average training loss: 0.7908\n",
      "====> Epoch: 1600 Average training loss: 0.7349\n",
      "====> Epoch: 1700 Average training loss: 0.6801\n",
      "====> Epoch: 1800 Average training loss: 0.6324\n",
      "====> Epoch: 100 Average training loss: 5.9018\n",
      "====> Epoch: 200 Average training loss: 4.7184\n",
      "====> Epoch: 300 Average training loss: 3.9984\n",
      "====> Epoch: 400 Average training loss: 3.4347\n",
      "====> Epoch: 500 Average training loss: 3.0269\n",
      "====> Epoch: 600 Average training loss: 2.7041\n",
      "====> Epoch: 700 Average training loss: 2.4345\n",
      "====> Epoch: 800 Average training loss: 2.2032\n",
      "====> Epoch: 900 Average training loss: 2.0062\n",
      "====> Epoch: 1000 Average training loss: 1.8592\n",
      "====> Epoch: 1100 Average training loss: 1.7116\n",
      "====> Epoch: 1200 Average training loss: 1.6016\n",
      "====> Epoch: 1300 Average training loss: 1.4870\n",
      "====> Epoch: 1400 Average training loss: 1.3908\n",
      "====> Epoch: 1500 Average training loss: 1.3209\n",
      "====> Epoch: 1600 Average training loss: 1.2458\n",
      "====> Epoch: 1700 Average training loss: 1.1822\n",
      "====> Epoch: 1800 Average training loss: 1.1338\n",
      "====> Epoch: 100 Average training loss: 5.9279\n",
      "====> Epoch: 200 Average training loss: 4.7336\n",
      "====> Epoch: 300 Average training loss: 3.9715\n",
      "====> Epoch: 400 Average training loss: 3.4361\n",
      "====> Epoch: 500 Average training loss: 2.9976\n",
      "====> Epoch: 600 Average training loss: 2.6864\n",
      "====> Epoch: 700 Average training loss: 2.4137\n",
      "====> Epoch: 800 Average training loss: 2.1844\n",
      "====> Epoch: 900 Average training loss: 1.9991\n",
      "====> Epoch: 1000 Average training loss: 1.8430\n",
      "====> Epoch: 1100 Average training loss: 1.7112\n",
      "====> Epoch: 1200 Average training loss: 1.5937\n",
      "====> Epoch: 1300 Average training loss: 1.4877\n",
      "====> Epoch: 1400 Average training loss: 1.3971\n",
      "====> Epoch: 1500 Average training loss: 1.3198\n",
      "====> Epoch: 1600 Average training loss: 1.2540\n",
      "====> Epoch: 1700 Average training loss: 1.1888\n",
      "====> Epoch: 1800 Average training loss: 1.1449\n",
      "====> Epoch: 100 Average training loss: 5.8972\n",
      "====> Epoch: 200 Average training loss: 4.7249\n",
      "====> Epoch: 300 Average training loss: 3.9642\n",
      "====> Epoch: 400 Average training loss: 3.4425\n",
      "====> Epoch: 500 Average training loss: 2.9859\n",
      "====> Epoch: 600 Average training loss: 2.6669\n",
      "====> Epoch: 700 Average training loss: 2.4040\n",
      "====> Epoch: 800 Average training loss: 2.1855\n",
      "====> Epoch: 900 Average training loss: 1.9866\n",
      "====> Epoch: 1000 Average training loss: 1.8178\n",
      "====> Epoch: 1100 Average training loss: 1.6793\n",
      "====> Epoch: 1200 Average training loss: 1.5644\n",
      "====> Epoch: 1300 Average training loss: 1.4556\n",
      "====> Epoch: 1400 Average training loss: 1.3669\n",
      "====> Epoch: 1500 Average training loss: 1.2890\n",
      "====> Epoch: 1600 Average training loss: 1.2168\n",
      "====> Epoch: 1700 Average training loss: 1.1524\n",
      "====> Epoch: 1800 Average training loss: 1.0898\n",
      "====> Epoch: 100 Average training loss: 5.9108\n",
      "====> Epoch: 200 Average training loss: 4.7327\n",
      "====> Epoch: 300 Average training loss: 3.9777\n",
      "====> Epoch: 400 Average training loss: 3.4338\n",
      "====> Epoch: 500 Average training loss: 3.0188\n",
      "====> Epoch: 600 Average training loss: 2.6984\n",
      "====> Epoch: 700 Average training loss: 2.4314\n",
      "====> Epoch: 800 Average training loss: 2.2044\n",
      "====> Epoch: 900 Average training loss: 2.0302\n",
      "====> Epoch: 1000 Average training loss: 1.8474\n",
      "====> Epoch: 1100 Average training loss: 1.7261\n",
      "====> Epoch: 1200 Average training loss: 1.5935\n",
      "====> Epoch: 1300 Average training loss: 1.4910\n",
      "====> Epoch: 1400 Average training loss: 1.3949\n",
      "====> Epoch: 1500 Average training loss: 1.3210\n",
      "====> Epoch: 1600 Average training loss: 1.2424\n",
      "====> Epoch: 1700 Average training loss: 1.1837\n",
      "====> Epoch: 1800 Average training loss: 1.1129\n",
      "====> Epoch: 100 Average training loss: 5.9155\n",
      "====> Epoch: 200 Average training loss: 4.7170\n",
      "====> Epoch: 300 Average training loss: 3.9812\n",
      "====> Epoch: 400 Average training loss: 3.4410\n",
      "====> Epoch: 500 Average training loss: 3.0325\n",
      "====> Epoch: 600 Average training loss: 2.2300\n",
      "====> Epoch: 700 Average training loss: 1.7457\n",
      "====> Epoch: 800 Average training loss: 1.5321\n",
      "====> Epoch: 900 Average training loss: 1.3743\n",
      "====> Epoch: 1000 Average training loss: 1.2455\n",
      "====> Epoch: 1100 Average training loss: 1.1545\n",
      "====> Epoch: 1200 Average training loss: 1.0385\n",
      "====> Epoch: 1300 Average training loss: 0.9812\n",
      "====> Epoch: 1400 Average training loss: 0.8988\n",
      "====> Epoch: 1500 Average training loss: 0.8325\n",
      "====> Epoch: 1600 Average training loss: 0.7682\n",
      "====> Epoch: 1700 Average training loss: 0.7135\n",
      "====> Epoch: 1800 Average training loss: 0.6714\n",
      "====> Epoch: 100 Average training loss: 5.9143\n",
      "====> Epoch: 200 Average training loss: 4.7488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 300 Average training loss: 3.9676\n",
      "====> Epoch: 400 Average training loss: 3.4465\n",
      "====> Epoch: 500 Average training loss: 3.0308\n",
      "====> Epoch: 600 Average training loss: 2.6875\n",
      "====> Epoch: 700 Average training loss: 2.4293\n",
      "====> Epoch: 800 Average training loss: 2.2105\n",
      "====> Epoch: 900 Average training loss: 2.0351\n",
      "====> Epoch: 1000 Average training loss: 1.8702\n",
      "====> Epoch: 1100 Average training loss: 1.7371\n",
      "====> Epoch: 1200 Average training loss: 1.6143\n",
      "====> Epoch: 1300 Average training loss: 1.5136\n",
      "====> Epoch: 1400 Average training loss: 1.4165\n",
      "====> Epoch: 1500 Average training loss: 1.3367\n",
      "====> Epoch: 1600 Average training loss: 1.2622\n",
      "====> Epoch: 1700 Average training loss: 1.1983\n",
      "====> Epoch: 1800 Average training loss: 1.1443\n",
      "====> Epoch: 100 Average training loss: 5.8892\n",
      "====> Epoch: 200 Average training loss: 4.7273\n",
      "====> Epoch: 300 Average training loss: 3.9613\n",
      "====> Epoch: 400 Average training loss: 3.4176\n",
      "====> Epoch: 500 Average training loss: 3.0031\n",
      "====> Epoch: 600 Average training loss: 2.6951\n",
      "====> Epoch: 700 Average training loss: 2.4264\n",
      "====> Epoch: 800 Average training loss: 2.2205\n",
      "====> Epoch: 900 Average training loss: 2.0206\n",
      "====> Epoch: 1000 Average training loss: 1.8625\n",
      "====> Epoch: 1100 Average training loss: 1.7281\n",
      "====> Epoch: 1200 Average training loss: 1.6008\n",
      "====> Epoch: 1300 Average training loss: 1.5001\n",
      "====> Epoch: 1400 Average training loss: 1.4130\n",
      "====> Epoch: 1500 Average training loss: 1.3298\n",
      "====> Epoch: 1600 Average training loss: 1.2562\n",
      "====> Epoch: 1700 Average training loss: 1.1936\n",
      "====> Epoch: 1800 Average training loss: 1.1469\n",
      "====> Epoch: 100 Average training loss: 5.9109\n",
      "====> Epoch: 200 Average training loss: 4.7491\n",
      "====> Epoch: 300 Average training loss: 3.9808\n",
      "====> Epoch: 400 Average training loss: 3.4589\n",
      "====> Epoch: 500 Average training loss: 3.0442\n",
      "====> Epoch: 600 Average training loss: 2.7017\n",
      "====> Epoch: 700 Average training loss: 1.7863\n",
      "====> Epoch: 800 Average training loss: 1.5622\n",
      "====> Epoch: 900 Average training loss: 1.3782\n",
      "====> Epoch: 1000 Average training loss: 1.2318\n",
      "====> Epoch: 1100 Average training loss: 1.1130\n",
      "====> Epoch: 1200 Average training loss: 1.0157\n",
      "====> Epoch: 1300 Average training loss: 0.9345\n",
      "====> Epoch: 1400 Average training loss: 0.8651\n",
      "====> Epoch: 1500 Average training loss: 0.8022\n",
      "====> Epoch: 1600 Average training loss: 0.7485\n",
      "====> Epoch: 1700 Average training loss: 0.7001\n",
      "====> Epoch: 1800 Average training loss: 0.6592\n",
      "====> Epoch: 100 Average training loss: 5.9071\n",
      "====> Epoch: 200 Average training loss: 4.7400\n",
      "====> Epoch: 300 Average training loss: 3.9796\n",
      "====> Epoch: 400 Average training loss: 3.4411\n",
      "====> Epoch: 500 Average training loss: 3.0282\n",
      "====> Epoch: 600 Average training loss: 2.6957\n",
      "====> Epoch: 700 Average training loss: 2.4338\n",
      "====> Epoch: 800 Average training loss: 2.2127\n",
      "====> Epoch: 900 Average training loss: 2.0140\n",
      "====> Epoch: 1000 Average training loss: 1.8720\n",
      "====> Epoch: 1100 Average training loss: 1.7366\n",
      "====> Epoch: 1200 Average training loss: 1.6078\n",
      "====> Epoch: 1300 Average training loss: 1.4858\n",
      "====> Epoch: 1400 Average training loss: 1.3980\n",
      "====> Epoch: 1500 Average training loss: 1.3060\n",
      "====> Epoch: 1600 Average training loss: 1.2241\n",
      "====> Epoch: 1700 Average training loss: 1.1579\n",
      "====> Epoch: 1800 Average training loss: 1.0866\n",
      "====> Epoch: 100 Average training loss: 5.9349\n",
      "====> Epoch: 200 Average training loss: 4.7617\n",
      "====> Epoch: 300 Average training loss: 4.0003\n",
      "====> Epoch: 400 Average training loss: 3.4513\n",
      "====> Epoch: 500 Average training loss: 3.0521\n",
      "====> Epoch: 600 Average training loss: 2.7141\n",
      "====> Epoch: 700 Average training loss: 2.4405\n",
      "====> Epoch: 800 Average training loss: 2.2213\n",
      "====> Epoch: 900 Average training loss: 2.0439\n",
      "====> Epoch: 1000 Average training loss: 1.8865\n",
      "====> Epoch: 1100 Average training loss: 1.7421\n",
      "====> Epoch: 1200 Average training loss: 1.6131\n",
      "====> Epoch: 1300 Average training loss: 1.5086\n",
      "====> Epoch: 1400 Average training loss: 1.4233\n",
      "====> Epoch: 1500 Average training loss: 1.3321\n",
      "====> Epoch: 1600 Average training loss: 1.2633\n",
      "====> Epoch: 1700 Average training loss: 1.1968\n",
      "====> Epoch: 1800 Average training loss: 1.1431\n",
      "====> Epoch: 100 Average training loss: 5.9107\n",
      "====> Epoch: 200 Average training loss: 4.7323\n",
      "====> Epoch: 300 Average training loss: 3.9851\n",
      "====> Epoch: 400 Average training loss: 3.4241\n",
      "====> Epoch: 500 Average training loss: 3.0198\n",
      "====> Epoch: 600 Average training loss: 2.6811\n",
      "====> Epoch: 700 Average training loss: 2.4238\n",
      "====> Epoch: 800 Average training loss: 2.2042\n",
      "====> Epoch: 900 Average training loss: 2.0147\n",
      "====> Epoch: 1000 Average training loss: 1.8612\n",
      "====> Epoch: 1100 Average training loss: 1.7245\n",
      "====> Epoch: 1200 Average training loss: 1.6094\n",
      "====> Epoch: 1300 Average training loss: 1.4988\n",
      "====> Epoch: 1400 Average training loss: 1.4102\n",
      "====> Epoch: 1500 Average training loss: 1.3260\n",
      "====> Epoch: 1600 Average training loss: 1.2616\n",
      "====> Epoch: 1700 Average training loss: 1.1943\n",
      "====> Epoch: 1800 Average training loss: 1.1454\n",
      "====> Epoch: 100 Average training loss: 5.9214\n",
      "====> Epoch: 200 Average training loss: 4.7350\n",
      "====> Epoch: 300 Average training loss: 3.9694\n",
      "====> Epoch: 400 Average training loss: 3.4421\n",
      "====> Epoch: 500 Average training loss: 3.0290\n",
      "====> Epoch: 600 Average training loss: 2.6958\n",
      "====> Epoch: 700 Average training loss: 2.4242\n",
      "====> Epoch: 800 Average training loss: 2.2095\n",
      "====> Epoch: 900 Average training loss: 2.0184\n",
      "====> Epoch: 1000 Average training loss: 1.8488\n",
      "====> Epoch: 1100 Average training loss: 1.7142\n",
      "====> Epoch: 1200 Average training loss: 1.5938\n",
      "====> Epoch: 1300 Average training loss: 1.4961\n",
      "====> Epoch: 1400 Average training loss: 1.4044\n",
      "====> Epoch: 1500 Average training loss: 1.3286\n",
      "====> Epoch: 1600 Average training loss: 1.2441\n",
      "====> Epoch: 1700 Average training loss: 1.1958\n",
      "====> Epoch: 1800 Average training loss: 1.1463\n",
      "====> Epoch: 100 Average training loss: 5.9061\n",
      "====> Epoch: 200 Average training loss: 4.7386\n",
      "====> Epoch: 300 Average training loss: 3.9739\n",
      "====> Epoch: 400 Average training loss: 3.4259\n",
      "====> Epoch: 500 Average training loss: 3.0086\n",
      "====> Epoch: 600 Average training loss: 2.6889\n",
      "====> Epoch: 700 Average training loss: 2.4315\n",
      "====> Epoch: 800 Average training loss: 2.1952\n",
      "====> Epoch: 900 Average training loss: 2.0004\n",
      "====> Epoch: 1000 Average training loss: 1.8480\n",
      "====> Epoch: 1100 Average training loss: 1.7147\n",
      "====> Epoch: 1200 Average training loss: 1.2214\n",
      "====> Epoch: 1300 Average training loss: 1.0618\n",
      "====> Epoch: 1400 Average training loss: 0.8957\n",
      "====> Epoch: 1500 Average training loss: 0.8149\n",
      "====> Epoch: 1600 Average training loss: 0.7518\n",
      "====> Epoch: 1700 Average training loss: 0.6961\n",
      "====> Epoch: 1800 Average training loss: 0.6584\n",
      "====> Epoch: 100 Average training loss: 5.9263\n",
      "====> Epoch: 200 Average training loss: 4.7663\n",
      "====> Epoch: 300 Average training loss: 3.9614\n",
      "====> Epoch: 400 Average training loss: 3.4233\n",
      "====> Epoch: 500 Average training loss: 3.0171\n",
      "====> Epoch: 600 Average training loss: 2.6950\n",
      "====> Epoch: 700 Average training loss: 2.4269\n",
      "====> Epoch: 800 Average training loss: 2.2029\n",
      "====> Epoch: 900 Average training loss: 2.0259\n",
      "====> Epoch: 1000 Average training loss: 1.8579\n",
      "====> Epoch: 1100 Average training loss: 1.7301\n",
      "====> Epoch: 1200 Average training loss: 1.6197\n",
      "====> Epoch: 1300 Average training loss: 1.5023\n",
      "====> Epoch: 1400 Average training loss: 1.4069\n",
      "====> Epoch: 1500 Average training loss: 1.3310\n",
      "====> Epoch: 1600 Average training loss: 1.2802\n",
      "====> Epoch: 1700 Average training loss: 1.2130\n",
      "====> Epoch: 1800 Average training loss: 1.1290\n",
      "====> Epoch: 100 Average training loss: 5.9231\n",
      "====> Epoch: 200 Average training loss: 4.7364\n",
      "====> Epoch: 300 Average training loss: 3.9645\n",
      "====> Epoch: 400 Average training loss: 3.4258\n",
      "====> Epoch: 500 Average training loss: 3.0170\n",
      "====> Epoch: 600 Average training loss: 2.6711\n",
      "====> Epoch: 700 Average training loss: 2.4014\n",
      "====> Epoch: 800 Average training loss: 2.1876\n",
      "====> Epoch: 900 Average training loss: 1.9977\n",
      "====> Epoch: 1000 Average training loss: 1.8476\n",
      "====> Epoch: 1100 Average training loss: 1.7040\n",
      "====> Epoch: 1200 Average training loss: 1.5811\n",
      "====> Epoch: 1300 Average training loss: 1.4837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1400 Average training loss: 1.3970\n",
      "====> Epoch: 1500 Average training loss: 1.3144\n",
      "====> Epoch: 1600 Average training loss: 1.2547\n",
      "====> Epoch: 1700 Average training loss: 1.1934\n",
      "====> Epoch: 1800 Average training loss: 1.1431\n",
      "====> Epoch: 100 Average training loss: 5.9194\n",
      "====> Epoch: 200 Average training loss: 4.7515\n",
      "====> Epoch: 300 Average training loss: 4.0011\n",
      "====> Epoch: 400 Average training loss: 3.4544\n",
      "====> Epoch: 500 Average training loss: 3.0465\n",
      "====> Epoch: 600 Average training loss: 2.7165\n",
      "====> Epoch: 700 Average training loss: 2.4398\n",
      "====> Epoch: 800 Average training loss: 2.2151\n",
      "====> Epoch: 900 Average training loss: 2.0456\n",
      "====> Epoch: 1000 Average training loss: 1.8772\n",
      "====> Epoch: 1100 Average training loss: 1.7316\n",
      "====> Epoch: 1200 Average training loss: 1.6192\n",
      "====> Epoch: 1300 Average training loss: 1.1539\n",
      "====> Epoch: 1400 Average training loss: 0.9633\n",
      "====> Epoch: 1500 Average training loss: 0.8763\n",
      "====> Epoch: 1600 Average training loss: 0.8144\n",
      "====> Epoch: 1700 Average training loss: 0.7639\n",
      "====> Epoch: 1800 Average training loss: 0.7110\n",
      "====> Epoch: 100 Average training loss: 5.9204\n",
      "====> Epoch: 200 Average training loss: 4.7416\n",
      "====> Epoch: 300 Average training loss: 3.9833\n",
      "====> Epoch: 400 Average training loss: 3.4236\n",
      "====> Epoch: 500 Average training loss: 3.0050\n",
      "====> Epoch: 600 Average training loss: 2.6813\n",
      "====> Epoch: 700 Average training loss: 2.4067\n",
      "====> Epoch: 800 Average training loss: 2.1857\n",
      "====> Epoch: 900 Average training loss: 2.0055\n",
      "====> Epoch: 1000 Average training loss: 1.8413\n",
      "====> Epoch: 1100 Average training loss: 1.7056\n",
      "====> Epoch: 1200 Average training loss: 1.5930\n",
      "====> Epoch: 1300 Average training loss: 1.4929\n",
      "====> Epoch: 1400 Average training loss: 1.4002\n",
      "====> Epoch: 1500 Average training loss: 1.3272\n",
      "====> Epoch: 1600 Average training loss: 1.2510\n",
      "====> Epoch: 1700 Average training loss: 1.1825\n",
      "====> Epoch: 1800 Average training loss: 1.1319\n",
      "====> Epoch: 100 Average training loss: 5.9045\n",
      "====> Epoch: 200 Average training loss: 4.1185\n",
      "====> Epoch: 300 Average training loss: 3.2367\n",
      "====> Epoch: 400 Average training loss: 2.5632\n",
      "====> Epoch: 500 Average training loss: 2.1831\n",
      "====> Epoch: 600 Average training loss: 1.9238\n",
      "====> Epoch: 700 Average training loss: 1.6878\n",
      "====> Epoch: 800 Average training loss: 1.5119\n",
      "====> Epoch: 900 Average training loss: 1.4318\n",
      "====> Epoch: 1000 Average training loss: 1.2940\n",
      "====> Epoch: 1100 Average training loss: 1.0900\n",
      "====> Epoch: 1200 Average training loss: 1.0170\n",
      "====> Epoch: 1300 Average training loss: 0.9470\n",
      "====> Epoch: 1400 Average training loss: 0.8418\n",
      "====> Epoch: 1500 Average training loss: 0.7143\n",
      "====> Epoch: 1600 Average training loss: 0.7156\n",
      "====> Epoch: 1700 Average training loss: 0.6673\n",
      "====> Epoch: 1800 Average training loss: 0.6082\n",
      "====> Epoch: 100 Average training loss: 5.9049\n",
      "====> Epoch: 200 Average training loss: 4.7425\n",
      "====> Epoch: 300 Average training loss: 3.9583\n",
      "====> Epoch: 400 Average training loss: 3.4154\n",
      "====> Epoch: 500 Average training loss: 3.0047\n",
      "====> Epoch: 600 Average training loss: 2.6895\n",
      "====> Epoch: 700 Average training loss: 2.4275\n",
      "====> Epoch: 800 Average training loss: 2.2018\n",
      "====> Epoch: 900 Average training loss: 2.0237\n",
      "====> Epoch: 1000 Average training loss: 1.8664\n",
      "====> Epoch: 1100 Average training loss: 1.7226\n",
      "====> Epoch: 1200 Average training loss: 1.6038\n",
      "====> Epoch: 1300 Average training loss: 1.5131\n",
      "====> Epoch: 1400 Average training loss: 1.4151\n",
      "====> Epoch: 1500 Average training loss: 1.3415\n",
      "====> Epoch: 1600 Average training loss: 1.2633\n",
      "====> Epoch: 1700 Average training loss: 1.2128\n",
      "====> Epoch: 1800 Average training loss: 1.1476\n",
      "====> Epoch: 100 Average training loss: 5.9346\n",
      "====> Epoch: 200 Average training loss: 4.7273\n",
      "====> Epoch: 300 Average training loss: 3.9941\n",
      "====> Epoch: 400 Average training loss: 3.4565\n",
      "====> Epoch: 500 Average training loss: 3.0497\n",
      "====> Epoch: 600 Average training loss: 2.7196\n",
      "====> Epoch: 700 Average training loss: 2.4669\n",
      "====> Epoch: 800 Average training loss: 2.2398\n",
      "====> Epoch: 900 Average training loss: 2.0445\n",
      "====> Epoch: 1000 Average training loss: 1.8977\n",
      "====> Epoch: 1100 Average training loss: 1.7413\n",
      "====> Epoch: 1200 Average training loss: 1.6157\n",
      "====> Epoch: 1300 Average training loss: 1.5374\n",
      "====> Epoch: 1400 Average training loss: 1.4068\n",
      "====> Epoch: 1500 Average training loss: 1.0608\n",
      "====> Epoch: 1600 Average training loss: 0.7672\n",
      "====> Epoch: 1700 Average training loss: 0.8006\n",
      "====> Epoch: 1800 Average training loss: 0.7831\n",
      "====> Epoch: 100 Average training loss: 5.9079\n",
      "====> Epoch: 200 Average training loss: 4.7243\n",
      "====> Epoch: 300 Average training loss: 3.9683\n",
      "====> Epoch: 400 Average training loss: 3.4218\n",
      "====> Epoch: 500 Average training loss: 3.0059\n",
      "====> Epoch: 600 Average training loss: 2.6992\n",
      "====> Epoch: 700 Average training loss: 2.4339\n",
      "====> Epoch: 800 Average training loss: 2.2305\n",
      "====> Epoch: 900 Average training loss: 2.0220\n",
      "====> Epoch: 1000 Average training loss: 1.8711\n",
      "====> Epoch: 1100 Average training loss: 1.7293\n",
      "====> Epoch: 1200 Average training loss: 1.6120\n",
      "====> Epoch: 1300 Average training loss: 1.5093\n",
      "====> Epoch: 1400 Average training loss: 1.4152\n",
      "====> Epoch: 1500 Average training loss: 1.3391\n",
      "====> Epoch: 1600 Average training loss: 1.2657\n",
      "====> Epoch: 1700 Average training loss: 1.2067\n",
      "====> Epoch: 1800 Average training loss: 1.1499\n",
      "====> Epoch: 100 Average training loss: 5.9149\n",
      "====> Epoch: 200 Average training loss: 4.7313\n",
      "====> Epoch: 300 Average training loss: 3.9743\n",
      "====> Epoch: 400 Average training loss: 3.4404\n",
      "====> Epoch: 500 Average training loss: 3.0290\n",
      "====> Epoch: 600 Average training loss: 2.7040\n",
      "====> Epoch: 700 Average training loss: 2.4200\n",
      "====> Epoch: 800 Average training loss: 2.1582\n",
      "====> Epoch: 900 Average training loss: 1.6596\n",
      "====> Epoch: 1000 Average training loss: 1.4196\n",
      "====> Epoch: 1100 Average training loss: 1.2247\n",
      "====> Epoch: 1200 Average training loss: 1.0830\n",
      "====> Epoch: 1300 Average training loss: 0.9897\n",
      "====> Epoch: 1400 Average training loss: 0.9144\n",
      "====> Epoch: 1500 Average training loss: 0.8548\n",
      "====> Epoch: 1600 Average training loss: 0.8067\n",
      "====> Epoch: 1700 Average training loss: 0.7464\n",
      "====> Epoch: 1800 Average training loss: 0.7050\n",
      "====> Epoch: 100 Average training loss: 5.9518\n",
      "====> Epoch: 200 Average training loss: 4.7066\n",
      "====> Epoch: 300 Average training loss: 3.9608\n",
      "====> Epoch: 400 Average training loss: 3.4402\n",
      "====> Epoch: 500 Average training loss: 3.0151\n",
      "====> Epoch: 600 Average training loss: 2.6988\n",
      "====> Epoch: 700 Average training loss: 2.4309\n",
      "====> Epoch: 800 Average training loss: 2.2382\n",
      "====> Epoch: 900 Average training loss: 2.0330\n",
      "====> Epoch: 1000 Average training loss: 1.8794\n",
      "====> Epoch: 1100 Average training loss: 1.7438\n",
      "====> Epoch: 1200 Average training loss: 1.6210\n",
      "====> Epoch: 1300 Average training loss: 1.5208\n",
      "====> Epoch: 1400 Average training loss: 1.4320\n",
      "====> Epoch: 1500 Average training loss: 1.3492\n",
      "====> Epoch: 1600 Average training loss: 1.2754\n",
      "====> Epoch: 1700 Average training loss: 1.2182\n",
      "====> Epoch: 1800 Average training loss: 1.1635\n",
      "====> Epoch: 100 Average training loss: 5.9183\n",
      "====> Epoch: 200 Average training loss: 4.7335\n",
      "====> Epoch: 300 Average training loss: 3.9990\n",
      "====> Epoch: 400 Average training loss: 3.4483\n",
      "====> Epoch: 500 Average training loss: 3.0340\n",
      "====> Epoch: 600 Average training loss: 2.7126\n",
      "====> Epoch: 700 Average training loss: 2.4414\n",
      "====> Epoch: 800 Average training loss: 2.2092\n",
      "====> Epoch: 900 Average training loss: 2.0185\n",
      "====> Epoch: 1000 Average training loss: 1.8549\n",
      "====> Epoch: 1100 Average training loss: 1.7430\n",
      "====> Epoch: 1200 Average training loss: 1.6171\n",
      "====> Epoch: 1300 Average training loss: 1.4629\n",
      "====> Epoch: 1400 Average training loss: 1.4001\n",
      "====> Epoch: 1500 Average training loss: 1.3469\n",
      "====> Epoch: 1600 Average training loss: 1.2313\n",
      "====> Epoch: 1700 Average training loss: 1.1855\n",
      "====> Epoch: 1800 Average training loss: 1.1223\n",
      "====> Epoch: 100 Average training loss: 5.9023\n",
      "====> Epoch: 200 Average training loss: 4.7293\n",
      "====> Epoch: 300 Average training loss: 3.9775\n",
      "====> Epoch: 400 Average training loss: 3.4489\n",
      "====> Epoch: 500 Average training loss: 3.0251\n",
      "====> Epoch: 600 Average training loss: 2.7066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 700 Average training loss: 2.4442\n",
      "====> Epoch: 800 Average training loss: 2.2271\n",
      "====> Epoch: 900 Average training loss: 2.0334\n",
      "====> Epoch: 1000 Average training loss: 1.8744\n",
      "====> Epoch: 1100 Average training loss: 1.7338\n",
      "====> Epoch: 1200 Average training loss: 1.6129\n",
      "====> Epoch: 1300 Average training loss: 1.5075\n",
      "====> Epoch: 1400 Average training loss: 1.4156\n",
      "====> Epoch: 1500 Average training loss: 1.3362\n",
      "====> Epoch: 1600 Average training loss: 1.2655\n",
      "====> Epoch: 1700 Average training loss: 1.2035\n",
      "====> Epoch: 1800 Average training loss: 1.1422\n",
      "====> Epoch: 100 Average training loss: 5.9101\n",
      "====> Epoch: 200 Average training loss: 4.7281\n",
      "====> Epoch: 300 Average training loss: 3.9759\n",
      "====> Epoch: 400 Average training loss: 3.4514\n",
      "====> Epoch: 500 Average training loss: 3.0420\n",
      "====> Epoch: 600 Average training loss: 2.7263\n",
      "====> Epoch: 700 Average training loss: 2.2541\n",
      "====> Epoch: 800 Average training loss: 2.0189\n",
      "====> Epoch: 900 Average training loss: 1.8236\n",
      "====> Epoch: 1000 Average training loss: 1.4451\n",
      "====> Epoch: 1100 Average training loss: 1.3761\n",
      "====> Epoch: 1200 Average training loss: 0.9627\n",
      "====> Epoch: 1300 Average training loss: 0.9187\n",
      "====> Epoch: 1400 Average training loss: 0.6821\n",
      "====> Epoch: 1500 Average training loss: 0.6801\n",
      "====> Epoch: 1600 Average training loss: 0.5818\n",
      "====> Epoch: 1700 Average training loss: 0.5181\n",
      "====> Epoch: 1800 Average training loss: 0.4719\n",
      "====> Epoch: 100 Average training loss: 5.9145\n",
      "====> Epoch: 200 Average training loss: 4.7699\n",
      "====> Epoch: 300 Average training loss: 4.0106\n",
      "====> Epoch: 400 Average training loss: 3.4774\n",
      "====> Epoch: 500 Average training loss: 3.0703\n",
      "====> Epoch: 600 Average training loss: 2.7382\n",
      "====> Epoch: 700 Average training loss: 1.9489\n",
      "====> Epoch: 800 Average training loss: 1.5576\n",
      "====> Epoch: 900 Average training loss: 1.3790\n",
      "====> Epoch: 1000 Average training loss: 1.2421\n",
      "====> Epoch: 1100 Average training loss: 1.1235\n",
      "====> Epoch: 1200 Average training loss: 1.0292\n",
      "====> Epoch: 1300 Average training loss: 0.9488\n",
      "====> Epoch: 1400 Average training loss: 0.8759\n",
      "====> Epoch: 1500 Average training loss: 0.8158\n",
      "====> Epoch: 1600 Average training loss: 0.7600\n",
      "====> Epoch: 1700 Average training loss: 0.7105\n",
      "====> Epoch: 1800 Average training loss: 0.6675\n",
      "====> Epoch: 100 Average training loss: 5.9311\n",
      "====> Epoch: 200 Average training loss: 4.7430\n",
      "====> Epoch: 300 Average training loss: 3.9684\n",
      "====> Epoch: 400 Average training loss: 3.4183\n",
      "====> Epoch: 500 Average training loss: 3.0056\n",
      "====> Epoch: 600 Average training loss: 2.6800\n",
      "====> Epoch: 700 Average training loss: 2.4070\n",
      "====> Epoch: 800 Average training loss: 2.1878\n",
      "====> Epoch: 900 Average training loss: 2.0037\n",
      "====> Epoch: 1000 Average training loss: 1.8444\n",
      "====> Epoch: 1100 Average training loss: 1.7114\n",
      "====> Epoch: 1200 Average training loss: 1.5869\n",
      "====> Epoch: 1300 Average training loss: 1.4922\n",
      "====> Epoch: 1400 Average training loss: 1.3967\n",
      "====> Epoch: 1500 Average training loss: 1.3145\n",
      "====> Epoch: 1600 Average training loss: 1.2438\n",
      "====> Epoch: 1700 Average training loss: 1.1828\n",
      "====> Epoch: 1800 Average training loss: 1.1236\n",
      "====> Epoch: 100 Average training loss: 5.9225\n",
      "====> Epoch: 200 Average training loss: 4.7592\n",
      "====> Epoch: 300 Average training loss: 4.0145\n",
      "====> Epoch: 400 Average training loss: 3.4672\n",
      "====> Epoch: 500 Average training loss: 3.0455\n",
      "====> Epoch: 600 Average training loss: 2.7236\n",
      "====> Epoch: 700 Average training loss: 2.4488\n",
      "====> Epoch: 800 Average training loss: 2.2197\n",
      "====> Epoch: 900 Average training loss: 2.0467\n",
      "====> Epoch: 1000 Average training loss: 1.8922\n",
      "====> Epoch: 1100 Average training loss: 1.7357\n",
      "====> Epoch: 1200 Average training loss: 1.6138\n",
      "====> Epoch: 1300 Average training loss: 1.5132\n",
      "====> Epoch: 1400 Average training loss: 1.4208\n",
      "====> Epoch: 1500 Average training loss: 1.3420\n",
      "====> Epoch: 1600 Average training loss: 1.2737\n",
      "====> Epoch: 1700 Average training loss: 1.1984\n",
      "====> Epoch: 1800 Average training loss: 1.1501\n",
      "====> Epoch: 100 Average training loss: 5.9248\n",
      "====> Epoch: 200 Average training loss: 4.7520\n",
      "====> Epoch: 300 Average training loss: 4.0277\n",
      "====> Epoch: 400 Average training loss: 3.4656\n",
      "====> Epoch: 500 Average training loss: 3.0620\n",
      "====> Epoch: 600 Average training loss: 2.7347\n",
      "====> Epoch: 700 Average training loss: 2.4749\n",
      "====> Epoch: 800 Average training loss: 2.2514\n",
      "====> Epoch: 900 Average training loss: 2.0545\n",
      "====> Epoch: 1000 Average training loss: 1.8731\n",
      "====> Epoch: 1100 Average training loss: 1.7521\n",
      "====> Epoch: 1200 Average training loss: 1.6355\n",
      "====> Epoch: 1300 Average training loss: 1.5151\n",
      "====> Epoch: 1400 Average training loss: 1.4283\n",
      "====> Epoch: 1500 Average training loss: 1.3433\n",
      "====> Epoch: 1600 Average training loss: 1.2522\n",
      "====> Epoch: 1700 Average training loss: 1.1895\n",
      "====> Epoch: 1800 Average training loss: 1.1349\n",
      "====> Epoch: 100 Average training loss: 5.9268\n",
      "====> Epoch: 200 Average training loss: 4.7255\n",
      "====> Epoch: 300 Average training loss: 3.9829\n",
      "====> Epoch: 400 Average training loss: 3.4581\n",
      "====> Epoch: 500 Average training loss: 3.0445\n",
      "====> Epoch: 600 Average training loss: 2.7172\n",
      "====> Epoch: 700 Average training loss: 2.4545\n",
      "====> Epoch: 800 Average training loss: 2.2340\n",
      "====> Epoch: 900 Average training loss: 2.0346\n",
      "====> Epoch: 1000 Average training loss: 1.8763\n",
      "====> Epoch: 1100 Average training loss: 1.7364\n",
      "====> Epoch: 1200 Average training loss: 1.6171\n",
      "====> Epoch: 1300 Average training loss: 1.5115\n",
      "====> Epoch: 1400 Average training loss: 1.4280\n",
      "====> Epoch: 1500 Average training loss: 1.3390\n",
      "====> Epoch: 1600 Average training loss: 1.2814\n",
      "====> Epoch: 1700 Average training loss: 1.2039\n",
      "====> Epoch: 1800 Average training loss: 1.1544\n",
      "====> Epoch: 100 Average training loss: 5.9325\n",
      "====> Epoch: 200 Average training loss: 4.7473\n",
      "====> Epoch: 300 Average training loss: 3.9828\n",
      "====> Epoch: 400 Average training loss: 3.4237\n",
      "====> Epoch: 500 Average training loss: 3.0327\n",
      "====> Epoch: 600 Average training loss: 2.6934\n",
      "====> Epoch: 700 Average training loss: 2.4265\n",
      "====> Epoch: 800 Average training loss: 2.2202\n",
      "====> Epoch: 900 Average training loss: 2.0304\n",
      "====> Epoch: 1000 Average training loss: 1.8631\n",
      "====> Epoch: 1100 Average training loss: 1.7183\n",
      "====> Epoch: 1200 Average training loss: 1.6081\n",
      "====> Epoch: 1300 Average training loss: 1.5013\n",
      "====> Epoch: 1400 Average training loss: 1.4129\n",
      "====> Epoch: 1500 Average training loss: 1.3338\n",
      "====> Epoch: 1600 Average training loss: 1.2466\n",
      "====> Epoch: 1700 Average training loss: 1.1826\n",
      "====> Epoch: 1800 Average training loss: 1.1442\n",
      "====> Epoch: 100 Average training loss: 5.9207\n",
      "====> Epoch: 200 Average training loss: 4.7149\n",
      "====> Epoch: 300 Average training loss: 3.9446\n",
      "====> Epoch: 400 Average training loss: 3.4252\n",
      "====> Epoch: 500 Average training loss: 2.9985\n",
      "====> Epoch: 600 Average training loss: 2.6929\n",
      "====> Epoch: 700 Average training loss: 2.4020\n",
      "====> Epoch: 800 Average training loss: 1.6954\n",
      "====> Epoch: 900 Average training loss: 1.4600\n",
      "====> Epoch: 1000 Average training loss: 1.2928\n",
      "====> Epoch: 1100 Average training loss: 1.1557\n",
      "====> Epoch: 1200 Average training loss: 1.0507\n",
      "====> Epoch: 1300 Average training loss: 0.9636\n",
      "====> Epoch: 1400 Average training loss: 0.8899\n",
      "====> Epoch: 1500 Average training loss: 0.8265\n",
      "====> Epoch: 1600 Average training loss: 0.7733\n",
      "====> Epoch: 1700 Average training loss: 0.7238\n",
      "====> Epoch: 1800 Average training loss: 0.6787\n",
      "====> Epoch: 100 Average training loss: 5.9232\n",
      "====> Epoch: 200 Average training loss: 4.7281\n",
      "====> Epoch: 300 Average training loss: 3.9792\n",
      "====> Epoch: 400 Average training loss: 3.4588\n",
      "====> Epoch: 500 Average training loss: 3.0529\n",
      "====> Epoch: 600 Average training loss: 2.7422\n",
      "====> Epoch: 700 Average training loss: 2.4717\n",
      "====> Epoch: 800 Average training loss: 2.2472\n",
      "====> Epoch: 900 Average training loss: 2.0609\n",
      "====> Epoch: 1000 Average training loss: 1.8911\n",
      "====> Epoch: 1100 Average training loss: 1.7646\n",
      "====> Epoch: 1200 Average training loss: 1.6466\n",
      "====> Epoch: 1300 Average training loss: 1.5261\n",
      "====> Epoch: 1400 Average training loss: 1.4375\n",
      "====> Epoch: 1500 Average training loss: 1.3596\n",
      "====> Epoch: 1600 Average training loss: 1.2870\n",
      "====> Epoch: 1700 Average training loss: 1.2280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1800 Average training loss: 1.1587\n",
      "====> Epoch: 100 Average training loss: 5.9426\n",
      "====> Epoch: 200 Average training loss: 4.7236\n",
      "====> Epoch: 300 Average training loss: 3.9735\n",
      "====> Epoch: 400 Average training loss: 3.4271\n",
      "====> Epoch: 500 Average training loss: 3.0364\n",
      "====> Epoch: 600 Average training loss: 2.6862\n",
      "====> Epoch: 700 Average training loss: 2.4163\n",
      "====> Epoch: 800 Average training loss: 2.2016\n",
      "====> Epoch: 900 Average training loss: 2.0116\n",
      "====> Epoch: 1000 Average training loss: 1.8521\n",
      "====> Epoch: 1100 Average training loss: 1.7092\n",
      "====> Epoch: 1200 Average training loss: 1.5914\n",
      "====> Epoch: 1300 Average training loss: 1.4884\n",
      "====> Epoch: 1400 Average training loss: 1.3883\n",
      "====> Epoch: 1500 Average training loss: 1.3208\n",
      "====> Epoch: 1600 Average training loss: 1.2522\n",
      "====> Epoch: 1700 Average training loss: 1.1985\n",
      "====> Epoch: 1800 Average training loss: 1.1094\n",
      "====> Epoch: 100 Average training loss: 5.9074\n",
      "====> Epoch: 200 Average training loss: 4.7247\n",
      "====> Epoch: 300 Average training loss: 3.9583\n",
      "====> Epoch: 400 Average training loss: 3.4253\n",
      "====> Epoch: 500 Average training loss: 3.0184\n",
      "====> Epoch: 600 Average training loss: 2.6970\n",
      "====> Epoch: 700 Average training loss: 2.4281\n",
      "====> Epoch: 800 Average training loss: 2.2189\n",
      "====> Epoch: 900 Average training loss: 2.0195\n",
      "====> Epoch: 1000 Average training loss: 1.8586\n",
      "====> Epoch: 1100 Average training loss: 1.7310\n",
      "====> Epoch: 1200 Average training loss: 1.6110\n",
      "====> Epoch: 1300 Average training loss: 1.5072\n",
      "====> Epoch: 1400 Average training loss: 1.4214\n",
      "====> Epoch: 1500 Average training loss: 1.3322\n",
      "====> Epoch: 1600 Average training loss: 1.2662\n",
      "====> Epoch: 1700 Average training loss: 1.2009\n",
      "====> Epoch: 1800 Average training loss: 1.1519\n",
      "====> Epoch: 100 Average training loss: 5.9413\n",
      "====> Epoch: 200 Average training loss: 4.7419\n",
      "====> Epoch: 300 Average training loss: 3.9725\n",
      "====> Epoch: 400 Average training loss: 3.4364\n",
      "====> Epoch: 500 Average training loss: 3.0205\n",
      "====> Epoch: 600 Average training loss: 2.6894\n",
      "====> Epoch: 700 Average training loss: 2.4200\n",
      "====> Epoch: 800 Average training loss: 2.1986\n",
      "====> Epoch: 900 Average training loss: 2.0095\n",
      "====> Epoch: 1000 Average training loss: 1.8422\n",
      "====> Epoch: 1100 Average training loss: 1.7031\n",
      "====> Epoch: 1200 Average training loss: 1.5997\n",
      "====> Epoch: 1300 Average training loss: 1.4880\n",
      "====> Epoch: 1400 Average training loss: 1.3974\n",
      "====> Epoch: 1500 Average training loss: 1.3142\n",
      "====> Epoch: 1600 Average training loss: 1.2625\n",
      "====> Epoch: 1700 Average training loss: 1.1765\n",
      "====> Epoch: 1800 Average training loss: 1.1255\n",
      "====> Epoch: 100 Average training loss: 5.9384\n",
      "====> Epoch: 200 Average training loss: 4.7305\n",
      "====> Epoch: 300 Average training loss: 3.9640\n",
      "====> Epoch: 400 Average training loss: 3.4200\n",
      "====> Epoch: 500 Average training loss: 2.9977\n",
      "====> Epoch: 600 Average training loss: 2.6649\n",
      "====> Epoch: 700 Average training loss: 2.3949\n",
      "====> Epoch: 800 Average training loss: 2.1852\n",
      "====> Epoch: 900 Average training loss: 1.9988\n",
      "====> Epoch: 1000 Average training loss: 1.8396\n",
      "====> Epoch: 1100 Average training loss: 1.7120\n",
      "====> Epoch: 1200 Average training loss: 1.5880\n",
      "====> Epoch: 1300 Average training loss: 1.4955\n",
      "====> Epoch: 1400 Average training loss: 1.4000\n",
      "====> Epoch: 1500 Average training loss: 1.3145\n",
      "====> Epoch: 1600 Average training loss: 1.2455\n",
      "====> Epoch: 1700 Average training loss: 1.1873\n",
      "====> Epoch: 1800 Average training loss: 1.1495\n",
      "====> Epoch: 100 Average training loss: 5.9385\n",
      "====> Epoch: 200 Average training loss: 4.7297\n",
      "====> Epoch: 300 Average training loss: 3.9723\n",
      "====> Epoch: 400 Average training loss: 3.4172\n",
      "====> Epoch: 500 Average training loss: 3.0028\n",
      "====> Epoch: 600 Average training loss: 2.6754\n",
      "====> Epoch: 700 Average training loss: 2.4152\n",
      "====> Epoch: 800 Average training loss: 2.1902\n",
      "====> Epoch: 900 Average training loss: 2.0027\n",
      "====> Epoch: 1000 Average training loss: 1.8519\n",
      "====> Epoch: 1100 Average training loss: 1.7187\n",
      "====> Epoch: 1200 Average training loss: 1.5948\n",
      "====> Epoch: 1300 Average training loss: 1.4870\n",
      "====> Epoch: 1400 Average training loss: 1.3969\n",
      "====> Epoch: 1500 Average training loss: 1.3223\n",
      "====> Epoch: 1600 Average training loss: 1.2492\n",
      "====> Epoch: 1700 Average training loss: 1.1729\n",
      "====> Epoch: 1800 Average training loss: 1.1290\n",
      "====> Epoch: 100 Average training loss: 5.9252\n",
      "====> Epoch: 200 Average training loss: 4.7371\n",
      "====> Epoch: 300 Average training loss: 3.9828\n",
      "====> Epoch: 400 Average training loss: 3.4252\n",
      "====> Epoch: 500 Average training loss: 3.0218\n",
      "====> Epoch: 600 Average training loss: 2.6947\n",
      "====> Epoch: 700 Average training loss: 2.4213\n",
      "====> Epoch: 800 Average training loss: 2.2094\n",
      "====> Epoch: 900 Average training loss: 2.0217\n",
      "====> Epoch: 1000 Average training loss: 1.8494\n",
      "====> Epoch: 1100 Average training loss: 1.7210\n",
      "====> Epoch: 1200 Average training loss: 1.6004\n",
      "====> Epoch: 1300 Average training loss: 1.5008\n",
      "====> Epoch: 1400 Average training loss: 1.4093\n",
      "====> Epoch: 1500 Average training loss: 1.3341\n",
      "====> Epoch: 1600 Average training loss: 1.2475\n",
      "====> Epoch: 1700 Average training loss: 1.1917\n",
      "====> Epoch: 1800 Average training loss: 1.1281\n",
      "====> Epoch: 100 Average training loss: 5.9316\n",
      "====> Epoch: 200 Average training loss: 4.7255\n",
      "====> Epoch: 300 Average training loss: 3.9878\n",
      "====> Epoch: 400 Average training loss: 3.4331\n",
      "====> Epoch: 500 Average training loss: 3.0138\n",
      "====> Epoch: 600 Average training loss: 2.6851\n",
      "====> Epoch: 700 Average training loss: 2.4149\n",
      "====> Epoch: 800 Average training loss: 2.1953\n",
      "====> Epoch: 900 Average training loss: 2.0053\n",
      "====> Epoch: 1000 Average training loss: 1.8347\n",
      "====> Epoch: 1100 Average training loss: 1.7061\n",
      "====> Epoch: 1200 Average training loss: 1.5903\n",
      "====> Epoch: 1300 Average training loss: 1.4593\n",
      "====> Epoch: 1400 Average training loss: 1.3993\n",
      "====> Epoch: 1500 Average training loss: 1.3247\n",
      "====> Epoch: 1600 Average training loss: 1.2129\n",
      "====> Epoch: 1700 Average training loss: 1.1860\n",
      "====> Epoch: 1800 Average training loss: 1.1367\n",
      "====> Epoch: 100 Average training loss: 5.8963\n",
      "====> Epoch: 200 Average training loss: 4.7146\n",
      "====> Epoch: 300 Average training loss: 3.9394\n",
      "====> Epoch: 400 Average training loss: 3.4092\n",
      "====> Epoch: 500 Average training loss: 3.0024\n",
      "====> Epoch: 600 Average training loss: 2.6772\n",
      "====> Epoch: 700 Average training loss: 2.4220\n",
      "====> Epoch: 800 Average training loss: 2.2107\n",
      "====> Epoch: 900 Average training loss: 2.0425\n",
      "====> Epoch: 1000 Average training loss: 1.8633\n",
      "====> Epoch: 1100 Average training loss: 1.7281\n",
      "====> Epoch: 1200 Average training loss: 1.6064\n",
      "====> Epoch: 1300 Average training loss: 1.5112\n",
      "====> Epoch: 1400 Average training loss: 1.4187\n",
      "====> Epoch: 1500 Average training loss: 1.3346\n",
      "====> Epoch: 1600 Average training loss: 1.2746\n",
      "====> Epoch: 1700 Average training loss: 1.1926\n",
      "====> Epoch: 1800 Average training loss: 1.1418\n",
      "====> Epoch: 100 Average training loss: 5.9355\n",
      "====> Epoch: 200 Average training loss: 4.7485\n",
      "====> Epoch: 300 Average training loss: 3.9782\n",
      "====> Epoch: 400 Average training loss: 3.4446\n",
      "====> Epoch: 500 Average training loss: 3.0133\n",
      "====> Epoch: 600 Average training loss: 2.6857\n",
      "====> Epoch: 700 Average training loss: 2.4538\n",
      "====> Epoch: 800 Average training loss: 1.7503\n",
      "====> Epoch: 900 Average training loss: 1.5282\n",
      "====> Epoch: 1000 Average training loss: 1.3081\n",
      "====> Epoch: 1100 Average training loss: 1.1814\n",
      "====> Epoch: 1200 Average training loss: 1.0851\n",
      "====> Epoch: 1300 Average training loss: 0.9949\n",
      "====> Epoch: 1400 Average training loss: 0.9237\n",
      "====> Epoch: 1500 Average training loss: 0.8547\n",
      "====> Epoch: 1600 Average training loss: 0.7899\n",
      "====> Epoch: 1700 Average training loss: 0.7556\n",
      "====> Epoch: 1800 Average training loss: 0.6758\n",
      "====> Epoch: 100 Average training loss: 5.9254\n",
      "====> Epoch: 200 Average training loss: 4.7384\n",
      "====> Epoch: 300 Average training loss: 3.9983\n",
      "====> Epoch: 400 Average training loss: 3.4374\n",
      "====> Epoch: 500 Average training loss: 3.0229\n",
      "====> Epoch: 600 Average training loss: 2.6976\n",
      "====> Epoch: 700 Average training loss: 2.4491\n",
      "====> Epoch: 800 Average training loss: 2.2228\n",
      "====> Epoch: 900 Average training loss: 2.0338\n",
      "====> Epoch: 1000 Average training loss: 1.8762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1100 Average training loss: 1.7303\n",
      "====> Epoch: 1200 Average training loss: 1.6188\n",
      "====> Epoch: 1300 Average training loss: 1.5125\n",
      "====> Epoch: 1400 Average training loss: 1.4274\n",
      "====> Epoch: 1500 Average training loss: 1.3388\n",
      "====> Epoch: 1600 Average training loss: 1.2835\n",
      "====> Epoch: 1700 Average training loss: 1.2152\n",
      "====> Epoch: 1800 Average training loss: 1.1513\n",
      "====> Epoch: 100 Average training loss: 5.9059\n",
      "====> Epoch: 200 Average training loss: 4.7518\n",
      "====> Epoch: 300 Average training loss: 3.9934\n",
      "====> Epoch: 400 Average training loss: 3.4515\n",
      "====> Epoch: 500 Average training loss: 3.0333\n",
      "====> Epoch: 600 Average training loss: 2.7081\n",
      "====> Epoch: 700 Average training loss: 2.4385\n",
      "====> Epoch: 800 Average training loss: 2.2067\n",
      "====> Epoch: 900 Average training loss: 2.0131\n",
      "====> Epoch: 1000 Average training loss: 1.8654\n",
      "====> Epoch: 1100 Average training loss: 1.7201\n",
      "====> Epoch: 1200 Average training loss: 1.6016\n",
      "====> Epoch: 1300 Average training loss: 1.4933\n",
      "====> Epoch: 1400 Average training loss: 1.4078\n",
      "====> Epoch: 1500 Average training loss: 1.3229\n",
      "====> Epoch: 1600 Average training loss: 1.2481\n",
      "====> Epoch: 1700 Average training loss: 1.1850\n",
      "====> Epoch: 1800 Average training loss: 1.1307\n",
      "====> Epoch: 100 Average training loss: 5.9260\n",
      "====> Epoch: 200 Average training loss: 4.7513\n",
      "====> Epoch: 300 Average training loss: 3.9719\n",
      "====> Epoch: 400 Average training loss: 3.4369\n",
      "====> Epoch: 500 Average training loss: 3.0222\n",
      "====> Epoch: 600 Average training loss: 2.7058\n",
      "====> Epoch: 700 Average training loss: 2.4342\n",
      "====> Epoch: 800 Average training loss: 2.2303\n",
      "====> Epoch: 900 Average training loss: 2.0345\n",
      "====> Epoch: 1000 Average training loss: 1.8900\n",
      "====> Epoch: 1100 Average training loss: 1.7357\n",
      "====> Epoch: 1200 Average training loss: 1.6086\n",
      "====> Epoch: 1300 Average training loss: 1.5207\n",
      "====> Epoch: 1400 Average training loss: 1.4231\n",
      "====> Epoch: 1500 Average training loss: 1.3364\n",
      "====> Epoch: 1600 Average training loss: 1.2674\n",
      "====> Epoch: 1700 Average training loss: 1.2031\n",
      "====> Epoch: 1800 Average training loss: 1.1416\n",
      "====> Epoch: 100 Average training loss: 5.9029\n",
      "====> Epoch: 200 Average training loss: 4.7369\n",
      "====> Epoch: 300 Average training loss: 3.9808\n",
      "====> Epoch: 400 Average training loss: 3.4458\n",
      "====> Epoch: 500 Average training loss: 3.0252\n",
      "====> Epoch: 600 Average training loss: 2.6836\n",
      "====> Epoch: 700 Average training loss: 2.4115\n",
      "====> Epoch: 800 Average training loss: 2.1902\n",
      "====> Epoch: 900 Average training loss: 2.0050\n",
      "====> Epoch: 1000 Average training loss: 1.8482\n",
      "====> Epoch: 1100 Average training loss: 1.7177\n",
      "====> Epoch: 1200 Average training loss: 1.5967\n",
      "====> Epoch: 1300 Average training loss: 1.4895\n",
      "====> Epoch: 1400 Average training loss: 1.4001\n",
      "====> Epoch: 1500 Average training loss: 1.3180\n",
      "====> Epoch: 1600 Average training loss: 1.2508\n",
      "====> Epoch: 1700 Average training loss: 1.1854\n",
      "====> Epoch: 1800 Average training loss: 1.1295\n",
      "====> Epoch: 100 Average training loss: 5.9120\n",
      "====> Epoch: 200 Average training loss: 4.7438\n",
      "====> Epoch: 300 Average training loss: 3.9815\n",
      "====> Epoch: 400 Average training loss: 3.4523\n",
      "====> Epoch: 500 Average training loss: 3.0365\n",
      "====> Epoch: 600 Average training loss: 2.7110\n",
      "====> Epoch: 700 Average training loss: 2.4214\n",
      "====> Epoch: 800 Average training loss: 2.1995\n",
      "====> Epoch: 900 Average training loss: 2.0148\n",
      "====> Epoch: 1000 Average training loss: 1.8474\n",
      "====> Epoch: 1100 Average training loss: 1.7111\n",
      "====> Epoch: 1200 Average training loss: 1.6081\n",
      "====> Epoch: 1300 Average training loss: 1.4808\n",
      "====> Epoch: 1400 Average training loss: 1.4021\n",
      "====> Epoch: 1500 Average training loss: 1.3203\n",
      "====> Epoch: 1600 Average training loss: 1.2496\n",
      "====> Epoch: 1700 Average training loss: 1.1955\n",
      "====> Epoch: 1800 Average training loss: 1.1234\n",
      "====> Epoch: 100 Average training loss: 5.9063\n",
      "====> Epoch: 200 Average training loss: 4.7403\n",
      "====> Epoch: 300 Average training loss: 3.9869\n",
      "====> Epoch: 400 Average training loss: 3.4193\n",
      "====> Epoch: 500 Average training loss: 3.0112\n",
      "====> Epoch: 600 Average training loss: 2.6747\n",
      "====> Epoch: 700 Average training loss: 2.4022\n",
      "====> Epoch: 800 Average training loss: 2.1933\n",
      "====> Epoch: 900 Average training loss: 2.0111\n",
      "====> Epoch: 1000 Average training loss: 1.8454\n",
      "====> Epoch: 1100 Average training loss: 1.7086\n",
      "====> Epoch: 1200 Average training loss: 1.5904\n",
      "====> Epoch: 1300 Average training loss: 1.4854\n",
      "====> Epoch: 1400 Average training loss: 1.4040\n",
      "====> Epoch: 1500 Average training loss: 1.3159\n",
      "====> Epoch: 1600 Average training loss: 1.2550\n",
      "====> Epoch: 1700 Average training loss: 1.1928\n",
      "====> Epoch: 1800 Average training loss: 1.1239\n",
      "====> Epoch: 100 Average training loss: 5.9109\n",
      "====> Epoch: 200 Average training loss: 4.7407\n",
      "====> Epoch: 300 Average training loss: 3.9928\n",
      "====> Epoch: 400 Average training loss: 3.4590\n",
      "====> Epoch: 500 Average training loss: 3.0409\n",
      "====> Epoch: 600 Average training loss: 2.7034\n",
      "====> Epoch: 700 Average training loss: 2.4421\n",
      "====> Epoch: 800 Average training loss: 2.2142\n",
      "====> Epoch: 900 Average training loss: 2.0238\n",
      "====> Epoch: 1000 Average training loss: 1.8582\n",
      "====> Epoch: 1100 Average training loss: 1.7248\n",
      "====> Epoch: 1200 Average training loss: 1.6024\n",
      "====> Epoch: 1300 Average training loss: 1.5010\n",
      "====> Epoch: 1400 Average training loss: 1.4055\n",
      "====> Epoch: 1500 Average training loss: 1.3296\n",
      "====> Epoch: 1600 Average training loss: 1.2580\n",
      "====> Epoch: 1700 Average training loss: 1.1906\n",
      "====> Epoch: 1800 Average training loss: 1.1346\n",
      "====> Epoch: 100 Average training loss: 5.9119\n",
      "====> Epoch: 200 Average training loss: 4.7470\n",
      "====> Epoch: 300 Average training loss: 3.9958\n",
      "====> Epoch: 400 Average training loss: 3.4562\n",
      "====> Epoch: 500 Average training loss: 3.0369\n",
      "====> Epoch: 600 Average training loss: 2.7212\n",
      "====> Epoch: 700 Average training loss: 2.4360\n",
      "====> Epoch: 800 Average training loss: 2.2060\n",
      "====> Epoch: 900 Average training loss: 2.0212\n",
      "====> Epoch: 1000 Average training loss: 1.8700\n",
      "====> Epoch: 1100 Average training loss: 1.7220\n",
      "====> Epoch: 1200 Average training loss: 1.6221\n",
      "====> Epoch: 1300 Average training loss: 1.5083\n",
      "====> Epoch: 1400 Average training loss: 1.4189\n",
      "====> Epoch: 1500 Average training loss: 1.3331\n",
      "====> Epoch: 1600 Average training loss: 1.2688\n",
      "====> Epoch: 1700 Average training loss: 1.2099\n",
      "====> Epoch: 1800 Average training loss: 1.1477\n",
      "====> Epoch: 100 Average training loss: 5.9329\n",
      "====> Epoch: 200 Average training loss: 4.7381\n",
      "====> Epoch: 300 Average training loss: 3.9671\n",
      "====> Epoch: 400 Average training loss: 3.4369\n",
      "====> Epoch: 500 Average training loss: 3.0276\n",
      "====> Epoch: 600 Average training loss: 2.6962\n",
      "====> Epoch: 700 Average training loss: 2.4311\n",
      "====> Epoch: 800 Average training loss: 2.2067\n",
      "====> Epoch: 900 Average training loss: 2.0094\n",
      "====> Epoch: 1000 Average training loss: 1.8563\n",
      "====> Epoch: 1100 Average training loss: 1.7275\n",
      "====> Epoch: 1200 Average training loss: 1.6131\n",
      "====> Epoch: 1300 Average training loss: 1.4972\n",
      "====> Epoch: 1400 Average training loss: 1.4135\n",
      "====> Epoch: 1500 Average training loss: 1.3359\n",
      "====> Epoch: 1600 Average training loss: 1.2665\n",
      "====> Epoch: 1700 Average training loss: 1.1923\n",
      "====> Epoch: 1800 Average training loss: 1.1459\n",
      "====> Epoch: 100 Average training loss: 5.9286\n",
      "====> Epoch: 200 Average training loss: 4.7718\n",
      "====> Epoch: 300 Average training loss: 3.9968\n",
      "====> Epoch: 400 Average training loss: 3.4763\n",
      "====> Epoch: 500 Average training loss: 3.0600\n",
      "====> Epoch: 600 Average training loss: 2.7252\n",
      "====> Epoch: 700 Average training loss: 2.4391\n",
      "====> Epoch: 800 Average training loss: 2.2385\n",
      "====> Epoch: 900 Average training loss: 2.0388\n",
      "====> Epoch: 1000 Average training loss: 1.8659\n",
      "====> Epoch: 1100 Average training loss: 1.7253\n",
      "====> Epoch: 1200 Average training loss: 1.5863\n",
      "====> Epoch: 1300 Average training loss: 1.4677\n",
      "====> Epoch: 1400 Average training loss: 1.3870\n",
      "====> Epoch: 1500 Average training loss: 1.2934\n",
      "====> Epoch: 1600 Average training loss: 1.2188\n",
      "====> Epoch: 1700 Average training loss: 1.1498\n",
      "====> Epoch: 1800 Average training loss: 1.0998\n",
      "====> Epoch: 100 Average training loss: 5.9064\n",
      "====> Epoch: 200 Average training loss: 4.7356\n",
      "====> Epoch: 300 Average training loss: 3.9799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 400 Average training loss: 3.4497\n",
      "====> Epoch: 500 Average training loss: 3.0385\n",
      "====> Epoch: 600 Average training loss: 2.7065\n",
      "====> Epoch: 700 Average training loss: 2.4274\n",
      "====> Epoch: 800 Average training loss: 2.2150\n",
      "====> Epoch: 900 Average training loss: 2.0163\n",
      "====> Epoch: 1000 Average training loss: 1.8489\n",
      "====> Epoch: 1100 Average training loss: 1.7060\n",
      "====> Epoch: 1200 Average training loss: 1.5948\n",
      "====> Epoch: 1300 Average training loss: 1.4933\n",
      "====> Epoch: 1400 Average training loss: 1.4041\n",
      "====> Epoch: 1500 Average training loss: 1.3354\n",
      "====> Epoch: 1600 Average training loss: 1.2546\n",
      "====> Epoch: 1700 Average training loss: 1.1907\n",
      "====> Epoch: 1800 Average training loss: 1.1326\n",
      "====> Epoch: 100 Average training loss: 5.9275\n",
      "====> Epoch: 200 Average training loss: 4.7026\n",
      "====> Epoch: 300 Average training loss: 3.9472\n",
      "====> Epoch: 400 Average training loss: 3.4117\n",
      "====> Epoch: 500 Average training loss: 3.0125\n",
      "====> Epoch: 600 Average training loss: 2.6795\n",
      "====> Epoch: 700 Average training loss: 2.4223\n",
      "====> Epoch: 800 Average training loss: 2.2035\n",
      "====> Epoch: 900 Average training loss: 2.0053\n",
      "====> Epoch: 1000 Average training loss: 1.8518\n",
      "====> Epoch: 1100 Average training loss: 1.7171\n",
      "====> Epoch: 1200 Average training loss: 1.6019\n",
      "====> Epoch: 1300 Average training loss: 1.5057\n",
      "====> Epoch: 1400 Average training loss: 1.4255\n",
      "====> Epoch: 1500 Average training loss: 1.3258\n",
      "====> Epoch: 1600 Average training loss: 1.2654\n",
      "====> Epoch: 1700 Average training loss: 1.1946\n",
      "====> Epoch: 1800 Average training loss: 1.1381\n",
      "====> Epoch: 100 Average training loss: 5.9040\n",
      "====> Epoch: 200 Average training loss: 4.7095\n",
      "====> Epoch: 300 Average training loss: 3.9530\n",
      "====> Epoch: 400 Average training loss: 3.4197\n",
      "====> Epoch: 500 Average training loss: 3.0058\n",
      "====> Epoch: 600 Average training loss: 2.6837\n",
      "====> Epoch: 700 Average training loss: 2.4200\n",
      "====> Epoch: 800 Average training loss: 2.1970\n",
      "====> Epoch: 900 Average training loss: 2.0202\n",
      "====> Epoch: 1000 Average training loss: 1.8615\n",
      "====> Epoch: 1100 Average training loss: 1.7109\n",
      "====> Epoch: 1200 Average training loss: 1.5987\n",
      "====> Epoch: 1300 Average training loss: 1.5095\n",
      "====> Epoch: 1400 Average training loss: 1.4045\n",
      "====> Epoch: 1500 Average training loss: 1.3265\n",
      "====> Epoch: 1600 Average training loss: 1.2595\n",
      "====> Epoch: 1700 Average training loss: 1.2008\n",
      "====> Epoch: 1800 Average training loss: 1.1416\n",
      "====> Epoch: 100 Average training loss: 5.9118\n",
      "====> Epoch: 200 Average training loss: 4.7247\n",
      "====> Epoch: 300 Average training loss: 3.9464\n",
      "====> Epoch: 400 Average training loss: 3.4300\n",
      "====> Epoch: 500 Average training loss: 3.0015\n",
      "====> Epoch: 600 Average training loss: 2.6916\n",
      "====> Epoch: 700 Average training loss: 2.4194\n",
      "====> Epoch: 800 Average training loss: 2.2210\n",
      "====> Epoch: 900 Average training loss: 2.0283\n",
      "====> Epoch: 1000 Average training loss: 1.8584\n",
      "====> Epoch: 1100 Average training loss: 1.7259\n",
      "====> Epoch: 1200 Average training loss: 1.6107\n",
      "====> Epoch: 1300 Average training loss: 1.4958\n",
      "====> Epoch: 1400 Average training loss: 1.4093\n",
      "====> Epoch: 1500 Average training loss: 1.3297\n",
      "====> Epoch: 1600 Average training loss: 1.2494\n",
      "====> Epoch: 1700 Average training loss: 1.1837\n",
      "====> Epoch: 1800 Average training loss: 1.1268\n",
      "====> Epoch: 100 Average training loss: 5.9117\n",
      "====> Epoch: 200 Average training loss: 4.7420\n",
      "====> Epoch: 300 Average training loss: 3.9766\n",
      "====> Epoch: 400 Average training loss: 3.4355\n",
      "====> Epoch: 500 Average training loss: 3.0281\n",
      "====> Epoch: 600 Average training loss: 2.7050\n",
      "====> Epoch: 700 Average training loss: 2.4282\n",
      "====> Epoch: 800 Average training loss: 2.2128\n",
      "====> Epoch: 900 Average training loss: 2.0130\n",
      "====> Epoch: 1000 Average training loss: 1.8597\n",
      "====> Epoch: 1100 Average training loss: 1.7194\n",
      "====> Epoch: 1200 Average training loss: 1.6108\n",
      "====> Epoch: 1300 Average training loss: 1.1561\n",
      "====> Epoch: 1400 Average training loss: 0.9748\n",
      "====> Epoch: 1500 Average training loss: 0.8896\n",
      "====> Epoch: 1600 Average training loss: 0.8259\n",
      "====> Epoch: 1700 Average training loss: 0.7716\n",
      "====> Epoch: 1800 Average training loss: 0.7239\n",
      "====> Epoch: 100 Average training loss: 5.9106\n",
      "====> Epoch: 200 Average training loss: 4.7397\n",
      "====> Epoch: 300 Average training loss: 3.9813\n",
      "====> Epoch: 400 Average training loss: 3.4326\n",
      "====> Epoch: 500 Average training loss: 3.0159\n",
      "====> Epoch: 600 Average training loss: 2.6795\n",
      "====> Epoch: 700 Average training loss: 2.4212\n",
      "====> Epoch: 800 Average training loss: 2.1944\n",
      "====> Epoch: 900 Average training loss: 1.7071\n",
      "====> Epoch: 1000 Average training loss: 1.4090\n",
      "====> Epoch: 1100 Average training loss: 1.1827\n",
      "====> Epoch: 1200 Average training loss: 1.0206\n",
      "====> Epoch: 1300 Average training loss: 0.9294\n",
      "====> Epoch: 1400 Average training loss: 0.8550\n",
      "====> Epoch: 1500 Average training loss: 0.7898\n",
      "====> Epoch: 1600 Average training loss: 0.7325\n",
      "====> Epoch: 1700 Average training loss: 0.6839\n",
      "====> Epoch: 1800 Average training loss: 0.6416\n",
      "====> Epoch: 100 Average training loss: 5.8944\n",
      "====> Epoch: 200 Average training loss: 4.7227\n",
      "====> Epoch: 300 Average training loss: 3.9838\n",
      "====> Epoch: 400 Average training loss: 3.4536\n",
      "====> Epoch: 500 Average training loss: 3.0374\n",
      "====> Epoch: 600 Average training loss: 2.4760\n",
      "====> Epoch: 700 Average training loss: 2.3573\n",
      "====> Epoch: 800 Average training loss: 2.2068\n",
      "====> Epoch: 900 Average training loss: 1.5632\n",
      "====> Epoch: 1000 Average training loss: 1.3710\n",
      "====> Epoch: 1100 Average training loss: 1.0815\n",
      "====> Epoch: 1200 Average training loss: 1.0611\n",
      "====> Epoch: 1300 Average training loss: 0.8866\n",
      "====> Epoch: 1400 Average training loss: 0.8159\n",
      "====> Epoch: 1500 Average training loss: 0.7536\n",
      "====> Epoch: 1600 Average training loss: 0.7176\n",
      "====> Epoch: 1700 Average training loss: 0.6973\n",
      "====> Epoch: 1800 Average training loss: 0.6591\n"
     ]
    }
   ],
   "source": [
    "epochs=[1800]\n",
    "hl=[2,3,4]\n",
    "lr=[0.0001,0.01,0.001]\n",
    "mm=[0.001,0.01]\n",
    "act=['relu','tanh']\n",
    "opt=['adam','adagrad','sgd']\n",
    "ldm=[2,3,4]\n",
    "\n",
    "min_loss=10000\n",
    "MODEL=None\n",
    "BESTCOMB=None\n",
    "\n",
    "for e in epochs:\n",
    "    for h in hl:\n",
    "        for l in lr:\n",
    "            for m in mm:\n",
    "                for a in act:\n",
    "                    for o in opt:\n",
    "                        for ld in ldm:\n",
    "                            \n",
    "                            D_in = trainloader.dataset.x.shape[1]\n",
    "                            \n",
    "                            if hl==2:\n",
    "                                model = VAE2(D_in,ld,a).to(device)\n",
    "                            if hl==3:\n",
    "                                model = VAE3(D_in,ld,a).to(device)\n",
    "                            if hl==4:\n",
    "                                model = VAE4(D_in,ld,a).to(device)\n",
    "                            \n",
    "                            if opt=='adam':\n",
    "                                optimizer = optim.Adam(model.parameters(), lr=l)\n",
    "                            if opt=='sgd':\n",
    "                                optimizer = optim.SGD(model.parameters(), lr=l,momentum=m)\n",
    "                            if opt=='adagrad':\n",
    "                                optimizer = torch.optim.Adagrad(model.parameters(), lr = l)\n",
    "                            \n",
    "                            start = time.time()\n",
    "                            for epoch in range(1, e+1):\n",
    "                                train(epoch)\n",
    "                            #     test(epoch)\n",
    "                            elapsed_time = time.time()-start\n",
    "                            #print(\"total_time taken is :\",elapsed_time)\n",
    "\n",
    "                            cur_loss=train_losses[len(train_losses)-1]\n",
    "                            if cur_loss < min_loss:\n",
    "                                min_loss=cur_loss\n",
    "                                MODEL=model\n",
    "                                BESTCOMB=[e,h,l,m,a,o,ld]\n",
    "                            \n",
    "                            \n",
    "                            ## junk --ignore\n",
    "                            model = VAE2(D_in,2,'relu').to(device)\n",
    "                            optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "5yodKYq4Z97c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1800, 4, 0.001, 0.001, 'relu', 'adam', 3]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BESTCOMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "wzRN_rxaZ97d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE2(\n",
       "  (linear1): Linear(in_features=8, out_features=10, bias=True)\n",
       "  (lin_bn1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear2): Linear(in_features=10, out_features=15, bias=True)\n",
       "  (lin_bn2): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=15, out_features=2, bias=True)\n",
       "  (bn1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc21): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc22): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc3): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc_bn3): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=2, out_features=15, bias=True)\n",
       "  (fc_bn4): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear4): Linear(in_features=15, out_features=10, bias=True)\n",
       "  (lin_bn4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear5): Linear(in_features=10, out_features=8, bias=True)\n",
       "  (lin_bn5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (Tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "WlECkpI4Z97d"
   },
   "outputs": [],
   "source": [
    "x_hat = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = MODEL(data)\n",
    "        x_hat.append(recon_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhfGnqZ8Z97d",
    "outputId": "7975c36b-9438-4180-f0f7-080e4d18e90e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.4852,  0.3759,  0.4209,  ...,  0.9563,  1.0404,  0.3530],\n",
       "         [ 0.9622,  0.1287,  0.7415,  ...,  0.8578, -0.0386,  0.5419],\n",
       "         [ 0.4835,  0.3758,  0.4205,  ...,  0.9413,  1.0325,  0.3541],\n",
       "         ...,\n",
       "         [ 0.4870,  0.3760,  0.4214,  ...,  0.9723,  1.0488,  0.3518],\n",
       "         [ 0.4850,  0.3759,  0.4209,  ...,  0.9548,  1.0396,  0.3531],\n",
       "         [ 0.3611,  0.3677,  0.3891,  ..., -0.1235,  0.4736,  0.4316]])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "okDzPTsGZ97e"
   },
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame(np.array(x_hat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-riYi8WwZ97e",
    "outputId": "9ec1cbe4-9f76-4243-ff50-5693636ed936",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.485203</td>\n",
       "      <td>0.375921</td>\n",
       "      <td>0.420938</td>\n",
       "      <td>0.344452</td>\n",
       "      <td>0.068266</td>\n",
       "      <td>0.956314</td>\n",
       "      <td>1.040355</td>\n",
       "      <td>0.352975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.962158</td>\n",
       "      <td>0.128706</td>\n",
       "      <td>0.741460</td>\n",
       "      <td>0.161833</td>\n",
       "      <td>0.355660</td>\n",
       "      <td>0.857796</td>\n",
       "      <td>-0.038624</td>\n",
       "      <td>0.541858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.483472</td>\n",
       "      <td>0.375809</td>\n",
       "      <td>0.420497</td>\n",
       "      <td>0.344664</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.941343</td>\n",
       "      <td>1.032497</td>\n",
       "      <td>0.354062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.484332</td>\n",
       "      <td>0.375867</td>\n",
       "      <td>0.420718</td>\n",
       "      <td>0.344558</td>\n",
       "      <td>0.068690</td>\n",
       "      <td>0.948755</td>\n",
       "      <td>1.036387</td>\n",
       "      <td>0.353522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.486555</td>\n",
       "      <td>0.376010</td>\n",
       "      <td>0.421284</td>\n",
       "      <td>0.344286</td>\n",
       "      <td>0.067601</td>\n",
       "      <td>0.968011</td>\n",
       "      <td>1.046494</td>\n",
       "      <td>0.352118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0.483483</td>\n",
       "      <td>0.375809</td>\n",
       "      <td>0.420499</td>\n",
       "      <td>0.344661</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>1.032504</td>\n",
       "      <td>0.354062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0.488356</td>\n",
       "      <td>0.376137</td>\n",
       "      <td>0.421747</td>\n",
       "      <td>0.344074</td>\n",
       "      <td>0.066705</td>\n",
       "      <td>0.983783</td>\n",
       "      <td>1.054774</td>\n",
       "      <td>0.350969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0.487042</td>\n",
       "      <td>0.376049</td>\n",
       "      <td>0.421413</td>\n",
       "      <td>0.344231</td>\n",
       "      <td>0.067354</td>\n",
       "      <td>0.972329</td>\n",
       "      <td>1.048762</td>\n",
       "      <td>0.351806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>0.485027</td>\n",
       "      <td>0.375913</td>\n",
       "      <td>0.420893</td>\n",
       "      <td>0.344475</td>\n",
       "      <td>0.068351</td>\n",
       "      <td>0.954782</td>\n",
       "      <td>1.039551</td>\n",
       "      <td>0.353082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0.361121</td>\n",
       "      <td>0.367662</td>\n",
       "      <td>0.389112</td>\n",
       "      <td>0.359537</td>\n",
       "      <td>0.129475</td>\n",
       "      <td>-0.123533</td>\n",
       "      <td>0.473553</td>\n",
       "      <td>0.431622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.485203  0.375921  0.420938  0.344452  0.068266  0.956314  1.040355   \n",
       "1     0.962158  0.128706  0.741460  0.161833  0.355660  0.857796 -0.038624   \n",
       "2     0.483472  0.375809  0.420497  0.344664  0.069110  0.941343  1.032497   \n",
       "3     0.484332  0.375867  0.420718  0.344558  0.068690  0.948755  1.036387   \n",
       "4     0.486555  0.376010  0.421284  0.344286  0.067601  0.968011  1.046494   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6995  0.483483  0.375809  0.420499  0.344661  0.069110  0.941358  1.032504   \n",
       "6996  0.488356  0.376137  0.421747  0.344074  0.066705  0.983783  1.054774   \n",
       "6997  0.487042  0.376049  0.421413  0.344231  0.067354  0.972329  1.048762   \n",
       "6998  0.485027  0.375913  0.420893  0.344475  0.068351  0.954782  1.039551   \n",
       "6999  0.361121  0.367662  0.389112  0.359537  0.129475 -0.123533  0.473553   \n",
       "\n",
       "             7  \n",
       "0     0.352975  \n",
       "1     0.541858  \n",
       "2     0.354062  \n",
       "3     0.353522  \n",
       "4     0.352118  \n",
       "...        ...  \n",
       "6995  0.354062  \n",
       "6996  0.350969  \n",
       "6997  0.351806  \n",
       "6998  0.353082  \n",
       "6999  0.431622  \n",
       "\n",
       "[7000 rows x 8 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "E7gXHb5KZ97e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "N6WOcdB8Z97e"
   },
   "outputs": [],
   "source": [
    "org =pd.DataFrame(np.array(trainloader.dataset.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "_b8xFx6SZ97e"
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(np.array(testloader.dataset.x)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Equq_25Z97f",
    "outputId": "8f5299ee-b7d6-498c-e8cf-4087daa3dcd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.192962\n",
       "1    0.141110\n",
       "2    0.287587\n",
       "3    0.248447\n",
       "4    0.192987\n",
       "5    0.456147\n",
       "6    0.499946\n",
       "7    0.286641\n",
       "dtype: float32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "6JdbQjxCZ97f"
   },
   "outputs": [],
   "source": [
    "syn_test = pd.concat([d1],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rlx9mkpWZ97f",
    "outputId": "85bb0514-f443-41b2-b2bb-eb4ce01e5ad5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugokdDbAZ97g",
    "outputId": "610b63e0-6c51-4644-c1c7-f12331f3cd57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.246317\n",
       "1    0.123391\n",
       "2    0.149038\n",
       "3    0.074345\n",
       "4    0.114435\n",
       "5    0.468882\n",
       "6    0.463726\n",
       "7    0.188770\n",
       "dtype: float32"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Xwp1ghAhZ97g"
   },
   "outputs": [],
   "source": [
    "# d1.to_csv('vae-wnn-yes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evasion Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(testloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = MODEL(data)\n",
    "        x_hat.append(recon_batch)\n",
    "\n",
    "d1 = pd.DataFrame(np.array(x_hat[0]))\n",
    "eva_test = pd.concat([d1],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "2389 0 611 0\n",
      "0.0\n",
      "1.0\n",
      "0.5\n",
      "Decision Tree\n",
      "1987 402 461 150\n",
      "0.24549918166939444\n",
      "0.8317287568020092\n",
      "0.5386139692357018\n",
      "LGBM Classifier\n",
      "2113 276 509 102\n",
      "0.16693944353518822\n",
      "0.884470489744663\n",
      "0.5257049666399256\n",
      "XGB Classifier\n",
      "2021 368 469 142\n",
      "0.23240589198036007\n",
      "0.845960652992884\n",
      "0.539183272486622\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../../datasets/Churn_Modelling.csv\"\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "df_base = pd.read_csv(DATA_PATH, sep=',')\n",
    "df_base.head()\n",
    "\n",
    "cols = df_base.columns\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=',')\n",
    "# replace nan with -99\n",
    "y = df['Exited']\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname','Geography',\n",
    "   'Gender','Exited'],axis=1,inplace=True)\n",
    "#df = df.fillna(-99)\n",
    "#df = df.fillna(-99)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data=scaler.fit_transform(df)\n",
    "df1=pd.DataFrame(data)\n",
    "# randomly split\n",
    "X_train, X_test,Y_train,Y_test = train_test_split(df1, y,test_size=0.3, stratify=y, random_state=4)\n",
    "\n",
    "\n",
    "Y_train.reset_index(drop = True);Y_test.reset_index(drop = True)\n",
    "\n",
    "## Models\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "print(\"LOGISTIC REGRESSION\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "preds = lr.predict(eva_test)\n",
    "\n",
    "#roc_auc_score(Y_test,ypred_lr)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "\n",
    "logi = DecisionTreeClassifier()\n",
    "logi.fit(X_train,Y_train)\n",
    "\n",
    "preds =logi.predict(eva_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "\n",
    "print(\"LGBM Classifier\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# parameters = {'n_estimators': [25,50,100,150,175,200]}\n",
    "parameters = {'criterion' : [\"gini\", \"entropy\"],\n",
    "              'n_estimators': [25,50,100,150,175,200]}\n",
    "# best_model=None\n",
    "# best_score=0.0\n",
    "\n",
    "# for ne in parameters['n_estimators']:\n",
    "#     gb = LGBMClassifier(n_estimators=ne)\n",
    "#     gb.fit(X_train,Y_train)\n",
    "#     y_predg=gb.predict(X_test)\n",
    "\n",
    "#     #accuracy=accuracy_score(Y_test,y_predg)\n",
    "#     auc=roc_auc_score(Y_test,y_predg)\n",
    "#     # print('Combination',c,ne)\n",
    "#     #print('AUC',auc)\n",
    "\n",
    "#     if auc > best_score:\n",
    "#         best_model=gb\n",
    "#         best_score=auc\n",
    "        \n",
    "gb = LGBMClassifier(n_estimators=150)\n",
    "gb.fit(X_train,Y_train)\n",
    "preds=gb.predict(eva_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "\n",
    "\n",
    "print(\"XGB Classifier\")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_model = xgb.fit(X_train,Y_train)\n",
    "preds = xgb_model.predict(eva_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poison Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = MODEL(data)\n",
    "        x_hat.append(recon_batch)\n",
    "\n",
    "d1 = pd.DataFrame(np.array(x_hat[0]))\n",
    "eva_train = pd.concat([d1],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "2416 0 584 0\n",
      "0.0\n",
      "1.0\n",
      "0.5\n",
      "Decision Tree\n",
      "1183 1233 289 295\n",
      "0.5051369863013698\n",
      "0.4896523178807947\n",
      "0.49739465209108225\n",
      "LGBM Classifier\n",
      "1962 454 511 73\n",
      "0.125\n",
      "0.8120860927152318\n",
      "0.4685430463576159\n",
      "XGB Classifier\n",
      "1292 1124 329 255\n",
      "0.4366438356164384\n",
      "0.5347682119205298\n",
      "0.4857060237684841\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../../datasets/Churn_Modelling.csv\"\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "df_base = pd.read_csv(DATA_PATH, sep=',')\n",
    "df_base.head()\n",
    "\n",
    "cols = df_base.columns\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=',')\n",
    "# replace nan with -99\n",
    "y = df['Exited']\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname','Geography',\n",
    "   'Gender','Exited'],axis=1,inplace=True)\n",
    "#df = df.fillna(-99)\n",
    "#df = df.fillna(-99)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data=scaler.fit_transform(df)\n",
    "df1=pd.DataFrame(data)\n",
    "# randomly split\n",
    "X_train, X_test,Y_train,Y_test = train_test_split(df1, y,test_size=0.3, random_state=4)\n",
    "\n",
    "\n",
    "Y_train.reset_index(drop = True);Y_test.reset_index(drop = True)\n",
    "\n",
    "## Models\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "print(\"LOGISTIC REGRESSION\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(eva_train,Y_train)\n",
    "\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "#roc_auc_score(Y_test,ypred_lr)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "\n",
    "logi = DecisionTreeClassifier()\n",
    "logi.fit(eva_train,Y_train)\n",
    "\n",
    "preds =logi.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "\n",
    "print(\"LGBM Classifier\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# parameters = {'n_estimators': [25,50,100,150,175,200]}\n",
    "# parameters = {'criterion' : [\"gini\", \"entropy\"],\n",
    "#               'n_estimators': [25,50,100,150,175,200]}\n",
    "# best_model=None\n",
    "# best_score=0.0\n",
    "\n",
    "# for ne in parameters['n_estimators']:\n",
    "#     gb = LGBMClassifier(n_estimators=ne)\n",
    "#     gb.fit(X_train,Y_train)\n",
    "#     y_predg=gb.predict(X_test)\n",
    "\n",
    "#     #accuracy=accuracy_score(Y_test,y_predg)\n",
    "#     auc=roc_auc_score(Y_test,y_predg)\n",
    "#     # print('Combination',c,ne)\n",
    "#     #print('AUC',auc)\n",
    "\n",
    "#     if auc > best_score:\n",
    "#         best_model=gb\n",
    "#         best_score=auc\n",
    "        \n",
    "gb = LGBMClassifier(n_estimators=150)\n",
    "gb.fit(eva_train,Y_train)\n",
    "preds=gb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n",
    "\n",
    "\n",
    "print(\"XGB Classifier\")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_model = xgb.fit(eva_train,Y_train)\n",
    "preds = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, preds).ravel()\n",
    "\n",
    "p1 =(tp+fn)\n",
    "sen = (tp/p1)\n",
    "\n",
    "p2 = (tn + fp)\n",
    "spec = tn/p2\n",
    "\n",
    "p3 = sen + spec\n",
    "auc_score = 0.5*p3\n",
    "\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(sen)\n",
    "print(spec)\n",
    "print(auc_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
